{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_G863wdo_kZn",
        "qUiYcUBqwb8G"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "tzaJL6aR_Vqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WMga9Buc9Yn",
        "outputId": "0be20d6e-0f7c-458e-bdda-479816c8d2b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdO1xax-c9P5",
        "outputId": "4832eb1f-c617-4647-b9f7-eaa572fb35b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqZjXUnPc9Is",
        "outputId": "9b786be5-0d99-4b46-c750-6c8544a998fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9-1Wo3PC-42n"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd , numpy as np , matplotlib.pyplot as plt , seaborn as sns\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense , Dropout\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.decomposition import PCA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "_G863wdo_kZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('train.csv')\n",
        "test_df=pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "1ntkrKlx_hb7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Ylecmqqv_qUF",
        "outputId": "1644cf77-435f-4bbd-d530-ab3838625ffc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n",
              "0   0    15674932  Okwudilichukwu          668    France   Male  33.0       3   \n",
              "1   1    15749177   Okwudiliolisa          627    France   Male  33.0       1   \n",
              "2   2    15694510           Hsueh          678    France   Male  40.0      10   \n",
              "3   3    15741417             Kao          581    France   Male  34.0       2   \n",
              "4   4    15766172       Chiemenam          716     Spain   Male  33.0       5   \n",
              "\n",
              "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
              "0       0.00              2        1.0             0.0        181449.97   \n",
              "1       0.00              2        1.0             1.0         49503.50   \n",
              "2       0.00              2        1.0             0.0        184866.69   \n",
              "3  148882.54              1        1.0             1.0         84560.88   \n",
              "4       0.00              2        1.0             1.0         15068.83   \n",
              "\n",
              "   Exited  \n",
              "0       0  \n",
              "1       0  \n",
              "2       0  \n",
              "3       0  \n",
              "4       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e55608e7-386f-4ac4-b417-a32ed45f0cc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>15674932</td>\n",
              "      <td>Okwudilichukwu</td>\n",
              "      <td>668</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15749177</td>\n",
              "      <td>Okwudiliolisa</td>\n",
              "      <td>627</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>15694510</td>\n",
              "      <td>Hsueh</td>\n",
              "      <td>678</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15741417</td>\n",
              "      <td>Kao</td>\n",
              "      <td>581</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>15766172</td>\n",
              "      <td>Chiemenam</td>\n",
              "      <td>716</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e55608e7-386f-4ac4-b417-a32ed45f0cc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e55608e7-386f-4ac4-b417-a32ed45f0cc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e55608e7-386f-4ac4-b417-a32ed45f0cc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb408856-b4e2-4547-bea8-1d193ea761f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb408856-b4e2-4547-bea8-1d193ea761f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb408856-b4e2-4547-bea8-1d193ea761f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns to delete :\n",
        "\n",
        "\n",
        "*   Surname\n",
        "*   CustomerId\n",
        "\n"
      ],
      "metadata": {
        "id": "3OTofv56Y-Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.drop(['Surname','CustomerId'],axis=1,inplace=True)\n",
        "test_df.drop(['Surname','CustomerId'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "MM-4fZwqZTmi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separating numerical columns from categorical ones"
      ],
      "metadata": {
        "id": "GXKZSiB_Y4ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFkwhnp9_44W",
        "outputId": "354eb265-0efd-446d-b36b-32667169e38f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                   int64\n",
              "CreditScore          int64\n",
              "Geography           object\n",
              "Gender              object\n",
              "Age                float64\n",
              "Tenure               int64\n",
              "Balance            float64\n",
              "NumOfProducts        int64\n",
              "HasCrCard          float64\n",
              "IsActiveMember     float64\n",
              "EstimatedSalary    float64\n",
              "Exited               int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_train_df=train_df[['Geography','Gender']]\n",
        "num_train_df=train_df.drop(['Geography','Gender'],axis=1)"
      ],
      "metadata": {
        "id": "efq728S4Zx_p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2nYRQ07Rn9nx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers detection and handling"
      ],
      "metadata": {
        "id": "V6I7pr2haRAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TYzWT1KaoWh",
        "outputId": "9d14cbfb-0e31-4c0d-a47f-253727ef5420"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84581"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_df0=num_train_df.drop('Exited',axis=1)"
      ],
      "metadata": {
        "id": "femTLHi7gvwl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using IsolationForest"
      ],
      "metadata": {
        "id": "jxX4QUg5iQo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "i = 1\n",
        "for c in train_df.columns:\n",
        "    if train_df[c].dtype != 'object':\n",
        "        plt.subplot(5, 2, i)\n",
        "        plt.hist(train_df[c],bins=50)\n",
        "        plt.xlabel(c)\n",
        "        plt.ylabel('Frequency')\n",
        "        i += 1\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "UD3x0ggal4Pm",
        "outputId": "dcb8fdca-aa52-44d9-fbd0-20d828fdf8d7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=IsolationForest(n_estimators=150, max_samples='auto',\n",
        "                      contamination=float(0.1),\n",
        "                      max_features=1.0)\n",
        "model.fit(num_train_df0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "gknZ0pLfdQD8",
        "outputId": "b4a8096d-98b8-4db0-fd1c-d26a163d25eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsolationForest(contamination=0.1, n_estimators=150)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.1, n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(contamination=0.1, n_estimators=150)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores=model.decision_function(num_train_df0)\n",
        "anomaly=model.predict(num_train_df0)\n",
        "\n",
        "num_train_df0['scores']=scores\n",
        "num_train_df0['anomaly']=anomaly\n",
        "\n",
        "num_train_df0.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "Ahkc93Dsg_Nr",
        "outputId": "93285040-e7b1-4d88-ce6f-d62d7237d1a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  CreditScore   Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0   0          668  33.0       3       0.00              2        1.0   \n",
              "1   1          627  33.0       1       0.00              2        1.0   \n",
              "2   2          678  40.0      10       0.00              2        1.0   \n",
              "3   3          581  34.0       2  148882.54              1        1.0   \n",
              "4   4          716  33.0       5       0.00              2        1.0   \n",
              "5   5          588  36.0       4  131778.58              1        1.0   \n",
              "6   6          593  30.0       8  144772.69              1        1.0   \n",
              "7   7          678  37.0       1  138476.41              1        1.0   \n",
              "8   8          676  43.0       4       0.00              2        1.0   \n",
              "9   9          583  40.0       4   81274.33              1        1.0   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary    scores  anomaly  \n",
              "0             0.0        181449.97  0.072747        1  \n",
              "1             1.0         49503.50  0.064841        1  \n",
              "2             0.0        184866.69  0.039993        1  \n",
              "3             1.0         84560.88  0.036833        1  \n",
              "4             1.0         15068.83  0.048939        1  \n",
              "5             0.0        136024.31  0.055549        1  \n",
              "6             0.0         29792.11  0.014748        1  \n",
              "7             0.0        106851.60  0.053960        1  \n",
              "8             0.0        142917.13  0.090302        1  \n",
              "9             1.0        170843.07  0.053088        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2054e6d-f779-4d06-96eb-c2374a007e26\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>scores</th>\n",
              "      <th>anomaly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>668</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>0.072747</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>627</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>0.064841</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>678</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>0.039993</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>581</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>0.036833</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>716</td>\n",
              "      <td>33.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>0.048939</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>588</td>\n",
              "      <td>36.0</td>\n",
              "      <td>4</td>\n",
              "      <td>131778.58</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>136024.31</td>\n",
              "      <td>0.055549</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>593</td>\n",
              "      <td>30.0</td>\n",
              "      <td>8</td>\n",
              "      <td>144772.69</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29792.11</td>\n",
              "      <td>0.014748</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>678</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1</td>\n",
              "      <td>138476.41</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>106851.60</td>\n",
              "      <td>0.053960</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>676</td>\n",
              "      <td>43.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>142917.13</td>\n",
              "      <td>0.090302</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>583</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4</td>\n",
              "      <td>81274.33</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>170843.07</td>\n",
              "      <td>0.053088</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2054e6d-f779-4d06-96eb-c2374a007e26')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2054e6d-f779-4d06-96eb-c2374a007e26 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2054e6d-f779-4d06-96eb-c2374a007e26');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-503a0059-ef5a-493e-b3ac-cc77183083fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-503a0059-ef5a-493e-b3ac-cc77183083fb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-503a0059-ef5a-493e-b3ac-cc77183083fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "num_train_df0"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly = num_train_df0.loc[num_train_df0['anomaly']==-1]\n",
        "anomaly_index = list(anomaly.index)\n",
        "print('Total number of outliers is:', len(anomaly))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paqcquBHhSD-",
        "outputId": "42d67171-b0ed-44fc-f141-c44dcbff4dbf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of outliers is: 14035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_df0[num_train_df0['anomaly']==-1].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "VkoD1X80hUHv",
        "outputId": "ca9d4a05-ccc2-4236-eacb-144e0f3cd97a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id  CreditScore   Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "12  12          759  71.0       9       0.00              1        1.0   \n",
              "19  19          559  61.0       1  153711.26              1        0.0   \n",
              "20  20          773  35.0       9       0.00              2        0.0   \n",
              "26  26          616  31.0       3  136789.14              2        0.0   \n",
              "32  32          797  55.0       0   99208.46              2        0.0   \n",
              "35  35          413  28.0       3  130969.77              2        1.0   \n",
              "37  37          752  37.0       6       0.00              2        0.0   \n",
              "38  38          551  31.0       9   82293.82              2        0.0   \n",
              "41  41          683  30.0       4  114779.35              1        0.0   \n",
              "42  42          684  31.0       3  142293.54              3        1.0   \n",
              "\n",
              "    IsActiveMember  EstimatedSalary    scores  anomaly  \n",
              "12             1.0         93081.87 -0.035815       -1  \n",
              "19             1.0        180890.40 -0.065522       -1  \n",
              "20             1.0         87549.36 -0.000056       -1  \n",
              "26             1.0         59346.40 -0.015024       -1  \n",
              "32             1.0         62402.38 -0.064849       -1  \n",
              "35             1.0        158891.79 -0.001899       -1  \n",
              "37             0.0          1187.88 -0.029243       -1  \n",
              "38             1.0         91565.25 -0.023428       -1  \n",
              "41             0.0        183171.47 -0.010000       -1  \n",
              "42             0.0        146650.60 -0.025750       -1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a918e543-19e9-4af3-8c03-07b4e39b88aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>scores</th>\n",
              "      <th>anomaly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>759</td>\n",
              "      <td>71.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>93081.87</td>\n",
              "      <td>-0.035815</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>559</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1</td>\n",
              "      <td>153711.26</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>180890.40</td>\n",
              "      <td>-0.065522</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>773</td>\n",
              "      <td>35.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>87549.36</td>\n",
              "      <td>-0.000056</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>616</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3</td>\n",
              "      <td>136789.14</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>59346.40</td>\n",
              "      <td>-0.015024</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>797</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>99208.46</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>62402.38</td>\n",
              "      <td>-0.064849</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>413</td>\n",
              "      <td>28.0</td>\n",
              "      <td>3</td>\n",
              "      <td>130969.77</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>158891.79</td>\n",
              "      <td>-0.001899</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>752</td>\n",
              "      <td>37.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1187.88</td>\n",
              "      <td>-0.029243</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>551</td>\n",
              "      <td>31.0</td>\n",
              "      <td>9</td>\n",
              "      <td>82293.82</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>91565.25</td>\n",
              "      <td>-0.023428</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>683</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4</td>\n",
              "      <td>114779.35</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>183171.47</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>684</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3</td>\n",
              "      <td>142293.54</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>146650.60</td>\n",
              "      <td>-0.025750</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a918e543-19e9-4af3-8c03-07b4e39b88aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a918e543-19e9-4af3-8c03-07b4e39b88aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a918e543-19e9-4af3-8c03-07b4e39b88aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c91dbad-0cfb-46f7-88b9-1d8c683f5fa7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c91dbad-0cfb-46f7-88b9-1d8c683f5fa7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c91dbad-0cfb-46f7-88b9-1d8c683f5fa7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"num_train_df0[num_train_df0['anomaly']==-1]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 12,\n        \"max\": 42,\n        \"samples\": [\n          41,\n          19,\n          35\n        ],\n        \"num_unique_values\": 10,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CreditScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122,\n        \"min\": 413,\n        \"max\": 797,\n        \"samples\": [\n          683,\n          559,\n          413\n        ],\n        \"num_unique_values\": 10,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.412837362262522,\n        \"min\": 28.0,\n        \"max\": 71.0,\n        \"samples\": [\n          61.0,\n          28.0,\n          71.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 9,\n        \"samples\": [\n          9,\n          1,\n          4\n        ],\n        \"num_unique_values\": 6,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62857.90350635369,\n        \"min\": 0.0,\n        \"max\": 153711.26,\n        \"samples\": [\n          153711.26,\n          82293.82,\n          0.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumOfProducts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HasCrCard\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48304589153964794,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsActiveMember\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48304589153964794,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EstimatedSalary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59432.81341724059,\n        \"min\": 1187.88,\n        \"max\": 183171.47,\n        \"samples\": [\n          183171.47,\n          180890.4\n        ],\n        \"num_unique_values\": 10,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scores\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02309813334708616,\n        \"min\": -0.06552163147967816,\n        \"max\": -5.5838422724496795e-05,\n        \"samples\": [\n          -0.009999970220146426,\n          -0.06552163147967816\n        ],\n        \"num_unique_values\": 10,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anomaly\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": -1,\n        \"samples\": [\n          -1\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_df0=num_train_df0.drop(anomaly_index,axis=0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "fpSUz4g6hT8y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_df0.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAHHlbwh09e",
        "outputId": "c22e9a73-431f-4974-b5eb-89fe10db821a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "126313"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_train_df0=cat_train_df.drop(anomaly_index,axis=0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "4A8ulSKuh4MO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target=train_df['Exited'].drop(anomaly_index,axis=0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "461fVePaiZ6p"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df0=pd.concat([num_train_df0,cat_train_df0,target],axis=1)\n",
        "train_df0.drop(['scores','anomaly'], axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "HXBNsT1Misnh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "i = 1\n",
        "for c in train_df0.columns:\n",
        "    if train_df0[c].dtype != 'object':\n",
        "        plt.subplot(5, 2, i)\n",
        "        plt.hist(train_df0[c],bins=50)\n",
        "        plt.xlabel(c)\n",
        "        plt.ylabel('Frequency')\n",
        "        i += 1\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "NCVC7fyGjFk9",
        "outputId": "6cff4330-61d0-4711-d210-91b13dfe02cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df0.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "eZ5rj-eojbsX",
        "outputId": "9c2bc33d-28aa-4f81-aea8-c4c9cfec9d17"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  CreditScore   Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0   0          668  33.0       3       0.00              2        1.0   \n",
              "1   1          627  33.0       1       0.00              2        1.0   \n",
              "2   2          678  40.0      10       0.00              2        1.0   \n",
              "3   3          581  34.0       2  148882.54              1        1.0   \n",
              "4   4          716  33.0       5       0.00              2        1.0   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary Geography Gender  Exited  \n",
              "0             0.0        181449.97    France   Male       0  \n",
              "1             1.0         49503.50    France   Male       0  \n",
              "2             0.0        184866.69    France   Male       0  \n",
              "3             1.0         84560.88    France   Male       0  \n",
              "4             1.0         15068.83     Spain   Male       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01a129fe-9bf4-4bd5-b409-2a19fb9cf758\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>668</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>627</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>678</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>581</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>716</td>\n",
              "      <td>33.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01a129fe-9bf4-4bd5-b409-2a19fb9cf758')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01a129fe-9bf4-4bd5-b409-2a19fb9cf758 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01a129fe-9bf4-4bd5-b409-2a19fb9cf758');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2f10ae41-d53d-4bdc-8294-a28c67a93534\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f10ae41-d53d-4bdc-8294-a28c67a93534')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2f10ae41-d53d-4bdc-8294-a28c67a93534 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df0"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df0=train_df0.drop('id',axis=1)\n",
        "test_df0=test_df.drop('id',axis=1)"
      ],
      "metadata": {
        "id": "xfG2GhjKmKi2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ouRWF7zdm4zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df0['Geography'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-tdHerDobK2",
        "outputId": "6e7f92d9-22f7-4dc2-f32a-eabe0ff98a91"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "France     86471\n",
              "Spain      32762\n",
              "Germany    29297\n",
              "Name: Geography, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummies = pd.get_dummies(train_df0[['Gender', 'Geography']])\n",
        "train_df0 = pd.concat([train_df0.drop(['Gender', 'Geography'], axis=1), dummies], axis=1)"
      ],
      "metadata": {
        "id": "pvpYgr0ro0Rt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummies = pd.get_dummies(test_df0[['Gender', 'Geography']])\n",
        "test_df0 = pd.concat([test_df0.drop(['Gender', 'Geography'], axis=1), dummies], axis=1)"
      ],
      "metadata": {
        "id": "BkPml54VqMKD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bNrq4W_Trp-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Features Engineering**"
      ],
      "metadata": {
        "id": "DHAnOZTcfYOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df0.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "E5mWs-eJfYkh",
        "outputId": "3425209c-8524-4015-9ae7-79edb6e7d99a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore   Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0          668  33.0       3       0.00              2        1.0   \n",
              "1          627  33.0       1       0.00              2        1.0   \n",
              "2          678  40.0      10       0.00              2        1.0   \n",
              "3          581  34.0       2  148882.54              1        1.0   \n",
              "4          716  33.0       5       0.00              2        1.0   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  Exited  Gender_Female  Gender_Male  \\\n",
              "0             0.0        181449.97       0              0            1   \n",
              "1             1.0         49503.50       0              0            1   \n",
              "2             0.0        184866.69       0              0            1   \n",
              "3             1.0         84560.88       0              0            1   \n",
              "4             1.0         15068.83       0              0            1   \n",
              "\n",
              "   Geography_France  Geography_Germany  Geography_Spain  \n",
              "0                 1                  0                0  \n",
              "1                 1                  0                0  \n",
              "2                 1                  0                0  \n",
              "3                 1                  0                0  \n",
              "4                 0                  0                1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9028ec4-5975-421b-a88a-38852b81a552\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Geography_France</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>668</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>627</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>678</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>581</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>716</td>\n",
              "      <td>33.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9028ec4-5975-421b-a88a-38852b81a552')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9028ec4-5975-421b-a88a-38852b81a552 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9028ec4-5975-421b-a88a-38852b81a552');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-731d6336-95d2-4945-aebe-14c76355de43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-731d6336-95d2-4945-aebe-14c76355de43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-731d6336-95d2-4945-aebe-14c76355de43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df0"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def newfeature(df):\n",
        "  df['has_card_active_member']=df['HasCrCard']*df['IsActiveMember']\n",
        "  df['has_card_active_member_male']=df['HasCrCard']*df['IsActiveMember']*df['Gender_Male']\n",
        "  df['Estimated_salary/Tenure']=df['EstimatedSalary']/(1+df['Tenure'])\n",
        "  df['age_cat']=(df['Age']/20).astype(int)\n",
        "  df['has_balance']=(df['Balance']>0.0).astype(int)\n",
        "  return df"
      ],
      "metadata": {
        "id": "ba8qhkiNfYhI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df1=newfeature(train_df0)"
      ],
      "metadata": {
        "id": "Ott2mZZgk4y5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df1=newfeature(test_df0)"
      ],
      "metadata": {
        "id": "A2BfYNXWk4vh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df0.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "TaGQz2uCk4tF",
        "outputId": "ca69b9f6-7a90-41f6-ba4d-6b521316b915"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore   Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0          668  33.0       3       0.00              2        1.0   \n",
              "1          627  33.0       1       0.00              2        1.0   \n",
              "2          678  40.0      10       0.00              2        1.0   \n",
              "3          581  34.0       2  148882.54              1        1.0   \n",
              "4          716  33.0       5       0.00              2        1.0   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  Exited  Gender_Female  Gender_Male  \\\n",
              "0             0.0        181449.97       0              0            1   \n",
              "1             1.0         49503.50       0              0            1   \n",
              "2             0.0        184866.69       0              0            1   \n",
              "3             1.0         84560.88       0              0            1   \n",
              "4             1.0         15068.83       0              0            1   \n",
              "\n",
              "   Geography_France  Geography_Germany  Geography_Spain  \\\n",
              "0                 1                  0                0   \n",
              "1                 1                  0                0   \n",
              "2                 1                  0                0   \n",
              "3                 1                  0                0   \n",
              "4                 0                  0                1   \n",
              "\n",
              "   has_card_active_member  has_card_active_member_male  \\\n",
              "0                     0.0                          0.0   \n",
              "1                     1.0                          1.0   \n",
              "2                     0.0                          0.0   \n",
              "3                     1.0                          1.0   \n",
              "4                     1.0                          1.0   \n",
              "\n",
              "   Estimated_salary/Tenure  age_cat  has_balance  \n",
              "0             45362.492500        1            0  \n",
              "1             24751.750000        1            0  \n",
              "2             16806.062727        2            0  \n",
              "3             28186.960000        1            1  \n",
              "4              2511.471667        1            0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a83d86b-c1c7-489f-8fc4-38e046b11148\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Geography_France</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>has_card_active_member</th>\n",
              "      <th>has_card_active_member_male</th>\n",
              "      <th>Estimated_salary/Tenure</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>has_balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>668</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45362.492500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>627</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24751.750000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>678</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16806.062727</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>581</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28186.960000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>716</td>\n",
              "      <td>33.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2511.471667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a83d86b-c1c7-489f-8fc4-38e046b11148')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a83d86b-c1c7-489f-8fc4-38e046b11148 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a83d86b-c1c7-489f-8fc4-38e046b11148');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-81ff44da-6a67-43c4-a65d-00a1185e81ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81ff44da-6a67-43c4-a65d-00a1185e81ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-81ff44da-6a67-43c4-a65d-00a1185e81ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df0"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "columns_to_normalize = ['CreditScore', 'Age', 'Tenure','Balance','NumOfProducts','EstimatedSalary','Estimated_salary/Tenure']\n",
        "train_df0_normalized = train_df0.copy()\n",
        "train_df0_normalized[columns_to_normalize] = scaler.fit_transform(train_df0_normalized[columns_to_normalize])\n"
      ],
      "metadata": {
        "id": "sN1p31l8qus-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df0_normalized = test_df0.copy()\n",
        "test_df0_normalized[columns_to_normalize] = scaler.fit_transform(test_df0_normalized[columns_to_normalize])"
      ],
      "metadata": {
        "id": "bjAqeF-Ou3RN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Modelling**"
      ],
      "metadata": {
        "id": "qUiYcUBqwb8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=train_df0_normalized.drop('Exited',axis=1)\n",
        "y=train_df0_normalized['Exited']"
      ],
      "metadata": {
        "id": "Nkkg_-hLzm4d"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=58)"
      ],
      "metadata": {
        "id": "ryND9sRiyGN5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "YwHU8fNf2VQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR=LogisticRegression()\n",
        "LR.fit(x_train,y_train)\n",
        "predicted_probabilities = LR.predict_proba(x_test)[:, 1]\n",
        "auc_roc = roc_auc_score(y_test, predicted_probabilities)\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VjAU-EFwg4u",
        "outputId": "834eb7f8-7371-446d-9e2e-5c57d674bb19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC Score: 0.8492393067783681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyBs1iVn7iBV",
        "outputId": "39e34d81-06a7-41c3-ac61-494a93d7c36e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_loguniform('C', 0.001, 1000)\n",
        "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
        "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
        "\n",
        "    clf = LogisticRegression(C=C, solver=solver, max_iter=max_iter, random_state=0)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict_proba(X_val)[:, 1]\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "    return auc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_auc = study.best_value\n",
        "\n",
        "print(\"Best AUC:\", best_auc)\n",
        "print(\"Best Hyperparameters:\", best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "OtWzyCw-1EIO",
        "outputId": "8e328823-05d4-4d5d-915a-07bd0b2a0890"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:53:57,874] A new study created in memory with name: no-name-9e61552e-8bd3-4ce3-8c46-8d879c75d713\n",
            "<ipython-input-40-4c3594451024>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 0.001, 1000)\n",
            "[W 2024-02-19 19:54:17,255] Trial 0 failed with parameters: {'C': 1.2070339042837128, 'solver': 'saga', 'max_iter': 129} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-40-4c3594451024>\", line 12, in objective\n",
            "    clf.fit(X_train, y_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1863, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 524, in _logistic_regression_path\n",
            "    w0, n_iter_i, warm_start_sag = sag_solver(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py\", line 325, in sag_solver\n",
            "    num_seen, n_iter_ = sag(\n",
            "KeyboardInterrupt\n",
            "[W 2024-02-19 19:54:17,266] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4c3594451024>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-4c3594451024>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1292\u001b[0m             path_func(\n\u001b[1;32m   1293\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             w0, n_iter_i, warm_start_sag = sag_solver(\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0msag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msag64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msag32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     num_seen, n_iter_ = sag(\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "Za5Be6p12aVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DTC=DecisionTreeClassifier()\n",
        "DTC.fit(x_train,y_train)\n",
        "predicted_probabilities = DTC.predict_proba(x_test)[:, 1]\n",
        "auc_roc = roc_auc_score(y_test, predicted_probabilities)\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e_jXSv72gaj",
        "outputId": "c902abe2-fd37-4f05-e4a8-439cd3cd3e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC Score: 0.6904888870152405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 32)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None])\n",
        "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
        "    splitter = trial.suggest_categorical('splitter', ['best', 'random'])\n",
        "\n",
        "\n",
        "    clf = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split,\n",
        "                                  min_samples_leaf=min_samples_leaf, max_features=max_features,\n",
        "                                  criterion=criterion, splitter=splitter, random_state=0)\n",
        "\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict_proba(X_val)[:, 1]\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "    return auc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_auc = study.best_value\n",
        "\n",
        "print(\"Best AUC:\", best_auc)\n",
        "print(\"Best Hyperparameters:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrZEP8la2nLB",
        "outputId": "21d1ee9b-e54d-4b39-b867-40e5ba974f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-18 15:38:02,253] A new study created in memory with name: no-name-9b75961c-91d7-4812-b9da-b053044968eb\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:02,333] Trial 0 finished with value: 0.8466079610582973 and parameters: {'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:02,396] Trial 1 finished with value: 0.8372640099349483 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 15, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "[I 2024-02-18 15:38:02,586] Trial 2 finished with value: 0.8116824379847323 and parameters: {'max_depth': 31, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': None, 'criterion': 'gini', 'splitter': 'random'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "[I 2024-02-18 15:38:03,307] Trial 3 finished with value: 0.8078800068999427 and parameters: {'max_depth': 29, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:03,380] Trial 4 finished with value: 0.8405923727946372 and parameters: {'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 11, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "[I 2024-02-18 15:38:04,012] Trial 5 finished with value: 0.8321457256983812 and parameters: {'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 12, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "[I 2024-02-18 15:38:04,198] Trial 6 finished with value: 0.8209180223133139 and parameters: {'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'best'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "[I 2024-02-18 15:38:04,955] Trial 7 finished with value: 0.8012724876871615 and parameters: {'max_depth': 20, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:04,994] Trial 8 finished with value: 0.5963892843002483 and parameters: {'max_depth': 1, 'min_samples_split': 20, 'min_samples_leaf': 18, 'max_features': 'auto', 'criterion': 'gini', 'splitter': 'best'}. Best is trial 0 with value: 0.8466079610582973.\n",
            "[I 2024-02-18 15:38:05,074] Trial 9 finished with value: 0.8517913216118524 and parameters: {'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 12, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 9 with value: 0.8517913216118524.\n",
            "[I 2024-02-18 15:38:05,200] Trial 10 finished with value: 0.8512384054487512 and parameters: {'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 9 with value: 0.8517913216118524.\n",
            "[I 2024-02-18 15:38:05,336] Trial 11 finished with value: 0.8512384054487512 and parameters: {'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 9 with value: 0.8517913216118524.\n",
            "[I 2024-02-18 15:38:05,455] Trial 12 finished with value: 0.8267159036006142 and parameters: {'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 9 with value: 0.8517913216118524.\n",
            "[I 2024-02-18 15:38:05,603] Trial 13 finished with value: 0.808478841685252 and parameters: {'max_depth': 25, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 9 with value: 0.8517913216118524.\n",
            "[I 2024-02-18 15:38:05,729] Trial 14 finished with value: 0.8546646549717195 and parameters: {'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 16, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 14 with value: 0.8546646549717195.\n",
            "[I 2024-02-18 15:38:05,855] Trial 15 finished with value: 0.8479457767009668 and parameters: {'max_depth': 32, 'min_samples_split': 6, 'min_samples_leaf': 14, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 14 with value: 0.8546646549717195.\n",
            "[I 2024-02-18 15:38:05,979] Trial 16 finished with value: 0.8248326164014901 and parameters: {'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 14 with value: 0.8546646549717195.\n",
            "[I 2024-02-18 15:38:06,115] Trial 17 finished with value: 0.8522234440750478 and parameters: {'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 13, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 14 with value: 0.8546646549717195.\n",
            "[I 2024-02-18 15:38:06,247] Trial 18 finished with value: 0.8267259150643709 and parameters: {'max_depth': 29, 'min_samples_split': 12, 'min_samples_leaf': 17, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 14 with value: 0.8546646549717195.\n",
            "[I 2024-02-18 15:38:06,351] Trial 19 finished with value: 0.8609382916879516 and parameters: {'max_depth': 13, 'min_samples_split': 13, 'min_samples_leaf': 17, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:06,436] Trial 20 finished with value: 0.8524866370572488 and parameters: {'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 17, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:06,526] Trial 21 finished with value: 0.8444103744634981 and parameters: {'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 17, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:06,603] Trial 22 finished with value: 0.7942907769478466 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:06,691] Trial 23 finished with value: 0.8414038889961778 and parameters: {'max_depth': 13, 'min_samples_split': 18, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:06,768] Trial 24 finished with value: 0.8333767896473865 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:06,828] Trial 25 finished with value: 0.7427867277451758 and parameters: {'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 18, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:06,993] Trial 26 finished with value: 0.8561285097877434 and parameters: {'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 14, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:07,209] Trial 27 finished with value: 0.8453518305959677 and parameters: {'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 9, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:07,317] Trial 28 finished with value: 0.8293261124758716 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 14, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:07,517] Trial 29 finished with value: 0.8465855443202202 and parameters: {'max_depth': 15, 'min_samples_split': 18, 'min_samples_leaf': 15, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:07,664] Trial 30 finished with value: 0.845505820391759 and parameters: {'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 11, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:07,752] Trial 31 finished with value: 0.8422322195538445 and parameters: {'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:07,910] Trial 32 finished with value: 0.8500615879870163 and parameters: {'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:07,999] Trial 33 finished with value: 0.8482801711268837 and parameters: {'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 14, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'random'}. Best is trial 19 with value: 0.8609382916879516.\n",
            "[I 2024-02-18 15:38:08,127] Trial 34 finished with value: 0.8680582485924394 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 16, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 34 with value: 0.8680582485924394.\n",
            "[I 2024-02-18 15:38:08,535] Trial 35 finished with value: 0.883767071618659 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 16, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:08,785] Trial 36 finished with value: 0.858914144599771 and parameters: {'max_depth': 4, 'min_samples_split': 15, 'min_samples_leaf': 13, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:08,986] Trial 37 finished with value: 0.8408172756232329 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 12, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:09,230] Trial 38 finished with value: 0.858914144599771 and parameters: {'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 13, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:09,615] Trial 39 finished with value: 0.8836437831643708 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:10,049] Trial 40 finished with value: 0.882694529121888 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:10,493] Trial 41 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:10,938] Trial 42 finished with value: 0.882694529121888 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:11,035] Trial 43 finished with value: 0.7227627547418215 and parameters: {'max_depth': 1, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:11,478] Trial 44 finished with value: 0.8827143357412184 and parameters: {'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:11,781] Trial 45 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:12,230] Trial 46 finished with value: 0.8820070151916408 and parameters: {'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:12,736] Trial 47 finished with value: 0.8785120589793393 and parameters: {'max_depth': 9, 'min_samples_split': 19, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:12,888] Trial 48 finished with value: 0.8014920513087627 and parameters: {'max_depth': 2, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:13,284] Trial 49 finished with value: 0.8836662575846301 and parameters: {'max_depth': 7, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:13,583] Trial 50 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:13,967] Trial 51 finished with value: 0.8836662575846301 and parameters: {'max_depth': 7, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:14,306] Trial 52 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:14,700] Trial 53 finished with value: 0.88368964049926 and parameters: {'max_depth': 7, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:14,832] Trial 54 finished with value: 0.8002773078121979 and parameters: {'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:15,363] Trial 55 finished with value: 0.8687293375212904 and parameters: {'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 3, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:15,763] Trial 56 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:15,954] Trial 57 finished with value: 0.8408172756232329 and parameters: {'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:16,356] Trial 58 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:17,312] Trial 59 finished with value: 0.8082311219484395 and parameters: {'max_depth': 19, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:17,538] Trial 60 finished with value: 0.8636261912524278 and parameters: {'max_depth': 11, 'min_samples_split': 19, 'min_samples_leaf': 8, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:17,942] Trial 61 finished with value: 0.8836505247694213 and parameters: {'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 11, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:18,295] Trial 62 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:18,558] Trial 63 finished with value: 0.858914144599771 and parameters: {'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:19,045] Trial 64 finished with value: 0.8783978086019825 and parameters: {'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:19,438] Trial 65 finished with value: 0.8836505247694213 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 11, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:20,142] Trial 66 finished with value: 0.8229221717099353 and parameters: {'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:20,765] Trial 67 finished with value: 0.8534640832663067 and parameters: {'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:21,522] Trial 68 finished with value: 0.8192056474201989 and parameters: {'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 12, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:21,677] Trial 69 finished with value: 0.8014920513087627 and parameters: {'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 1, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:21,808] Trial 70 finished with value: 0.8002773078121979 and parameters: {'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 6, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:22,208] Trial 71 finished with value: 0.8836505247694213 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 11, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:22,742] Trial 72 finished with value: 0.8712381663561057 and parameters: {'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 11, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:23,139] Trial 73 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:23,498] Trial 74 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:23,994] Trial 75 finished with value: 0.8785120589793393 and parameters: {'max_depth': 9, 'min_samples_split': 19, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:24,247] Trial 76 finished with value: 0.858914144599771 and parameters: {'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:24,612] Trial 77 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 5, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:25,227] Trial 78 finished with value: 0.853131527459949 and parameters: {'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:25,636] Trial 79 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:25,821] Trial 80 finished with value: 0.8523568233060935 and parameters: {'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:26,224] Trial 81 finished with value: 0.8836437831643708 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:26,670] Trial 82 finished with value: 0.8824805642771013 and parameters: {'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:27,139] Trial 83 finished with value: 0.8778810916133798 and parameters: {'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:27,574] Trial 84 finished with value: 0.8836662575846301 and parameters: {'max_depth': 7, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:27,948] Trial 85 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:28,626] Trial 86 finished with value: 0.8687719394180191 and parameters: {'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:29,082] Trial 87 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:29,436] Trial 88 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:29,515] Trial 89 finished with value: 0.7713467227810472 and parameters: {'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:29,823] Trial 90 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:30,206] Trial 91 finished with value: 0.8836437831643708 and parameters: {'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:30,696] Trial 92 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 17, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:31,092] Trial 93 finished with value: 0.8835152600520433 and parameters: {'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:31,348] Trial 94 finished with value: 0.858914144599771 and parameters: {'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:31,783] Trial 95 finished with value: 0.882467751622369 and parameters: {'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:32,123] Trial 96 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:32,257] Trial 97 finished with value: 0.8580417196189098 and parameters: {'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:32,663] Trial 98 finished with value: 0.8836662575846301 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:32,818] Trial 99 finished with value: 0.8014920513087627 and parameters: {'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:33,481] Trial 100 finished with value: 0.8289066800927714 and parameters: {'max_depth': 14, 'min_samples_split': 16, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:33,982] Trial 101 finished with value: 0.8783978086019825 and parameters: {'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:34,394] Trial 102 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:34,737] Trial 103 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 19, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:35,172] Trial 104 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:35,710] Trial 105 finished with value: 0.8694942176784815 and parameters: {'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:36,008] Trial 106 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:36,396] Trial 107 finished with value: 0.8836662575846301 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:36,518] Trial 108 finished with value: 0.8145508719642445 and parameters: {'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:36,614] Trial 109 finished with value: 0.817146465616574 and parameters: {'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'gini', 'splitter': 'random'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:37,010] Trial 110 finished with value: 0.8836649381047111 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:37,422] Trial 111 finished with value: 0.8836662575846301 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:37,903] Trial 112 finished with value: 0.8783525208786428 and parameters: {'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:38,205] Trial 113 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:38,645] Trial 114 finished with value: 0.8836960251958079 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 5, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:39,096] Trial 115 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 5, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:39,667] Trial 116 finished with value: 0.8820070151916408 and parameters: {'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:39,861] Trial 117 finished with value: 0.8531166959288377 and parameters: {'max_depth': 11, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:40,316] Trial 118 finished with value: 0.8822997342408817 and parameters: {'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:40,626] Trial 119 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:40,970] Trial 120 finished with value: 0.8798447661437431 and parameters: {'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:41,363] Trial 121 finished with value: 0.8836662575846301 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:41,746] Trial 122 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:42,176] Trial 123 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:42,349] Trial 124 finished with value: 0.8635279837320096 and parameters: {'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 9, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:42,848] Trial 125 finished with value: 0.8784208165824275 and parameters: {'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:43,249] Trial 126 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:43,601] Trial 127 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:43,744] Trial 128 finished with value: 0.872939581634593 and parameters: {'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:44,535] Trial 129 finished with value: 0.8137755224909752 and parameters: {'max_depth': 26, 'min_samples_split': 14, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:44,707] Trial 130 finished with value: 0.8251358336079005 and parameters: {'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 9, 'max_features': 'auto', 'criterion': 'gini', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:45,141] Trial 131 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:45,458] Trial 132 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:45,855] Trial 133 finished with value: 0.8836645343294354 and parameters: {'max_depth': 7, 'min_samples_split': 17, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:46,340] Trial 134 finished with value: 0.8785120589793393 and parameters: {'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:46,701] Trial 135 finished with value: 0.8800774236207153 and parameters: {'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 15, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:47,103] Trial 136 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:47,359] Trial 137 finished with value: 0.858914144599771 and parameters: {'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:47,713] Trial 138 finished with value: 0.880023382626219 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 11, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:48,156] Trial 139 finished with value: 0.8824805642771013 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:48,552] Trial 140 finished with value: 0.8836437831643708 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:48,939] Trial 141 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:49,387] Trial 142 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:49,691] Trial 143 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:50,178] Trial 144 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:50,804] Trial 145 finished with value: 0.8784010063579609 and parameters: {'max_depth': 9, 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:51,186] Trial 146 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 20, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:51,336] Trial 147 finished with value: 0.8358704084117697 and parameters: {'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:51,488] Trial 148 finished with value: 0.8442324177209816 and parameters: {'max_depth': 8, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:51,615] Trial 149 finished with value: 0.8663332196705933 and parameters: {'max_depth': 6, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:52,089] Trial 150 finished with value: 0.8783978086019825 and parameters: {'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:52,494] Trial 151 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:52,891] Trial 152 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:53,289] Trial 153 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:53,742] Trial 154 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:54,090] Trial 155 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:54,414] Trial 156 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:54,826] Trial 157 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:55,211] Trial 158 finished with value: 0.8827860815605292 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:55,665] Trial 159 finished with value: 0.8824805642771013 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:56,079] Trial 160 finished with value: 0.8836437831643708 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:56,450] Trial 161 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:56,850] Trial 162 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:57,289] Trial 163 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:57,687] Trial 164 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:58,486] Trial 165 finished with value: 0.8028430617506218 and parameters: {'max_depth': 30, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:58,978] Trial 166 finished with value: 0.8783978086019825 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:59,303] Trial 167 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:38:59,661] Trial 168 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:38:59,803] Trial 169 finished with value: 0.8523296189468894 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 9, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:00,258] Trial 170 finished with value: 0.8827143357412184 and parameters: {'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:00,664] Trial 171 finished with value: 0.8836437831643708 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:01,057] Trial 172 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:01,567] Trial 173 finished with value: 0.8837091514974064 and parameters: {'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:02,169] Trial 174 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:02,758] Trial 175 finished with value: 0.8824805642771013 and parameters: {'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:03,443] Trial 176 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:03,935] Trial 177 finished with value: 0.8783525208786428 and parameters: {'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:04,334] Trial 178 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:04,471] Trial 179 finished with value: 0.8002773078121979 and parameters: {'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:04,682] Trial 180 finished with value: 0.8354517222919022 and parameters: {'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:05,073] Trial 181 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:05,527] Trial 182 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:05,894] Trial 183 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:06,288] Trial 184 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:06,689] Trial 185 finished with value: 0.8836680132860524 and parameters: {'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:07,122] Trial 186 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:07,241] Trial 187 finished with value: 0.8085979950481 and parameters: {'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:07,654] Trial 188 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:08,098] Trial 189 finished with value: 0.8826834144863955 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:08,454] Trial 190 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:08,854] Trial 191 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:09,254] Trial 192 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:09,661] Trial 193 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:10,005] Trial 194 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:10,468] Trial 195 finished with value: 0.8826834144863955 and parameters: {'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:10,880] Trial 196 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:11,201] Trial 197 finished with value: 0.8726565892433342 and parameters: {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:11,700] Trial 198 finished with value: 0.8789696373105891 and parameters: {'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:12,132] Trial 199 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:12,645] Trial 200 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:13,158] Trial 201 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:13,616] Trial 202 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:14,010] Trial 203 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:14,353] Trial 204 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:14,768] Trial 205 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:15,170] Trial 206 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:15,632] Trial 207 finished with value: 0.8826834144863955 and parameters: {'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:15,975] Trial 208 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:39:16,111] Trial 209 finished with value: 0.8522955684336796 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:16,568] Trial 210 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:16,966] Trial 211 finished with value: 0.88371641945237 and parameters: {'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:17,366] Trial 212 finished with value: 0.8836680132860524 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:17,731] Trial 213 finished with value: 0.8799877458529973 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:18,175] Trial 214 finished with value: 0.8825102417598695 and parameters: {'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 35 with value: 0.883767071618659.\n",
            "[I 2024-02-18 15:39:18,586] Trial 215 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 215 with value: 0.8838815491196084.\n",
            "[I 2024-02-18 15:39:18,976] Trial 216 finished with value: 0.8838353168505344 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 215 with value: 0.8838815491196084.\n",
            "[I 2024-02-18 15:39:19,332] Trial 217 finished with value: 0.8800840714922197 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 215 with value: 0.8838815491196084.\n",
            "[I 2024-02-18 15:39:19,441] Trial 218 finished with value: 0.8509814529576425 and parameters: {'max_depth': 5, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 215 with value: 0.8838815491196084.\n",
            "[I 2024-02-18 15:39:19,838] Trial 219 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:20,289] Trial 220 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:20,701] Trial 221 finished with value: 0.8836645667756629 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 13, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:21,054] Trial 222 finished with value: 0.8800840714922197 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:21,447] Trial 223 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:21,891] Trial 224 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:22,289] Trial 225 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:22,697] Trial 226 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:22,806] Trial 227 finished with value: 0.8297960311889867 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:22,963] Trial 228 finished with value: 0.8539755367557788 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:23,462] Trial 229 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:23,918] Trial 230 finished with value: 0.8800840714922197 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:24,382] Trial 231 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:24,785] Trial 232 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:25,170] Trial 233 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:25,612] Trial 234 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:25,979] Trial 235 finished with value: 0.8800840714922197 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:26,379] Trial 236 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:26,789] Trial 237 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:27,236] Trial 238 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:27,591] Trial 239 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:28,028] Trial 240 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:28,451] Trial 241 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:28,865] Trial 242 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:29,269] Trial 243 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:29,634] Trial 244 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:30,045] Trial 245 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:30,453] Trial 246 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:30,893] Trial 247 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:31,578] Trial 248 finished with value: 0.8459080634845484 and parameters: {'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:31,980] Trial 249 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:32,340] Trial 250 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:32,780] Trial 251 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:32,902] Trial 252 finished with value: 0.8509814529576425 and parameters: {'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:33,297] Trial 253 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:39:33,439] Trial 254 finished with value: 0.8465044431719755 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:33,807] Trial 255 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:34,289] Trial 256 finished with value: 0.8813668006508395 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:35,243] Trial 257 finished with value: 0.8389088498080567 and parameters: {'max_depth': 23, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:35,722] Trial 258 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:36,131] Trial 259 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:36,858] Trial 260 finished with value: 0.8341331833135137 and parameters: {'max_depth': 19, 'min_samples_split': 14, 'min_samples_leaf': 17, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:37,217] Trial 261 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:37,368] Trial 262 finished with value: 0.8515252156794477 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:37,814] Trial 263 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:38,180] Trial 264 finished with value: 0.8800840714922197 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:38,331] Trial 265 finished with value: 0.8465044431719755 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:38,749] Trial 266 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:39,170] Trial 267 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:39,678] Trial 268 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:40,145] Trial 269 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:40,567] Trial 270 finished with value: 0.8838353168505344 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:40,881] Trial 271 finished with value: 0.8726621952304219 and parameters: {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:41,006] Trial 272 finished with value: 0.8647058394730248 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:41,422] Trial 273 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:41,890] Trial 274 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:42,199] Trial 275 finished with value: 0.8726621952304219 and parameters: {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 17, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:42,608] Trial 276 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:43,057] Trial 277 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:43,420] Trial 278 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:43,830] Trial 279 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:44,239] Trial 280 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:44,611] Trial 281 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:44,994] Trial 282 finished with value: 0.8829534968842392 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:45,852] Trial 283 finished with value: 0.8419423990342618 and parameters: {'max_depth': 26, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:39:46,057] Trial 284 finished with value: 0.8561900602813414 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:46,205] Trial 285 finished with value: 0.7227627547418215 and parameters: {'max_depth': 1, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:46,779] Trial 286 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:47,194] Trial 287 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:47,563] Trial 288 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:47,696] Trial 289 finished with value: 0.8515252156794477 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:47,850] Trial 290 finished with value: 0.8516975628297402 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:48,202] Trial 291 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:48,616] Trial 292 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:48,763] Trial 293 finished with value: 0.8779197350703515 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:49,180] Trial 294 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:49,543] Trial 295 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:50,040] Trial 296 finished with value: 0.8796918470734599 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:50,350] Trial 297 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:50,770] Trial 298 finished with value: 0.8831413317004662 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:51,173] Trial 299 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:51,541] Trial 300 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:51,944] Trial 301 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:52,395] Trial 302 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:52,814] Trial 303 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:53,180] Trial 304 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:39:53,327] Trial 305 finished with value: 0.8465044431719755 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:53,646] Trial 306 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:54,133] Trial 307 finished with value: 0.8796918470734599 and parameters: {'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:54,672] Trial 308 finished with value: 0.8745464558163714 and parameters: {'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:55,138] Trial 309 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:55,509] Trial 310 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:55,919] Trial 311 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:56,368] Trial 312 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:56,501] Trial 313 finished with value: 0.8710380019734228 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:56,679] Trial 314 finished with value: 0.8045037822495311 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:57,189] Trial 315 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:57,345] Trial 316 finished with value: 0.7846491929743564 and parameters: {'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:57,824] Trial 317 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:58,232] Trial 318 finished with value: 0.8831702484994557 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:58,902] Trial 319 finished with value: 0.8552165364606767 and parameters: {'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:59,269] Trial 320 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:59,593] Trial 321 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 11, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:39:59,991] Trial 322 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:00,510] Trial 323 finished with value: 0.8796918470734599 and parameters: {'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:00,974] Trial 324 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:01,384] Trial 325 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:01,758] Trial 326 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:02,197] Trial 327 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:02,609] Trial 328 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:02,985] Trial 329 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:03,408] Trial 330 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:03,824] Trial 331 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:40:04,005] Trial 332 finished with value: 0.8516975628297402 and parameters: {'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:04,379] Trial 333 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:04,527] Trial 334 finished with value: 0.8710380019734228 and parameters: {'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:04,993] Trial 335 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:05,510] Trial 336 finished with value: 0.8796918470734599 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:05,832] Trial 337 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:06,249] Trial 338 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:06,370] Trial 339 finished with value: 0.8297110653345314 and parameters: {'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:06,783] Trial 340 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:07,237] Trial 341 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:07,649] Trial 342 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:08,112] Trial 343 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:08,660] Trial 344 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:08,921] Trial 345 finished with value: 0.8410948891509966 and parameters: {'max_depth': 31, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:09,236] Trial 346 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:09,695] Trial 347 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:10,113] Trial 348 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:10,488] Trial 349 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:10,930] Trial 350 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:11,431] Trial 351 finished with value: 0.8796918470734599 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:11,852] Trial 352 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:12,223] Trial 353 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:12,774] Trial 354 finished with value: 0.8745464558163714 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:12,906] Trial 355 finished with value: 0.8710380019734228 and parameters: {'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:40:13,063] Trial 356 finished with value: 0.8516975628297402 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:13,430] Trial 357 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:13,898] Trial 358 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:14,287] Trial 359 finished with value: 0.8829534968842392 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:15,031] Trial 360 finished with value: 0.8422299122665544 and parameters: {'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:15,529] Trial 361 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:15,896] Trial 362 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:16,299] Trial 363 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:16,574] Trial 364 finished with value: 0.858914144599771 and parameters: {'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:16,801] Trial 365 finished with value: 0.8429161319528372 and parameters: {'max_depth': 18, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:17,210] Trial 366 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:17,365] Trial 367 finished with value: 0.8561900602813414 and parameters: {'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 19, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:17,688] Trial 368 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:18,097] Trial 369 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:18,459] Trial 370 finished with value: 0.8800774236207153 and parameters: {'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 15, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:18,965] Trial 371 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:19,487] Trial 372 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:19,687] Trial 373 finished with value: 0.8646948654378516 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:20,166] Trial 374 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:20,623] Trial 375 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:20,948] Trial 376 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:21,451] Trial 377 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:21,798] Trial 378 finished with value: 0.8794177088971766 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:22,210] Trial 379 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:22,667] Trial 380 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:23,089] Trial 381 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:40:23,218] Trial 382 finished with value: 0.8045037822495311 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:23,671] Trial 383 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:24,083] Trial 384 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:24,446] Trial 385 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:24,914] Trial 386 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:25,417] Trial 387 finished with value: 0.8796918470734599 and parameters: {'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:25,837] Trial 388 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:26,213] Trial 389 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:26,364] Trial 390 finished with value: 0.7996961237746575 and parameters: {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:26,515] Trial 391 finished with value: 0.8465044431719755 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:26,680] Trial 392 finished with value: 0.8779197350703515 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:27,053] Trial 393 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:27,458] Trial 394 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:27,917] Trial 395 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:28,235] Trial 396 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:28,626] Trial 397 finished with value: 0.8829534968842392 and parameters: {'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:28,985] Trial 398 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:29,398] Trial 399 finished with value: 0.8836595159795796 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:29,899] Trial 400 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:30,374] Trial 401 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:30,967] Trial 402 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:31,389] Trial 403 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:31,853] Trial 404 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:40:32,040] Trial 405 finished with value: 0.8618306566781893 and parameters: {'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 14, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:32,456] Trial 406 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:32,829] Trial 407 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:33,252] Trial 408 finished with value: 0.8836471936233963 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 12, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:33,754] Trial 409 finished with value: 0.8796918470734599 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:34,220] Trial 410 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:34,532] Trial 411 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:34,659] Trial 412 finished with value: 0.8645575025310941 and parameters: {'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:34,805] Trial 413 finished with value: 0.8465044431719755 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:34,968] Trial 414 finished with value: 0.8014920513087627 and parameters: {'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:35,709] Trial 415 finished with value: 0.839261223049154 and parameters: {'max_depth': 21, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:35,852] Trial 416 finished with value: 0.8404037015867677 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:36,220] Trial 417 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:36,642] Trial 418 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:37,102] Trial 419 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:37,523] Trial 420 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:37,791] Trial 421 finished with value: 0.858914144599771 and parameters: {'max_depth': 4, 'min_samples_split': 15, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:38,157] Trial 422 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:38,623] Trial 423 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:38,945] Trial 424 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:39,380] Trial 425 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:39,794] Trial 426 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:40,340] Trial 427 finished with value: 0.8743676807078941 and parameters: {'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:40,713] Trial 428 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:41,117] Trial 429 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:41,704] Trial 430 finished with value: 0.8829624556481701 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:40:41,847] Trial 431 finished with value: 0.845600556165833 and parameters: {'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:42,315] Trial 432 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:42,734] Trial 433 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:43,419] Trial 434 finished with value: 0.848878046945913 and parameters: {'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:43,768] Trial 435 finished with value: 0.8794177088971766 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:44,232] Trial 436 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:44,660] Trial 437 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:44,818] Trial 438 finished with value: 0.8516975628297402 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:45,221] Trial 439 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:45,368] Trial 440 finished with value: 0.7996961237746575 and parameters: {'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:45,733] Trial 441 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:46,154] Trial 442 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:46,652] Trial 443 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:47,124] Trial 444 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:47,499] Trial 445 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:47,913] Trial 446 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:48,369] Trial 447 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:48,775] Trial 448 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:49,128] Trial 449 finished with value: 0.880075603026838 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 16, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:49,274] Trial 450 finished with value: 0.8706748674001994 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:49,772] Trial 451 finished with value: 0.8796918470734599 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:50,569] Trial 452 finished with value: 0.8247241594783132 and parameters: {'max_depth': 24, 'min_samples_split': 13, 'min_samples_leaf': 13, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:51,239] Trial 453 finished with value: 0.8552165364606767 and parameters: {'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:51,680] Trial 454 finished with value: 0.8831413317004662 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:40:51,811] Trial 455 finished with value: 0.8045037822495311 and parameters: {'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 20, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:52,136] Trial 456 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:52,633] Trial 457 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:53,199] Trial 458 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:53,673] Trial 459 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:54,043] Trial 460 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:54,465] Trial 461 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:54,627] Trial 462 finished with value: 0.8516975628297402 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:55,000] Trial 463 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:55,155] Trial 464 finished with value: 0.7996961237746575 and parameters: {'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:55,379] Trial 465 finished with value: 0.8408172756232329 and parameters: {'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:55,793] Trial 466 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:56,296] Trial 467 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:56,764] Trial 468 finished with value: 0.8829292271060573 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:56,892] Trial 469 finished with value: 0.8645575025310941 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:57,303] Trial 470 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:57,669] Trial 471 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:58,134] Trial 472 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:58,568] Trial 473 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:58,945] Trial 474 finished with value: 0.8829286683099166 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:59,403] Trial 475 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:40:59,824] Trial 476 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:00,194] Trial 477 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "[I 2024-02-18 15:41:00,418] Trial 478 finished with value: 0.8482306077117847 and parameters: {'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 19, 'max_features': 'auto', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:00,872] Trial 479 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:01,509] Trial 480 finished with value: 0.8597684429548597 and parameters: {'max_depth': 13, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:01,834] Trial 481 finished with value: 0.8727157531366417 and parameters: {'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:02,591] Trial 482 finished with value: 0.8424785404977373 and parameters: {'max_depth': 32, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:02,946] Trial 483 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:03,461] Trial 484 finished with value: 0.8796592854815795 and parameters: {'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:03,979] Trial 485 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:04,572] Trial 486 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:04,729] Trial 487 finished with value: 0.8385234751484394 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:04,852] Trial 488 finished with value: 0.8509814529576425 and parameters: {'max_depth': 5, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'random'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:05,263] Trial 489 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:05,637] Trial 490 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:06,093] Trial 491 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:06,232] Trial 492 finished with value: 0.8515252156794477 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 19, 'max_features': 'log2', 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:06,605] Trial 493 finished with value: 0.8800840426511285 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:07,080] Trial 494 finished with value: 0.8813668006508395 and parameters: {'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'gini', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:07,502] Trial 495 finished with value: 0.8838815491196084 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:07,626] Trial 496 finished with value: 0.7227627547418215 and parameters: {'max_depth': 1, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:08,091] Trial 497 finished with value: 0.8830606487480428 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:08,467] Trial 498 finished with value: 0.8800715472483984 and parameters: {'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n",
            "[I 2024-02-18 15:41:08,897] Trial 499 finished with value: 0.8838836473089877 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}. Best is trial 219 with value: 0.8838836473089877.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best AUC: 0.8838836473089877\n",
            "Best Hyperparameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RFC=RandomForestClassifier()\n",
        "RFC.fit(x_train,y_train)\n",
        "predicted_probabilities = RFC.predict_proba(x_test)[:, 1]\n",
        "auc_roc = roc_auc_score(y_test, predicted_probabilities)\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS6-DIiq28jU",
        "outputId": "eef0051f-0d1c-4b14-a79e-7088fcc3fa75"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC Score: 0.8662813188077115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
        "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None])\n",
        "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
        "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
        "                                 min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
        "                                 max_features=max_features, criterion=criterion, bootstrap=bootstrap,\n",
        "                                 random_state=0)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict_proba(X_val)[:, 1]\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "    return auc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_auc = study.best_value\n",
        "\n",
        "print(\"Best AUC:\", best_auc)\n",
        "print(\"Best Hyperparameters:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9-FjvUZ44sZ",
        "outputId": "22b40d78-3381-4023-d24a-e0f76f6a2b98"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 16:36:03,126] A new study created in memory with name: no-name-46ff3a75-fe1e-4803-920e-5620418419b1\n",
            "[I 2024-02-19 16:38:59,639] Trial 0 finished with value: 0.886609722910827 and parameters: {'n_estimators': 762, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'gini', 'bootstrap': False}. Best is trial 0 with value: 0.886609722910827.\n",
            "[I 2024-02-19 16:43:57,275] Trial 1 finished with value: 0.885572708344533 and parameters: {'n_estimators': 948, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy', 'bootstrap': False}. Best is trial 0 with value: 0.886609722910827.\n",
            "[I 2024-02-19 16:48:02,738] Trial 2 finished with value: 0.8850816904652362 and parameters: {'n_estimators': 763, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'criterion': 'entropy', 'bootstrap': False}. Best is trial 0 with value: 0.886609722910827.\n",
            "[I 2024-02-19 16:53:26,445] Trial 3 finished with value: 0.880164487738758 and parameters: {'n_estimators': 926, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 18, 'max_features': None, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 0 with value: 0.886609722910827.\n",
            "[I 2024-02-19 16:56:02,217] Trial 4 finished with value: 0.8869469009400888 and parameters: {'n_estimators': 763, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 13, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False}. Best is trial 4 with value: 0.8869469009400888.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "[I 2024-02-19 16:58:14,054] Trial 5 finished with value: 0.8828032769210296 and parameters: {'n_estimators': 510, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'auto', 'criterion': 'entropy', 'bootstrap': True}. Best is trial 4 with value: 0.8869469009400888.\n",
            "[I 2024-02-19 17:00:33,532] Trial 6 finished with value: 0.8845751198512073 and parameters: {'n_estimators': 494, 'max_depth': 21, 'min_samples_split': 20, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'criterion': 'gini', 'bootstrap': False}. Best is trial 4 with value: 0.8869469009400888.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "[I 2024-02-19 17:01:18,192] Trial 7 finished with value: 0.8868672452240156 and parameters: {'n_estimators': 217, 'max_depth': 10, 'min_samples_split': 19, 'min_samples_leaf': 14, 'max_features': 'auto', 'criterion': 'gini', 'bootstrap': False}. Best is trial 4 with value: 0.8869469009400888.\n",
            "[I 2024-02-19 17:04:01,114] Trial 8 finished with value: 0.8751445010866424 and parameters: {'n_estimators': 333, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 4 with value: 0.8869469009400888.\n",
            "[I 2024-02-19 17:18:20,825] Trial 9 finished with value: 0.8139354095730145 and parameters: {'n_estimators': 611, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 4 with value: 0.8869469009400888.\n",
            "[I 2024-02-19 17:20:32,321] Trial 10 finished with value: 0.8864675275225876 and parameters: {'n_estimators': 735, 'max_depth': 13, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': True}. Best is trial 4 with value: 0.8869469009400888.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "[I 2024-02-19 17:20:56,922] Trial 11 finished with value: 0.886593516362211 and parameters: {'n_estimators': 131, 'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 13, 'max_features': 'auto', 'criterion': 'gini', 'bootstrap': False}. Best is trial 4 with value: 0.8869469009400888.\n",
            "[I 2024-02-19 17:21:08,108] Trial 12 finished with value: 0.8674067416130234 and parameters: {'n_estimators': 148, 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 10, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False}. Best is trial 4 with value: 0.8869469009400888.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "[I 2024-02-19 17:22:04,769] Trial 13 finished with value: 0.886519650003712 and parameters: {'n_estimators': 301, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 15, 'max_features': 'auto', 'criterion': 'gini', 'bootstrap': False}. Best is trial 4 with value: 0.8869469009400888.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "[I 2024-02-19 17:23:12,669] Trial 14 finished with value: 0.8855802071149429 and parameters: {'n_estimators': 363, 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': 'auto', 'criterion': 'gini', 'bootstrap': True}. Best is trial 4 with value: 0.8869469009400888.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best AUC: 0.8869469009400888\n",
            "Best Hyperparameters: {'n_estimators': 763, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 13, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CBC=CatBoostClassifier()\n",
        "CBC.fit(x_train,y_train)\n",
        "predicted_probabilities = CBC.predict_proba(x_test)[:, 1]\n",
        "auc_roc = roc_auc_score(y_test, predicted_probabilities)\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVPBbDU3_XiZ",
        "outputId": "ac9069ce-7906-4b4d-db46-2c6ad374d4a5"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.079235\n",
            "0:\tlearn: 0.6185099\ttotal: 52.5ms\tremaining: 52.4s\n",
            "1:\tlearn: 0.5573846\ttotal: 82.1ms\tremaining: 41s\n",
            "2:\tlearn: 0.5126890\ttotal: 111ms\tremaining: 36.8s\n",
            "3:\tlearn: 0.4750399\ttotal: 141ms\tremaining: 35.1s\n",
            "4:\tlearn: 0.4456760\ttotal: 173ms\tremaining: 34.4s\n",
            "5:\tlearn: 0.4227944\ttotal: 204ms\tremaining: 33.7s\n",
            "6:\tlearn: 0.4037147\ttotal: 234ms\tremaining: 33.2s\n",
            "7:\tlearn: 0.3882484\ttotal: 262ms\tremaining: 32.5s\n",
            "8:\tlearn: 0.3761046\ttotal: 289ms\tremaining: 31.8s\n",
            "9:\tlearn: 0.3661706\ttotal: 316ms\tremaining: 31.2s\n",
            "10:\tlearn: 0.3572549\ttotal: 342ms\tremaining: 30.7s\n",
            "11:\tlearn: 0.3498980\ttotal: 368ms\tremaining: 30.3s\n",
            "12:\tlearn: 0.3438316\ttotal: 400ms\tremaining: 30.4s\n",
            "13:\tlearn: 0.3389120\ttotal: 428ms\tremaining: 30.1s\n",
            "14:\tlearn: 0.3349363\ttotal: 454ms\tremaining: 29.8s\n",
            "15:\tlearn: 0.3316547\ttotal: 483ms\tremaining: 29.7s\n",
            "16:\tlearn: 0.3286366\ttotal: 541ms\tremaining: 31.3s\n",
            "17:\tlearn: 0.3263304\ttotal: 568ms\tremaining: 31s\n",
            "18:\tlearn: 0.3242165\ttotal: 595ms\tremaining: 30.7s\n",
            "19:\tlearn: 0.3223943\ttotal: 626ms\tremaining: 30.7s\n",
            "20:\tlearn: 0.3208029\ttotal: 656ms\tremaining: 30.6s\n",
            "21:\tlearn: 0.3198763\ttotal: 683ms\tremaining: 30.4s\n",
            "22:\tlearn: 0.3184563\ttotal: 711ms\tremaining: 30.2s\n",
            "23:\tlearn: 0.3174726\ttotal: 742ms\tremaining: 30.2s\n",
            "24:\tlearn: 0.3164376\ttotal: 768ms\tremaining: 30s\n",
            "25:\tlearn: 0.3157336\ttotal: 796ms\tremaining: 29.8s\n",
            "26:\tlearn: 0.3149777\ttotal: 823ms\tremaining: 29.6s\n",
            "27:\tlearn: 0.3144357\ttotal: 854ms\tremaining: 29.7s\n",
            "28:\tlearn: 0.3138503\ttotal: 880ms\tremaining: 29.5s\n",
            "29:\tlearn: 0.3132552\ttotal: 907ms\tremaining: 29.3s\n",
            "30:\tlearn: 0.3128811\ttotal: 932ms\tremaining: 29.1s\n",
            "31:\tlearn: 0.3124730\ttotal: 963ms\tremaining: 29.1s\n",
            "32:\tlearn: 0.3120526\ttotal: 990ms\tremaining: 29s\n",
            "33:\tlearn: 0.3118518\ttotal: 1.01s\tremaining: 28.9s\n",
            "34:\tlearn: 0.3115922\ttotal: 1.04s\tremaining: 28.8s\n",
            "35:\tlearn: 0.3112436\ttotal: 1.08s\tremaining: 28.8s\n",
            "36:\tlearn: 0.3109455\ttotal: 1.11s\tremaining: 28.8s\n",
            "37:\tlearn: 0.3106252\ttotal: 1.14s\tremaining: 28.8s\n",
            "38:\tlearn: 0.3104147\ttotal: 1.17s\tremaining: 28.7s\n",
            "39:\tlearn: 0.3102346\ttotal: 1.19s\tremaining: 28.6s\n",
            "40:\tlearn: 0.3100379\ttotal: 1.22s\tremaining: 28.5s\n",
            "41:\tlearn: 0.3098893\ttotal: 1.24s\tremaining: 28.4s\n",
            "42:\tlearn: 0.3097642\ttotal: 1.27s\tremaining: 28.3s\n",
            "43:\tlearn: 0.3095409\ttotal: 1.3s\tremaining: 28.3s\n",
            "44:\tlearn: 0.3093874\ttotal: 1.33s\tremaining: 28.2s\n",
            "45:\tlearn: 0.3092419\ttotal: 1.35s\tremaining: 28.1s\n",
            "46:\tlearn: 0.3091307\ttotal: 1.39s\tremaining: 28.1s\n",
            "47:\tlearn: 0.3089837\ttotal: 1.41s\tremaining: 28s\n",
            "48:\tlearn: 0.3088232\ttotal: 1.44s\tremaining: 27.9s\n",
            "49:\tlearn: 0.3087049\ttotal: 1.46s\tremaining: 27.8s\n",
            "50:\tlearn: 0.3086273\ttotal: 1.49s\tremaining: 27.7s\n",
            "51:\tlearn: 0.3085449\ttotal: 1.53s\tremaining: 27.9s\n",
            "52:\tlearn: 0.3084028\ttotal: 1.57s\tremaining: 28s\n",
            "53:\tlearn: 0.3082968\ttotal: 1.59s\tremaining: 27.9s\n",
            "54:\tlearn: 0.3082013\ttotal: 1.62s\tremaining: 27.8s\n",
            "55:\tlearn: 0.3081121\ttotal: 1.64s\tremaining: 27.7s\n",
            "56:\tlearn: 0.3080255\ttotal: 1.67s\tremaining: 27.7s\n",
            "57:\tlearn: 0.3079290\ttotal: 1.7s\tremaining: 27.6s\n",
            "58:\tlearn: 0.3078487\ttotal: 1.74s\tremaining: 27.7s\n",
            "59:\tlearn: 0.3077666\ttotal: 1.76s\tremaining: 27.6s\n",
            "60:\tlearn: 0.3076860\ttotal: 1.81s\tremaining: 27.9s\n",
            "61:\tlearn: 0.3076222\ttotal: 1.86s\tremaining: 28.2s\n",
            "62:\tlearn: 0.3075620\ttotal: 1.91s\tremaining: 28.4s\n",
            "63:\tlearn: 0.3074990\ttotal: 1.97s\tremaining: 28.8s\n",
            "64:\tlearn: 0.3074081\ttotal: 2.01s\tremaining: 28.9s\n",
            "65:\tlearn: 0.3073547\ttotal: 2.05s\tremaining: 29s\n",
            "66:\tlearn: 0.3072801\ttotal: 2.09s\tremaining: 29.1s\n",
            "67:\tlearn: 0.3072085\ttotal: 2.15s\tremaining: 29.4s\n",
            "68:\tlearn: 0.3071345\ttotal: 2.22s\tremaining: 29.9s\n",
            "69:\tlearn: 0.3070718\ttotal: 2.27s\tremaining: 30.2s\n",
            "70:\tlearn: 0.3070162\ttotal: 2.34s\tremaining: 30.6s\n",
            "71:\tlearn: 0.3069519\ttotal: 2.37s\tremaining: 30.6s\n",
            "72:\tlearn: 0.3068852\ttotal: 2.41s\tremaining: 30.7s\n",
            "73:\tlearn: 0.3068240\ttotal: 2.46s\tremaining: 30.7s\n",
            "74:\tlearn: 0.3067456\ttotal: 2.52s\tremaining: 31s\n",
            "75:\tlearn: 0.3066854\ttotal: 2.6s\tremaining: 31.6s\n",
            "76:\tlearn: 0.3066342\ttotal: 2.67s\tremaining: 32s\n",
            "77:\tlearn: 0.3065687\ttotal: 2.73s\tremaining: 32.3s\n",
            "78:\tlearn: 0.3065155\ttotal: 2.81s\tremaining: 32.7s\n",
            "79:\tlearn: 0.3064645\ttotal: 2.86s\tremaining: 32.9s\n",
            "80:\tlearn: 0.3064182\ttotal: 2.91s\tremaining: 33.1s\n",
            "81:\tlearn: 0.3063604\ttotal: 2.95s\tremaining: 33s\n",
            "82:\tlearn: 0.3063117\ttotal: 2.99s\tremaining: 33s\n",
            "83:\tlearn: 0.3062740\ttotal: 3.02s\tremaining: 33s\n",
            "84:\tlearn: 0.3062205\ttotal: 3.09s\tremaining: 33.2s\n",
            "85:\tlearn: 0.3061514\ttotal: 3.16s\tremaining: 33.6s\n",
            "86:\tlearn: 0.3061029\ttotal: 3.23s\tremaining: 33.9s\n",
            "87:\tlearn: 0.3060586\ttotal: 3.29s\tremaining: 34.1s\n",
            "88:\tlearn: 0.3060244\ttotal: 3.36s\tremaining: 34.4s\n",
            "89:\tlearn: 0.3059953\ttotal: 3.43s\tremaining: 34.7s\n",
            "90:\tlearn: 0.3059564\ttotal: 3.48s\tremaining: 34.8s\n",
            "91:\tlearn: 0.3059083\ttotal: 3.55s\tremaining: 35s\n",
            "92:\tlearn: 0.3058749\ttotal: 3.62s\tremaining: 35.3s\n",
            "93:\tlearn: 0.3058378\ttotal: 3.66s\tremaining: 35.3s\n",
            "94:\tlearn: 0.3057891\ttotal: 3.72s\tremaining: 35.5s\n",
            "95:\tlearn: 0.3057539\ttotal: 3.77s\tremaining: 35.5s\n",
            "96:\tlearn: 0.3056929\ttotal: 3.84s\tremaining: 35.8s\n",
            "97:\tlearn: 0.3056608\ttotal: 3.89s\tremaining: 35.8s\n",
            "98:\tlearn: 0.3056070\ttotal: 3.96s\tremaining: 36s\n",
            "99:\tlearn: 0.3055638\ttotal: 4.01s\tremaining: 36.1s\n",
            "100:\tlearn: 0.3055168\ttotal: 4.07s\tremaining: 36.2s\n",
            "101:\tlearn: 0.3054620\ttotal: 4.14s\tremaining: 36.4s\n",
            "102:\tlearn: 0.3054016\ttotal: 4.2s\tremaining: 36.6s\n",
            "103:\tlearn: 0.3053650\ttotal: 4.27s\tremaining: 36.8s\n",
            "104:\tlearn: 0.3053286\ttotal: 4.34s\tremaining: 37s\n",
            "105:\tlearn: 0.3053047\ttotal: 4.41s\tremaining: 37.2s\n",
            "106:\tlearn: 0.3052621\ttotal: 4.48s\tremaining: 37.4s\n",
            "107:\tlearn: 0.3052372\ttotal: 4.55s\tremaining: 37.6s\n",
            "108:\tlearn: 0.3052130\ttotal: 4.58s\tremaining: 37.5s\n",
            "109:\tlearn: 0.3051844\ttotal: 4.62s\tremaining: 37.3s\n",
            "110:\tlearn: 0.3051478\ttotal: 4.65s\tremaining: 37.3s\n",
            "111:\tlearn: 0.3050900\ttotal: 4.68s\tremaining: 37.1s\n",
            "112:\tlearn: 0.3050482\ttotal: 4.71s\tremaining: 37s\n",
            "113:\tlearn: 0.3050131\ttotal: 4.74s\tremaining: 36.8s\n",
            "114:\tlearn: 0.3049755\ttotal: 4.77s\tremaining: 36.7s\n",
            "115:\tlearn: 0.3049252\ttotal: 4.79s\tremaining: 36.5s\n",
            "116:\tlearn: 0.3048958\ttotal: 4.82s\tremaining: 36.4s\n",
            "117:\tlearn: 0.3048784\ttotal: 4.85s\tremaining: 36.2s\n",
            "118:\tlearn: 0.3048410\ttotal: 4.87s\tremaining: 36.1s\n",
            "119:\tlearn: 0.3048079\ttotal: 4.9s\tremaining: 35.9s\n",
            "120:\tlearn: 0.3047659\ttotal: 4.93s\tremaining: 35.8s\n",
            "121:\tlearn: 0.3047199\ttotal: 4.96s\tremaining: 35.7s\n",
            "122:\tlearn: 0.3046744\ttotal: 4.99s\tremaining: 35.6s\n",
            "123:\tlearn: 0.3046266\ttotal: 5.01s\tremaining: 35.4s\n",
            "124:\tlearn: 0.3045979\ttotal: 5.04s\tremaining: 35.3s\n",
            "125:\tlearn: 0.3045628\ttotal: 5.06s\tremaining: 35.1s\n",
            "126:\tlearn: 0.3045307\ttotal: 5.09s\tremaining: 35s\n",
            "127:\tlearn: 0.3044898\ttotal: 5.12s\tremaining: 34.9s\n",
            "128:\tlearn: 0.3044378\ttotal: 5.15s\tremaining: 34.8s\n",
            "129:\tlearn: 0.3044018\ttotal: 5.18s\tremaining: 34.7s\n",
            "130:\tlearn: 0.3043658\ttotal: 5.21s\tremaining: 34.5s\n",
            "131:\tlearn: 0.3043388\ttotal: 5.23s\tremaining: 34.4s\n",
            "132:\tlearn: 0.3042830\ttotal: 5.26s\tremaining: 34.3s\n",
            "133:\tlearn: 0.3042507\ttotal: 5.28s\tremaining: 34.2s\n",
            "134:\tlearn: 0.3042037\ttotal: 5.31s\tremaining: 34s\n",
            "135:\tlearn: 0.3041595\ttotal: 5.34s\tremaining: 33.9s\n",
            "136:\tlearn: 0.3041105\ttotal: 5.37s\tremaining: 33.8s\n",
            "137:\tlearn: 0.3040734\ttotal: 5.39s\tremaining: 33.7s\n",
            "138:\tlearn: 0.3040287\ttotal: 5.42s\tremaining: 33.6s\n",
            "139:\tlearn: 0.3039715\ttotal: 5.45s\tremaining: 33.5s\n",
            "140:\tlearn: 0.3039471\ttotal: 5.48s\tremaining: 33.4s\n",
            "141:\tlearn: 0.3039202\ttotal: 5.5s\tremaining: 33.2s\n",
            "142:\tlearn: 0.3038841\ttotal: 5.53s\tremaining: 33.1s\n",
            "143:\tlearn: 0.3038347\ttotal: 5.55s\tremaining: 33s\n",
            "144:\tlearn: 0.3037882\ttotal: 5.59s\tremaining: 33s\n",
            "145:\tlearn: 0.3037502\ttotal: 5.62s\tremaining: 32.9s\n",
            "146:\tlearn: 0.3037244\ttotal: 5.66s\tremaining: 32.8s\n",
            "147:\tlearn: 0.3036757\ttotal: 5.68s\tremaining: 32.7s\n",
            "148:\tlearn: 0.3036452\ttotal: 5.71s\tremaining: 32.6s\n",
            "149:\tlearn: 0.3036071\ttotal: 5.74s\tremaining: 32.5s\n",
            "150:\tlearn: 0.3035420\ttotal: 5.77s\tremaining: 32.4s\n",
            "151:\tlearn: 0.3034897\ttotal: 5.8s\tremaining: 32.4s\n",
            "152:\tlearn: 0.3034474\ttotal: 5.82s\tremaining: 32.2s\n",
            "153:\tlearn: 0.3034062\ttotal: 5.85s\tremaining: 32.1s\n",
            "154:\tlearn: 0.3033772\ttotal: 5.87s\tremaining: 32s\n",
            "155:\tlearn: 0.3033305\ttotal: 5.9s\tremaining: 31.9s\n",
            "156:\tlearn: 0.3033014\ttotal: 5.93s\tremaining: 31.8s\n",
            "157:\tlearn: 0.3032683\ttotal: 5.95s\tremaining: 31.7s\n",
            "158:\tlearn: 0.3032113\ttotal: 5.98s\tremaining: 31.6s\n",
            "159:\tlearn: 0.3031778\ttotal: 6.01s\tremaining: 31.6s\n",
            "160:\tlearn: 0.3031298\ttotal: 6.04s\tremaining: 31.5s\n",
            "161:\tlearn: 0.3030863\ttotal: 6.07s\tremaining: 31.4s\n",
            "162:\tlearn: 0.3030465\ttotal: 6.1s\tremaining: 31.3s\n",
            "163:\tlearn: 0.3029881\ttotal: 6.13s\tremaining: 31.2s\n",
            "164:\tlearn: 0.3029447\ttotal: 6.15s\tremaining: 31.1s\n",
            "165:\tlearn: 0.3029045\ttotal: 6.18s\tremaining: 31s\n",
            "166:\tlearn: 0.3028468\ttotal: 6.21s\tremaining: 31s\n",
            "167:\tlearn: 0.3028015\ttotal: 6.24s\tremaining: 30.9s\n",
            "168:\tlearn: 0.3027608\ttotal: 6.26s\tremaining: 30.8s\n",
            "169:\tlearn: 0.3027096\ttotal: 6.29s\tremaining: 30.7s\n",
            "170:\tlearn: 0.3026604\ttotal: 6.32s\tremaining: 30.6s\n",
            "171:\tlearn: 0.3026153\ttotal: 6.35s\tremaining: 30.6s\n",
            "172:\tlearn: 0.3025701\ttotal: 6.38s\tremaining: 30.5s\n",
            "173:\tlearn: 0.3025321\ttotal: 6.4s\tremaining: 30.4s\n",
            "174:\tlearn: 0.3024745\ttotal: 6.43s\tremaining: 30.3s\n",
            "175:\tlearn: 0.3024384\ttotal: 6.46s\tremaining: 30.2s\n",
            "176:\tlearn: 0.3023901\ttotal: 6.49s\tremaining: 30.2s\n",
            "177:\tlearn: 0.3023476\ttotal: 6.51s\tremaining: 30.1s\n",
            "178:\tlearn: 0.3023118\ttotal: 6.54s\tremaining: 30s\n",
            "179:\tlearn: 0.3022680\ttotal: 6.57s\tremaining: 29.9s\n",
            "180:\tlearn: 0.3022264\ttotal: 6.59s\tremaining: 29.8s\n",
            "181:\tlearn: 0.3021789\ttotal: 6.62s\tremaining: 29.8s\n",
            "182:\tlearn: 0.3021263\ttotal: 6.67s\tremaining: 29.8s\n",
            "183:\tlearn: 0.3020910\ttotal: 6.7s\tremaining: 29.7s\n",
            "184:\tlearn: 0.3020548\ttotal: 6.72s\tremaining: 29.6s\n",
            "185:\tlearn: 0.3020106\ttotal: 6.75s\tremaining: 29.6s\n",
            "186:\tlearn: 0.3019613\ttotal: 6.78s\tremaining: 29.5s\n",
            "187:\tlearn: 0.3019071\ttotal: 6.8s\tremaining: 29.4s\n",
            "188:\tlearn: 0.3018751\ttotal: 6.83s\tremaining: 29.3s\n",
            "189:\tlearn: 0.3018338\ttotal: 6.86s\tremaining: 29.2s\n",
            "190:\tlearn: 0.3017999\ttotal: 6.89s\tremaining: 29.2s\n",
            "191:\tlearn: 0.3017540\ttotal: 6.91s\tremaining: 29.1s\n",
            "192:\tlearn: 0.3017005\ttotal: 6.94s\tremaining: 29s\n",
            "193:\tlearn: 0.3016513\ttotal: 6.97s\tremaining: 28.9s\n",
            "194:\tlearn: 0.3016249\ttotal: 6.99s\tremaining: 28.9s\n",
            "195:\tlearn: 0.3015850\ttotal: 7.02s\tremaining: 28.8s\n",
            "196:\tlearn: 0.3015443\ttotal: 7.05s\tremaining: 28.8s\n",
            "197:\tlearn: 0.3015007\ttotal: 7.08s\tremaining: 28.7s\n",
            "198:\tlearn: 0.3014471\ttotal: 7.11s\tremaining: 28.6s\n",
            "199:\tlearn: 0.3013915\ttotal: 7.14s\tremaining: 28.6s\n",
            "200:\tlearn: 0.3013456\ttotal: 7.16s\tremaining: 28.5s\n",
            "201:\tlearn: 0.3013107\ttotal: 7.19s\tremaining: 28.4s\n",
            "202:\tlearn: 0.3012677\ttotal: 7.22s\tremaining: 28.3s\n",
            "203:\tlearn: 0.3012314\ttotal: 7.24s\tremaining: 28.3s\n",
            "204:\tlearn: 0.3011882\ttotal: 7.27s\tremaining: 28.2s\n",
            "205:\tlearn: 0.3011514\ttotal: 7.3s\tremaining: 28.1s\n",
            "206:\tlearn: 0.3011181\ttotal: 7.33s\tremaining: 28.1s\n",
            "207:\tlearn: 0.3010808\ttotal: 7.36s\tremaining: 28s\n",
            "208:\tlearn: 0.3010284\ttotal: 7.38s\tremaining: 27.9s\n",
            "209:\tlearn: 0.3009964\ttotal: 7.41s\tremaining: 27.9s\n",
            "210:\tlearn: 0.3009557\ttotal: 7.43s\tremaining: 27.8s\n",
            "211:\tlearn: 0.3009105\ttotal: 7.46s\tremaining: 27.7s\n",
            "212:\tlearn: 0.3008628\ttotal: 7.49s\tremaining: 27.7s\n",
            "213:\tlearn: 0.3008279\ttotal: 7.52s\tremaining: 27.6s\n",
            "214:\tlearn: 0.3007971\ttotal: 7.54s\tremaining: 27.5s\n",
            "215:\tlearn: 0.3007552\ttotal: 7.57s\tremaining: 27.5s\n",
            "216:\tlearn: 0.3007215\ttotal: 7.59s\tremaining: 27.4s\n",
            "217:\tlearn: 0.3006784\ttotal: 7.62s\tremaining: 27.3s\n",
            "218:\tlearn: 0.3006433\ttotal: 7.65s\tremaining: 27.3s\n",
            "219:\tlearn: 0.3006074\ttotal: 7.69s\tremaining: 27.3s\n",
            "220:\tlearn: 0.3005724\ttotal: 7.72s\tremaining: 27.2s\n",
            "221:\tlearn: 0.3005243\ttotal: 7.75s\tremaining: 27.2s\n",
            "222:\tlearn: 0.3004830\ttotal: 7.78s\tremaining: 27.1s\n",
            "223:\tlearn: 0.3004524\ttotal: 7.8s\tremaining: 27s\n",
            "224:\tlearn: 0.3004043\ttotal: 7.83s\tremaining: 27s\n",
            "225:\tlearn: 0.3003492\ttotal: 7.86s\tremaining: 26.9s\n",
            "226:\tlearn: 0.3002985\ttotal: 7.88s\tremaining: 26.8s\n",
            "227:\tlearn: 0.3002625\ttotal: 7.91s\tremaining: 26.8s\n",
            "228:\tlearn: 0.3002272\ttotal: 7.94s\tremaining: 26.7s\n",
            "229:\tlearn: 0.3001843\ttotal: 7.97s\tremaining: 26.7s\n",
            "230:\tlearn: 0.3001553\ttotal: 7.99s\tremaining: 26.6s\n",
            "231:\tlearn: 0.3001090\ttotal: 8.02s\tremaining: 26.5s\n",
            "232:\tlearn: 0.3000764\ttotal: 8.04s\tremaining: 26.5s\n",
            "233:\tlearn: 0.3000299\ttotal: 8.07s\tremaining: 26.4s\n",
            "234:\tlearn: 0.2999931\ttotal: 8.1s\tremaining: 26.4s\n",
            "235:\tlearn: 0.2999628\ttotal: 8.13s\tremaining: 26.3s\n",
            "236:\tlearn: 0.2999323\ttotal: 8.16s\tremaining: 26.3s\n",
            "237:\tlearn: 0.2998894\ttotal: 8.19s\tremaining: 26.2s\n",
            "238:\tlearn: 0.2998527\ttotal: 8.21s\tremaining: 26.1s\n",
            "239:\tlearn: 0.2998216\ttotal: 8.24s\tremaining: 26.1s\n",
            "240:\tlearn: 0.2997889\ttotal: 8.27s\tremaining: 26s\n",
            "241:\tlearn: 0.2997602\ttotal: 8.29s\tremaining: 26s\n",
            "242:\tlearn: 0.2997272\ttotal: 8.32s\tremaining: 25.9s\n",
            "243:\tlearn: 0.2996837\ttotal: 8.35s\tremaining: 25.9s\n",
            "244:\tlearn: 0.2996495\ttotal: 8.38s\tremaining: 25.8s\n",
            "245:\tlearn: 0.2996092\ttotal: 8.4s\tremaining: 25.7s\n",
            "246:\tlearn: 0.2995704\ttotal: 8.43s\tremaining: 25.7s\n",
            "247:\tlearn: 0.2995330\ttotal: 8.45s\tremaining: 25.6s\n",
            "248:\tlearn: 0.2994938\ttotal: 8.48s\tremaining: 25.6s\n",
            "249:\tlearn: 0.2994522\ttotal: 8.5s\tremaining: 25.5s\n",
            "250:\tlearn: 0.2994095\ttotal: 8.53s\tremaining: 25.5s\n",
            "251:\tlearn: 0.2993813\ttotal: 8.55s\tremaining: 25.4s\n",
            "252:\tlearn: 0.2993532\ttotal: 8.59s\tremaining: 25.4s\n",
            "253:\tlearn: 0.2993142\ttotal: 8.62s\tremaining: 25.3s\n",
            "254:\tlearn: 0.2992763\ttotal: 8.64s\tremaining: 25.2s\n",
            "255:\tlearn: 0.2992367\ttotal: 8.67s\tremaining: 25.2s\n",
            "256:\tlearn: 0.2991933\ttotal: 8.71s\tremaining: 25.2s\n",
            "257:\tlearn: 0.2991302\ttotal: 8.74s\tremaining: 25.1s\n",
            "258:\tlearn: 0.2990978\ttotal: 8.77s\tremaining: 25.1s\n",
            "259:\tlearn: 0.2990626\ttotal: 8.79s\tremaining: 25s\n",
            "260:\tlearn: 0.2990156\ttotal: 8.82s\tremaining: 25s\n",
            "261:\tlearn: 0.2989803\ttotal: 8.85s\tremaining: 24.9s\n",
            "262:\tlearn: 0.2989345\ttotal: 8.87s\tremaining: 24.9s\n",
            "263:\tlearn: 0.2989144\ttotal: 8.9s\tremaining: 24.8s\n",
            "264:\tlearn: 0.2988793\ttotal: 8.93s\tremaining: 24.8s\n",
            "265:\tlearn: 0.2988515\ttotal: 8.96s\tremaining: 24.7s\n",
            "266:\tlearn: 0.2988216\ttotal: 8.98s\tremaining: 24.7s\n",
            "267:\tlearn: 0.2987755\ttotal: 9.01s\tremaining: 24.6s\n",
            "268:\tlearn: 0.2987389\ttotal: 9.04s\tremaining: 24.6s\n",
            "269:\tlearn: 0.2987014\ttotal: 9.07s\tremaining: 24.5s\n",
            "270:\tlearn: 0.2986630\ttotal: 9.1s\tremaining: 24.5s\n",
            "271:\tlearn: 0.2986041\ttotal: 9.12s\tremaining: 24.4s\n",
            "272:\tlearn: 0.2985574\ttotal: 9.15s\tremaining: 24.4s\n",
            "273:\tlearn: 0.2985192\ttotal: 9.18s\tremaining: 24.3s\n",
            "274:\tlearn: 0.2984755\ttotal: 9.2s\tremaining: 24.3s\n",
            "275:\tlearn: 0.2984449\ttotal: 9.23s\tremaining: 24.2s\n",
            "276:\tlearn: 0.2984114\ttotal: 9.26s\tremaining: 24.2s\n",
            "277:\tlearn: 0.2983628\ttotal: 9.29s\tremaining: 24.1s\n",
            "278:\tlearn: 0.2983211\ttotal: 9.31s\tremaining: 24.1s\n",
            "279:\tlearn: 0.2982845\ttotal: 9.34s\tremaining: 24s\n",
            "280:\tlearn: 0.2982498\ttotal: 9.36s\tremaining: 24s\n",
            "281:\tlearn: 0.2982013\ttotal: 9.39s\tremaining: 23.9s\n",
            "282:\tlearn: 0.2981485\ttotal: 9.42s\tremaining: 23.9s\n",
            "283:\tlearn: 0.2981121\ttotal: 9.45s\tremaining: 23.8s\n",
            "284:\tlearn: 0.2980770\ttotal: 9.48s\tremaining: 23.8s\n",
            "285:\tlearn: 0.2980399\ttotal: 9.5s\tremaining: 23.7s\n",
            "286:\tlearn: 0.2980161\ttotal: 9.53s\tremaining: 23.7s\n",
            "287:\tlearn: 0.2979850\ttotal: 9.55s\tremaining: 23.6s\n",
            "288:\tlearn: 0.2979322\ttotal: 9.58s\tremaining: 23.6s\n",
            "289:\tlearn: 0.2979013\ttotal: 9.61s\tremaining: 23.5s\n",
            "290:\tlearn: 0.2978692\ttotal: 9.63s\tremaining: 23.5s\n",
            "291:\tlearn: 0.2978373\ttotal: 9.67s\tremaining: 23.4s\n",
            "292:\tlearn: 0.2977991\ttotal: 9.71s\tremaining: 23.4s\n",
            "293:\tlearn: 0.2977732\ttotal: 9.73s\tremaining: 23.4s\n",
            "294:\tlearn: 0.2977383\ttotal: 9.77s\tremaining: 23.3s\n",
            "295:\tlearn: 0.2977153\ttotal: 9.79s\tremaining: 23.3s\n",
            "296:\tlearn: 0.2976922\ttotal: 9.82s\tremaining: 23.2s\n",
            "297:\tlearn: 0.2976658\ttotal: 9.84s\tremaining: 23.2s\n",
            "298:\tlearn: 0.2976202\ttotal: 9.87s\tremaining: 23.1s\n",
            "299:\tlearn: 0.2975878\ttotal: 9.9s\tremaining: 23.1s\n",
            "300:\tlearn: 0.2975606\ttotal: 9.93s\tremaining: 23.1s\n",
            "301:\tlearn: 0.2975203\ttotal: 9.95s\tremaining: 23s\n",
            "302:\tlearn: 0.2974873\ttotal: 9.98s\tremaining: 23s\n",
            "303:\tlearn: 0.2974380\ttotal: 10s\tremaining: 22.9s\n",
            "304:\tlearn: 0.2973963\ttotal: 10s\tremaining: 22.9s\n",
            "305:\tlearn: 0.2973629\ttotal: 10.1s\tremaining: 22.8s\n",
            "306:\tlearn: 0.2973166\ttotal: 10.1s\tremaining: 22.8s\n",
            "307:\tlearn: 0.2972783\ttotal: 10.1s\tremaining: 22.8s\n",
            "308:\tlearn: 0.2972305\ttotal: 10.2s\tremaining: 22.7s\n",
            "309:\tlearn: 0.2972062\ttotal: 10.2s\tremaining: 22.7s\n",
            "310:\tlearn: 0.2971641\ttotal: 10.2s\tremaining: 22.6s\n",
            "311:\tlearn: 0.2971239\ttotal: 10.2s\tremaining: 22.6s\n",
            "312:\tlearn: 0.2970777\ttotal: 10.3s\tremaining: 22.5s\n",
            "313:\tlearn: 0.2970474\ttotal: 10.3s\tremaining: 22.5s\n",
            "314:\tlearn: 0.2970169\ttotal: 10.3s\tremaining: 22.4s\n",
            "315:\tlearn: 0.2969727\ttotal: 10.3s\tremaining: 22.4s\n",
            "316:\tlearn: 0.2969357\ttotal: 10.4s\tremaining: 22.3s\n",
            "317:\tlearn: 0.2968900\ttotal: 10.4s\tremaining: 22.3s\n",
            "318:\tlearn: 0.2968498\ttotal: 10.4s\tremaining: 22.3s\n",
            "319:\tlearn: 0.2968278\ttotal: 10.5s\tremaining: 22.2s\n",
            "320:\tlearn: 0.2967972\ttotal: 10.5s\tremaining: 22.2s\n",
            "321:\tlearn: 0.2967595\ttotal: 10.5s\tremaining: 22.1s\n",
            "322:\tlearn: 0.2967124\ttotal: 10.5s\tremaining: 22.1s\n",
            "323:\tlearn: 0.2966731\ttotal: 10.6s\tremaining: 22s\n",
            "324:\tlearn: 0.2966242\ttotal: 10.6s\tremaining: 22s\n",
            "325:\tlearn: 0.2965955\ttotal: 10.6s\tremaining: 21.9s\n",
            "326:\tlearn: 0.2965598\ttotal: 10.6s\tremaining: 21.9s\n",
            "327:\tlearn: 0.2965385\ttotal: 10.7s\tremaining: 21.9s\n",
            "328:\tlearn: 0.2964999\ttotal: 10.7s\tremaining: 21.8s\n",
            "329:\tlearn: 0.2964739\ttotal: 10.7s\tremaining: 21.8s\n",
            "330:\tlearn: 0.2964252\ttotal: 10.8s\tremaining: 21.8s\n",
            "331:\tlearn: 0.2963970\ttotal: 10.8s\tremaining: 21.7s\n",
            "332:\tlearn: 0.2963630\ttotal: 10.8s\tremaining: 21.7s\n",
            "333:\tlearn: 0.2963244\ttotal: 10.8s\tremaining: 21.6s\n",
            "334:\tlearn: 0.2962973\ttotal: 10.9s\tremaining: 21.6s\n",
            "335:\tlearn: 0.2962600\ttotal: 10.9s\tremaining: 21.5s\n",
            "336:\tlearn: 0.2962184\ttotal: 10.9s\tremaining: 21.5s\n",
            "337:\tlearn: 0.2961747\ttotal: 11s\tremaining: 21.5s\n",
            "338:\tlearn: 0.2961571\ttotal: 11s\tremaining: 21.4s\n",
            "339:\tlearn: 0.2961286\ttotal: 11s\tremaining: 21.4s\n",
            "340:\tlearn: 0.2961001\ttotal: 11s\tremaining: 21.3s\n",
            "341:\tlearn: 0.2960614\ttotal: 11.1s\tremaining: 21.3s\n",
            "342:\tlearn: 0.2960310\ttotal: 11.1s\tremaining: 21.3s\n",
            "343:\tlearn: 0.2959875\ttotal: 11.1s\tremaining: 21.2s\n",
            "344:\tlearn: 0.2959658\ttotal: 11.1s\tremaining: 21.2s\n",
            "345:\tlearn: 0.2959273\ttotal: 11.2s\tremaining: 21.1s\n",
            "346:\tlearn: 0.2958876\ttotal: 11.2s\tremaining: 21.1s\n",
            "347:\tlearn: 0.2958519\ttotal: 11.2s\tremaining: 21s\n",
            "348:\tlearn: 0.2958250\ttotal: 11.3s\tremaining: 21s\n",
            "349:\tlearn: 0.2958056\ttotal: 11.3s\tremaining: 21s\n",
            "350:\tlearn: 0.2957694\ttotal: 11.3s\tremaining: 20.9s\n",
            "351:\tlearn: 0.2957292\ttotal: 11.3s\tremaining: 20.9s\n",
            "352:\tlearn: 0.2957027\ttotal: 11.4s\tremaining: 20.8s\n",
            "353:\tlearn: 0.2956541\ttotal: 11.4s\tremaining: 20.8s\n",
            "354:\tlearn: 0.2956153\ttotal: 11.4s\tremaining: 20.8s\n",
            "355:\tlearn: 0.2955945\ttotal: 11.5s\tremaining: 20.7s\n",
            "356:\tlearn: 0.2955669\ttotal: 11.5s\tremaining: 20.7s\n",
            "357:\tlearn: 0.2955329\ttotal: 11.5s\tremaining: 20.6s\n",
            "358:\tlearn: 0.2954913\ttotal: 11.5s\tremaining: 20.6s\n",
            "359:\tlearn: 0.2954714\ttotal: 11.6s\tremaining: 20.6s\n",
            "360:\tlearn: 0.2954397\ttotal: 11.6s\tremaining: 20.5s\n",
            "361:\tlearn: 0.2954015\ttotal: 11.6s\tremaining: 20.5s\n",
            "362:\tlearn: 0.2953553\ttotal: 11.6s\tremaining: 20.4s\n",
            "363:\tlearn: 0.2953068\ttotal: 11.7s\tremaining: 20.4s\n",
            "364:\tlearn: 0.2952739\ttotal: 11.7s\tremaining: 20.4s\n",
            "365:\tlearn: 0.2952428\ttotal: 11.7s\tremaining: 20.4s\n",
            "366:\tlearn: 0.2952039\ttotal: 11.8s\tremaining: 20.3s\n",
            "367:\tlearn: 0.2951662\ttotal: 11.8s\tremaining: 20.3s\n",
            "368:\tlearn: 0.2951347\ttotal: 11.8s\tremaining: 20.2s\n",
            "369:\tlearn: 0.2950934\ttotal: 11.9s\tremaining: 20.2s\n",
            "370:\tlearn: 0.2950591\ttotal: 11.9s\tremaining: 20.1s\n",
            "371:\tlearn: 0.2950260\ttotal: 11.9s\tremaining: 20.1s\n",
            "372:\tlearn: 0.2949883\ttotal: 11.9s\tremaining: 20.1s\n",
            "373:\tlearn: 0.2949569\ttotal: 12s\tremaining: 20s\n",
            "374:\tlearn: 0.2949187\ttotal: 12s\tremaining: 20s\n",
            "375:\tlearn: 0.2948861\ttotal: 12s\tremaining: 20s\n",
            "376:\tlearn: 0.2948450\ttotal: 12.1s\tremaining: 19.9s\n",
            "377:\tlearn: 0.2948056\ttotal: 12.1s\tremaining: 19.9s\n",
            "378:\tlearn: 0.2947808\ttotal: 12.1s\tremaining: 19.8s\n",
            "379:\tlearn: 0.2947462\ttotal: 12.1s\tremaining: 19.8s\n",
            "380:\tlearn: 0.2947186\ttotal: 12.2s\tremaining: 19.8s\n",
            "381:\tlearn: 0.2946872\ttotal: 12.2s\tremaining: 19.7s\n",
            "382:\tlearn: 0.2946546\ttotal: 12.2s\tremaining: 19.7s\n",
            "383:\tlearn: 0.2946192\ttotal: 12.2s\tremaining: 19.6s\n",
            "384:\tlearn: 0.2945856\ttotal: 12.3s\tremaining: 19.6s\n",
            "385:\tlearn: 0.2945639\ttotal: 12.3s\tremaining: 19.6s\n",
            "386:\tlearn: 0.2945291\ttotal: 12.3s\tremaining: 19.5s\n",
            "387:\tlearn: 0.2944904\ttotal: 12.4s\tremaining: 19.5s\n",
            "388:\tlearn: 0.2944634\ttotal: 12.4s\tremaining: 19.5s\n",
            "389:\tlearn: 0.2944441\ttotal: 12.4s\tremaining: 19.4s\n",
            "390:\tlearn: 0.2944118\ttotal: 12.4s\tremaining: 19.4s\n",
            "391:\tlearn: 0.2943983\ttotal: 12.5s\tremaining: 19.3s\n",
            "392:\tlearn: 0.2943744\ttotal: 12.5s\tremaining: 19.3s\n",
            "393:\tlearn: 0.2943408\ttotal: 12.5s\tremaining: 19.3s\n",
            "394:\tlearn: 0.2943162\ttotal: 12.6s\tremaining: 19.2s\n",
            "395:\tlearn: 0.2942852\ttotal: 12.6s\tremaining: 19.2s\n",
            "396:\tlearn: 0.2942453\ttotal: 12.6s\tremaining: 19.1s\n",
            "397:\tlearn: 0.2942221\ttotal: 12.6s\tremaining: 19.1s\n",
            "398:\tlearn: 0.2941920\ttotal: 12.7s\tremaining: 19.1s\n",
            "399:\tlearn: 0.2941610\ttotal: 12.7s\tremaining: 19s\n",
            "400:\tlearn: 0.2941237\ttotal: 12.7s\tremaining: 19s\n",
            "401:\tlearn: 0.2940773\ttotal: 12.8s\tremaining: 19s\n",
            "402:\tlearn: 0.2940453\ttotal: 12.8s\tremaining: 19s\n",
            "403:\tlearn: 0.2940173\ttotal: 12.8s\tremaining: 18.9s\n",
            "404:\tlearn: 0.2939829\ttotal: 12.8s\tremaining: 18.9s\n",
            "405:\tlearn: 0.2939498\ttotal: 12.9s\tremaining: 18.8s\n",
            "406:\tlearn: 0.2939341\ttotal: 12.9s\tremaining: 18.8s\n",
            "407:\tlearn: 0.2938886\ttotal: 12.9s\tremaining: 18.8s\n",
            "408:\tlearn: 0.2938513\ttotal: 13s\tremaining: 18.7s\n",
            "409:\tlearn: 0.2938211\ttotal: 13s\tremaining: 18.7s\n",
            "410:\tlearn: 0.2937922\ttotal: 13s\tremaining: 18.7s\n",
            "411:\tlearn: 0.2937586\ttotal: 13s\tremaining: 18.6s\n",
            "412:\tlearn: 0.2937307\ttotal: 13.1s\tremaining: 18.6s\n",
            "413:\tlearn: 0.2936948\ttotal: 13.1s\tremaining: 18.5s\n",
            "414:\tlearn: 0.2936676\ttotal: 13.1s\tremaining: 18.5s\n",
            "415:\tlearn: 0.2936340\ttotal: 13.2s\tremaining: 18.5s\n",
            "416:\tlearn: 0.2936077\ttotal: 13.2s\tremaining: 18.4s\n",
            "417:\tlearn: 0.2935689\ttotal: 13.2s\tremaining: 18.4s\n",
            "418:\tlearn: 0.2935380\ttotal: 13.2s\tremaining: 18.4s\n",
            "419:\tlearn: 0.2934998\ttotal: 13.3s\tremaining: 18.3s\n",
            "420:\tlearn: 0.2934580\ttotal: 13.3s\tremaining: 18.3s\n",
            "421:\tlearn: 0.2934400\ttotal: 13.3s\tremaining: 18.2s\n",
            "422:\tlearn: 0.2934195\ttotal: 13.3s\tremaining: 18.2s\n",
            "423:\tlearn: 0.2933736\ttotal: 13.4s\tremaining: 18.2s\n",
            "424:\tlearn: 0.2933605\ttotal: 13.4s\tremaining: 18.1s\n",
            "425:\tlearn: 0.2933218\ttotal: 13.4s\tremaining: 18.1s\n",
            "426:\tlearn: 0.2932982\ttotal: 13.5s\tremaining: 18.1s\n",
            "427:\tlearn: 0.2932686\ttotal: 13.5s\tremaining: 18s\n",
            "428:\tlearn: 0.2932439\ttotal: 13.5s\tremaining: 18s\n",
            "429:\tlearn: 0.2932268\ttotal: 13.5s\tremaining: 17.9s\n",
            "430:\tlearn: 0.2932100\ttotal: 13.6s\tremaining: 17.9s\n",
            "431:\tlearn: 0.2931836\ttotal: 13.6s\tremaining: 17.9s\n",
            "432:\tlearn: 0.2931444\ttotal: 13.6s\tremaining: 17.8s\n",
            "433:\tlearn: 0.2931159\ttotal: 13.6s\tremaining: 17.8s\n",
            "434:\tlearn: 0.2930824\ttotal: 13.7s\tremaining: 17.8s\n",
            "435:\tlearn: 0.2930396\ttotal: 13.7s\tremaining: 17.7s\n",
            "436:\tlearn: 0.2930093\ttotal: 13.7s\tremaining: 17.7s\n",
            "437:\tlearn: 0.2929827\ttotal: 13.8s\tremaining: 17.7s\n",
            "438:\tlearn: 0.2929614\ttotal: 13.8s\tremaining: 17.6s\n",
            "439:\tlearn: 0.2929379\ttotal: 13.8s\tremaining: 17.6s\n",
            "440:\tlearn: 0.2929055\ttotal: 13.8s\tremaining: 17.6s\n",
            "441:\tlearn: 0.2928818\ttotal: 13.9s\tremaining: 17.5s\n",
            "442:\tlearn: 0.2928404\ttotal: 13.9s\tremaining: 17.5s\n",
            "443:\tlearn: 0.2928087\ttotal: 13.9s\tremaining: 17.4s\n",
            "444:\tlearn: 0.2927831\ttotal: 14s\tremaining: 17.4s\n",
            "445:\tlearn: 0.2927569\ttotal: 14s\tremaining: 17.4s\n",
            "446:\tlearn: 0.2927298\ttotal: 14s\tremaining: 17.3s\n",
            "447:\tlearn: 0.2927074\ttotal: 14s\tremaining: 17.3s\n",
            "448:\tlearn: 0.2926734\ttotal: 14.1s\tremaining: 17.3s\n",
            "449:\tlearn: 0.2926439\ttotal: 14.1s\tremaining: 17.2s\n",
            "450:\tlearn: 0.2926160\ttotal: 14.1s\tremaining: 17.2s\n",
            "451:\tlearn: 0.2925994\ttotal: 14.2s\tremaining: 17.2s\n",
            "452:\tlearn: 0.2925713\ttotal: 14.2s\tremaining: 17.1s\n",
            "453:\tlearn: 0.2925519\ttotal: 14.2s\tremaining: 17.1s\n",
            "454:\tlearn: 0.2925072\ttotal: 14.2s\tremaining: 17.1s\n",
            "455:\tlearn: 0.2924840\ttotal: 14.3s\tremaining: 17s\n",
            "456:\tlearn: 0.2924489\ttotal: 14.3s\tremaining: 17s\n",
            "457:\tlearn: 0.2924126\ttotal: 14.3s\tremaining: 16.9s\n",
            "458:\tlearn: 0.2923905\ttotal: 14.3s\tremaining: 16.9s\n",
            "459:\tlearn: 0.2923648\ttotal: 14.4s\tremaining: 16.9s\n",
            "460:\tlearn: 0.2923249\ttotal: 14.4s\tremaining: 16.8s\n",
            "461:\tlearn: 0.2922933\ttotal: 14.4s\tremaining: 16.8s\n",
            "462:\tlearn: 0.2922602\ttotal: 14.5s\tremaining: 16.8s\n",
            "463:\tlearn: 0.2922367\ttotal: 14.6s\tremaining: 16.8s\n",
            "464:\tlearn: 0.2922211\ttotal: 14.6s\tremaining: 16.8s\n",
            "465:\tlearn: 0.2922003\ttotal: 14.6s\tremaining: 16.8s\n",
            "466:\tlearn: 0.2921681\ttotal: 14.7s\tremaining: 16.8s\n",
            "467:\tlearn: 0.2921394\ttotal: 14.7s\tremaining: 16.7s\n",
            "468:\tlearn: 0.2921077\ttotal: 14.8s\tremaining: 16.8s\n",
            "469:\tlearn: 0.2920830\ttotal: 14.9s\tremaining: 16.8s\n",
            "470:\tlearn: 0.2920500\ttotal: 14.9s\tremaining: 16.8s\n",
            "471:\tlearn: 0.2920114\ttotal: 15s\tremaining: 16.8s\n",
            "472:\tlearn: 0.2919664\ttotal: 15.1s\tremaining: 16.8s\n",
            "473:\tlearn: 0.2919403\ttotal: 15.1s\tremaining: 16.8s\n",
            "474:\tlearn: 0.2918958\ttotal: 15.2s\tremaining: 16.8s\n",
            "475:\tlearn: 0.2918494\ttotal: 15.3s\tremaining: 16.8s\n",
            "476:\tlearn: 0.2918150\ttotal: 15.4s\tremaining: 16.8s\n",
            "477:\tlearn: 0.2917782\ttotal: 15.4s\tremaining: 16.9s\n",
            "478:\tlearn: 0.2917523\ttotal: 15.5s\tremaining: 16.9s\n",
            "479:\tlearn: 0.2917281\ttotal: 15.6s\tremaining: 16.9s\n",
            "480:\tlearn: 0.2917015\ttotal: 15.6s\tremaining: 16.9s\n",
            "481:\tlearn: 0.2916850\ttotal: 15.7s\tremaining: 16.9s\n",
            "482:\tlearn: 0.2916544\ttotal: 15.8s\tremaining: 16.9s\n",
            "483:\tlearn: 0.2916281\ttotal: 15.9s\tremaining: 16.9s\n",
            "484:\tlearn: 0.2915938\ttotal: 15.9s\tremaining: 16.9s\n",
            "485:\tlearn: 0.2915542\ttotal: 16s\tremaining: 16.9s\n",
            "486:\tlearn: 0.2915192\ttotal: 16s\tremaining: 16.9s\n",
            "487:\tlearn: 0.2914721\ttotal: 16.1s\tremaining: 16.9s\n",
            "488:\tlearn: 0.2914501\ttotal: 16.2s\tremaining: 16.9s\n",
            "489:\tlearn: 0.2914243\ttotal: 16.2s\tremaining: 16.9s\n",
            "490:\tlearn: 0.2913908\ttotal: 16.3s\tremaining: 16.8s\n",
            "491:\tlearn: 0.2913576\ttotal: 16.3s\tremaining: 16.9s\n",
            "492:\tlearn: 0.2913289\ttotal: 16.4s\tremaining: 16.9s\n",
            "493:\tlearn: 0.2912917\ttotal: 16.5s\tremaining: 16.9s\n",
            "494:\tlearn: 0.2912516\ttotal: 16.5s\tremaining: 16.9s\n",
            "495:\tlearn: 0.2912215\ttotal: 16.6s\tremaining: 16.9s\n",
            "496:\tlearn: 0.2912036\ttotal: 16.6s\tremaining: 16.8s\n",
            "497:\tlearn: 0.2911695\ttotal: 16.7s\tremaining: 16.8s\n",
            "498:\tlearn: 0.2911389\ttotal: 16.8s\tremaining: 16.8s\n",
            "499:\tlearn: 0.2911104\ttotal: 16.9s\tremaining: 16.9s\n",
            "500:\tlearn: 0.2910884\ttotal: 16.9s\tremaining: 16.9s\n",
            "501:\tlearn: 0.2910596\ttotal: 17s\tremaining: 16.9s\n",
            "502:\tlearn: 0.2910235\ttotal: 17.1s\tremaining: 16.9s\n",
            "503:\tlearn: 0.2909930\ttotal: 17.1s\tremaining: 16.9s\n",
            "504:\tlearn: 0.2909599\ttotal: 17.2s\tremaining: 16.8s\n",
            "505:\tlearn: 0.2909283\ttotal: 17.2s\tremaining: 16.8s\n",
            "506:\tlearn: 0.2909010\ttotal: 17.2s\tremaining: 16.7s\n",
            "507:\tlearn: 0.2908817\ttotal: 17.2s\tremaining: 16.7s\n",
            "508:\tlearn: 0.2908532\ttotal: 17.3s\tremaining: 16.7s\n",
            "509:\tlearn: 0.2908200\ttotal: 17.3s\tremaining: 16.6s\n",
            "510:\tlearn: 0.2907839\ttotal: 17.3s\tremaining: 16.6s\n",
            "511:\tlearn: 0.2907496\ttotal: 17.4s\tremaining: 16.5s\n",
            "512:\tlearn: 0.2907269\ttotal: 17.4s\tremaining: 16.5s\n",
            "513:\tlearn: 0.2907020\ttotal: 17.4s\tremaining: 16.5s\n",
            "514:\tlearn: 0.2906776\ttotal: 17.4s\tremaining: 16.4s\n",
            "515:\tlearn: 0.2906462\ttotal: 17.5s\tremaining: 16.4s\n",
            "516:\tlearn: 0.2906180\ttotal: 17.5s\tremaining: 16.3s\n",
            "517:\tlearn: 0.2905828\ttotal: 17.5s\tremaining: 16.3s\n",
            "518:\tlearn: 0.2905492\ttotal: 17.5s\tremaining: 16.3s\n",
            "519:\tlearn: 0.2905219\ttotal: 17.6s\tremaining: 16.2s\n",
            "520:\tlearn: 0.2904808\ttotal: 17.6s\tremaining: 16.2s\n",
            "521:\tlearn: 0.2904598\ttotal: 17.6s\tremaining: 16.1s\n",
            "522:\tlearn: 0.2904185\ttotal: 17.6s\tremaining: 16.1s\n",
            "523:\tlearn: 0.2903816\ttotal: 17.7s\tremaining: 16.1s\n",
            "524:\tlearn: 0.2903596\ttotal: 17.7s\tremaining: 16s\n",
            "525:\tlearn: 0.2903335\ttotal: 17.7s\tremaining: 16s\n",
            "526:\tlearn: 0.2903037\ttotal: 17.8s\tremaining: 15.9s\n",
            "527:\tlearn: 0.2902703\ttotal: 17.8s\tremaining: 15.9s\n",
            "528:\tlearn: 0.2902401\ttotal: 17.8s\tremaining: 15.9s\n",
            "529:\tlearn: 0.2902150\ttotal: 17.8s\tremaining: 15.8s\n",
            "530:\tlearn: 0.2901716\ttotal: 17.9s\tremaining: 15.8s\n",
            "531:\tlearn: 0.2901474\ttotal: 17.9s\tremaining: 15.8s\n",
            "532:\tlearn: 0.2901290\ttotal: 17.9s\tremaining: 15.7s\n",
            "533:\tlearn: 0.2900984\ttotal: 18s\tremaining: 15.7s\n",
            "534:\tlearn: 0.2900717\ttotal: 18s\tremaining: 15.6s\n",
            "535:\tlearn: 0.2900475\ttotal: 18s\tremaining: 15.6s\n",
            "536:\tlearn: 0.2900186\ttotal: 18.1s\tremaining: 15.6s\n",
            "537:\tlearn: 0.2899842\ttotal: 18.1s\tremaining: 15.5s\n",
            "538:\tlearn: 0.2899674\ttotal: 18.1s\tremaining: 15.5s\n",
            "539:\tlearn: 0.2899387\ttotal: 18.1s\tremaining: 15.4s\n",
            "540:\tlearn: 0.2899068\ttotal: 18.2s\tremaining: 15.4s\n",
            "541:\tlearn: 0.2898777\ttotal: 18.2s\tremaining: 15.4s\n",
            "542:\tlearn: 0.2898509\ttotal: 18.2s\tremaining: 15.3s\n",
            "543:\tlearn: 0.2898199\ttotal: 18.2s\tremaining: 15.3s\n",
            "544:\tlearn: 0.2897943\ttotal: 18.3s\tremaining: 15.3s\n",
            "545:\tlearn: 0.2897676\ttotal: 18.3s\tremaining: 15.2s\n",
            "546:\tlearn: 0.2897348\ttotal: 18.3s\tremaining: 15.2s\n",
            "547:\tlearn: 0.2897036\ttotal: 18.3s\tremaining: 15.1s\n",
            "548:\tlearn: 0.2896864\ttotal: 18.4s\tremaining: 15.1s\n",
            "549:\tlearn: 0.2896553\ttotal: 18.4s\tremaining: 15.1s\n",
            "550:\tlearn: 0.2896313\ttotal: 18.4s\tremaining: 15s\n",
            "551:\tlearn: 0.2895974\ttotal: 18.5s\tremaining: 15s\n",
            "552:\tlearn: 0.2895713\ttotal: 18.5s\tremaining: 14.9s\n",
            "553:\tlearn: 0.2895466\ttotal: 18.5s\tremaining: 14.9s\n",
            "554:\tlearn: 0.2895229\ttotal: 18.5s\tremaining: 14.9s\n",
            "555:\tlearn: 0.2895003\ttotal: 18.6s\tremaining: 14.8s\n",
            "556:\tlearn: 0.2894737\ttotal: 18.6s\tremaining: 14.8s\n",
            "557:\tlearn: 0.2894370\ttotal: 18.6s\tremaining: 14.8s\n",
            "558:\tlearn: 0.2894131\ttotal: 18.7s\tremaining: 14.7s\n",
            "559:\tlearn: 0.2893732\ttotal: 18.7s\tremaining: 14.7s\n",
            "560:\tlearn: 0.2893563\ttotal: 18.7s\tremaining: 14.6s\n",
            "561:\tlearn: 0.2893375\ttotal: 18.7s\tremaining: 14.6s\n",
            "562:\tlearn: 0.2893140\ttotal: 18.8s\tremaining: 14.6s\n",
            "563:\tlearn: 0.2892738\ttotal: 18.8s\tremaining: 14.5s\n",
            "564:\tlearn: 0.2892498\ttotal: 18.8s\tremaining: 14.5s\n",
            "565:\tlearn: 0.2892114\ttotal: 18.9s\tremaining: 14.5s\n",
            "566:\tlearn: 0.2891809\ttotal: 18.9s\tremaining: 14.4s\n",
            "567:\tlearn: 0.2891487\ttotal: 18.9s\tremaining: 14.4s\n",
            "568:\tlearn: 0.2891081\ttotal: 19s\tremaining: 14.4s\n",
            "569:\tlearn: 0.2890911\ttotal: 19s\tremaining: 14.3s\n",
            "570:\tlearn: 0.2890626\ttotal: 19s\tremaining: 14.3s\n",
            "571:\tlearn: 0.2890515\ttotal: 19s\tremaining: 14.2s\n",
            "572:\tlearn: 0.2890179\ttotal: 19.1s\tremaining: 14.2s\n",
            "573:\tlearn: 0.2889811\ttotal: 19.1s\tremaining: 14.2s\n",
            "574:\tlearn: 0.2889448\ttotal: 19.1s\tremaining: 14.1s\n",
            "575:\tlearn: 0.2889246\ttotal: 19.1s\tremaining: 14.1s\n",
            "576:\tlearn: 0.2889087\ttotal: 19.2s\tremaining: 14.1s\n",
            "577:\tlearn: 0.2888686\ttotal: 19.2s\tremaining: 14s\n",
            "578:\tlearn: 0.2888331\ttotal: 19.2s\tremaining: 14s\n",
            "579:\tlearn: 0.2888029\ttotal: 19.3s\tremaining: 13.9s\n",
            "580:\tlearn: 0.2887651\ttotal: 19.3s\tremaining: 13.9s\n",
            "581:\tlearn: 0.2887271\ttotal: 19.3s\tremaining: 13.9s\n",
            "582:\tlearn: 0.2887062\ttotal: 19.3s\tremaining: 13.8s\n",
            "583:\tlearn: 0.2886871\ttotal: 19.4s\tremaining: 13.8s\n",
            "584:\tlearn: 0.2886561\ttotal: 19.4s\tremaining: 13.8s\n",
            "585:\tlearn: 0.2886140\ttotal: 19.4s\tremaining: 13.7s\n",
            "586:\tlearn: 0.2885877\ttotal: 19.4s\tremaining: 13.7s\n",
            "587:\tlearn: 0.2885686\ttotal: 19.5s\tremaining: 13.6s\n",
            "588:\tlearn: 0.2885508\ttotal: 19.5s\tremaining: 13.6s\n",
            "589:\tlearn: 0.2885253\ttotal: 19.5s\tremaining: 13.6s\n",
            "590:\tlearn: 0.2884993\ttotal: 19.6s\tremaining: 13.5s\n",
            "591:\tlearn: 0.2884791\ttotal: 19.6s\tremaining: 13.5s\n",
            "592:\tlearn: 0.2884496\ttotal: 19.6s\tremaining: 13.5s\n",
            "593:\tlearn: 0.2884265\ttotal: 19.6s\tremaining: 13.4s\n",
            "594:\tlearn: 0.2883952\ttotal: 19.7s\tremaining: 13.4s\n",
            "595:\tlearn: 0.2883634\ttotal: 19.7s\tremaining: 13.3s\n",
            "596:\tlearn: 0.2883232\ttotal: 19.7s\tremaining: 13.3s\n",
            "597:\tlearn: 0.2882993\ttotal: 19.7s\tremaining: 13.3s\n",
            "598:\tlearn: 0.2882527\ttotal: 19.8s\tremaining: 13.2s\n",
            "599:\tlearn: 0.2882179\ttotal: 19.8s\tremaining: 13.2s\n",
            "600:\tlearn: 0.2881822\ttotal: 19.8s\tremaining: 13.2s\n",
            "601:\tlearn: 0.2881579\ttotal: 19.9s\tremaining: 13.1s\n",
            "602:\tlearn: 0.2881325\ttotal: 19.9s\tremaining: 13.1s\n",
            "603:\tlearn: 0.2881020\ttotal: 19.9s\tremaining: 13.1s\n",
            "604:\tlearn: 0.2880795\ttotal: 20s\tremaining: 13s\n",
            "605:\tlearn: 0.2880546\ttotal: 20s\tremaining: 13s\n",
            "606:\tlearn: 0.2880117\ttotal: 20s\tremaining: 13s\n",
            "607:\tlearn: 0.2879902\ttotal: 20s\tremaining: 12.9s\n",
            "608:\tlearn: 0.2879572\ttotal: 20.1s\tremaining: 12.9s\n",
            "609:\tlearn: 0.2879212\ttotal: 20.1s\tremaining: 12.9s\n",
            "610:\tlearn: 0.2878887\ttotal: 20.1s\tremaining: 12.8s\n",
            "611:\tlearn: 0.2878574\ttotal: 20.2s\tremaining: 12.8s\n",
            "612:\tlearn: 0.2878354\ttotal: 20.2s\tremaining: 12.7s\n",
            "613:\tlearn: 0.2878162\ttotal: 20.2s\tremaining: 12.7s\n",
            "614:\tlearn: 0.2877882\ttotal: 20.2s\tremaining: 12.7s\n",
            "615:\tlearn: 0.2877618\ttotal: 20.3s\tremaining: 12.6s\n",
            "616:\tlearn: 0.2877423\ttotal: 20.3s\tremaining: 12.6s\n",
            "617:\tlearn: 0.2877169\ttotal: 20.3s\tremaining: 12.6s\n",
            "618:\tlearn: 0.2876928\ttotal: 20.3s\tremaining: 12.5s\n",
            "619:\tlearn: 0.2876595\ttotal: 20.4s\tremaining: 12.5s\n",
            "620:\tlearn: 0.2876284\ttotal: 20.4s\tremaining: 12.5s\n",
            "621:\tlearn: 0.2876108\ttotal: 20.4s\tremaining: 12.4s\n",
            "622:\tlearn: 0.2875795\ttotal: 20.5s\tremaining: 12.4s\n",
            "623:\tlearn: 0.2875440\ttotal: 20.5s\tremaining: 12.3s\n",
            "624:\tlearn: 0.2875198\ttotal: 20.5s\tremaining: 12.3s\n",
            "625:\tlearn: 0.2875071\ttotal: 20.5s\tremaining: 12.3s\n",
            "626:\tlearn: 0.2874728\ttotal: 20.6s\tremaining: 12.2s\n",
            "627:\tlearn: 0.2874508\ttotal: 20.6s\tremaining: 12.2s\n",
            "628:\tlearn: 0.2874256\ttotal: 20.6s\tremaining: 12.2s\n",
            "629:\tlearn: 0.2873959\ttotal: 20.7s\tremaining: 12.1s\n",
            "630:\tlearn: 0.2873615\ttotal: 20.7s\tremaining: 12.1s\n",
            "631:\tlearn: 0.2873472\ttotal: 20.7s\tremaining: 12.1s\n",
            "632:\tlearn: 0.2873127\ttotal: 20.7s\tremaining: 12s\n",
            "633:\tlearn: 0.2872892\ttotal: 20.8s\tremaining: 12s\n",
            "634:\tlearn: 0.2872749\ttotal: 20.8s\tremaining: 12s\n",
            "635:\tlearn: 0.2872316\ttotal: 20.8s\tremaining: 11.9s\n",
            "636:\tlearn: 0.2872050\ttotal: 20.8s\tremaining: 11.9s\n",
            "637:\tlearn: 0.2871875\ttotal: 20.9s\tremaining: 11.8s\n",
            "638:\tlearn: 0.2871522\ttotal: 20.9s\tremaining: 11.8s\n",
            "639:\tlearn: 0.2871287\ttotal: 20.9s\tremaining: 11.8s\n",
            "640:\tlearn: 0.2871064\ttotal: 21s\tremaining: 11.7s\n",
            "641:\tlearn: 0.2870806\ttotal: 21s\tremaining: 11.7s\n",
            "642:\tlearn: 0.2870704\ttotal: 21s\tremaining: 11.7s\n",
            "643:\tlearn: 0.2870418\ttotal: 21.1s\tremaining: 11.6s\n",
            "644:\tlearn: 0.2870219\ttotal: 21.1s\tremaining: 11.6s\n",
            "645:\tlearn: 0.2869950\ttotal: 21.1s\tremaining: 11.6s\n",
            "646:\tlearn: 0.2869657\ttotal: 21.1s\tremaining: 11.5s\n",
            "647:\tlearn: 0.2869301\ttotal: 21.2s\tremaining: 11.5s\n",
            "648:\tlearn: 0.2869006\ttotal: 21.2s\tremaining: 11.5s\n",
            "649:\tlearn: 0.2868804\ttotal: 21.2s\tremaining: 11.4s\n",
            "650:\tlearn: 0.2868635\ttotal: 21.2s\tremaining: 11.4s\n",
            "651:\tlearn: 0.2868370\ttotal: 21.3s\tremaining: 11.4s\n",
            "652:\tlearn: 0.2868096\ttotal: 21.3s\tremaining: 11.3s\n",
            "653:\tlearn: 0.2867740\ttotal: 21.3s\tremaining: 11.3s\n",
            "654:\tlearn: 0.2867552\ttotal: 21.3s\tremaining: 11.2s\n",
            "655:\tlearn: 0.2867265\ttotal: 21.4s\tremaining: 11.2s\n",
            "656:\tlearn: 0.2867109\ttotal: 21.4s\tremaining: 11.2s\n",
            "657:\tlearn: 0.2866771\ttotal: 21.4s\tremaining: 11.1s\n",
            "658:\tlearn: 0.2866461\ttotal: 21.5s\tremaining: 11.1s\n",
            "659:\tlearn: 0.2866249\ttotal: 21.5s\tremaining: 11.1s\n",
            "660:\tlearn: 0.2865901\ttotal: 21.5s\tremaining: 11s\n",
            "661:\tlearn: 0.2865590\ttotal: 21.5s\tremaining: 11s\n",
            "662:\tlearn: 0.2865308\ttotal: 21.6s\tremaining: 11s\n",
            "663:\tlearn: 0.2865008\ttotal: 21.6s\tremaining: 10.9s\n",
            "664:\tlearn: 0.2864736\ttotal: 21.6s\tremaining: 10.9s\n",
            "665:\tlearn: 0.2864452\ttotal: 21.7s\tremaining: 10.9s\n",
            "666:\tlearn: 0.2864300\ttotal: 21.7s\tremaining: 10.8s\n",
            "667:\tlearn: 0.2864016\ttotal: 21.7s\tremaining: 10.8s\n",
            "668:\tlearn: 0.2863825\ttotal: 21.7s\tremaining: 10.8s\n",
            "669:\tlearn: 0.2863547\ttotal: 21.8s\tremaining: 10.7s\n",
            "670:\tlearn: 0.2863257\ttotal: 21.8s\tremaining: 10.7s\n",
            "671:\tlearn: 0.2862987\ttotal: 21.8s\tremaining: 10.6s\n",
            "672:\tlearn: 0.2862837\ttotal: 21.8s\tremaining: 10.6s\n",
            "673:\tlearn: 0.2862526\ttotal: 21.9s\tremaining: 10.6s\n",
            "674:\tlearn: 0.2862135\ttotal: 21.9s\tremaining: 10.5s\n",
            "675:\tlearn: 0.2861921\ttotal: 21.9s\tremaining: 10.5s\n",
            "676:\tlearn: 0.2861632\ttotal: 22s\tremaining: 10.5s\n",
            "677:\tlearn: 0.2861216\ttotal: 22s\tremaining: 10.4s\n",
            "678:\tlearn: 0.2861025\ttotal: 22s\tremaining: 10.4s\n",
            "679:\tlearn: 0.2860738\ttotal: 22.1s\tremaining: 10.4s\n",
            "680:\tlearn: 0.2860470\ttotal: 22.1s\tremaining: 10.3s\n",
            "681:\tlearn: 0.2860218\ttotal: 22.1s\tremaining: 10.3s\n",
            "682:\tlearn: 0.2860066\ttotal: 22.1s\tremaining: 10.3s\n",
            "683:\tlearn: 0.2859793\ttotal: 22.2s\tremaining: 10.2s\n",
            "684:\tlearn: 0.2859551\ttotal: 22.2s\tremaining: 10.2s\n",
            "685:\tlearn: 0.2859261\ttotal: 22.2s\tremaining: 10.2s\n",
            "686:\tlearn: 0.2858934\ttotal: 22.2s\tremaining: 10.1s\n",
            "687:\tlearn: 0.2858677\ttotal: 22.3s\tremaining: 10.1s\n",
            "688:\tlearn: 0.2858452\ttotal: 22.3s\tremaining: 10.1s\n",
            "689:\tlearn: 0.2858219\ttotal: 22.3s\tremaining: 10s\n",
            "690:\tlearn: 0.2857867\ttotal: 22.4s\tremaining: 9.99s\n",
            "691:\tlearn: 0.2857570\ttotal: 22.4s\tremaining: 9.96s\n",
            "692:\tlearn: 0.2857248\ttotal: 22.4s\tremaining: 9.93s\n",
            "693:\tlearn: 0.2857044\ttotal: 22.4s\tremaining: 9.89s\n",
            "694:\tlearn: 0.2856669\ttotal: 22.5s\tremaining: 9.86s\n",
            "695:\tlearn: 0.2856521\ttotal: 22.5s\tremaining: 9.83s\n",
            "696:\tlearn: 0.2856242\ttotal: 22.5s\tremaining: 9.79s\n",
            "697:\tlearn: 0.2855920\ttotal: 22.6s\tremaining: 9.76s\n",
            "698:\tlearn: 0.2855533\ttotal: 22.6s\tremaining: 9.72s\n",
            "699:\tlearn: 0.2855199\ttotal: 22.6s\tremaining: 9.69s\n",
            "700:\tlearn: 0.2854891\ttotal: 22.6s\tremaining: 9.65s\n",
            "701:\tlearn: 0.2854549\ttotal: 22.7s\tremaining: 9.62s\n",
            "702:\tlearn: 0.2854225\ttotal: 22.7s\tremaining: 9.58s\n",
            "703:\tlearn: 0.2853809\ttotal: 22.7s\tremaining: 9.55s\n",
            "704:\tlearn: 0.2853487\ttotal: 22.7s\tremaining: 9.52s\n",
            "705:\tlearn: 0.2853164\ttotal: 22.8s\tremaining: 9.48s\n",
            "706:\tlearn: 0.2852911\ttotal: 22.8s\tremaining: 9.45s\n",
            "707:\tlearn: 0.2852667\ttotal: 22.8s\tremaining: 9.41s\n",
            "708:\tlearn: 0.2852415\ttotal: 22.8s\tremaining: 9.38s\n",
            "709:\tlearn: 0.2852192\ttotal: 22.9s\tremaining: 9.34s\n",
            "710:\tlearn: 0.2851912\ttotal: 22.9s\tremaining: 9.31s\n",
            "711:\tlearn: 0.2851727\ttotal: 22.9s\tremaining: 9.28s\n",
            "712:\tlearn: 0.2851339\ttotal: 23s\tremaining: 9.25s\n",
            "713:\tlearn: 0.2851179\ttotal: 23s\tremaining: 9.21s\n",
            "714:\tlearn: 0.2850982\ttotal: 23s\tremaining: 9.18s\n",
            "715:\tlearn: 0.2850627\ttotal: 23.1s\tremaining: 9.14s\n",
            "716:\tlearn: 0.2850349\ttotal: 23.1s\tremaining: 9.11s\n",
            "717:\tlearn: 0.2850116\ttotal: 23.1s\tremaining: 9.07s\n",
            "718:\tlearn: 0.2849677\ttotal: 23.1s\tremaining: 9.04s\n",
            "719:\tlearn: 0.2849460\ttotal: 23.2s\tremaining: 9.01s\n",
            "720:\tlearn: 0.2849174\ttotal: 23.2s\tremaining: 8.97s\n",
            "721:\tlearn: 0.2848919\ttotal: 23.2s\tremaining: 8.94s\n",
            "722:\tlearn: 0.2848588\ttotal: 23.2s\tremaining: 8.9s\n",
            "723:\tlearn: 0.2848289\ttotal: 23.3s\tremaining: 8.87s\n",
            "724:\tlearn: 0.2848009\ttotal: 23.3s\tremaining: 8.84s\n",
            "725:\tlearn: 0.2847661\ttotal: 23.3s\tremaining: 8.8s\n",
            "726:\tlearn: 0.2847416\ttotal: 23.3s\tremaining: 8.77s\n",
            "727:\tlearn: 0.2847131\ttotal: 23.4s\tremaining: 8.73s\n",
            "728:\tlearn: 0.2846868\ttotal: 23.4s\tremaining: 8.7s\n",
            "729:\tlearn: 0.2846569\ttotal: 23.4s\tremaining: 8.67s\n",
            "730:\tlearn: 0.2846280\ttotal: 23.5s\tremaining: 8.63s\n",
            "731:\tlearn: 0.2845970\ttotal: 23.5s\tremaining: 8.6s\n",
            "732:\tlearn: 0.2845578\ttotal: 23.5s\tremaining: 8.56s\n",
            "733:\tlearn: 0.2845296\ttotal: 23.5s\tremaining: 8.53s\n",
            "734:\tlearn: 0.2845082\ttotal: 23.6s\tremaining: 8.5s\n",
            "735:\tlearn: 0.2844808\ttotal: 23.6s\tremaining: 8.46s\n",
            "736:\tlearn: 0.2844518\ttotal: 23.6s\tremaining: 8.43s\n",
            "737:\tlearn: 0.2844303\ttotal: 23.6s\tremaining: 8.4s\n",
            "738:\tlearn: 0.2844087\ttotal: 23.7s\tremaining: 8.36s\n",
            "739:\tlearn: 0.2843777\ttotal: 23.7s\tremaining: 8.33s\n",
            "740:\tlearn: 0.2843475\ttotal: 23.7s\tremaining: 8.29s\n",
            "741:\tlearn: 0.2843184\ttotal: 23.8s\tremaining: 8.26s\n",
            "742:\tlearn: 0.2842889\ttotal: 23.8s\tremaining: 8.23s\n",
            "743:\tlearn: 0.2842569\ttotal: 23.8s\tremaining: 8.2s\n",
            "744:\tlearn: 0.2842370\ttotal: 23.8s\tremaining: 8.16s\n",
            "745:\tlearn: 0.2842134\ttotal: 23.9s\tremaining: 8.13s\n",
            "746:\tlearn: 0.2841820\ttotal: 23.9s\tremaining: 8.09s\n",
            "747:\tlearn: 0.2841643\ttotal: 23.9s\tremaining: 8.06s\n",
            "748:\tlearn: 0.2841364\ttotal: 24s\tremaining: 8.03s\n",
            "749:\tlearn: 0.2841124\ttotal: 24s\tremaining: 8s\n",
            "750:\tlearn: 0.2840905\ttotal: 24s\tremaining: 7.96s\n",
            "751:\tlearn: 0.2840633\ttotal: 24.1s\tremaining: 7.93s\n",
            "752:\tlearn: 0.2840241\ttotal: 24.1s\tremaining: 7.9s\n",
            "753:\tlearn: 0.2839989\ttotal: 24.1s\tremaining: 7.87s\n",
            "754:\tlearn: 0.2839847\ttotal: 24.1s\tremaining: 7.83s\n",
            "755:\tlearn: 0.2839539\ttotal: 24.2s\tremaining: 7.8s\n",
            "756:\tlearn: 0.2839251\ttotal: 24.2s\tremaining: 7.76s\n",
            "757:\tlearn: 0.2838931\ttotal: 24.2s\tremaining: 7.73s\n",
            "758:\tlearn: 0.2838674\ttotal: 24.2s\tremaining: 7.7s\n",
            "759:\tlearn: 0.2838539\ttotal: 24.3s\tremaining: 7.67s\n",
            "760:\tlearn: 0.2838243\ttotal: 24.3s\tremaining: 7.63s\n",
            "761:\tlearn: 0.2838084\ttotal: 24.3s\tremaining: 7.6s\n",
            "762:\tlearn: 0.2837883\ttotal: 24.4s\tremaining: 7.56s\n",
            "763:\tlearn: 0.2837514\ttotal: 24.4s\tremaining: 7.53s\n",
            "764:\tlearn: 0.2837304\ttotal: 24.4s\tremaining: 7.5s\n",
            "765:\tlearn: 0.2836995\ttotal: 24.4s\tremaining: 7.46s\n",
            "766:\tlearn: 0.2836788\ttotal: 24.5s\tremaining: 7.43s\n",
            "767:\tlearn: 0.2836490\ttotal: 24.5s\tremaining: 7.4s\n",
            "768:\tlearn: 0.2836087\ttotal: 24.5s\tremaining: 7.37s\n",
            "769:\tlearn: 0.2835877\ttotal: 24.6s\tremaining: 7.33s\n",
            "770:\tlearn: 0.2835635\ttotal: 24.6s\tremaining: 7.3s\n",
            "771:\tlearn: 0.2835363\ttotal: 24.6s\tremaining: 7.27s\n",
            "772:\tlearn: 0.2835219\ttotal: 24.6s\tremaining: 7.23s\n",
            "773:\tlearn: 0.2834973\ttotal: 24.7s\tremaining: 7.2s\n",
            "774:\tlearn: 0.2834729\ttotal: 24.7s\tremaining: 7.17s\n",
            "775:\tlearn: 0.2834590\ttotal: 24.7s\tremaining: 7.13s\n",
            "776:\tlearn: 0.2834327\ttotal: 24.7s\tremaining: 7.1s\n",
            "777:\tlearn: 0.2834096\ttotal: 24.8s\tremaining: 7.07s\n",
            "778:\tlearn: 0.2833804\ttotal: 24.8s\tremaining: 7.04s\n",
            "779:\tlearn: 0.2833682\ttotal: 24.8s\tremaining: 7s\n",
            "780:\tlearn: 0.2833376\ttotal: 24.9s\tremaining: 6.97s\n",
            "781:\tlearn: 0.2833166\ttotal: 24.9s\tremaining: 6.94s\n",
            "782:\tlearn: 0.2832849\ttotal: 24.9s\tremaining: 6.91s\n",
            "783:\tlearn: 0.2832572\ttotal: 24.9s\tremaining: 6.87s\n",
            "784:\tlearn: 0.2832201\ttotal: 25s\tremaining: 6.84s\n",
            "785:\tlearn: 0.2831938\ttotal: 25s\tremaining: 6.81s\n",
            "786:\tlearn: 0.2831547\ttotal: 25.1s\tremaining: 6.78s\n",
            "787:\tlearn: 0.2831330\ttotal: 25.1s\tremaining: 6.75s\n",
            "788:\tlearn: 0.2831164\ttotal: 25.1s\tremaining: 6.71s\n",
            "789:\tlearn: 0.2830865\ttotal: 25.1s\tremaining: 6.68s\n",
            "790:\tlearn: 0.2830592\ttotal: 25.2s\tremaining: 6.65s\n",
            "791:\tlearn: 0.2830363\ttotal: 25.2s\tremaining: 6.62s\n",
            "792:\tlearn: 0.2830082\ttotal: 25.2s\tremaining: 6.58s\n",
            "793:\tlearn: 0.2829710\ttotal: 25.2s\tremaining: 6.55s\n",
            "794:\tlearn: 0.2829442\ttotal: 25.3s\tremaining: 6.52s\n",
            "795:\tlearn: 0.2829321\ttotal: 25.3s\tremaining: 6.48s\n",
            "796:\tlearn: 0.2828967\ttotal: 25.3s\tremaining: 6.45s\n",
            "797:\tlearn: 0.2828778\ttotal: 25.4s\tremaining: 6.42s\n",
            "798:\tlearn: 0.2828642\ttotal: 25.4s\tremaining: 6.38s\n",
            "799:\tlearn: 0.2828419\ttotal: 25.4s\tremaining: 6.35s\n",
            "800:\tlearn: 0.2828219\ttotal: 25.4s\tremaining: 6.32s\n",
            "801:\tlearn: 0.2827888\ttotal: 25.5s\tremaining: 6.29s\n",
            "802:\tlearn: 0.2827661\ttotal: 25.5s\tremaining: 6.25s\n",
            "803:\tlearn: 0.2827392\ttotal: 25.5s\tremaining: 6.22s\n",
            "804:\tlearn: 0.2827100\ttotal: 25.5s\tremaining: 6.19s\n",
            "805:\tlearn: 0.2826915\ttotal: 25.6s\tremaining: 6.16s\n",
            "806:\tlearn: 0.2826656\ttotal: 25.6s\tremaining: 6.12s\n",
            "807:\tlearn: 0.2826456\ttotal: 25.6s\tremaining: 6.09s\n",
            "808:\tlearn: 0.2826183\ttotal: 25.7s\tremaining: 6.06s\n",
            "809:\tlearn: 0.2825921\ttotal: 25.7s\tremaining: 6.02s\n",
            "810:\tlearn: 0.2825636\ttotal: 25.7s\tremaining: 5.99s\n",
            "811:\tlearn: 0.2825532\ttotal: 25.7s\tremaining: 5.96s\n",
            "812:\tlearn: 0.2825354\ttotal: 25.8s\tremaining: 5.93s\n",
            "813:\tlearn: 0.2825048\ttotal: 25.8s\tremaining: 5.89s\n",
            "814:\tlearn: 0.2824733\ttotal: 25.8s\tremaining: 5.86s\n",
            "815:\tlearn: 0.2824433\ttotal: 25.8s\tremaining: 5.83s\n",
            "816:\tlearn: 0.2824092\ttotal: 25.9s\tremaining: 5.8s\n",
            "817:\tlearn: 0.2823781\ttotal: 25.9s\tremaining: 5.76s\n",
            "818:\tlearn: 0.2823560\ttotal: 25.9s\tremaining: 5.73s\n",
            "819:\tlearn: 0.2823296\ttotal: 26s\tremaining: 5.7s\n",
            "820:\tlearn: 0.2823140\ttotal: 26s\tremaining: 5.67s\n",
            "821:\tlearn: 0.2822978\ttotal: 26s\tremaining: 5.64s\n",
            "822:\tlearn: 0.2822719\ttotal: 26.1s\tremaining: 5.61s\n",
            "823:\tlearn: 0.2822448\ttotal: 26.1s\tremaining: 5.57s\n",
            "824:\tlearn: 0.2822167\ttotal: 26.1s\tremaining: 5.54s\n",
            "825:\tlearn: 0.2822052\ttotal: 26.1s\tremaining: 5.51s\n",
            "826:\tlearn: 0.2821796\ttotal: 26.2s\tremaining: 5.47s\n",
            "827:\tlearn: 0.2821677\ttotal: 26.2s\tremaining: 5.44s\n",
            "828:\tlearn: 0.2821416\ttotal: 26.2s\tremaining: 5.41s\n",
            "829:\tlearn: 0.2821178\ttotal: 26.3s\tremaining: 5.38s\n",
            "830:\tlearn: 0.2820935\ttotal: 26.3s\tremaining: 5.34s\n",
            "831:\tlearn: 0.2820613\ttotal: 26.3s\tremaining: 5.31s\n",
            "832:\tlearn: 0.2820334\ttotal: 26.3s\tremaining: 5.28s\n",
            "833:\tlearn: 0.2820089\ttotal: 26.4s\tremaining: 5.25s\n",
            "834:\tlearn: 0.2819759\ttotal: 26.4s\tremaining: 5.22s\n",
            "835:\tlearn: 0.2819453\ttotal: 26.4s\tremaining: 5.18s\n",
            "836:\tlearn: 0.2819270\ttotal: 26.5s\tremaining: 5.15s\n",
            "837:\tlearn: 0.2819041\ttotal: 26.5s\tremaining: 5.12s\n",
            "838:\tlearn: 0.2818894\ttotal: 26.5s\tremaining: 5.09s\n",
            "839:\tlearn: 0.2818662\ttotal: 26.5s\tremaining: 5.05s\n",
            "840:\tlearn: 0.2818382\ttotal: 26.6s\tremaining: 5.02s\n",
            "841:\tlearn: 0.2818060\ttotal: 26.6s\tremaining: 4.99s\n",
            "842:\tlearn: 0.2817786\ttotal: 26.6s\tremaining: 4.96s\n",
            "843:\tlearn: 0.2817543\ttotal: 26.7s\tremaining: 4.93s\n",
            "844:\tlearn: 0.2817256\ttotal: 26.7s\tremaining: 4.89s\n",
            "845:\tlearn: 0.2816968\ttotal: 26.7s\tremaining: 4.86s\n",
            "846:\tlearn: 0.2816623\ttotal: 26.7s\tremaining: 4.83s\n",
            "847:\tlearn: 0.2816449\ttotal: 26.8s\tremaining: 4.8s\n",
            "848:\tlearn: 0.2816281\ttotal: 26.8s\tremaining: 4.76s\n",
            "849:\tlearn: 0.2816003\ttotal: 26.8s\tremaining: 4.73s\n",
            "850:\tlearn: 0.2815806\ttotal: 26.8s\tremaining: 4.7s\n",
            "851:\tlearn: 0.2815513\ttotal: 26.9s\tremaining: 4.67s\n",
            "852:\tlearn: 0.2815356\ttotal: 26.9s\tremaining: 4.63s\n",
            "853:\tlearn: 0.2815146\ttotal: 26.9s\tremaining: 4.6s\n",
            "854:\tlearn: 0.2814878\ttotal: 27s\tremaining: 4.57s\n",
            "855:\tlearn: 0.2814536\ttotal: 27s\tremaining: 4.54s\n",
            "856:\tlearn: 0.2814253\ttotal: 27.1s\tremaining: 4.51s\n",
            "857:\tlearn: 0.2813994\ttotal: 27.1s\tremaining: 4.49s\n",
            "858:\tlearn: 0.2813815\ttotal: 27.1s\tremaining: 4.45s\n",
            "859:\tlearn: 0.2813462\ttotal: 27.2s\tremaining: 4.43s\n",
            "860:\tlearn: 0.2813247\ttotal: 27.2s\tremaining: 4.4s\n",
            "861:\tlearn: 0.2813116\ttotal: 27.3s\tremaining: 4.37s\n",
            "862:\tlearn: 0.2812870\ttotal: 27.4s\tremaining: 4.34s\n",
            "863:\tlearn: 0.2812651\ttotal: 27.4s\tremaining: 4.32s\n",
            "864:\tlearn: 0.2812428\ttotal: 27.5s\tremaining: 4.29s\n",
            "865:\tlearn: 0.2812242\ttotal: 27.5s\tremaining: 4.26s\n",
            "866:\tlearn: 0.2811995\ttotal: 27.6s\tremaining: 4.23s\n",
            "867:\tlearn: 0.2811616\ttotal: 27.6s\tremaining: 4.2s\n",
            "868:\tlearn: 0.2811373\ttotal: 27.7s\tremaining: 4.17s\n",
            "869:\tlearn: 0.2811074\ttotal: 27.8s\tremaining: 4.15s\n",
            "870:\tlearn: 0.2810883\ttotal: 27.8s\tremaining: 4.12s\n",
            "871:\tlearn: 0.2810647\ttotal: 27.9s\tremaining: 4.09s\n",
            "872:\tlearn: 0.2810371\ttotal: 28s\tremaining: 4.07s\n",
            "873:\tlearn: 0.2810094\ttotal: 28s\tremaining: 4.04s\n",
            "874:\tlearn: 0.2809721\ttotal: 28.1s\tremaining: 4.01s\n",
            "875:\tlearn: 0.2809404\ttotal: 28.2s\tremaining: 3.99s\n",
            "876:\tlearn: 0.2809304\ttotal: 28.2s\tremaining: 3.96s\n",
            "877:\tlearn: 0.2808959\ttotal: 28.3s\tremaining: 3.93s\n",
            "878:\tlearn: 0.2808710\ttotal: 28.4s\tremaining: 3.9s\n",
            "879:\tlearn: 0.2808408\ttotal: 28.4s\tremaining: 3.88s\n",
            "880:\tlearn: 0.2808193\ttotal: 28.5s\tremaining: 3.85s\n",
            "881:\tlearn: 0.2807920\ttotal: 28.5s\tremaining: 3.82s\n",
            "882:\tlearn: 0.2807686\ttotal: 28.6s\tremaining: 3.79s\n",
            "883:\tlearn: 0.2807349\ttotal: 28.7s\tremaining: 3.76s\n",
            "884:\tlearn: 0.2807184\ttotal: 28.7s\tremaining: 3.73s\n",
            "885:\tlearn: 0.2806860\ttotal: 28.8s\tremaining: 3.71s\n",
            "886:\tlearn: 0.2806700\ttotal: 28.8s\tremaining: 3.67s\n",
            "887:\tlearn: 0.2806438\ttotal: 28.9s\tremaining: 3.64s\n",
            "888:\tlearn: 0.2806162\ttotal: 28.9s\tremaining: 3.61s\n",
            "889:\tlearn: 0.2805825\ttotal: 29s\tremaining: 3.58s\n",
            "890:\tlearn: 0.2805534\ttotal: 29s\tremaining: 3.55s\n",
            "891:\tlearn: 0.2805138\ttotal: 29.1s\tremaining: 3.52s\n",
            "892:\tlearn: 0.2804931\ttotal: 29.2s\tremaining: 3.49s\n",
            "893:\tlearn: 0.2804683\ttotal: 29.2s\tremaining: 3.46s\n",
            "894:\tlearn: 0.2804420\ttotal: 29.3s\tremaining: 3.44s\n",
            "895:\tlearn: 0.2804023\ttotal: 29.4s\tremaining: 3.41s\n",
            "896:\tlearn: 0.2803866\ttotal: 29.4s\tremaining: 3.38s\n",
            "897:\tlearn: 0.2803519\ttotal: 29.5s\tremaining: 3.35s\n",
            "898:\tlearn: 0.2803402\ttotal: 29.5s\tremaining: 3.32s\n",
            "899:\tlearn: 0.2803060\ttotal: 29.6s\tremaining: 3.29s\n",
            "900:\tlearn: 0.2802721\ttotal: 29.7s\tremaining: 3.26s\n",
            "901:\tlearn: 0.2802465\ttotal: 29.8s\tremaining: 3.23s\n",
            "902:\tlearn: 0.2802221\ttotal: 29.8s\tremaining: 3.2s\n",
            "903:\tlearn: 0.2801974\ttotal: 29.8s\tremaining: 3.17s\n",
            "904:\tlearn: 0.2801756\ttotal: 29.9s\tremaining: 3.13s\n",
            "905:\tlearn: 0.2801499\ttotal: 29.9s\tremaining: 3.1s\n",
            "906:\tlearn: 0.2801038\ttotal: 29.9s\tremaining: 3.07s\n",
            "907:\tlearn: 0.2800727\ttotal: 29.9s\tremaining: 3.03s\n",
            "908:\tlearn: 0.2800491\ttotal: 30s\tremaining: 3s\n",
            "909:\tlearn: 0.2800217\ttotal: 30s\tremaining: 2.97s\n",
            "910:\tlearn: 0.2799897\ttotal: 30s\tremaining: 2.93s\n",
            "911:\tlearn: 0.2799659\ttotal: 30s\tremaining: 2.9s\n",
            "912:\tlearn: 0.2799517\ttotal: 30.1s\tremaining: 2.87s\n",
            "913:\tlearn: 0.2799368\ttotal: 30.1s\tremaining: 2.83s\n",
            "914:\tlearn: 0.2799073\ttotal: 30.1s\tremaining: 2.8s\n",
            "915:\tlearn: 0.2798848\ttotal: 30.2s\tremaining: 2.77s\n",
            "916:\tlearn: 0.2798630\ttotal: 30.2s\tremaining: 2.73s\n",
            "917:\tlearn: 0.2798319\ttotal: 30.2s\tremaining: 2.7s\n",
            "918:\tlearn: 0.2798091\ttotal: 30.3s\tremaining: 2.67s\n",
            "919:\tlearn: 0.2797824\ttotal: 30.3s\tremaining: 2.63s\n",
            "920:\tlearn: 0.2797582\ttotal: 30.3s\tremaining: 2.6s\n",
            "921:\tlearn: 0.2797370\ttotal: 30.4s\tremaining: 2.57s\n",
            "922:\tlearn: 0.2797147\ttotal: 30.4s\tremaining: 2.54s\n",
            "923:\tlearn: 0.2796929\ttotal: 30.4s\tremaining: 2.5s\n",
            "924:\tlearn: 0.2796747\ttotal: 30.4s\tremaining: 2.47s\n",
            "925:\tlearn: 0.2796498\ttotal: 30.5s\tremaining: 2.43s\n",
            "926:\tlearn: 0.2796186\ttotal: 30.5s\tremaining: 2.4s\n",
            "927:\tlearn: 0.2796035\ttotal: 30.5s\tremaining: 2.37s\n",
            "928:\tlearn: 0.2795862\ttotal: 30.5s\tremaining: 2.33s\n",
            "929:\tlearn: 0.2795718\ttotal: 30.6s\tremaining: 2.3s\n",
            "930:\tlearn: 0.2795645\ttotal: 30.6s\tremaining: 2.27s\n",
            "931:\tlearn: 0.2795555\ttotal: 30.6s\tremaining: 2.23s\n",
            "932:\tlearn: 0.2795355\ttotal: 30.7s\tremaining: 2.2s\n",
            "933:\tlearn: 0.2795097\ttotal: 30.7s\tremaining: 2.17s\n",
            "934:\tlearn: 0.2794718\ttotal: 30.7s\tremaining: 2.13s\n",
            "935:\tlearn: 0.2794474\ttotal: 30.7s\tremaining: 2.1s\n",
            "936:\tlearn: 0.2794223\ttotal: 30.8s\tremaining: 2.07s\n",
            "937:\tlearn: 0.2793958\ttotal: 30.8s\tremaining: 2.04s\n",
            "938:\tlearn: 0.2793666\ttotal: 30.8s\tremaining: 2s\n",
            "939:\tlearn: 0.2793512\ttotal: 30.9s\tremaining: 1.97s\n",
            "940:\tlearn: 0.2793205\ttotal: 30.9s\tremaining: 1.94s\n",
            "941:\tlearn: 0.2792926\ttotal: 30.9s\tremaining: 1.9s\n",
            "942:\tlearn: 0.2792730\ttotal: 30.9s\tremaining: 1.87s\n",
            "943:\tlearn: 0.2792257\ttotal: 31s\tremaining: 1.84s\n",
            "944:\tlearn: 0.2791955\ttotal: 31s\tremaining: 1.8s\n",
            "945:\tlearn: 0.2791787\ttotal: 31s\tremaining: 1.77s\n",
            "946:\tlearn: 0.2791538\ttotal: 31s\tremaining: 1.74s\n",
            "947:\tlearn: 0.2791180\ttotal: 31.1s\tremaining: 1.7s\n",
            "948:\tlearn: 0.2790850\ttotal: 31.1s\tremaining: 1.67s\n",
            "949:\tlearn: 0.2790552\ttotal: 31.1s\tremaining: 1.64s\n",
            "950:\tlearn: 0.2790281\ttotal: 31.2s\tremaining: 1.6s\n",
            "951:\tlearn: 0.2790060\ttotal: 31.2s\tremaining: 1.57s\n",
            "952:\tlearn: 0.2789864\ttotal: 31.2s\tremaining: 1.54s\n",
            "953:\tlearn: 0.2789687\ttotal: 31.3s\tremaining: 1.51s\n",
            "954:\tlearn: 0.2789577\ttotal: 31.3s\tremaining: 1.47s\n",
            "955:\tlearn: 0.2789384\ttotal: 31.3s\tremaining: 1.44s\n",
            "956:\tlearn: 0.2789156\ttotal: 31.3s\tremaining: 1.41s\n",
            "957:\tlearn: 0.2788960\ttotal: 31.4s\tremaining: 1.37s\n",
            "958:\tlearn: 0.2788707\ttotal: 31.4s\tremaining: 1.34s\n",
            "959:\tlearn: 0.2788403\ttotal: 31.4s\tremaining: 1.31s\n",
            "960:\tlearn: 0.2788217\ttotal: 31.4s\tremaining: 1.27s\n",
            "961:\tlearn: 0.2787914\ttotal: 31.5s\tremaining: 1.24s\n",
            "962:\tlearn: 0.2787499\ttotal: 31.5s\tremaining: 1.21s\n",
            "963:\tlearn: 0.2787216\ttotal: 31.5s\tremaining: 1.18s\n",
            "964:\tlearn: 0.2786990\ttotal: 31.6s\tremaining: 1.14s\n",
            "965:\tlearn: 0.2786730\ttotal: 31.6s\tremaining: 1.11s\n",
            "966:\tlearn: 0.2786482\ttotal: 31.6s\tremaining: 1.08s\n",
            "967:\tlearn: 0.2786247\ttotal: 31.6s\tremaining: 1.04s\n",
            "968:\tlearn: 0.2785740\ttotal: 31.7s\tremaining: 1.01s\n",
            "969:\tlearn: 0.2785552\ttotal: 31.7s\tremaining: 980ms\n",
            "970:\tlearn: 0.2785407\ttotal: 31.7s\tremaining: 947ms\n",
            "971:\tlearn: 0.2785190\ttotal: 31.7s\tremaining: 914ms\n",
            "972:\tlearn: 0.2784801\ttotal: 31.8s\tremaining: 882ms\n",
            "973:\tlearn: 0.2784636\ttotal: 31.8s\tremaining: 849ms\n",
            "974:\tlearn: 0.2784299\ttotal: 31.8s\tremaining: 816ms\n",
            "975:\tlearn: 0.2784000\ttotal: 31.9s\tremaining: 783ms\n",
            "976:\tlearn: 0.2783714\ttotal: 31.9s\tremaining: 751ms\n",
            "977:\tlearn: 0.2783420\ttotal: 31.9s\tremaining: 718ms\n",
            "978:\tlearn: 0.2783161\ttotal: 31.9s\tremaining: 685ms\n",
            "979:\tlearn: 0.2782860\ttotal: 32s\tremaining: 652ms\n",
            "980:\tlearn: 0.2782565\ttotal: 32s\tremaining: 620ms\n",
            "981:\tlearn: 0.2782365\ttotal: 32s\tremaining: 587ms\n",
            "982:\tlearn: 0.2782108\ttotal: 32s\tremaining: 554ms\n",
            "983:\tlearn: 0.2781915\ttotal: 32.1s\tremaining: 522ms\n",
            "984:\tlearn: 0.2781650\ttotal: 32.1s\tremaining: 489ms\n",
            "985:\tlearn: 0.2781521\ttotal: 32.1s\tremaining: 456ms\n",
            "986:\tlearn: 0.2781257\ttotal: 32.2s\tremaining: 424ms\n",
            "987:\tlearn: 0.2781107\ttotal: 32.2s\tremaining: 391ms\n",
            "988:\tlearn: 0.2780892\ttotal: 32.2s\tremaining: 358ms\n",
            "989:\tlearn: 0.2780627\ttotal: 32.2s\tremaining: 326ms\n",
            "990:\tlearn: 0.2780327\ttotal: 32.3s\tremaining: 293ms\n",
            "991:\tlearn: 0.2780155\ttotal: 32.3s\tremaining: 261ms\n",
            "992:\tlearn: 0.2779806\ttotal: 32.3s\tremaining: 228ms\n",
            "993:\tlearn: 0.2779647\ttotal: 32.4s\tremaining: 195ms\n",
            "994:\tlearn: 0.2779454\ttotal: 32.4s\tremaining: 163ms\n",
            "995:\tlearn: 0.2779183\ttotal: 32.4s\tremaining: 130ms\n",
            "996:\tlearn: 0.2778927\ttotal: 32.4s\tremaining: 97.6ms\n",
            "997:\tlearn: 0.2778621\ttotal: 32.5s\tremaining: 65.1ms\n",
            "998:\tlearn: 0.2778378\ttotal: 32.5s\tremaining: 32.5ms\n",
            "999:\tlearn: 0.2778049\ttotal: 32.5s\tremaining: 0us\n",
            "AUC-ROC Score: 0.8844217062039803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
        "        'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
        "    }\n",
        "\n",
        "    clf = CatBoostClassifier(**params, verbose=0, random_state=0)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Train classifier\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate classifier on validation set\n",
        "    y_pred = clf.predict_proba(X_val)[:, 1]\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "    return auc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_auc = study.best_value\n",
        "\n",
        "print(\"Best AUC:\", best_auc)\n",
        "print(\"Best Hyperparameters:\", best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htkxpSRq_hS6",
        "outputId": "a79c7f28-00af-4726-aa1f-e4ef2add3222"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 17:35:59,269] A new study created in memory with name: no-name-f0eb9037-9b1b-4e6a-82c9-786ec82cc9ca\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:36:16,768] Trial 0 finished with value: 0.8781499556695924 and parameters: {'iterations': 417, 'depth': 8, 'learning_rate': 0.12221958982704786, 'l2_leaf_reg': 0.06512013296560977, 'scale_pos_weight': 8.047541332666922}. Best is trial 0 with value: 0.8781499556695924.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:36:39,827] Trial 1 finished with value: 0.8892718265848307 and parameters: {'iterations': 810, 'depth': 5, 'learning_rate': 0.04881111341806022, 'l2_leaf_reg': 0.020740375280634046, 'scale_pos_weight': 7.690167082028772}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:37:03,798] Trial 2 finished with value: 0.888022735249157 and parameters: {'iterations': 445, 'depth': 9, 'learning_rate': 0.03433517526593721, 'l2_leaf_reg': 0.381878295739674, 'scale_pos_weight': 7.013223483846511}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:37:40,226] Trial 3 finished with value: 0.8840841896341074 and parameters: {'iterations': 671, 'depth': 9, 'learning_rate': 0.04905940188623615, 'l2_leaf_reg': 0.5893019604122923, 'scale_pos_weight': 5.581987571596098}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:37:51,295] Trial 4 finished with value: 0.8727580183168553 and parameters: {'iterations': 251, 'depth': 8, 'learning_rate': 0.2555039321226828, 'l2_leaf_reg': 0.06457730305835244, 'scale_pos_weight': 4.145063508145327}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:38:12,261] Trial 5 finished with value: 0.8802356219587928 and parameters: {'iterations': 380, 'depth': 9, 'learning_rate': 0.15002235584642015, 'l2_leaf_reg': 4.243946919665179, 'scale_pos_weight': 6.453928039543163}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:38:21,148] Trial 6 finished with value: 0.8837378764734307 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.2988766550639573, 'l2_leaf_reg': 6.495962456469655, 'scale_pos_weight': 9.10560427904876}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:38:30,879] Trial 7 finished with value: 0.8856214960095913 and parameters: {'iterations': 286, 'depth': 6, 'learning_rate': 0.2523019171767111, 'l2_leaf_reg': 0.1605430810522387, 'scale_pos_weight': 3.661128237057744}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:38:57,532] Trial 8 finished with value: 0.8878616084790207 and parameters: {'iterations': 839, 'depth': 6, 'learning_rate': 0.05568038343657539, 'l2_leaf_reg': 0.012390292780782334, 'scale_pos_weight': 5.622569545829604}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:39:30,080] Trial 9 finished with value: 0.8699410264990475 and parameters: {'iterations': 398, 'depth': 10, 'learning_rate': 0.16193086702989384, 'l2_leaf_reg': 0.7366165747529777, 'scale_pos_weight': 6.483628386721425}. Best is trial 1 with value: 0.8892718265848307.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:39:53,459] Trial 10 finished with value: 0.8893007185838283 and parameters: {'iterations': 945, 'depth': 4, 'learning_rate': 0.010254420744812693, 'l2_leaf_reg': 0.014625388595517479, 'scale_pos_weight': 0.5850022774936443}. Best is trial 10 with value: 0.8893007185838283.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:40:18,280] Trial 11 finished with value: 0.8894543465835547 and parameters: {'iterations': 995, 'depth': 4, 'learning_rate': 0.010218690847566004, 'l2_leaf_reg': 0.010079733899123521, 'scale_pos_weight': 0.838211453564512}. Best is trial 11 with value: 0.8894543465835547.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:40:42,518] Trial 12 finished with value: 0.8892983590097006 and parameters: {'iterations': 991, 'depth': 4, 'learning_rate': 0.010132079325390883, 'l2_leaf_reg': 0.010448064497969615, 'scale_pos_weight': 0.4777741013971887}. Best is trial 11 with value: 0.8894543465835547.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:41:07,206] Trial 13 finished with value: 0.8893641750564685 and parameters: {'iterations': 981, 'depth': 4, 'learning_rate': 0.011086498959821268, 'l2_leaf_reg': 0.040965409706502344, 'scale_pos_weight': 0.4068325146897415}. Best is trial 11 with value: 0.8894543465835547.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:41:26,907] Trial 14 finished with value: 0.890010183352132 and parameters: {'iterations': 667, 'depth': 5, 'learning_rate': 0.019695288963951483, 'l2_leaf_reg': 0.044284750703963996, 'scale_pos_weight': 1.9370952867573148}. Best is trial 14 with value: 0.890010183352132.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:41:44,860] Trial 15 finished with value: 0.8899668782269597 and parameters: {'iterations': 650, 'depth': 5, 'learning_rate': 0.020355472718175255, 'l2_leaf_reg': 0.1445182859190004, 'scale_pos_weight': 2.2326340768271633}. Best is trial 14 with value: 0.890010183352132.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:42:05,162] Trial 16 finished with value: 0.8899883152866457 and parameters: {'iterations': 610, 'depth': 6, 'learning_rate': 0.02134043193090618, 'l2_leaf_reg': 0.2075774466628336, 'scale_pos_weight': 2.371091078773077}. Best is trial 14 with value: 0.890010183352132.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:42:23,736] Trial 17 finished with value: 0.8900399008368152 and parameters: {'iterations': 596, 'depth': 6, 'learning_rate': 0.019480476649500037, 'l2_leaf_reg': 1.7985298502567144, 'scale_pos_weight': 2.4072610293480023}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:42:51,950] Trial 18 finished with value: 0.8900175615870215 and parameters: {'iterations': 744, 'depth': 7, 'learning_rate': 0.019268510999342996, 'l2_leaf_reg': 1.815892199976882, 'scale_pos_weight': 2.2446564090179386}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:43:19,195] Trial 19 finished with value: 0.8896083106217018 and parameters: {'iterations': 762, 'depth': 7, 'learning_rate': 0.027596262564016583, 'l2_leaf_reg': 1.7503753264293973, 'scale_pos_weight': 3.0549206133669573}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:43:38,026] Trial 20 finished with value: 0.8896229867344668 and parameters: {'iterations': 534, 'depth': 7, 'learning_rate': 0.015434271299883987, 'l2_leaf_reg': 1.6203373125168274, 'scale_pos_weight': 4.3852532318954385}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:43:59,558] Trial 21 finished with value: 0.8899587767789474 and parameters: {'iterations': 731, 'depth': 5, 'learning_rate': 0.01675629408749468, 'l2_leaf_reg': 1.558038148132568, 'scale_pos_weight': 1.8530184833492647}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:44:16,442] Trial 22 finished with value: 0.8900241508621406 and parameters: {'iterations': 535, 'depth': 6, 'learning_rate': 0.032349178704772386, 'l2_leaf_reg': 3.571215440293236, 'scale_pos_weight': 1.8891768764462231}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:44:36,842] Trial 23 finished with value: 0.8897825611532031 and parameters: {'iterations': 545, 'depth': 7, 'learning_rate': 0.03385181600778834, 'l2_leaf_reg': 3.4256703337457584, 'scale_pos_weight': 2.9511449907363128}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:44:52,530] Trial 24 finished with value: 0.889673443633854 and parameters: {'iterations': 494, 'depth': 6, 'learning_rate': 0.07223917047332194, 'l2_leaf_reg': 9.981785749415463, 'scale_pos_weight': 1.4008972540116869}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:45:28,963] Trial 25 finished with value: 0.8892018794570429 and parameters: {'iterations': 855, 'depth': 8, 'learning_rate': 0.028026608997079823, 'l2_leaf_reg': 2.8899791052859567, 'scale_pos_weight': 3.448636747625024}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:45:46,566] Trial 26 finished with value: 0.889633480629931 and parameters: {'iterations': 563, 'depth': 6, 'learning_rate': 0.013498725886933365, 'l2_leaf_reg': 1.2407330867804103, 'scale_pos_weight': 1.3263420501420977}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:46:14,173] Trial 27 finished with value: 0.8897283932208223 and parameters: {'iterations': 735, 'depth': 7, 'learning_rate': 0.026795824670039766, 'l2_leaf_reg': 0.8533361251731718, 'scale_pos_weight': 4.651692470053111}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:46:35,497] Trial 28 finished with value: 0.8894319854182119 and parameters: {'iterations': 618, 'depth': 7, 'learning_rate': 0.03853803754017388, 'l2_leaf_reg': 2.611748112680602, 'scale_pos_weight': 2.6206906751052994}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:47:13,286] Trial 29 finished with value: 0.8851894857464518 and parameters: {'iterations': 897, 'depth': 8, 'learning_rate': 0.09351885317025622, 'l2_leaf_reg': 5.283452469200489, 'scale_pos_weight': 1.377659302671121}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:47:28,254] Trial 30 finished with value: 0.8889548400815437 and parameters: {'iterations': 457, 'depth': 6, 'learning_rate': 0.013819302557443448, 'l2_leaf_reg': 8.558436948974492, 'scale_pos_weight': 9.93664777613769}. Best is trial 17 with value: 0.8900399008368152.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:47:48,863] Trial 31 finished with value: 0.8901565134739828 and parameters: {'iterations': 706, 'depth': 5, 'learning_rate': 0.023611792575234415, 'l2_leaf_reg': 0.36526688647518263, 'scale_pos_weight': 1.9223238352022165}. Best is trial 31 with value: 0.8901565134739828.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:48:09,945] Trial 32 finished with value: 0.8900977578866409 and parameters: {'iterations': 714, 'depth': 5, 'learning_rate': 0.024023717359020313, 'l2_leaf_reg': 0.4131509301423325, 'scale_pos_weight': 3.6094459516445854}. Best is trial 31 with value: 0.8901565134739828.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:48:31,352] Trial 33 finished with value: 0.890098123145794 and parameters: {'iterations': 789, 'depth': 5, 'learning_rate': 0.03889877281579141, 'l2_leaf_reg': 0.3556177883104769, 'scale_pos_weight': 3.5893078609773847}. Best is trial 31 with value: 0.8901565134739828.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:48:54,084] Trial 34 finished with value: 0.8900772230170627 and parameters: {'iterations': 780, 'depth': 5, 'learning_rate': 0.041566413010390005, 'l2_leaf_reg': 0.354364611463244, 'scale_pos_weight': 3.7810345947997286}. Best is trial 31 with value: 0.8901565134739828.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:49:16,764] Trial 35 finished with value: 0.8901505013083254 and parameters: {'iterations': 772, 'depth': 5, 'learning_rate': 0.04328903121486415, 'l2_leaf_reg': 0.3636534512587521, 'scale_pos_weight': 5.1473989558967075}. Best is trial 31 with value: 0.8901565134739828.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:49:37,532] Trial 36 finished with value: 0.8897644333414428 and parameters: {'iterations': 705, 'depth': 5, 'learning_rate': 0.05760114359523799, 'l2_leaf_reg': 0.2524713572403424, 'scale_pos_weight': 5.27968912319173}. Best is trial 31 with value: 0.8901565134739828.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:49:57,412] Trial 37 finished with value: 0.8900991787447459 and parameters: {'iterations': 811, 'depth': 4, 'learning_rate': 0.06994271737689532, 'l2_leaf_reg': 0.4455011673816654, 'scale_pos_weight': 4.820479590132367}. Best is trial 31 with value: 0.8901565134739828.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:50:20,055] Trial 38 finished with value: 0.8895966990332299 and parameters: {'iterations': 868, 'depth': 4, 'learning_rate': 0.07851332273653644, 'l2_leaf_reg': 0.11127815015621506, 'scale_pos_weight': 7.4286470205422575}. Best is trial 31 with value: 0.8901565134739828.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:50:41,405] Trial 39 finished with value: 0.8902251274058625 and parameters: {'iterations': 805, 'depth': 4, 'learning_rate': 0.04465229304436396, 'l2_leaf_reg': 0.5526559031163887, 'scale_pos_weight': 4.994270748919062}. Best is trial 39 with value: 0.8902251274058625.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:51:03,700] Trial 40 finished with value: 0.8899418652801663 and parameters: {'iterations': 912, 'depth': 4, 'learning_rate': 0.06701687446389983, 'l2_leaf_reg': 0.5261435464455213, 'scale_pos_weight': 6.017833642119806}. Best is trial 39 with value: 0.8902251274058625.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:51:24,843] Trial 41 finished with value: 0.890267811590475 and parameters: {'iterations': 803, 'depth': 4, 'learning_rate': 0.04466907217925532, 'l2_leaf_reg': 0.2603777830200597, 'scale_pos_weight': 4.731283476359849}. Best is trial 41 with value: 0.890267811590475.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:51:46,621] Trial 42 finished with value: 0.8902907681282373 and parameters: {'iterations': 816, 'depth': 4, 'learning_rate': 0.046367141347707405, 'l2_leaf_reg': 0.8003112380884168, 'scale_pos_weight': 4.81820563700669}. Best is trial 42 with value: 0.8902907681282373.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:52:07,107] Trial 43 finished with value: 0.8902930400401685 and parameters: {'iterations': 825, 'depth': 4, 'learning_rate': 0.0460002754144138, 'l2_leaf_reg': 0.8874987887236301, 'scale_pos_weight': 5.280432443310148}. Best is trial 43 with value: 0.8902930400401685.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:52:28,926] Trial 44 finished with value: 0.8901416985627397 and parameters: {'iterations': 823, 'depth': 4, 'learning_rate': 0.047773301268708705, 'l2_leaf_reg': 0.9162740261849683, 'scale_pos_weight': 6.544374753473769}. Best is trial 43 with value: 0.8902930400401685.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:52:52,561] Trial 45 finished with value: 0.8894958582862863 and parameters: {'iterations': 907, 'depth': 4, 'learning_rate': 0.0975266801819167, 'l2_leaf_reg': 0.5665611785800322, 'scale_pos_weight': 8.266849680062542}. Best is trial 43 with value: 0.8902930400401685.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:53:09,694] Trial 46 finished with value: 0.8903123585967677 and parameters: {'iterations': 690, 'depth': 4, 'learning_rate': 0.05448177925552803, 'l2_leaf_reg': 0.09165997221410027, 'scale_pos_weight': 5.876546795296569}. Best is trial 46 with value: 0.8903123585967677.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:53:31,769] Trial 47 finished with value: 0.8900635002306867 and parameters: {'iterations': 846, 'depth': 4, 'learning_rate': 0.0555383205595784, 'l2_leaf_reg': 0.08619576874228166, 'scale_pos_weight': 5.949219503174534}. Best is trial 46 with value: 0.8903123585967677.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:53:56,217] Trial 48 finished with value: 0.8902483104042994 and parameters: {'iterations': 954, 'depth': 4, 'learning_rate': 0.04822038408287694, 'l2_leaf_reg': 0.18461176693534997, 'scale_pos_weight': 5.564015904983995}. Best is trial 46 with value: 0.8903123585967677.\n",
            "<ipython-input-117-b18502c2ec9a>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-117-b18502c2ec9a>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-117-b18502c2ec9a>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 17:54:20,305] Trial 49 finished with value: 0.8898399871972285 and parameters: {'iterations': 935, 'depth': 4, 'learning_rate': 0.06232199818079213, 'l2_leaf_reg': 0.06321891198107826, 'scale_pos_weight': 6.9697650307712005}. Best is trial 46 with value: 0.8903123585967677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best AUC: 0.8903123585967677\n",
            "Best Hyperparameters: {'iterations': 690, 'depth': 4, 'learning_rate': 0.05448177925552803, 'l2_leaf_reg': 0.09165997221410027, 'scale_pos_weight': 5.876546795296569}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LGBM=LGBMClassifier()\n",
        "LGBM.fit(x_train,y_train)\n",
        "predicted_probabilities = LGBM.predict_proba(x_test)[:, 1]\n",
        "auc_roc = roc_auc_score(y_test, predicted_probabilities)\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juYmL3VQ_4QF",
        "outputId": "3e3f0a88-7f0c-4527-ba8e-cdbf8f7e444f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 19565, number of negative: 81485\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1123\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193617 -> initscore=-1.426677\n",
            "[LightGBM] [Info] Start training from score -1.426677\n",
            "AUC-ROC Score: 0.8872394222735658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100)\n",
        "    }\n",
        "\n",
        "    clf = LGBMClassifier(**params, random_state=0)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict_proba(X_val)[:, 1]\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "    return auc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_auc = study.best_value\n",
        "\n",
        "print(\"Best AUC:\", best_auc)\n",
        "print(\"Best Hyperparameters:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1PxCYLUdEU_L",
        "outputId": "eedc67f4-723d-44a5-e186-dfcc823d8d7f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:54:53,287] A new study created in memory with name: no-name-01412a80-ed22-45fa-9d70-bc99275423be\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050180 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:04,137] Trial 0 finished with value: 0.8841945611645919 and parameters: {'n_estimators': 395, 'max_depth': 20, 'learning_rate': 0.014381166562228468, 'subsample': 0.8931901158946817, 'colsample_bytree': 0.5654323668684468, 'reg_alpha': 0.00018365566913792743, 'reg_lambda': 0.0017913273938726872, 'min_child_samples': 19}. Best is trial 0 with value: 0.8841945611645919.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:11,485] Trial 1 finished with value: 0.8849419431746168 and parameters: {'n_estimators': 457, 'max_depth': 19, 'learning_rate': 0.023155157170441427, 'subsample': 0.8005520705543547, 'colsample_bytree': 0.5097287319000712, 'reg_alpha': 0.00441584396870521, 'reg_lambda': 4.811103864049754e-05, 'min_child_samples': 41}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023171 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:18,641] Trial 2 finished with value: 0.8848413390071701 and parameters: {'n_estimators': 558, 'max_depth': 24, 'learning_rate': 0.03229272940128527, 'subsample': 0.5727794317933429, 'colsample_bytree': 0.6458823142532295, 'reg_alpha': 2.4763535557845592e-05, 'reg_lambda': 0.00015819040010454048, 'min_child_samples': 21}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017862 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:21,321] Trial 3 finished with value: 0.8838952332045877 and parameters: {'n_estimators': 155, 'max_depth': 21, 'learning_rate': 0.15506678626838633, 'subsample': 0.6534212830347104, 'colsample_bytree': 0.5459547021328772, 'reg_alpha': 0.0003040479277830989, 'reg_lambda': 0.0011483936300364323, 'min_child_samples': 20}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029534 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:23,401] Trial 4 finished with value: 0.8830327060203786 and parameters: {'n_estimators': 134, 'max_depth': 19, 'learning_rate': 0.17929443031153106, 'subsample': 0.7252447438607843, 'colsample_bytree': 0.7041221211611992, 'reg_alpha': 0.005559590174992638, 'reg_lambda': 1.229815537687557e-05, 'min_child_samples': 33}. Best is trial 1 with value: 0.8849419431746168.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017377 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:29,938] Trial 5 finished with value: 0.8826241819297911 and parameters: {'n_estimators': 701, 'max_depth': 3, 'learning_rate': 0.292262771579318, 'subsample': 0.5743021974152712, 'colsample_bytree': 0.6090236353210587, 'reg_alpha': 6.480877061595255, 'reg_lambda': 0.0004655327882232641, 'min_child_samples': 63}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005394 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:32,236] Trial 6 finished with value: 0.884100153505122 and parameters: {'n_estimators': 132, 'max_depth': 31, 'learning_rate': 0.06957449286016486, 'subsample': 0.9957097445513753, 'colsample_bytree': 0.987058429143375, 'reg_alpha': 0.0006943793671943338, 'reg_lambda': 2.128331763834902, 'min_child_samples': 69}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026259 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:39,941] Trial 7 finished with value: 0.8848933312725821 and parameters: {'n_estimators': 543, 'max_depth': 22, 'learning_rate': 0.041139380089733904, 'subsample': 0.5714843912332455, 'colsample_bytree': 0.6358244439429226, 'reg_alpha': 0.0006627464333704376, 'reg_lambda': 0.0003895547349569337, 'min_child_samples': 65}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:46,980] Trial 8 finished with value: 0.8837046163449903 and parameters: {'n_estimators': 429, 'max_depth': 26, 'learning_rate': 0.012200892868820267, 'subsample': 0.9232540083663452, 'colsample_bytree': 0.5120114757574324, 'reg_alpha': 3.6526499247774176, 'reg_lambda': 0.00868188207637794, 'min_child_samples': 11}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008863 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:55:56,606] Trial 9 finished with value: 0.8708610222048598 and parameters: {'n_estimators': 856, 'max_depth': 32, 'learning_rate': 0.19853371128456393, 'subsample': 0.8872501422887491, 'colsample_bytree': 0.9585561380402776, 'reg_alpha': 0.06440379253748368, 'reg_lambda': 1.0904370259464167, 'min_child_samples': 84}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009336 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:56:10,135] Trial 10 finished with value: 0.8846792448915584 and parameters: {'n_estimators': 990, 'max_depth': 10, 'learning_rate': 0.02382074812307524, 'subsample': 0.7876500045248315, 'colsample_bytree': 0.8348246555589031, 'reg_alpha': 0.12081668670133787, 'reg_lambda': 0.13009728257011186, 'min_child_samples': 43}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006856 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:56:18,561] Trial 11 finished with value: 0.883472618492427 and parameters: {'n_estimators': 557, 'max_depth': 13, 'learning_rate': 0.05989040005373957, 'subsample': 0.5084031253825161, 'colsample_bytree': 0.7447962030751545, 'reg_alpha': 0.005076267937239731, 'reg_lambda': 3.1749552513931475e-05, 'min_child_samples': 96}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004294 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:56:23,904] Trial 12 finished with value: 0.8847602993732954 and parameters: {'n_estimators': 357, 'max_depth': 14, 'learning_rate': 0.031057765652794285, 'subsample': 0.7719075210267854, 'colsample_bytree': 0.6466995535293213, 'reg_alpha': 0.046203766361874954, 'reg_lambda': 8.844663066997446e-05, 'min_child_samples': 54}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008061 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:56:32,430] Trial 13 finished with value: 0.8838503481160565 and parameters: {'n_estimators': 647, 'max_depth': 26, 'learning_rate': 0.045956920390868704, 'subsample': 0.6939648102308438, 'colsample_bytree': 0.8179254014197403, 'reg_alpha': 0.0015355969825858282, 'reg_lambda': 0.02992025771204767, 'min_child_samples': 76}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017439 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:56:37,613] Trial 14 finished with value: 0.8843734927563515 and parameters: {'n_estimators': 313, 'max_depth': 15, 'learning_rate': 0.020172795147682873, 'subsample': 0.8101750369123458, 'colsample_bytree': 0.5053983187247119, 'reg_alpha': 2.397074784525441e-05, 'reg_lambda': 1.0219391528173286e-05, 'min_child_samples': 43}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027106 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:56:46,528] Trial 15 finished with value: 0.8809591129261314 and parameters: {'n_estimators': 753, 'max_depth': 10, 'learning_rate': 0.09860409408640675, 'subsample': 0.6289901994988205, 'colsample_bytree': 0.599125657813081, 'reg_alpha': 0.3000777646996108, 'reg_lambda': 0.00017786863292513353, 'min_child_samples': 57}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004222 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:56:53,692] Trial 16 finished with value: 0.884490528558369 and parameters: {'n_estimators': 494, 'max_depth': 23, 'learning_rate': 0.04084571687843499, 'subsample': 0.8412694405413353, 'colsample_bytree': 0.6769861721950667, 'reg_alpha': 8.179983052995383e-05, 'reg_lambda': 0.0048415126039095145, 'min_child_samples': 41}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004715 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:56:58,173] Trial 17 finished with value: 0.8839553868451223 and parameters: {'n_estimators': 274, 'max_depth': 17, 'learning_rate': 0.019717177214026625, 'subsample': 0.5044799182183481, 'colsample_bytree': 0.804489001978432, 'reg_alpha': 0.0019053663190135427, 'reg_lambda': 0.05569476202401012, 'min_child_samples': 84}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017454 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 19:57:03,627] Trial 18 finished with value: 0.8819495494970426 and parameters: {'n_estimators': 597, 'max_depth': 2, 'learning_rate': 0.08567759560324802, 'subsample': 0.7188718027205556, 'colsample_bytree': 0.5891775453394162, 'reg_alpha': 0.021630720420954513, 'reg_lambda': 5.252634583374934e-05, 'min_child_samples': 35}. Best is trial 1 with value: 0.8849419431746168.\n",
            "<ipython-input-42-da920fb77080>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-42-da920fb77080>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
            "<ipython-input-42-da920fb77080>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
            "<ipython-input-42-da920fb77080>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 19595, number of negative: 81455\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033134 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 101050, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193914 -> initscore=-1.424776\n",
            "[LightGBM] [Info] Start training from score -1.424776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-02-19 19:57:04,367] Trial 19 failed with parameters: {'n_estimators': 476, 'max_depth': 28, 'learning_rate': 0.010697166574488381, 'subsample': 0.6500840759261672, 'colsample_bytree': 0.7277861405867023, 'reg_alpha': 0.8650692686313571, 'reg_lambda': 0.0005598538046746251, 'min_child_samples': 69} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-42-da920fb77080>\", line 18, in objective\n",
            "    clf.fit(X_train, y_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\", line 1142, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\", line 842, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\", line 276, in train\n",
            "    booster.update(fobj=fobj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 3658, in update\n",
            "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "[W 2024-02-19 19:57:04,374] Trial 19 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-da920fb77080>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-da920fb77080>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    274\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3658\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3659\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3660\u001b[0m                 ctypes.byref(is_finished)))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVC=SVC(probability=True)\n",
        "SVC.fit(x_train,y_train)\n",
        "predicted_probabilities = SVC.predict_proba(x_test)[:, 1]\n",
        "auc_roc = roc_auc_score(y_test, predicted_probabilities)\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpVht-kvFhOD",
        "outputId": "d01c79ab-4141-41ad-fdd9-f61c8c93d43d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC Score: 0.8211218117164603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANN**"
      ],
      "metadata": {
        "id": "vbHZ1Zti3HX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHPWQ0ri4K45",
        "outputId": "baced909-a7f7-4714-e6c1-a3b7f36a9efa"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model.add(Dense(units=32, input_shape=(18,), activation='relu'))\n",
        "\n",
        "# Add hidden layers\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxTgDacp4AlL",
        "outputId": "4dba146c-7983-484e-cec4-005f6aa8b35c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 32)                608       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               16896     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                16416     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296609 (1.13 MB)\n",
            "Trainable params: 296609 (1.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "                    epochs=50, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "mipwJHEQ5i1r",
        "outputId": "73c2f8ec-e004-4fec-fd62-f76aab77c145"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3714/3714 - 26s - loss: 0.3414 - accuracy: 0.8577 - val_loss: 0.3206 - val_accuracy: 0.8656 - 26s/epoch - 7ms/step\n",
            "Epoch 2/50\n",
            "3714/3714 - 26s - loss: 0.3207 - accuracy: 0.8657 - val_loss: 0.3200 - val_accuracy: 0.8670 - 26s/epoch - 7ms/step\n",
            "Epoch 3/50\n",
            "3714/3714 - 24s - loss: 0.3177 - accuracy: 0.8668 - val_loss: 0.3164 - val_accuracy: 0.8682 - 24s/epoch - 6ms/step\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-f6c2c9a995e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(x_train, y_train, validation_data=(x_test, y_test),\n\u001b[0m\u001b[1;32m      2\u001b[0m                     epochs=50, verbose=2)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_inputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0mpossible_gradient_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradients_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPossibleTapeGradientTypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m     if (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36mPossibleTapeGradientTypes\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mPossibleTapeGradientTypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m   \u001b[0;34m\"\"\"Determines whether and how `args` may require tape gradients.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_Py_TapeSetPossibleGradientTypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities = model.predict(x_test)\n",
        "\n",
        "auc_roc = roc_auc_score(y_test, predicted_probabilities)\n",
        "\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joZ7_hht5gKJ",
        "outputId": "24428f98-1f7b-421a-918b-3584f6c08ae6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "929/929 [==============================] - 5s 5ms/step\n",
            "AUC-ROC Score: 0.8873548106409948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nJLk0UniSeiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the model\n",
        "model1 = Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model1.add(Dense(units=64, input_shape=(18,), activation='relu'))\n",
        "\n",
        "# Add hidden layers\n",
        "model1.add(Dense(units=64, activation='relu'))\n",
        "model1.add(Dense(units=256, activation='relu'))\n",
        "model1.add(Dense(units=256, activation='relu'))\n",
        "model1.add(Dropout(0.02))\n",
        "model1.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "# Add output layer\n",
        "model1.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akdgGaK2SaF3",
        "outputId": "7a6f04de-eacd-407f-aeaa-060493979232"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 64)                1216      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 256)               16640     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120833 (472.00 KB)\n",
            "Trainable params: 120833 (472.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "                    epochs=50, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI3Tiao1SaCM",
        "outputId": "2a146cb4-ea0c-4dcb-ea8b-4ade7a1acee8"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3714/3714 - 42s - loss: 0.3367 - accuracy: 0.8602 - val_loss: 0.3263 - val_accuracy: 0.8687 - 42s/epoch - 11ms/step\n",
            "Epoch 2/50\n",
            "3714/3714 - 16s - loss: 0.3205 - accuracy: 0.8662 - val_loss: 0.3212 - val_accuracy: 0.8672 - 16s/epoch - 4ms/step\n",
            "Epoch 3/50\n",
            "3714/3714 - 18s - loss: 0.3177 - accuracy: 0.8673 - val_loss: 0.3202 - val_accuracy: 0.8680 - 18s/epoch - 5ms/step\n",
            "Epoch 4/50\n",
            "3714/3714 - 17s - loss: 0.3164 - accuracy: 0.8674 - val_loss: 0.3159 - val_accuracy: 0.8682 - 17s/epoch - 5ms/step\n",
            "Epoch 5/50\n",
            "3714/3714 - 16s - loss: 0.3149 - accuracy: 0.8688 - val_loss: 0.3150 - val_accuracy: 0.8687 - 16s/epoch - 4ms/step\n",
            "Epoch 6/50\n",
            "3714/3714 - 17s - loss: 0.3149 - accuracy: 0.8683 - val_loss: 0.3185 - val_accuracy: 0.8687 - 17s/epoch - 5ms/step\n",
            "Epoch 7/50\n",
            "3714/3714 - 17s - loss: 0.3141 - accuracy: 0.8690 - val_loss: 0.3160 - val_accuracy: 0.8678 - 17s/epoch - 5ms/step\n",
            "Epoch 8/50\n",
            "3714/3714 - 16s - loss: 0.3139 - accuracy: 0.8692 - val_loss: 0.3170 - val_accuracy: 0.8681 - 16s/epoch - 4ms/step\n",
            "Epoch 9/50\n",
            "3714/3714 - 17s - loss: 0.3132 - accuracy: 0.8701 - val_loss: 0.3160 - val_accuracy: 0.8686 - 17s/epoch - 5ms/step\n",
            "Epoch 10/50\n",
            "3714/3714 - 15s - loss: 0.3129 - accuracy: 0.8691 - val_loss: 0.3145 - val_accuracy: 0.8700 - 15s/epoch - 4ms/step\n",
            "Epoch 11/50\n",
            "3714/3714 - 17s - loss: 0.3127 - accuracy: 0.8702 - val_loss: 0.3161 - val_accuracy: 0.8700 - 17s/epoch - 5ms/step\n",
            "Epoch 12/50\n",
            "3714/3714 - 16s - loss: 0.3126 - accuracy: 0.8691 - val_loss: 0.3160 - val_accuracy: 0.8704 - 16s/epoch - 4ms/step\n",
            "Epoch 13/50\n",
            "3714/3714 - 18s - loss: 0.3123 - accuracy: 0.8700 - val_loss: 0.3162 - val_accuracy: 0.8696 - 18s/epoch - 5ms/step\n",
            "Epoch 14/50\n",
            "3714/3714 - 17s - loss: 0.3117 - accuracy: 0.8697 - val_loss: 0.3145 - val_accuracy: 0.8696 - 17s/epoch - 5ms/step\n",
            "Epoch 15/50\n",
            "3714/3714 - 16s - loss: 0.3118 - accuracy: 0.8702 - val_loss: 0.3157 - val_accuracy: 0.8686 - 16s/epoch - 4ms/step\n",
            "Epoch 16/50\n",
            "3714/3714 - 19s - loss: 0.3116 - accuracy: 0.8698 - val_loss: 0.3141 - val_accuracy: 0.8685 - 19s/epoch - 5ms/step\n",
            "Epoch 17/50\n",
            "3714/3714 - 15s - loss: 0.3116 - accuracy: 0.8701 - val_loss: 0.3142 - val_accuracy: 0.8700 - 15s/epoch - 4ms/step\n",
            "Epoch 18/50\n",
            "3714/3714 - 17s - loss: 0.3111 - accuracy: 0.8702 - val_loss: 0.3142 - val_accuracy: 0.8688 - 17s/epoch - 5ms/step\n",
            "Epoch 19/50\n",
            "3714/3714 - 17s - loss: 0.3112 - accuracy: 0.8701 - val_loss: 0.3159 - val_accuracy: 0.8694 - 17s/epoch - 5ms/step\n",
            "Epoch 20/50\n",
            "3714/3714 - 17s - loss: 0.3110 - accuracy: 0.8701 - val_loss: 0.3141 - val_accuracy: 0.8696 - 17s/epoch - 5ms/step\n",
            "Epoch 21/50\n",
            "3714/3714 - 17s - loss: 0.3106 - accuracy: 0.8700 - val_loss: 0.3200 - val_accuracy: 0.8665 - 17s/epoch - 5ms/step\n",
            "Epoch 22/50\n",
            "3714/3714 - 16s - loss: 0.3105 - accuracy: 0.8700 - val_loss: 0.3131 - val_accuracy: 0.8692 - 16s/epoch - 4ms/step\n",
            "Epoch 23/50\n",
            "3714/3714 - 18s - loss: 0.3102 - accuracy: 0.8705 - val_loss: 0.3137 - val_accuracy: 0.8702 - 18s/epoch - 5ms/step\n",
            "Epoch 24/50\n",
            "3714/3714 - 17s - loss: 0.3105 - accuracy: 0.8704 - val_loss: 0.3136 - val_accuracy: 0.8696 - 17s/epoch - 5ms/step\n",
            "Epoch 25/50\n",
            "3714/3714 - 17s - loss: 0.3103 - accuracy: 0.8706 - val_loss: 0.3139 - val_accuracy: 0.8697 - 17s/epoch - 5ms/step\n",
            "Epoch 26/50\n",
            "3714/3714 - 15s - loss: 0.3103 - accuracy: 0.8701 - val_loss: 0.3150 - val_accuracy: 0.8678 - 15s/epoch - 4ms/step\n",
            "Epoch 27/50\n",
            "3714/3714 - 16s - loss: 0.3100 - accuracy: 0.8705 - val_loss: 0.3177 - val_accuracy: 0.8665 - 16s/epoch - 4ms/step\n",
            "Epoch 28/50\n",
            "3714/3714 - 16s - loss: 0.3099 - accuracy: 0.8704 - val_loss: 0.3133 - val_accuracy: 0.8689 - 16s/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "3714/3714 - 15s - loss: 0.3099 - accuracy: 0.8710 - val_loss: 0.3130 - val_accuracy: 0.8700 - 15s/epoch - 4ms/step\n",
            "Epoch 30/50\n",
            "3714/3714 - 16s - loss: 0.3098 - accuracy: 0.8702 - val_loss: 0.3156 - val_accuracy: 0.8686 - 16s/epoch - 4ms/step\n",
            "Epoch 31/50\n",
            "3714/3714 - 16s - loss: 0.3098 - accuracy: 0.8710 - val_loss: 0.3131 - val_accuracy: 0.8696 - 16s/epoch - 4ms/step\n",
            "Epoch 32/50\n",
            "3714/3714 - 15s - loss: 0.3095 - accuracy: 0.8713 - val_loss: 0.3135 - val_accuracy: 0.8691 - 15s/epoch - 4ms/step\n",
            "Epoch 33/50\n",
            "3714/3714 - 16s - loss: 0.3095 - accuracy: 0.8705 - val_loss: 0.3138 - val_accuracy: 0.8683 - 16s/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "3714/3714 - 17s - loss: 0.3094 - accuracy: 0.8712 - val_loss: 0.3180 - val_accuracy: 0.8681 - 17s/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "3714/3714 - 16s - loss: 0.3095 - accuracy: 0.8711 - val_loss: 0.3147 - val_accuracy: 0.8681 - 16s/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "3714/3714 - 15s - loss: 0.3099 - accuracy: 0.8707 - val_loss: 0.3147 - val_accuracy: 0.8693 - 15s/epoch - 4ms/step\n",
            "Epoch 37/50\n",
            "3714/3714 - 16s - loss: 0.3092 - accuracy: 0.8710 - val_loss: 0.3135 - val_accuracy: 0.8694 - 16s/epoch - 4ms/step\n",
            "Epoch 38/50\n",
            "3714/3714 - 17s - loss: 0.3091 - accuracy: 0.8709 - val_loss: 0.3160 - val_accuracy: 0.8685 - 17s/epoch - 5ms/step\n",
            "Epoch 39/50\n",
            "3714/3714 - 17s - loss: 0.3091 - accuracy: 0.8707 - val_loss: 0.3160 - val_accuracy: 0.8697 - 17s/epoch - 5ms/step\n",
            "Epoch 40/50\n",
            "3714/3714 - 15s - loss: 0.3090 - accuracy: 0.8710 - val_loss: 0.3144 - val_accuracy: 0.8690 - 15s/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "3714/3714 - 15s - loss: 0.3087 - accuracy: 0.8712 - val_loss: 0.3143 - val_accuracy: 0.8682 - 15s/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "3714/3714 - 17s - loss: 0.3090 - accuracy: 0.8712 - val_loss: 0.3131 - val_accuracy: 0.8693 - 17s/epoch - 5ms/step\n",
            "Epoch 43/50\n",
            "3714/3714 - 16s - loss: 0.3087 - accuracy: 0.8709 - val_loss: 0.3160 - val_accuracy: 0.8685 - 16s/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "3714/3714 - 16s - loss: 0.3089 - accuracy: 0.8714 - val_loss: 0.3136 - val_accuracy: 0.8684 - 16s/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "3714/3714 - 16s - loss: 0.3086 - accuracy: 0.8711 - val_loss: 0.3153 - val_accuracy: 0.8692 - 16s/epoch - 4ms/step\n",
            "Epoch 46/50\n",
            "3714/3714 - 17s - loss: 0.3089 - accuracy: 0.8712 - val_loss: 0.3137 - val_accuracy: 0.8695 - 17s/epoch - 5ms/step\n",
            "Epoch 47/50\n",
            "3714/3714 - 17s - loss: 0.3085 - accuracy: 0.8715 - val_loss: 0.3154 - val_accuracy: 0.8685 - 17s/epoch - 4ms/step\n",
            "Epoch 48/50\n",
            "3714/3714 - 16s - loss: 0.3080 - accuracy: 0.8713 - val_loss: 0.3152 - val_accuracy: 0.8689 - 16s/epoch - 4ms/step\n",
            "Epoch 49/50\n",
            "3714/3714 - 17s - loss: 0.3083 - accuracy: 0.8715 - val_loss: 0.3148 - val_accuracy: 0.8686 - 17s/epoch - 5ms/step\n",
            "Epoch 50/50\n",
            "3714/3714 - 16s - loss: 0.3082 - accuracy: 0.8713 - val_loss: 0.3148 - val_accuracy: 0.8691 - 16s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities = model1.predict(x_test)\n",
        "\n",
        "auc_roc1 = roc_auc_score(y_test, predicted_probabilities)\n",
        "\n",
        "print(\"AUC-ROC Score:\", auc_roc1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWBHSrHrSZ78",
        "outputId": "8c1c74de-9c55-43a9-de3c-5889eea90c49"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "929/929 [==============================] - 2s 2ms/step\n",
            "AUC-ROC Score: 0.8822570470892911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Voting Classifier**"
      ],
      "metadata": {
        "id": "hMtp1LskWc6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1BFE_3W8a1h",
        "outputId": "07a69877-8699-46f4-b8fc-7c589a6a43be"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Define the models with specific parameters\n",
        "catboost_model = CatBoostClassifier(iterations=866, depth=8, learning_rate=0.014698212608323668, l2_leaf_reg=6.763239895719053, scale_pos_weight=3.454672664101342)\n",
        "lgbm_model = LGBMClassifier(n_estimators=352, max_depth=9, learning_rate=0.03007832416750618, subsample=0.6487749522395558, colsample_bytree=0.6210315108589157, reg_alpha=0.14327109965365606, reg_lambda=0.006906421854897233, min_child_samples=100)\n",
        "\n",
        "\n",
        "# Wrap the Keras model inside a scikit-learn classifier\n",
        "neural_net_classifier = KerasClassifier(build_fn=create_neural_net)\n",
        "\n",
        "# Define the voting classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('catboost', catboost_model),\n",
        "        ('neural_net', neural_net_classifier),\n",
        "        ('lgbm', lgbm_model)\n",
        "    ],\n",
        "    voting='soft'  # Use soft voting for probability voting\n",
        ")\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(x_train, y_train)\n",
        "\n",
        "# Evaluate the voting classifier\n",
        "accuracy = voting_clf.score(x_test, y_test)\n",
        "print(\"Voting Classifier Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89QZtfD0Who6",
        "outputId": "e8c79877-4348-48d7-f5ce-55c171ef170b"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6838992\ttotal: 34.3ms\tremaining: 29.6s\n",
            "1:\tlearn: 0.6748727\ttotal: 71.7ms\tremaining: 31s\n",
            "2:\tlearn: 0.6658654\ttotal: 109ms\tremaining: 31.2s\n",
            "3:\tlearn: 0.6573452\ttotal: 147ms\tremaining: 31.7s\n",
            "4:\tlearn: 0.6489115\ttotal: 185ms\tremaining: 31.9s\n",
            "5:\tlearn: 0.6411732\ttotal: 221ms\tremaining: 31.7s\n",
            "6:\tlearn: 0.6333383\ttotal: 262ms\tremaining: 32.2s\n",
            "7:\tlearn: 0.6259515\ttotal: 300ms\tremaining: 32.2s\n",
            "8:\tlearn: 0.6187353\ttotal: 333ms\tremaining: 31.7s\n",
            "9:\tlearn: 0.6117540\ttotal: 367ms\tremaining: 31.4s\n",
            "10:\tlearn: 0.6050953\ttotal: 400ms\tremaining: 31.1s\n",
            "11:\tlearn: 0.5990473\ttotal: 444ms\tremaining: 31.6s\n",
            "12:\tlearn: 0.5931391\ttotal: 482ms\tremaining: 31.7s\n",
            "13:\tlearn: 0.5871154\ttotal: 516ms\tremaining: 31.4s\n",
            "14:\tlearn: 0.5813467\ttotal: 555ms\tremaining: 31.5s\n",
            "15:\tlearn: 0.5758017\ttotal: 588ms\tremaining: 31.2s\n",
            "16:\tlearn: 0.5704505\ttotal: 622ms\tremaining: 31.1s\n",
            "17:\tlearn: 0.5653728\ttotal: 656ms\tremaining: 30.9s\n",
            "18:\tlearn: 0.5604401\ttotal: 696ms\tremaining: 31s\n",
            "19:\tlearn: 0.5558178\ttotal: 749ms\tremaining: 31.7s\n",
            "20:\tlearn: 0.5513958\ttotal: 783ms\tremaining: 31.5s\n",
            "21:\tlearn: 0.5472552\ttotal: 819ms\tremaining: 31.4s\n",
            "22:\tlearn: 0.5431561\ttotal: 855ms\tremaining: 31.3s\n",
            "23:\tlearn: 0.5390279\ttotal: 893ms\tremaining: 31.3s\n",
            "24:\tlearn: 0.5353720\ttotal: 934ms\tremaining: 31.4s\n",
            "25:\tlearn: 0.5316634\ttotal: 968ms\tremaining: 31.3s\n",
            "26:\tlearn: 0.5279372\ttotal: 1s\tremaining: 31.2s\n",
            "27:\tlearn: 0.5247019\ttotal: 1.04s\tremaining: 31s\n",
            "28:\tlearn: 0.5214351\ttotal: 1.07s\tremaining: 30.9s\n",
            "29:\tlearn: 0.5181083\ttotal: 1.1s\tremaining: 30.8s\n",
            "30:\tlearn: 0.5150097\ttotal: 1.15s\tremaining: 30.9s\n",
            "31:\tlearn: 0.5121124\ttotal: 1.18s\tremaining: 30.7s\n",
            "32:\tlearn: 0.5092816\ttotal: 1.21s\tremaining: 30.6s\n",
            "33:\tlearn: 0.5067285\ttotal: 1.25s\tremaining: 30.6s\n",
            "34:\tlearn: 0.5040728\ttotal: 1.29s\tremaining: 30.5s\n",
            "35:\tlearn: 0.5015957\ttotal: 1.32s\tremaining: 30.5s\n",
            "36:\tlearn: 0.4989929\ttotal: 1.36s\tremaining: 30.5s\n",
            "37:\tlearn: 0.4966601\ttotal: 1.4s\tremaining: 30.4s\n",
            "38:\tlearn: 0.4942917\ttotal: 1.44s\tremaining: 30.4s\n",
            "39:\tlearn: 0.4921149\ttotal: 1.47s\tremaining: 30.4s\n",
            "40:\tlearn: 0.4898322\ttotal: 1.51s\tremaining: 30.3s\n",
            "41:\tlearn: 0.4878330\ttotal: 1.54s\tremaining: 30.2s\n",
            "42:\tlearn: 0.4859100\ttotal: 1.58s\tremaining: 30.3s\n",
            "43:\tlearn: 0.4838662\ttotal: 1.62s\tremaining: 30.2s\n",
            "44:\tlearn: 0.4819677\ttotal: 1.65s\tremaining: 30.1s\n",
            "45:\tlearn: 0.4802743\ttotal: 1.68s\tremaining: 30s\n",
            "46:\tlearn: 0.4784899\ttotal: 1.72s\tremaining: 30s\n",
            "47:\tlearn: 0.4767046\ttotal: 1.77s\tremaining: 30.2s\n",
            "48:\tlearn: 0.4751237\ttotal: 1.81s\tremaining: 30.2s\n",
            "49:\tlearn: 0.4735465\ttotal: 1.84s\tremaining: 30.1s\n",
            "50:\tlearn: 0.4720806\ttotal: 1.88s\tremaining: 30s\n",
            "51:\tlearn: 0.4705309\ttotal: 1.91s\tremaining: 30s\n",
            "52:\tlearn: 0.4691274\ttotal: 1.95s\tremaining: 29.9s\n",
            "53:\tlearn: 0.4677139\ttotal: 1.98s\tremaining: 29.8s\n",
            "54:\tlearn: 0.4663501\ttotal: 2.04s\tremaining: 30.1s\n",
            "55:\tlearn: 0.4650783\ttotal: 2.12s\tremaining: 30.6s\n",
            "56:\tlearn: 0.4638486\ttotal: 2.2s\tremaining: 31.3s\n",
            "57:\tlearn: 0.4626635\ttotal: 2.29s\tremaining: 31.9s\n",
            "58:\tlearn: 0.4614961\ttotal: 2.38s\tremaining: 32.6s\n",
            "59:\tlearn: 0.4604793\ttotal: 2.46s\tremaining: 33.1s\n",
            "60:\tlearn: 0.4593775\ttotal: 2.54s\tremaining: 33.6s\n",
            "61:\tlearn: 0.4584225\ttotal: 2.63s\tremaining: 34.1s\n",
            "62:\tlearn: 0.4577140\ttotal: 2.7s\tremaining: 34.4s\n",
            "63:\tlearn: 0.4566844\ttotal: 2.8s\tremaining: 35s\n",
            "64:\tlearn: 0.4558267\ttotal: 2.88s\tremaining: 35.5s\n",
            "65:\tlearn: 0.4548976\ttotal: 2.97s\tremaining: 36s\n",
            "66:\tlearn: 0.4540820\ttotal: 3.06s\tremaining: 36.5s\n",
            "67:\tlearn: 0.4531202\ttotal: 3.14s\tremaining: 36.8s\n",
            "68:\tlearn: 0.4522717\ttotal: 3.19s\tremaining: 36.8s\n",
            "69:\tlearn: 0.4515213\ttotal: 3.23s\tremaining: 36.8s\n",
            "70:\tlearn: 0.4506907\ttotal: 3.31s\tremaining: 37.1s\n",
            "71:\tlearn: 0.4499626\ttotal: 3.4s\tremaining: 37.5s\n",
            "72:\tlearn: 0.4492233\ttotal: 3.48s\tremaining: 37.8s\n",
            "73:\tlearn: 0.4485017\ttotal: 3.56s\tremaining: 38.1s\n",
            "74:\tlearn: 0.4478263\ttotal: 3.64s\tremaining: 38.4s\n",
            "75:\tlearn: 0.4471151\ttotal: 3.73s\tremaining: 38.7s\n",
            "76:\tlearn: 0.4465402\ttotal: 3.79s\tremaining: 38.9s\n",
            "77:\tlearn: 0.4458722\ttotal: 3.88s\tremaining: 39.2s\n",
            "78:\tlearn: 0.4452170\ttotal: 3.93s\tremaining: 39.1s\n",
            "79:\tlearn: 0.4446238\ttotal: 4.02s\tremaining: 39.5s\n",
            "80:\tlearn: 0.4440151\ttotal: 4.07s\tremaining: 39.4s\n",
            "81:\tlearn: 0.4434961\ttotal: 4.15s\tremaining: 39.6s\n",
            "82:\tlearn: 0.4429308\ttotal: 4.22s\tremaining: 39.8s\n",
            "83:\tlearn: 0.4424398\ttotal: 4.3s\tremaining: 40.1s\n",
            "84:\tlearn: 0.4419701\ttotal: 4.39s\tremaining: 40.3s\n",
            "85:\tlearn: 0.4415128\ttotal: 4.47s\tremaining: 40.5s\n",
            "86:\tlearn: 0.4410320\ttotal: 4.54s\tremaining: 40.7s\n",
            "87:\tlearn: 0.4405638\ttotal: 4.62s\tremaining: 40.8s\n",
            "88:\tlearn: 0.4401806\ttotal: 4.69s\tremaining: 40.9s\n",
            "89:\tlearn: 0.4397508\ttotal: 4.73s\tremaining: 40.8s\n",
            "90:\tlearn: 0.4392845\ttotal: 4.77s\tremaining: 40.6s\n",
            "91:\tlearn: 0.4388230\ttotal: 4.8s\tremaining: 40.4s\n",
            "92:\tlearn: 0.4383851\ttotal: 4.83s\tremaining: 40.2s\n",
            "93:\tlearn: 0.4379904\ttotal: 4.88s\tremaining: 40.1s\n",
            "94:\tlearn: 0.4376233\ttotal: 4.92s\tremaining: 40s\n",
            "95:\tlearn: 0.4373092\ttotal: 4.96s\tremaining: 39.8s\n",
            "96:\tlearn: 0.4369308\ttotal: 4.99s\tremaining: 39.6s\n",
            "97:\tlearn: 0.4365238\ttotal: 5.03s\tremaining: 39.4s\n",
            "98:\tlearn: 0.4361803\ttotal: 5.06s\tremaining: 39.2s\n",
            "99:\tlearn: 0.4358485\ttotal: 5.1s\tremaining: 39s\n",
            "100:\tlearn: 0.4355277\ttotal: 5.13s\tremaining: 38.9s\n",
            "101:\tlearn: 0.4351633\ttotal: 5.17s\tremaining: 38.7s\n",
            "102:\tlearn: 0.4347944\ttotal: 5.21s\tremaining: 38.6s\n",
            "103:\tlearn: 0.4344733\ttotal: 5.24s\tremaining: 38.4s\n",
            "104:\tlearn: 0.4341576\ttotal: 5.28s\tremaining: 38.2s\n",
            "105:\tlearn: 0.4340237\ttotal: 5.3s\tremaining: 38s\n",
            "106:\tlearn: 0.4337551\ttotal: 5.33s\tremaining: 37.8s\n",
            "107:\tlearn: 0.4334563\ttotal: 5.37s\tremaining: 37.7s\n",
            "108:\tlearn: 0.4331894\ttotal: 5.4s\tremaining: 37.5s\n",
            "109:\tlearn: 0.4329050\ttotal: 5.44s\tremaining: 37.4s\n",
            "110:\tlearn: 0.4326670\ttotal: 5.47s\tremaining: 37.2s\n",
            "111:\tlearn: 0.4324299\ttotal: 5.51s\tremaining: 37.1s\n",
            "112:\tlearn: 0.4322144\ttotal: 5.55s\tremaining: 37s\n",
            "113:\tlearn: 0.4319669\ttotal: 5.58s\tremaining: 36.8s\n",
            "114:\tlearn: 0.4317100\ttotal: 5.62s\tremaining: 36.7s\n",
            "115:\tlearn: 0.4314773\ttotal: 5.65s\tremaining: 36.5s\n",
            "116:\tlearn: 0.4312910\ttotal: 5.69s\tremaining: 36.4s\n",
            "117:\tlearn: 0.4310777\ttotal: 5.72s\tremaining: 36.3s\n",
            "118:\tlearn: 0.4308792\ttotal: 5.76s\tremaining: 36.2s\n",
            "119:\tlearn: 0.4306867\ttotal: 5.8s\tremaining: 36s\n",
            "120:\tlearn: 0.4305425\ttotal: 5.82s\tremaining: 35.9s\n",
            "121:\tlearn: 0.4303173\ttotal: 5.86s\tremaining: 35.8s\n",
            "122:\tlearn: 0.4301393\ttotal: 5.91s\tremaining: 35.7s\n",
            "123:\tlearn: 0.4299062\ttotal: 5.95s\tremaining: 35.6s\n",
            "124:\tlearn: 0.4297683\ttotal: 5.99s\tremaining: 35.5s\n",
            "125:\tlearn: 0.4295936\ttotal: 6.02s\tremaining: 35.4s\n",
            "126:\tlearn: 0.4294208\ttotal: 6.05s\tremaining: 35.2s\n",
            "127:\tlearn: 0.4292422\ttotal: 6.09s\tremaining: 35.1s\n",
            "128:\tlearn: 0.4290886\ttotal: 6.12s\tremaining: 35s\n",
            "129:\tlearn: 0.4289453\ttotal: 6.16s\tremaining: 34.9s\n",
            "130:\tlearn: 0.4287941\ttotal: 6.21s\tremaining: 34.8s\n",
            "131:\tlearn: 0.4286805\ttotal: 6.24s\tremaining: 34.7s\n",
            "132:\tlearn: 0.4285283\ttotal: 6.27s\tremaining: 34.6s\n",
            "133:\tlearn: 0.4283635\ttotal: 6.31s\tremaining: 34.5s\n",
            "134:\tlearn: 0.4282189\ttotal: 6.34s\tremaining: 34.3s\n",
            "135:\tlearn: 0.4280517\ttotal: 6.38s\tremaining: 34.2s\n",
            "136:\tlearn: 0.4279036\ttotal: 6.42s\tremaining: 34.1s\n",
            "137:\tlearn: 0.4277636\ttotal: 6.45s\tremaining: 34s\n",
            "138:\tlearn: 0.4276018\ttotal: 6.49s\tremaining: 33.9s\n",
            "139:\tlearn: 0.4274685\ttotal: 6.52s\tremaining: 33.8s\n",
            "140:\tlearn: 0.4273520\ttotal: 6.56s\tremaining: 33.7s\n",
            "141:\tlearn: 0.4272445\ttotal: 6.59s\tremaining: 33.6s\n",
            "142:\tlearn: 0.4271078\ttotal: 6.63s\tremaining: 33.5s\n",
            "143:\tlearn: 0.4269662\ttotal: 6.66s\tremaining: 33.4s\n",
            "144:\tlearn: 0.4268663\ttotal: 6.7s\tremaining: 33.3s\n",
            "145:\tlearn: 0.4267590\ttotal: 6.73s\tremaining: 33.2s\n",
            "146:\tlearn: 0.4266542\ttotal: 6.77s\tremaining: 33.1s\n",
            "147:\tlearn: 0.4265546\ttotal: 6.8s\tremaining: 33s\n",
            "148:\tlearn: 0.4264312\ttotal: 6.84s\tremaining: 32.9s\n",
            "149:\tlearn: 0.4263126\ttotal: 6.88s\tremaining: 32.8s\n",
            "150:\tlearn: 0.4261856\ttotal: 6.93s\tremaining: 32.8s\n",
            "151:\tlearn: 0.4260753\ttotal: 6.97s\tremaining: 32.7s\n",
            "152:\tlearn: 0.4259551\ttotal: 7s\tremaining: 32.6s\n",
            "153:\tlearn: 0.4258582\ttotal: 7.04s\tremaining: 32.5s\n",
            "154:\tlearn: 0.4257697\ttotal: 7.07s\tremaining: 32.4s\n",
            "155:\tlearn: 0.4256620\ttotal: 7.11s\tremaining: 32.4s\n",
            "156:\tlearn: 0.4255604\ttotal: 7.14s\tremaining: 32.3s\n",
            "157:\tlearn: 0.4254274\ttotal: 7.18s\tremaining: 32.2s\n",
            "158:\tlearn: 0.4253261\ttotal: 7.21s\tremaining: 32.1s\n",
            "159:\tlearn: 0.4252217\ttotal: 7.25s\tremaining: 32s\n",
            "160:\tlearn: 0.4251166\ttotal: 7.29s\tremaining: 31.9s\n",
            "161:\tlearn: 0.4250197\ttotal: 7.32s\tremaining: 31.8s\n",
            "162:\tlearn: 0.4249399\ttotal: 7.36s\tremaining: 31.7s\n",
            "163:\tlearn: 0.4248645\ttotal: 7.39s\tremaining: 31.7s\n",
            "164:\tlearn: 0.4247811\ttotal: 7.43s\tremaining: 31.6s\n",
            "165:\tlearn: 0.4246960\ttotal: 7.46s\tremaining: 31.5s\n",
            "166:\tlearn: 0.4246040\ttotal: 7.5s\tremaining: 31.4s\n",
            "167:\tlearn: 0.4245176\ttotal: 7.53s\tremaining: 31.3s\n",
            "168:\tlearn: 0.4244366\ttotal: 7.57s\tremaining: 31.2s\n",
            "169:\tlearn: 0.4243346\ttotal: 7.6s\tremaining: 31.1s\n",
            "170:\tlearn: 0.4242299\ttotal: 7.63s\tremaining: 31s\n",
            "171:\tlearn: 0.4241264\ttotal: 7.67s\tremaining: 31s\n",
            "172:\tlearn: 0.4240302\ttotal: 7.71s\tremaining: 30.9s\n",
            "173:\tlearn: 0.4239640\ttotal: 7.75s\tremaining: 30.8s\n",
            "174:\tlearn: 0.4238989\ttotal: 7.78s\tremaining: 30.7s\n",
            "175:\tlearn: 0.4238183\ttotal: 7.82s\tremaining: 30.6s\n",
            "176:\tlearn: 0.4237352\ttotal: 7.85s\tremaining: 30.6s\n",
            "177:\tlearn: 0.4236637\ttotal: 7.89s\tremaining: 30.5s\n",
            "178:\tlearn: 0.4235786\ttotal: 7.94s\tremaining: 30.5s\n",
            "179:\tlearn: 0.4235003\ttotal: 7.97s\tremaining: 30.4s\n",
            "180:\tlearn: 0.4234157\ttotal: 8.01s\tremaining: 30.3s\n",
            "181:\tlearn: 0.4233129\ttotal: 8.04s\tremaining: 30.2s\n",
            "182:\tlearn: 0.4232389\ttotal: 8.08s\tremaining: 30.1s\n",
            "183:\tlearn: 0.4231572\ttotal: 8.11s\tremaining: 30.1s\n",
            "184:\tlearn: 0.4231155\ttotal: 8.15s\tremaining: 30s\n",
            "185:\tlearn: 0.4230291\ttotal: 8.18s\tremaining: 29.9s\n",
            "186:\tlearn: 0.4229787\ttotal: 8.21s\tremaining: 29.8s\n",
            "187:\tlearn: 0.4228949\ttotal: 8.25s\tremaining: 29.7s\n",
            "188:\tlearn: 0.4228038\ttotal: 8.29s\tremaining: 29.7s\n",
            "189:\tlearn: 0.4227424\ttotal: 8.32s\tremaining: 29.6s\n",
            "190:\tlearn: 0.4226722\ttotal: 8.36s\tremaining: 29.5s\n",
            "191:\tlearn: 0.4225861\ttotal: 8.39s\tremaining: 29.5s\n",
            "192:\tlearn: 0.4225179\ttotal: 8.42s\tremaining: 29.4s\n",
            "193:\tlearn: 0.4224586\ttotal: 8.46s\tremaining: 29.3s\n",
            "194:\tlearn: 0.4223949\ttotal: 8.49s\tremaining: 29.2s\n",
            "195:\tlearn: 0.4223284\ttotal: 8.52s\tremaining: 29.1s\n",
            "196:\tlearn: 0.4222637\ttotal: 8.56s\tremaining: 29.1s\n",
            "197:\tlearn: 0.4221857\ttotal: 8.59s\tremaining: 29s\n",
            "198:\tlearn: 0.4221315\ttotal: 8.63s\tremaining: 28.9s\n",
            "199:\tlearn: 0.4220881\ttotal: 8.67s\tremaining: 28.9s\n",
            "200:\tlearn: 0.4220085\ttotal: 8.7s\tremaining: 28.8s\n",
            "201:\tlearn: 0.4219491\ttotal: 8.74s\tremaining: 28.7s\n",
            "202:\tlearn: 0.4219091\ttotal: 8.77s\tremaining: 28.7s\n",
            "203:\tlearn: 0.4218707\ttotal: 8.8s\tremaining: 28.6s\n",
            "204:\tlearn: 0.4218197\ttotal: 8.84s\tremaining: 28.5s\n",
            "205:\tlearn: 0.4217662\ttotal: 8.87s\tremaining: 28.4s\n",
            "206:\tlearn: 0.4217154\ttotal: 8.91s\tremaining: 28.4s\n",
            "207:\tlearn: 0.4216427\ttotal: 8.96s\tremaining: 28.3s\n",
            "208:\tlearn: 0.4215844\ttotal: 8.99s\tremaining: 28.3s\n",
            "209:\tlearn: 0.4215488\ttotal: 9.03s\tremaining: 28.2s\n",
            "210:\tlearn: 0.4214788\ttotal: 9.06s\tremaining: 28.1s\n",
            "211:\tlearn: 0.4214366\ttotal: 9.1s\tremaining: 28.1s\n",
            "212:\tlearn: 0.4213880\ttotal: 9.13s\tremaining: 28s\n",
            "213:\tlearn: 0.4213243\ttotal: 9.17s\tremaining: 27.9s\n",
            "214:\tlearn: 0.4212712\ttotal: 9.21s\tremaining: 27.9s\n",
            "215:\tlearn: 0.4212158\ttotal: 9.24s\tremaining: 27.8s\n",
            "216:\tlearn: 0.4211868\ttotal: 9.27s\tremaining: 27.7s\n",
            "217:\tlearn: 0.4211322\ttotal: 9.3s\tremaining: 27.6s\n",
            "218:\tlearn: 0.4210774\ttotal: 9.34s\tremaining: 27.6s\n",
            "219:\tlearn: 0.4210369\ttotal: 9.37s\tremaining: 27.5s\n",
            "220:\tlearn: 0.4209753\ttotal: 9.4s\tremaining: 27.4s\n",
            "221:\tlearn: 0.4209085\ttotal: 9.44s\tremaining: 27.4s\n",
            "222:\tlearn: 0.4208723\ttotal: 9.47s\tremaining: 27.3s\n",
            "223:\tlearn: 0.4208151\ttotal: 9.51s\tremaining: 27.3s\n",
            "224:\tlearn: 0.4207547\ttotal: 9.54s\tremaining: 27.2s\n",
            "225:\tlearn: 0.4207208\ttotal: 9.57s\tremaining: 27.1s\n",
            "226:\tlearn: 0.4206688\ttotal: 9.61s\tremaining: 27.1s\n",
            "227:\tlearn: 0.4206050\ttotal: 9.65s\tremaining: 27s\n",
            "228:\tlearn: 0.4205696\ttotal: 9.68s\tremaining: 26.9s\n",
            "229:\tlearn: 0.4205184\ttotal: 9.72s\tremaining: 26.9s\n",
            "230:\tlearn: 0.4204824\ttotal: 9.75s\tremaining: 26.8s\n",
            "231:\tlearn: 0.4204369\ttotal: 9.78s\tremaining: 26.7s\n",
            "232:\tlearn: 0.4204289\ttotal: 9.81s\tremaining: 26.7s\n",
            "233:\tlearn: 0.4204001\ttotal: 9.85s\tremaining: 26.6s\n",
            "234:\tlearn: 0.4203408\ttotal: 9.88s\tremaining: 26.5s\n",
            "235:\tlearn: 0.4202809\ttotal: 9.92s\tremaining: 26.5s\n",
            "236:\tlearn: 0.4202332\ttotal: 9.97s\tremaining: 26.4s\n",
            "237:\tlearn: 0.4201857\ttotal: 10s\tremaining: 26.4s\n",
            "238:\tlearn: 0.4201412\ttotal: 10s\tremaining: 26.3s\n",
            "239:\tlearn: 0.4201083\ttotal: 10.1s\tremaining: 26.3s\n",
            "240:\tlearn: 0.4200685\ttotal: 10.1s\tremaining: 26.2s\n",
            "241:\tlearn: 0.4200250\ttotal: 10.1s\tremaining: 26.2s\n",
            "242:\tlearn: 0.4199873\ttotal: 10.2s\tremaining: 26.1s\n",
            "243:\tlearn: 0.4199415\ttotal: 10.2s\tremaining: 26s\n",
            "244:\tlearn: 0.4199020\ttotal: 10.2s\tremaining: 26s\n",
            "245:\tlearn: 0.4198622\ttotal: 10.3s\tremaining: 25.9s\n",
            "246:\tlearn: 0.4198293\ttotal: 10.3s\tremaining: 25.9s\n",
            "247:\tlearn: 0.4197895\ttotal: 10.3s\tremaining: 25.8s\n",
            "248:\tlearn: 0.4197228\ttotal: 10.4s\tremaining: 25.7s\n",
            "249:\tlearn: 0.4196899\ttotal: 10.4s\tremaining: 25.7s\n",
            "250:\tlearn: 0.4196354\ttotal: 10.5s\tremaining: 25.6s\n",
            "251:\tlearn: 0.4196041\ttotal: 10.5s\tremaining: 25.6s\n",
            "252:\tlearn: 0.4195689\ttotal: 10.5s\tremaining: 25.5s\n",
            "253:\tlearn: 0.4195220\ttotal: 10.6s\tremaining: 25.4s\n",
            "254:\tlearn: 0.4194672\ttotal: 10.6s\tremaining: 25.4s\n",
            "255:\tlearn: 0.4194142\ttotal: 10.6s\tremaining: 25.3s\n",
            "256:\tlearn: 0.4193772\ttotal: 10.7s\tremaining: 25.3s\n",
            "257:\tlearn: 0.4193469\ttotal: 10.7s\tremaining: 25.2s\n",
            "258:\tlearn: 0.4193102\ttotal: 10.7s\tremaining: 25.2s\n",
            "259:\tlearn: 0.4192800\ttotal: 10.8s\tremaining: 25.1s\n",
            "260:\tlearn: 0.4192441\ttotal: 10.8s\tremaining: 25s\n",
            "261:\tlearn: 0.4191961\ttotal: 10.8s\tremaining: 25s\n",
            "262:\tlearn: 0.4191449\ttotal: 10.9s\tremaining: 24.9s\n",
            "263:\tlearn: 0.4190989\ttotal: 10.9s\tremaining: 24.9s\n",
            "264:\tlearn: 0.4190496\ttotal: 10.9s\tremaining: 24.8s\n",
            "265:\tlearn: 0.4190132\ttotal: 11s\tremaining: 24.8s\n",
            "266:\tlearn: 0.4189542\ttotal: 11s\tremaining: 24.7s\n",
            "267:\tlearn: 0.4189255\ttotal: 11.1s\tremaining: 24.7s\n",
            "268:\tlearn: 0.4188937\ttotal: 11.1s\tremaining: 24.6s\n",
            "269:\tlearn: 0.4188417\ttotal: 11.1s\tremaining: 24.6s\n",
            "270:\tlearn: 0.4187875\ttotal: 11.2s\tremaining: 24.5s\n",
            "271:\tlearn: 0.4187843\ttotal: 11.2s\tremaining: 24.4s\n",
            "272:\tlearn: 0.4187532\ttotal: 11.2s\tremaining: 24.4s\n",
            "273:\tlearn: 0.4187089\ttotal: 11.3s\tremaining: 24.3s\n",
            "274:\tlearn: 0.4186517\ttotal: 11.3s\tremaining: 24.3s\n",
            "275:\tlearn: 0.4186064\ttotal: 11.3s\tremaining: 24.2s\n",
            "276:\tlearn: 0.4185704\ttotal: 11.4s\tremaining: 24.2s\n",
            "277:\tlearn: 0.4185350\ttotal: 11.4s\tremaining: 24.1s\n",
            "278:\tlearn: 0.4184905\ttotal: 11.4s\tremaining: 24.1s\n",
            "279:\tlearn: 0.4184496\ttotal: 11.5s\tremaining: 24s\n",
            "280:\tlearn: 0.4184019\ttotal: 11.5s\tremaining: 24s\n",
            "281:\tlearn: 0.4183759\ttotal: 11.5s\tremaining: 23.9s\n",
            "282:\tlearn: 0.4183230\ttotal: 11.6s\tremaining: 23.8s\n",
            "283:\tlearn: 0.4182906\ttotal: 11.6s\tremaining: 23.8s\n",
            "284:\tlearn: 0.4182545\ttotal: 11.7s\tremaining: 23.7s\n",
            "285:\tlearn: 0.4182192\ttotal: 11.7s\tremaining: 23.7s\n",
            "286:\tlearn: 0.4181746\ttotal: 11.7s\tremaining: 23.6s\n",
            "287:\tlearn: 0.4181354\ttotal: 11.8s\tremaining: 23.6s\n",
            "288:\tlearn: 0.4181087\ttotal: 11.8s\tremaining: 23.5s\n",
            "289:\tlearn: 0.4180601\ttotal: 11.8s\tremaining: 23.5s\n",
            "290:\tlearn: 0.4180217\ttotal: 11.9s\tremaining: 23.4s\n",
            "291:\tlearn: 0.4179947\ttotal: 11.9s\tremaining: 23.4s\n",
            "292:\tlearn: 0.4179684\ttotal: 11.9s\tremaining: 23.3s\n",
            "293:\tlearn: 0.4179127\ttotal: 12s\tremaining: 23.3s\n",
            "294:\tlearn: 0.4178881\ttotal: 12s\tremaining: 23.3s\n",
            "295:\tlearn: 0.4178556\ttotal: 12.1s\tremaining: 23.2s\n",
            "296:\tlearn: 0.4177971\ttotal: 12.1s\tremaining: 23.2s\n",
            "297:\tlearn: 0.4177871\ttotal: 12.1s\tremaining: 23.1s\n",
            "298:\tlearn: 0.4177526\ttotal: 12.1s\tremaining: 23s\n",
            "299:\tlearn: 0.4177139\ttotal: 12.2s\tremaining: 23s\n",
            "300:\tlearn: 0.4176826\ttotal: 12.2s\tremaining: 22.9s\n",
            "301:\tlearn: 0.4176469\ttotal: 12.3s\tremaining: 22.9s\n",
            "302:\tlearn: 0.4176054\ttotal: 12.3s\tremaining: 22.8s\n",
            "303:\tlearn: 0.4175574\ttotal: 12.3s\tremaining: 22.8s\n",
            "304:\tlearn: 0.4175101\ttotal: 12.4s\tremaining: 22.7s\n",
            "305:\tlearn: 0.4174699\ttotal: 12.4s\tremaining: 22.7s\n",
            "306:\tlearn: 0.4174436\ttotal: 12.4s\tremaining: 22.6s\n",
            "307:\tlearn: 0.4174050\ttotal: 12.5s\tremaining: 22.6s\n",
            "308:\tlearn: 0.4173662\ttotal: 12.5s\tremaining: 22.5s\n",
            "309:\tlearn: 0.4173424\ttotal: 12.5s\tremaining: 22.5s\n",
            "310:\tlearn: 0.4173012\ttotal: 12.6s\tremaining: 22.4s\n",
            "311:\tlearn: 0.4172728\ttotal: 12.6s\tremaining: 22.4s\n",
            "312:\tlearn: 0.4172410\ttotal: 12.6s\tremaining: 22.3s\n",
            "313:\tlearn: 0.4171827\ttotal: 12.7s\tremaining: 22.3s\n",
            "314:\tlearn: 0.4171584\ttotal: 12.7s\tremaining: 22.2s\n",
            "315:\tlearn: 0.4171213\ttotal: 12.8s\tremaining: 22.2s\n",
            "316:\tlearn: 0.4170897\ttotal: 12.8s\tremaining: 22.2s\n",
            "317:\tlearn: 0.4170535\ttotal: 12.8s\tremaining: 22.1s\n",
            "318:\tlearn: 0.4170248\ttotal: 12.9s\tremaining: 22.1s\n",
            "319:\tlearn: 0.4169966\ttotal: 12.9s\tremaining: 22s\n",
            "320:\tlearn: 0.4169902\ttotal: 12.9s\tremaining: 21.9s\n",
            "321:\tlearn: 0.4169533\ttotal: 13s\tremaining: 21.9s\n",
            "322:\tlearn: 0.4169225\ttotal: 13s\tremaining: 21.9s\n",
            "323:\tlearn: 0.4168910\ttotal: 13s\tremaining: 21.8s\n",
            "324:\tlearn: 0.4168516\ttotal: 13.1s\tremaining: 21.8s\n",
            "325:\tlearn: 0.4168248\ttotal: 13.1s\tremaining: 21.7s\n",
            "326:\tlearn: 0.4167968\ttotal: 13.2s\tremaining: 21.7s\n",
            "327:\tlearn: 0.4167621\ttotal: 13.2s\tremaining: 21.6s\n",
            "328:\tlearn: 0.4167303\ttotal: 13.2s\tremaining: 21.6s\n",
            "329:\tlearn: 0.4166941\ttotal: 13.2s\tremaining: 21.5s\n",
            "330:\tlearn: 0.4166718\ttotal: 13.3s\tremaining: 21.5s\n",
            "331:\tlearn: 0.4166310\ttotal: 13.3s\tremaining: 21.4s\n",
            "332:\tlearn: 0.4166043\ttotal: 13.3s\tremaining: 21.4s\n",
            "333:\tlearn: 0.4165605\ttotal: 13.4s\tremaining: 21.3s\n",
            "334:\tlearn: 0.4165094\ttotal: 13.4s\tremaining: 21.3s\n",
            "335:\tlearn: 0.4164731\ttotal: 13.4s\tremaining: 21.2s\n",
            "336:\tlearn: 0.4164289\ttotal: 13.5s\tremaining: 21.2s\n",
            "337:\tlearn: 0.4164060\ttotal: 13.5s\tremaining: 21.1s\n",
            "338:\tlearn: 0.4163761\ttotal: 13.6s\tremaining: 21.1s\n",
            "339:\tlearn: 0.4163329\ttotal: 13.6s\tremaining: 21s\n",
            "340:\tlearn: 0.4162740\ttotal: 13.6s\tremaining: 21s\n",
            "341:\tlearn: 0.4162561\ttotal: 13.7s\tremaining: 20.9s\n",
            "342:\tlearn: 0.4162296\ttotal: 13.7s\tremaining: 20.9s\n",
            "343:\tlearn: 0.4161812\ttotal: 13.7s\tremaining: 20.8s\n",
            "344:\tlearn: 0.4161758\ttotal: 13.8s\tremaining: 20.8s\n",
            "345:\tlearn: 0.4161342\ttotal: 13.8s\tremaining: 20.7s\n",
            "346:\tlearn: 0.4161077\ttotal: 13.8s\tremaining: 20.7s\n",
            "347:\tlearn: 0.4160725\ttotal: 13.9s\tremaining: 20.6s\n",
            "348:\tlearn: 0.4160556\ttotal: 13.9s\tremaining: 20.6s\n",
            "349:\tlearn: 0.4160262\ttotal: 13.9s\tremaining: 20.5s\n",
            "350:\tlearn: 0.4159954\ttotal: 14s\tremaining: 20.5s\n",
            "351:\tlearn: 0.4159678\ttotal: 14s\tremaining: 20.4s\n",
            "352:\tlearn: 0.4159486\ttotal: 14s\tremaining: 20.4s\n",
            "353:\tlearn: 0.4159089\ttotal: 14.1s\tremaining: 20.4s\n",
            "354:\tlearn: 0.4158899\ttotal: 14.1s\tremaining: 20.3s\n",
            "355:\tlearn: 0.4158563\ttotal: 14.1s\tremaining: 20.3s\n",
            "356:\tlearn: 0.4158377\ttotal: 14.2s\tremaining: 20.2s\n",
            "357:\tlearn: 0.4158107\ttotal: 14.2s\tremaining: 20.2s\n",
            "358:\tlearn: 0.4157875\ttotal: 14.3s\tremaining: 20.1s\n",
            "359:\tlearn: 0.4157522\ttotal: 14.3s\tremaining: 20.1s\n",
            "360:\tlearn: 0.4157318\ttotal: 14.3s\tremaining: 20s\n",
            "361:\tlearn: 0.4157142\ttotal: 14.4s\tremaining: 20s\n",
            "362:\tlearn: 0.4156819\ttotal: 14.4s\tremaining: 19.9s\n",
            "363:\tlearn: 0.4156512\ttotal: 14.4s\tremaining: 19.9s\n",
            "364:\tlearn: 0.4156282\ttotal: 14.5s\tremaining: 19.8s\n",
            "365:\tlearn: 0.4156050\ttotal: 14.5s\tremaining: 19.8s\n",
            "366:\tlearn: 0.4155804\ttotal: 14.5s\tremaining: 19.7s\n",
            "367:\tlearn: 0.4155481\ttotal: 14.6s\tremaining: 19.7s\n",
            "368:\tlearn: 0.4155110\ttotal: 14.6s\tremaining: 19.7s\n",
            "369:\tlearn: 0.4154807\ttotal: 14.7s\tremaining: 19.7s\n",
            "370:\tlearn: 0.4154635\ttotal: 14.8s\tremaining: 19.7s\n",
            "371:\tlearn: 0.4154355\ttotal: 14.9s\tremaining: 19.8s\n",
            "372:\tlearn: 0.4153984\ttotal: 14.9s\tremaining: 19.8s\n",
            "373:\tlearn: 0.4153726\ttotal: 15s\tremaining: 19.8s\n",
            "374:\tlearn: 0.4153461\ttotal: 15.1s\tremaining: 19.8s\n",
            "375:\tlearn: 0.4153265\ttotal: 15.2s\tremaining: 19.8s\n",
            "376:\tlearn: 0.4153127\ttotal: 15.3s\tremaining: 19.8s\n",
            "377:\tlearn: 0.4152967\ttotal: 15.4s\tremaining: 19.8s\n",
            "378:\tlearn: 0.4152661\ttotal: 15.4s\tremaining: 19.9s\n",
            "379:\tlearn: 0.4152236\ttotal: 15.5s\tremaining: 19.8s\n",
            "380:\tlearn: 0.4151896\ttotal: 15.5s\tremaining: 19.8s\n",
            "381:\tlearn: 0.4151512\ttotal: 15.6s\tremaining: 19.8s\n",
            "382:\tlearn: 0.4151193\ttotal: 15.6s\tremaining: 19.7s\n",
            "383:\tlearn: 0.4150826\ttotal: 15.7s\tremaining: 19.7s\n",
            "384:\tlearn: 0.4150580\ttotal: 15.8s\tremaining: 19.7s\n",
            "385:\tlearn: 0.4150392\ttotal: 15.8s\tremaining: 19.7s\n",
            "386:\tlearn: 0.4150096\ttotal: 15.9s\tremaining: 19.7s\n",
            "387:\tlearn: 0.4149762\ttotal: 16s\tremaining: 19.7s\n",
            "388:\tlearn: 0.4149453\ttotal: 16.1s\tremaining: 19.7s\n",
            "389:\tlearn: 0.4149117\ttotal: 16.2s\tremaining: 19.7s\n",
            "390:\tlearn: 0.4148788\ttotal: 16.2s\tremaining: 19.7s\n",
            "391:\tlearn: 0.4148561\ttotal: 16.3s\tremaining: 19.7s\n",
            "392:\tlearn: 0.4148381\ttotal: 16.4s\tremaining: 19.7s\n",
            "393:\tlearn: 0.4148235\ttotal: 16.5s\tremaining: 19.7s\n",
            "394:\tlearn: 0.4148009\ttotal: 16.5s\tremaining: 19.7s\n",
            "395:\tlearn: 0.4147709\ttotal: 16.6s\tremaining: 19.7s\n",
            "396:\tlearn: 0.4147556\ttotal: 16.7s\tremaining: 19.7s\n",
            "397:\tlearn: 0.4147231\ttotal: 16.8s\tremaining: 19.7s\n",
            "398:\tlearn: 0.4147091\ttotal: 16.9s\tremaining: 19.7s\n",
            "399:\tlearn: 0.4146794\ttotal: 16.9s\tremaining: 19.7s\n",
            "400:\tlearn: 0.4146406\ttotal: 17s\tremaining: 19.7s\n",
            "401:\tlearn: 0.4146030\ttotal: 17.1s\tremaining: 19.7s\n",
            "402:\tlearn: 0.4145905\ttotal: 17.2s\tremaining: 19.7s\n",
            "403:\tlearn: 0.4145624\ttotal: 17.2s\tremaining: 19.7s\n",
            "404:\tlearn: 0.4145305\ttotal: 17.3s\tremaining: 19.7s\n",
            "405:\tlearn: 0.4145034\ttotal: 17.3s\tremaining: 19.6s\n",
            "406:\tlearn: 0.4144842\ttotal: 17.3s\tremaining: 19.5s\n",
            "407:\tlearn: 0.4144687\ttotal: 17.4s\tremaining: 19.5s\n",
            "408:\tlearn: 0.4144337\ttotal: 17.4s\tremaining: 19.4s\n",
            "409:\tlearn: 0.4144154\ttotal: 17.4s\tremaining: 19.4s\n",
            "410:\tlearn: 0.4143826\ttotal: 17.5s\tremaining: 19.3s\n",
            "411:\tlearn: 0.4143498\ttotal: 17.5s\tremaining: 19.3s\n",
            "412:\tlearn: 0.4143157\ttotal: 17.5s\tremaining: 19.2s\n",
            "413:\tlearn: 0.4142865\ttotal: 17.6s\tremaining: 19.2s\n",
            "414:\tlearn: 0.4142639\ttotal: 17.6s\tremaining: 19.1s\n",
            "415:\tlearn: 0.4142548\ttotal: 17.6s\tremaining: 19.1s\n",
            "416:\tlearn: 0.4142313\ttotal: 17.7s\tremaining: 19s\n",
            "417:\tlearn: 0.4142054\ttotal: 17.7s\tremaining: 19s\n",
            "418:\tlearn: 0.4141778\ttotal: 17.7s\tremaining: 18.9s\n",
            "419:\tlearn: 0.4141503\ttotal: 17.8s\tremaining: 18.9s\n",
            "420:\tlearn: 0.4141260\ttotal: 17.8s\tremaining: 18.8s\n",
            "421:\tlearn: 0.4141028\ttotal: 17.9s\tremaining: 18.8s\n",
            "422:\tlearn: 0.4140743\ttotal: 17.9s\tremaining: 18.7s\n",
            "423:\tlearn: 0.4140602\ttotal: 17.9s\tremaining: 18.7s\n",
            "424:\tlearn: 0.4140341\ttotal: 18s\tremaining: 18.6s\n",
            "425:\tlearn: 0.4140178\ttotal: 18s\tremaining: 18.6s\n",
            "426:\tlearn: 0.4140021\ttotal: 18s\tremaining: 18.5s\n",
            "427:\tlearn: 0.4139749\ttotal: 18.1s\tremaining: 18.5s\n",
            "428:\tlearn: 0.4139480\ttotal: 18.1s\tremaining: 18.4s\n",
            "429:\tlearn: 0.4139164\ttotal: 18.1s\tremaining: 18.4s\n",
            "430:\tlearn: 0.4138953\ttotal: 18.2s\tremaining: 18.4s\n",
            "431:\tlearn: 0.4138800\ttotal: 18.2s\tremaining: 18.3s\n",
            "432:\tlearn: 0.4138516\ttotal: 18.2s\tremaining: 18.2s\n",
            "433:\tlearn: 0.4138209\ttotal: 18.3s\tremaining: 18.2s\n",
            "434:\tlearn: 0.4137956\ttotal: 18.3s\tremaining: 18.2s\n",
            "435:\tlearn: 0.4137743\ttotal: 18.4s\tremaining: 18.1s\n",
            "436:\tlearn: 0.4137443\ttotal: 18.4s\tremaining: 18.1s\n",
            "437:\tlearn: 0.4137247\ttotal: 18.4s\tremaining: 18s\n",
            "438:\tlearn: 0.4137097\ttotal: 18.5s\tremaining: 18s\n",
            "439:\tlearn: 0.4136875\ttotal: 18.5s\tremaining: 17.9s\n",
            "440:\tlearn: 0.4136603\ttotal: 18.5s\tremaining: 17.9s\n",
            "441:\tlearn: 0.4136340\ttotal: 18.6s\tremaining: 17.8s\n",
            "442:\tlearn: 0.4136181\ttotal: 18.6s\tremaining: 17.8s\n",
            "443:\tlearn: 0.4135997\ttotal: 18.6s\tremaining: 17.7s\n",
            "444:\tlearn: 0.4135828\ttotal: 18.7s\tremaining: 17.7s\n",
            "445:\tlearn: 0.4135603\ttotal: 18.7s\tremaining: 17.6s\n",
            "446:\tlearn: 0.4135417\ttotal: 18.8s\tremaining: 17.6s\n",
            "447:\tlearn: 0.4135008\ttotal: 18.8s\tremaining: 17.5s\n",
            "448:\tlearn: 0.4134732\ttotal: 18.8s\tremaining: 17.5s\n",
            "449:\tlearn: 0.4134540\ttotal: 18.9s\tremaining: 17.4s\n",
            "450:\tlearn: 0.4134383\ttotal: 18.9s\tremaining: 17.4s\n",
            "451:\tlearn: 0.4134110\ttotal: 18.9s\tremaining: 17.3s\n",
            "452:\tlearn: 0.4133865\ttotal: 19s\tremaining: 17.3s\n",
            "453:\tlearn: 0.4133693\ttotal: 19s\tremaining: 17.3s\n",
            "454:\tlearn: 0.4133490\ttotal: 19s\tremaining: 17.2s\n",
            "455:\tlearn: 0.4133199\ttotal: 19.1s\tremaining: 17.2s\n",
            "456:\tlearn: 0.4132908\ttotal: 19.1s\tremaining: 17.1s\n",
            "457:\tlearn: 0.4132647\ttotal: 19.2s\tremaining: 17.1s\n",
            "458:\tlearn: 0.4132523\ttotal: 19.2s\tremaining: 17s\n",
            "459:\tlearn: 0.4132455\ttotal: 19.2s\tremaining: 17s\n",
            "460:\tlearn: 0.4132288\ttotal: 19.3s\tremaining: 16.9s\n",
            "461:\tlearn: 0.4132118\ttotal: 19.3s\tremaining: 16.9s\n",
            "462:\tlearn: 0.4131916\ttotal: 19.3s\tremaining: 16.8s\n",
            "463:\tlearn: 0.4131695\ttotal: 19.4s\tremaining: 16.8s\n",
            "464:\tlearn: 0.4131510\ttotal: 19.4s\tremaining: 16.7s\n",
            "465:\tlearn: 0.4131252\ttotal: 19.4s\tremaining: 16.7s\n",
            "466:\tlearn: 0.4131021\ttotal: 19.5s\tremaining: 16.6s\n",
            "467:\tlearn: 0.4130770\ttotal: 19.5s\tremaining: 16.6s\n",
            "468:\tlearn: 0.4130563\ttotal: 19.5s\tremaining: 16.5s\n",
            "469:\tlearn: 0.4130353\ttotal: 19.6s\tremaining: 16.5s\n",
            "470:\tlearn: 0.4130117\ttotal: 19.6s\tremaining: 16.5s\n",
            "471:\tlearn: 0.4129892\ttotal: 19.7s\tremaining: 16.4s\n",
            "472:\tlearn: 0.4129786\ttotal: 19.7s\tremaining: 16.4s\n",
            "473:\tlearn: 0.4129437\ttotal: 19.7s\tremaining: 16.3s\n",
            "474:\tlearn: 0.4129362\ttotal: 19.8s\tremaining: 16.3s\n",
            "475:\tlearn: 0.4129191\ttotal: 19.8s\tremaining: 16.2s\n",
            "476:\tlearn: 0.4128946\ttotal: 19.8s\tremaining: 16.2s\n",
            "477:\tlearn: 0.4128744\ttotal: 19.9s\tremaining: 16.1s\n",
            "478:\tlearn: 0.4128307\ttotal: 19.9s\tremaining: 16.1s\n",
            "479:\tlearn: 0.4128034\ttotal: 19.9s\tremaining: 16s\n",
            "480:\tlearn: 0.4127724\ttotal: 20s\tremaining: 16s\n",
            "481:\tlearn: 0.4127457\ttotal: 20s\tremaining: 15.9s\n",
            "482:\tlearn: 0.4127354\ttotal: 20s\tremaining: 15.9s\n",
            "483:\tlearn: 0.4127190\ttotal: 20.1s\tremaining: 15.8s\n",
            "484:\tlearn: 0.4126889\ttotal: 20.1s\tremaining: 15.8s\n",
            "485:\tlearn: 0.4126717\ttotal: 20.1s\tremaining: 15.8s\n",
            "486:\tlearn: 0.4126471\ttotal: 20.2s\tremaining: 15.7s\n",
            "487:\tlearn: 0.4126257\ttotal: 20.2s\tremaining: 15.7s\n",
            "488:\tlearn: 0.4126041\ttotal: 20.3s\tremaining: 15.6s\n",
            "489:\tlearn: 0.4125755\ttotal: 20.3s\tremaining: 15.6s\n",
            "490:\tlearn: 0.4125557\ttotal: 20.3s\tremaining: 15.5s\n",
            "491:\tlearn: 0.4125371\ttotal: 20.4s\tremaining: 15.5s\n",
            "492:\tlearn: 0.4125126\ttotal: 20.4s\tremaining: 15.4s\n",
            "493:\tlearn: 0.4124909\ttotal: 20.4s\tremaining: 15.4s\n",
            "494:\tlearn: 0.4124616\ttotal: 20.5s\tremaining: 15.3s\n",
            "495:\tlearn: 0.4124310\ttotal: 20.5s\tremaining: 15.3s\n",
            "496:\tlearn: 0.4124182\ttotal: 20.5s\tremaining: 15.2s\n",
            "497:\tlearn: 0.4124029\ttotal: 20.6s\tremaining: 15.2s\n",
            "498:\tlearn: 0.4123557\ttotal: 20.6s\tremaining: 15.2s\n",
            "499:\tlearn: 0.4123257\ttotal: 20.6s\tremaining: 15.1s\n",
            "500:\tlearn: 0.4123119\ttotal: 20.7s\tremaining: 15.1s\n",
            "501:\tlearn: 0.4122978\ttotal: 20.7s\tremaining: 15s\n",
            "502:\tlearn: 0.4122920\ttotal: 20.7s\tremaining: 15s\n",
            "503:\tlearn: 0.4122525\ttotal: 20.8s\tremaining: 14.9s\n",
            "504:\tlearn: 0.4122143\ttotal: 20.8s\tremaining: 14.9s\n",
            "505:\tlearn: 0.4121629\ttotal: 20.9s\tremaining: 14.8s\n",
            "506:\tlearn: 0.4121325\ttotal: 20.9s\tremaining: 14.8s\n",
            "507:\tlearn: 0.4121124\ttotal: 20.9s\tremaining: 14.7s\n",
            "508:\tlearn: 0.4121007\ttotal: 21s\tremaining: 14.7s\n",
            "509:\tlearn: 0.4120644\ttotal: 21s\tremaining: 14.7s\n",
            "510:\tlearn: 0.4120493\ttotal: 21s\tremaining: 14.6s\n",
            "511:\tlearn: 0.4120185\ttotal: 21.1s\tremaining: 14.6s\n",
            "512:\tlearn: 0.4119894\ttotal: 21.1s\tremaining: 14.5s\n",
            "513:\tlearn: 0.4119576\ttotal: 21.1s\tremaining: 14.5s\n",
            "514:\tlearn: 0.4119358\ttotal: 21.2s\tremaining: 14.4s\n",
            "515:\tlearn: 0.4119345\ttotal: 21.2s\tremaining: 14.4s\n",
            "516:\tlearn: 0.4119153\ttotal: 21.2s\tremaining: 14.3s\n",
            "517:\tlearn: 0.4118790\ttotal: 21.3s\tremaining: 14.3s\n",
            "518:\tlearn: 0.4118525\ttotal: 21.3s\tremaining: 14.2s\n",
            "519:\tlearn: 0.4118223\ttotal: 21.3s\tremaining: 14.2s\n",
            "520:\tlearn: 0.4117863\ttotal: 21.4s\tremaining: 14.2s\n",
            "521:\tlearn: 0.4117671\ttotal: 21.4s\tremaining: 14.1s\n",
            "522:\tlearn: 0.4117454\ttotal: 21.4s\tremaining: 14.1s\n",
            "523:\tlearn: 0.4117447\ttotal: 21.5s\tremaining: 14s\n",
            "524:\tlearn: 0.4117348\ttotal: 21.5s\tremaining: 14s\n",
            "525:\tlearn: 0.4117251\ttotal: 21.5s\tremaining: 13.9s\n",
            "526:\tlearn: 0.4117086\ttotal: 21.6s\tremaining: 13.9s\n",
            "527:\tlearn: 0.4116842\ttotal: 21.6s\tremaining: 13.8s\n",
            "528:\tlearn: 0.4116671\ttotal: 21.6s\tremaining: 13.8s\n",
            "529:\tlearn: 0.4116464\ttotal: 21.7s\tremaining: 13.7s\n",
            "530:\tlearn: 0.4116290\ttotal: 21.7s\tremaining: 13.7s\n",
            "531:\tlearn: 0.4115921\ttotal: 21.7s\tremaining: 13.6s\n",
            "532:\tlearn: 0.4115741\ttotal: 21.8s\tremaining: 13.6s\n",
            "533:\tlearn: 0.4115433\ttotal: 21.8s\tremaining: 13.6s\n",
            "534:\tlearn: 0.4115240\ttotal: 21.8s\tremaining: 13.5s\n",
            "535:\tlearn: 0.4115037\ttotal: 21.9s\tremaining: 13.5s\n",
            "536:\tlearn: 0.4114589\ttotal: 21.9s\tremaining: 13.4s\n",
            "537:\tlearn: 0.4114291\ttotal: 21.9s\tremaining: 13.4s\n",
            "538:\tlearn: 0.4114171\ttotal: 22s\tremaining: 13.3s\n",
            "539:\tlearn: 0.4113730\ttotal: 22s\tremaining: 13.3s\n",
            "540:\tlearn: 0.4113560\ttotal: 22.1s\tremaining: 13.2s\n",
            "541:\tlearn: 0.4113366\ttotal: 22.1s\tremaining: 13.2s\n",
            "542:\tlearn: 0.4113154\ttotal: 22.1s\tremaining: 13.2s\n",
            "543:\tlearn: 0.4112897\ttotal: 22.2s\tremaining: 13.1s\n",
            "544:\tlearn: 0.4112687\ttotal: 22.2s\tremaining: 13.1s\n",
            "545:\tlearn: 0.4112486\ttotal: 22.2s\tremaining: 13s\n",
            "546:\tlearn: 0.4112282\ttotal: 22.3s\tremaining: 13s\n",
            "547:\tlearn: 0.4111953\ttotal: 22.3s\tremaining: 12.9s\n",
            "548:\tlearn: 0.4111754\ttotal: 22.3s\tremaining: 12.9s\n",
            "549:\tlearn: 0.4111481\ttotal: 22.4s\tremaining: 12.9s\n",
            "550:\tlearn: 0.4111245\ttotal: 22.4s\tremaining: 12.8s\n",
            "551:\tlearn: 0.4111067\ttotal: 22.4s\tremaining: 12.8s\n",
            "552:\tlearn: 0.4110874\ttotal: 22.5s\tremaining: 12.7s\n",
            "553:\tlearn: 0.4110865\ttotal: 22.5s\tremaining: 12.7s\n",
            "554:\tlearn: 0.4110703\ttotal: 22.5s\tremaining: 12.6s\n",
            "555:\tlearn: 0.4110498\ttotal: 22.6s\tremaining: 12.6s\n",
            "556:\tlearn: 0.4110099\ttotal: 22.6s\tremaining: 12.5s\n",
            "557:\tlearn: 0.4109744\ttotal: 22.6s\tremaining: 12.5s\n",
            "558:\tlearn: 0.4109549\ttotal: 22.7s\tremaining: 12.5s\n",
            "559:\tlearn: 0.4109235\ttotal: 22.7s\tremaining: 12.4s\n",
            "560:\tlearn: 0.4108815\ttotal: 22.8s\tremaining: 12.4s\n",
            "561:\tlearn: 0.4108608\ttotal: 22.8s\tremaining: 12.3s\n",
            "562:\tlearn: 0.4108368\ttotal: 22.8s\tremaining: 12.3s\n",
            "563:\tlearn: 0.4108166\ttotal: 22.9s\tremaining: 12.2s\n",
            "564:\tlearn: 0.4108047\ttotal: 22.9s\tremaining: 12.2s\n",
            "565:\tlearn: 0.4107827\ttotal: 22.9s\tremaining: 12.2s\n",
            "566:\tlearn: 0.4107638\ttotal: 23s\tremaining: 12.1s\n",
            "567:\tlearn: 0.4107245\ttotal: 23s\tremaining: 12.1s\n",
            "568:\tlearn: 0.4107065\ttotal: 23s\tremaining: 12s\n",
            "569:\tlearn: 0.4106810\ttotal: 23.1s\tremaining: 12s\n",
            "570:\tlearn: 0.4106491\ttotal: 23.1s\tremaining: 11.9s\n",
            "571:\tlearn: 0.4106357\ttotal: 23.1s\tremaining: 11.9s\n",
            "572:\tlearn: 0.4106319\ttotal: 23.2s\tremaining: 11.8s\n",
            "573:\tlearn: 0.4105935\ttotal: 23.2s\tremaining: 11.8s\n",
            "574:\tlearn: 0.4105658\ttotal: 23.3s\tremaining: 11.8s\n",
            "575:\tlearn: 0.4105464\ttotal: 23.3s\tremaining: 11.7s\n",
            "576:\tlearn: 0.4105194\ttotal: 23.3s\tremaining: 11.7s\n",
            "577:\tlearn: 0.4105017\ttotal: 23.4s\tremaining: 11.6s\n",
            "578:\tlearn: 0.4104796\ttotal: 23.4s\tremaining: 11.6s\n",
            "579:\tlearn: 0.4104675\ttotal: 23.4s\tremaining: 11.6s\n",
            "580:\tlearn: 0.4104357\ttotal: 23.5s\tremaining: 11.5s\n",
            "581:\tlearn: 0.4104196\ttotal: 23.5s\tremaining: 11.5s\n",
            "582:\tlearn: 0.4104006\ttotal: 23.6s\tremaining: 11.4s\n",
            "583:\tlearn: 0.4103732\ttotal: 23.6s\tremaining: 11.4s\n",
            "584:\tlearn: 0.4103517\ttotal: 23.6s\tremaining: 11.3s\n",
            "585:\tlearn: 0.4103360\ttotal: 23.7s\tremaining: 11.3s\n",
            "586:\tlearn: 0.4103039\ttotal: 23.7s\tremaining: 11.3s\n",
            "587:\tlearn: 0.4102926\ttotal: 23.7s\tremaining: 11.2s\n",
            "588:\tlearn: 0.4102761\ttotal: 23.8s\tremaining: 11.2s\n",
            "589:\tlearn: 0.4102452\ttotal: 23.8s\tremaining: 11.1s\n",
            "590:\tlearn: 0.4102181\ttotal: 23.8s\tremaining: 11.1s\n",
            "591:\tlearn: 0.4101976\ttotal: 23.9s\tremaining: 11.1s\n",
            "592:\tlearn: 0.4101772\ttotal: 23.9s\tremaining: 11s\n",
            "593:\tlearn: 0.4101541\ttotal: 24s\tremaining: 11s\n",
            "594:\tlearn: 0.4101319\ttotal: 24s\tremaining: 10.9s\n",
            "595:\tlearn: 0.4101044\ttotal: 24s\tremaining: 10.9s\n",
            "596:\tlearn: 0.4100900\ttotal: 24.1s\tremaining: 10.8s\n",
            "597:\tlearn: 0.4100773\ttotal: 24.1s\tremaining: 10.8s\n",
            "598:\tlearn: 0.4100616\ttotal: 24.1s\tremaining: 10.8s\n",
            "599:\tlearn: 0.4100493\ttotal: 24.2s\tremaining: 10.7s\n",
            "600:\tlearn: 0.4100216\ttotal: 24.2s\tremaining: 10.7s\n",
            "601:\tlearn: 0.4100026\ttotal: 24.3s\tremaining: 10.6s\n",
            "602:\tlearn: 0.4099802\ttotal: 24.3s\tremaining: 10.6s\n",
            "603:\tlearn: 0.4099494\ttotal: 24.3s\tremaining: 10.6s\n",
            "604:\tlearn: 0.4099224\ttotal: 24.4s\tremaining: 10.5s\n",
            "605:\tlearn: 0.4099022\ttotal: 24.4s\tremaining: 10.5s\n",
            "606:\tlearn: 0.4098791\ttotal: 24.4s\tremaining: 10.4s\n",
            "607:\tlearn: 0.4098564\ttotal: 24.5s\tremaining: 10.4s\n",
            "608:\tlearn: 0.4098262\ttotal: 24.5s\tremaining: 10.3s\n",
            "609:\tlearn: 0.4098079\ttotal: 24.6s\tremaining: 10.3s\n",
            "610:\tlearn: 0.4097831\ttotal: 24.6s\tremaining: 10.3s\n",
            "611:\tlearn: 0.4097570\ttotal: 24.6s\tremaining: 10.2s\n",
            "612:\tlearn: 0.4097414\ttotal: 24.7s\tremaining: 10.2s\n",
            "613:\tlearn: 0.4097260\ttotal: 24.7s\tremaining: 10.1s\n",
            "614:\tlearn: 0.4097097\ttotal: 24.7s\tremaining: 10.1s\n",
            "615:\tlearn: 0.4096876\ttotal: 24.8s\tremaining: 10.1s\n",
            "616:\tlearn: 0.4096591\ttotal: 24.8s\tremaining: 10s\n",
            "617:\tlearn: 0.4096434\ttotal: 24.8s\tremaining: 9.97s\n",
            "618:\tlearn: 0.4096126\ttotal: 24.9s\tremaining: 9.93s\n",
            "619:\tlearn: 0.4095901\ttotal: 24.9s\tremaining: 9.88s\n",
            "620:\tlearn: 0.4095756\ttotal: 24.9s\tremaining: 9.84s\n",
            "621:\tlearn: 0.4095360\ttotal: 25s\tremaining: 9.8s\n",
            "622:\tlearn: 0.4095123\ttotal: 25s\tremaining: 9.75s\n",
            "623:\tlearn: 0.4094955\ttotal: 25.1s\tremaining: 9.71s\n",
            "624:\tlearn: 0.4094772\ttotal: 25.1s\tremaining: 9.67s\n",
            "625:\tlearn: 0.4094555\ttotal: 25.1s\tremaining: 9.63s\n",
            "626:\tlearn: 0.4094359\ttotal: 25.2s\tremaining: 9.59s\n",
            "627:\tlearn: 0.4094082\ttotal: 25.2s\tremaining: 9.54s\n",
            "628:\tlearn: 0.4093784\ttotal: 25.2s\tremaining: 9.5s\n",
            "629:\tlearn: 0.4093775\ttotal: 25.3s\tremaining: 9.46s\n",
            "630:\tlearn: 0.4093652\ttotal: 25.3s\tremaining: 9.42s\n",
            "631:\tlearn: 0.4093357\ttotal: 25.3s\tremaining: 9.38s\n",
            "632:\tlearn: 0.4093181\ttotal: 25.4s\tremaining: 9.34s\n",
            "633:\tlearn: 0.4092901\ttotal: 25.4s\tremaining: 9.29s\n",
            "634:\tlearn: 0.4092697\ttotal: 25.4s\tremaining: 9.25s\n",
            "635:\tlearn: 0.4092554\ttotal: 25.5s\tremaining: 9.21s\n",
            "636:\tlearn: 0.4092461\ttotal: 25.5s\tremaining: 9.17s\n",
            "637:\tlearn: 0.4092296\ttotal: 25.5s\tremaining: 9.13s\n",
            "638:\tlearn: 0.4092035\ttotal: 25.6s\tremaining: 9.08s\n",
            "639:\tlearn: 0.4091731\ttotal: 25.6s\tremaining: 9.04s\n",
            "640:\tlearn: 0.4091727\ttotal: 25.6s\tremaining: 8.99s\n",
            "641:\tlearn: 0.4091504\ttotal: 25.7s\tremaining: 8.95s\n",
            "642:\tlearn: 0.4091354\ttotal: 25.7s\tremaining: 8.91s\n",
            "643:\tlearn: 0.4091093\ttotal: 25.7s\tremaining: 8.87s\n",
            "644:\tlearn: 0.4090978\ttotal: 25.8s\tremaining: 8.83s\n",
            "645:\tlearn: 0.4090723\ttotal: 25.8s\tremaining: 8.79s\n",
            "646:\tlearn: 0.4090442\ttotal: 25.8s\tremaining: 8.75s\n",
            "647:\tlearn: 0.4090177\ttotal: 25.9s\tremaining: 8.7s\n",
            "648:\tlearn: 0.4089901\ttotal: 25.9s\tremaining: 8.66s\n",
            "649:\tlearn: 0.4089775\ttotal: 25.9s\tremaining: 8.62s\n",
            "650:\tlearn: 0.4089532\ttotal: 26s\tremaining: 8.58s\n",
            "651:\tlearn: 0.4089344\ttotal: 26s\tremaining: 8.54s\n",
            "652:\tlearn: 0.4088977\ttotal: 26.1s\tremaining: 8.5s\n",
            "653:\tlearn: 0.4088827\ttotal: 26.1s\tremaining: 8.46s\n",
            "654:\tlearn: 0.4088697\ttotal: 26.1s\tremaining: 8.41s\n",
            "655:\tlearn: 0.4088469\ttotal: 26.2s\tremaining: 8.37s\n",
            "656:\tlearn: 0.4088178\ttotal: 26.2s\tremaining: 8.33s\n",
            "657:\tlearn: 0.4087995\ttotal: 26.2s\tremaining: 8.29s\n",
            "658:\tlearn: 0.4087814\ttotal: 26.3s\tremaining: 8.25s\n",
            "659:\tlearn: 0.4087602\ttotal: 26.3s\tremaining: 8.21s\n",
            "660:\tlearn: 0.4087420\ttotal: 26.4s\tremaining: 8.17s\n",
            "661:\tlearn: 0.4087286\ttotal: 26.4s\tremaining: 8.13s\n",
            "662:\tlearn: 0.4087156\ttotal: 26.4s\tremaining: 8.09s\n",
            "663:\tlearn: 0.4086983\ttotal: 26.5s\tremaining: 8.05s\n",
            "664:\tlearn: 0.4086885\ttotal: 26.5s\tremaining: 8.01s\n",
            "665:\tlearn: 0.4086796\ttotal: 26.5s\tremaining: 7.96s\n",
            "666:\tlearn: 0.4086550\ttotal: 26.6s\tremaining: 7.93s\n",
            "667:\tlearn: 0.4086306\ttotal: 26.6s\tremaining: 7.89s\n",
            "668:\tlearn: 0.4086074\ttotal: 26.6s\tremaining: 7.84s\n",
            "669:\tlearn: 0.4085834\ttotal: 26.7s\tremaining: 7.8s\n",
            "670:\tlearn: 0.4085729\ttotal: 26.7s\tremaining: 7.76s\n",
            "671:\tlearn: 0.4085463\ttotal: 26.7s\tremaining: 7.72s\n",
            "672:\tlearn: 0.4085279\ttotal: 26.8s\tremaining: 7.68s\n",
            "673:\tlearn: 0.4085050\ttotal: 26.8s\tremaining: 7.64s\n",
            "674:\tlearn: 0.4084946\ttotal: 26.8s\tremaining: 7.6s\n",
            "675:\tlearn: 0.4084662\ttotal: 26.9s\tremaining: 7.56s\n",
            "676:\tlearn: 0.4084386\ttotal: 26.9s\tremaining: 7.51s\n",
            "677:\tlearn: 0.4084221\ttotal: 27s\tremaining: 7.47s\n",
            "678:\tlearn: 0.4084011\ttotal: 27s\tremaining: 7.43s\n",
            "679:\tlearn: 0.4083835\ttotal: 27s\tremaining: 7.39s\n",
            "680:\tlearn: 0.4083578\ttotal: 27.1s\tremaining: 7.35s\n",
            "681:\tlearn: 0.4083574\ttotal: 27.1s\tremaining: 7.3s\n",
            "682:\tlearn: 0.4083471\ttotal: 27.1s\tremaining: 7.27s\n",
            "683:\tlearn: 0.4083288\ttotal: 27.2s\tremaining: 7.23s\n",
            "684:\tlearn: 0.4083100\ttotal: 27.2s\tremaining: 7.2s\n",
            "685:\tlearn: 0.4082926\ttotal: 27.3s\tremaining: 7.17s\n",
            "686:\tlearn: 0.4082602\ttotal: 27.4s\tremaining: 7.13s\n",
            "687:\tlearn: 0.4082495\ttotal: 27.5s\tremaining: 7.1s\n",
            "688:\tlearn: 0.4082201\ttotal: 27.5s\tremaining: 7.08s\n",
            "689:\tlearn: 0.4082083\ttotal: 27.6s\tremaining: 7.04s\n",
            "690:\tlearn: 0.4081952\ttotal: 27.7s\tremaining: 7.01s\n",
            "691:\tlearn: 0.4081859\ttotal: 27.8s\tremaining: 6.99s\n",
            "692:\tlearn: 0.4081557\ttotal: 27.9s\tremaining: 6.96s\n",
            "693:\tlearn: 0.4081348\ttotal: 27.9s\tremaining: 6.93s\n",
            "694:\tlearn: 0.4080955\ttotal: 28s\tremaining: 6.9s\n",
            "695:\tlearn: 0.4080699\ttotal: 28.1s\tremaining: 6.87s\n",
            "696:\tlearn: 0.4080478\ttotal: 28.2s\tremaining: 6.83s\n",
            "697:\tlearn: 0.4080416\ttotal: 28.2s\tremaining: 6.79s\n",
            "698:\tlearn: 0.4080310\ttotal: 28.3s\tremaining: 6.76s\n",
            "699:\tlearn: 0.4080207\ttotal: 28.3s\tremaining: 6.72s\n",
            "700:\tlearn: 0.4079886\ttotal: 28.4s\tremaining: 6.68s\n",
            "701:\tlearn: 0.4079445\ttotal: 28.5s\tremaining: 6.65s\n",
            "702:\tlearn: 0.4079269\ttotal: 28.5s\tremaining: 6.62s\n",
            "703:\tlearn: 0.4079006\ttotal: 28.6s\tremaining: 6.58s\n",
            "704:\tlearn: 0.4078815\ttotal: 28.7s\tremaining: 6.55s\n",
            "705:\tlearn: 0.4078637\ttotal: 28.7s\tremaining: 6.51s\n",
            "706:\tlearn: 0.4078475\ttotal: 28.8s\tremaining: 6.48s\n",
            "707:\tlearn: 0.4078308\ttotal: 28.9s\tremaining: 6.45s\n",
            "708:\tlearn: 0.4078059\ttotal: 29s\tremaining: 6.41s\n",
            "709:\tlearn: 0.4077851\ttotal: 29s\tremaining: 6.38s\n",
            "710:\tlearn: 0.4077740\ttotal: 29.1s\tremaining: 6.34s\n",
            "711:\tlearn: 0.4077511\ttotal: 29.2s\tremaining: 6.31s\n",
            "712:\tlearn: 0.4077207\ttotal: 29.2s\tremaining: 6.27s\n",
            "713:\tlearn: 0.4077077\ttotal: 29.3s\tremaining: 6.24s\n",
            "714:\tlearn: 0.4076822\ttotal: 29.4s\tremaining: 6.21s\n",
            "715:\tlearn: 0.4076613\ttotal: 29.5s\tremaining: 6.18s\n",
            "716:\tlearn: 0.4076322\ttotal: 29.6s\tremaining: 6.15s\n",
            "717:\tlearn: 0.4076147\ttotal: 29.7s\tremaining: 6.11s\n",
            "718:\tlearn: 0.4075937\ttotal: 29.8s\tremaining: 6.08s\n",
            "719:\tlearn: 0.4075742\ttotal: 29.8s\tremaining: 6.05s\n",
            "720:\tlearn: 0.4075554\ttotal: 29.9s\tremaining: 6.01s\n",
            "721:\tlearn: 0.4075548\ttotal: 29.9s\tremaining: 5.97s\n",
            "722:\tlearn: 0.4075315\ttotal: 29.9s\tremaining: 5.92s\n",
            "723:\tlearn: 0.4075103\ttotal: 30s\tremaining: 5.88s\n",
            "724:\tlearn: 0.4074853\ttotal: 30s\tremaining: 5.84s\n",
            "725:\tlearn: 0.4074707\ttotal: 30s\tremaining: 5.79s\n",
            "726:\tlearn: 0.4074409\ttotal: 30.1s\tremaining: 5.75s\n",
            "727:\tlearn: 0.4074206\ttotal: 30.1s\tremaining: 5.71s\n",
            "728:\tlearn: 0.4073929\ttotal: 30.2s\tremaining: 5.67s\n",
            "729:\tlearn: 0.4073690\ttotal: 30.2s\tremaining: 5.62s\n",
            "730:\tlearn: 0.4073628\ttotal: 30.2s\tremaining: 5.58s\n",
            "731:\tlearn: 0.4073350\ttotal: 30.3s\tremaining: 5.54s\n",
            "732:\tlearn: 0.4073116\ttotal: 30.3s\tremaining: 5.5s\n",
            "733:\tlearn: 0.4072707\ttotal: 30.3s\tremaining: 5.45s\n",
            "734:\tlearn: 0.4072504\ttotal: 30.4s\tremaining: 5.41s\n",
            "735:\tlearn: 0.4072290\ttotal: 30.4s\tremaining: 5.37s\n",
            "736:\tlearn: 0.4071908\ttotal: 30.4s\tremaining: 5.33s\n",
            "737:\tlearn: 0.4071574\ttotal: 30.5s\tremaining: 5.29s\n",
            "738:\tlearn: 0.4071449\ttotal: 30.5s\tremaining: 5.24s\n",
            "739:\tlearn: 0.4071211\ttotal: 30.6s\tremaining: 5.2s\n",
            "740:\tlearn: 0.4071094\ttotal: 30.6s\tremaining: 5.16s\n",
            "741:\tlearn: 0.4070914\ttotal: 30.6s\tremaining: 5.12s\n",
            "742:\tlearn: 0.4070674\ttotal: 30.7s\tremaining: 5.08s\n",
            "743:\tlearn: 0.4070494\ttotal: 30.7s\tremaining: 5.03s\n",
            "744:\tlearn: 0.4070313\ttotal: 30.7s\tremaining: 4.99s\n",
            "745:\tlearn: 0.4070051\ttotal: 30.8s\tremaining: 4.95s\n",
            "746:\tlearn: 0.4069759\ttotal: 30.8s\tremaining: 4.91s\n",
            "747:\tlearn: 0.4069613\ttotal: 30.8s\tremaining: 4.87s\n",
            "748:\tlearn: 0.4069467\ttotal: 30.9s\tremaining: 4.82s\n",
            "749:\tlearn: 0.4069246\ttotal: 30.9s\tremaining: 4.78s\n",
            "750:\tlearn: 0.4068954\ttotal: 30.9s\tremaining: 4.74s\n",
            "751:\tlearn: 0.4068589\ttotal: 31s\tremaining: 4.7s\n",
            "752:\tlearn: 0.4068333\ttotal: 31s\tremaining: 4.65s\n",
            "753:\tlearn: 0.4068108\ttotal: 31.1s\tremaining: 4.61s\n",
            "754:\tlearn: 0.4067843\ttotal: 31.1s\tremaining: 4.57s\n",
            "755:\tlearn: 0.4067603\ttotal: 31.1s\tremaining: 4.53s\n",
            "756:\tlearn: 0.4067416\ttotal: 31.2s\tremaining: 4.49s\n",
            "757:\tlearn: 0.4067238\ttotal: 31.2s\tremaining: 4.44s\n",
            "758:\tlearn: 0.4066924\ttotal: 31.2s\tremaining: 4.4s\n",
            "759:\tlearn: 0.4066690\ttotal: 31.3s\tremaining: 4.36s\n",
            "760:\tlearn: 0.4066431\ttotal: 31.3s\tremaining: 4.32s\n",
            "761:\tlearn: 0.4066214\ttotal: 31.3s\tremaining: 4.28s\n",
            "762:\tlearn: 0.4066061\ttotal: 31.4s\tremaining: 4.23s\n",
            "763:\tlearn: 0.4065920\ttotal: 31.4s\tremaining: 4.19s\n",
            "764:\tlearn: 0.4065676\ttotal: 31.5s\tremaining: 4.15s\n",
            "765:\tlearn: 0.4065400\ttotal: 31.5s\tremaining: 4.11s\n",
            "766:\tlearn: 0.4065109\ttotal: 31.5s\tremaining: 4.07s\n",
            "767:\tlearn: 0.4064882\ttotal: 31.6s\tremaining: 4.03s\n",
            "768:\tlearn: 0.4064582\ttotal: 31.6s\tremaining: 3.98s\n",
            "769:\tlearn: 0.4064370\ttotal: 31.6s\tremaining: 3.94s\n",
            "770:\tlearn: 0.4064128\ttotal: 31.7s\tremaining: 3.9s\n",
            "771:\tlearn: 0.4063751\ttotal: 31.7s\tremaining: 3.86s\n",
            "772:\tlearn: 0.4063446\ttotal: 31.7s\tremaining: 3.82s\n",
            "773:\tlearn: 0.4063229\ttotal: 31.8s\tremaining: 3.78s\n",
            "774:\tlearn: 0.4063095\ttotal: 31.8s\tremaining: 3.73s\n",
            "775:\tlearn: 0.4062906\ttotal: 31.9s\tremaining: 3.69s\n",
            "776:\tlearn: 0.4062592\ttotal: 31.9s\tremaining: 3.65s\n",
            "777:\tlearn: 0.4062291\ttotal: 31.9s\tremaining: 3.61s\n",
            "778:\tlearn: 0.4062119\ttotal: 32s\tremaining: 3.57s\n",
            "779:\tlearn: 0.4062095\ttotal: 32s\tremaining: 3.52s\n",
            "780:\tlearn: 0.4061803\ttotal: 32s\tremaining: 3.48s\n",
            "781:\tlearn: 0.4061675\ttotal: 32s\tremaining: 3.44s\n",
            "782:\tlearn: 0.4061386\ttotal: 32.1s\tremaining: 3.4s\n",
            "783:\tlearn: 0.4061253\ttotal: 32.1s\tremaining: 3.36s\n",
            "784:\tlearn: 0.4061108\ttotal: 32.2s\tremaining: 3.32s\n",
            "785:\tlearn: 0.4060991\ttotal: 32.2s\tremaining: 3.27s\n",
            "786:\tlearn: 0.4060686\ttotal: 32.2s\tremaining: 3.23s\n",
            "787:\tlearn: 0.4060498\ttotal: 32.3s\tremaining: 3.19s\n",
            "788:\tlearn: 0.4060335\ttotal: 32.3s\tremaining: 3.15s\n",
            "789:\tlearn: 0.4060084\ttotal: 32.3s\tremaining: 3.11s\n",
            "790:\tlearn: 0.4059953\ttotal: 32.4s\tremaining: 3.07s\n",
            "791:\tlearn: 0.4059737\ttotal: 32.4s\tremaining: 3.03s\n",
            "792:\tlearn: 0.4059526\ttotal: 32.4s\tremaining: 2.99s\n",
            "793:\tlearn: 0.4059372\ttotal: 32.5s\tremaining: 2.94s\n",
            "794:\tlearn: 0.4059255\ttotal: 32.5s\tremaining: 2.9s\n",
            "795:\tlearn: 0.4058972\ttotal: 32.5s\tremaining: 2.86s\n",
            "796:\tlearn: 0.4058950\ttotal: 32.6s\tremaining: 2.82s\n",
            "797:\tlearn: 0.4058848\ttotal: 32.6s\tremaining: 2.78s\n",
            "798:\tlearn: 0.4058582\ttotal: 32.6s\tremaining: 2.74s\n",
            "799:\tlearn: 0.4058360\ttotal: 32.7s\tremaining: 2.7s\n",
            "800:\tlearn: 0.4058069\ttotal: 32.7s\tremaining: 2.65s\n",
            "801:\tlearn: 0.4057863\ttotal: 32.8s\tremaining: 2.61s\n",
            "802:\tlearn: 0.4057658\ttotal: 32.8s\tremaining: 2.57s\n",
            "803:\tlearn: 0.4057384\ttotal: 32.8s\tremaining: 2.53s\n",
            "804:\tlearn: 0.4057161\ttotal: 32.9s\tremaining: 2.49s\n",
            "805:\tlearn: 0.4056921\ttotal: 32.9s\tremaining: 2.45s\n",
            "806:\tlearn: 0.4056657\ttotal: 32.9s\tremaining: 2.41s\n",
            "807:\tlearn: 0.4056419\ttotal: 33s\tremaining: 2.37s\n",
            "808:\tlearn: 0.4056277\ttotal: 33s\tremaining: 2.33s\n",
            "809:\tlearn: 0.4056002\ttotal: 33s\tremaining: 2.28s\n",
            "810:\tlearn: 0.4055652\ttotal: 33.1s\tremaining: 2.24s\n",
            "811:\tlearn: 0.4055508\ttotal: 33.1s\tremaining: 2.2s\n",
            "812:\tlearn: 0.4055261\ttotal: 33.2s\tremaining: 2.16s\n",
            "813:\tlearn: 0.4055124\ttotal: 33.2s\tremaining: 2.12s\n",
            "814:\tlearn: 0.4054835\ttotal: 33.2s\tremaining: 2.08s\n",
            "815:\tlearn: 0.4054600\ttotal: 33.3s\tremaining: 2.04s\n",
            "816:\tlearn: 0.4054218\ttotal: 33.3s\tremaining: 2s\n",
            "817:\tlearn: 0.4053931\ttotal: 33.3s\tremaining: 1.96s\n",
            "818:\tlearn: 0.4053696\ttotal: 33.4s\tremaining: 1.91s\n",
            "819:\tlearn: 0.4053476\ttotal: 33.4s\tremaining: 1.87s\n",
            "820:\tlearn: 0.4053309\ttotal: 33.5s\tremaining: 1.83s\n",
            "821:\tlearn: 0.4053103\ttotal: 33.5s\tremaining: 1.79s\n",
            "822:\tlearn: 0.4052838\ttotal: 33.5s\tremaining: 1.75s\n",
            "823:\tlearn: 0.4052647\ttotal: 33.6s\tremaining: 1.71s\n",
            "824:\tlearn: 0.4052404\ttotal: 33.6s\tremaining: 1.67s\n",
            "825:\tlearn: 0.4052234\ttotal: 33.6s\tremaining: 1.63s\n",
            "826:\tlearn: 0.4051907\ttotal: 33.7s\tremaining: 1.59s\n",
            "827:\tlearn: 0.4051654\ttotal: 33.7s\tremaining: 1.55s\n",
            "828:\tlearn: 0.4051315\ttotal: 33.8s\tremaining: 1.51s\n",
            "829:\tlearn: 0.4051061\ttotal: 33.8s\tremaining: 1.47s\n",
            "830:\tlearn: 0.4050841\ttotal: 33.8s\tremaining: 1.42s\n",
            "831:\tlearn: 0.4050630\ttotal: 33.9s\tremaining: 1.38s\n",
            "832:\tlearn: 0.4050379\ttotal: 33.9s\tremaining: 1.34s\n",
            "833:\tlearn: 0.4050151\ttotal: 33.9s\tremaining: 1.3s\n",
            "834:\tlearn: 0.4049899\ttotal: 34s\tremaining: 1.26s\n",
            "835:\tlearn: 0.4049622\ttotal: 34s\tremaining: 1.22s\n",
            "836:\tlearn: 0.4049295\ttotal: 34.1s\tremaining: 1.18s\n",
            "837:\tlearn: 0.4049127\ttotal: 34.1s\tremaining: 1.14s\n",
            "838:\tlearn: 0.4048962\ttotal: 34.1s\tremaining: 1.1s\n",
            "839:\tlearn: 0.4048759\ttotal: 34.2s\tremaining: 1.06s\n",
            "840:\tlearn: 0.4048611\ttotal: 34.2s\tremaining: 1.02s\n",
            "841:\tlearn: 0.4048441\ttotal: 34.2s\tremaining: 976ms\n",
            "842:\tlearn: 0.4048216\ttotal: 34.3s\tremaining: 935ms\n",
            "843:\tlearn: 0.4048038\ttotal: 34.3s\tremaining: 894ms\n",
            "844:\tlearn: 0.4047900\ttotal: 34.3s\tremaining: 853ms\n",
            "845:\tlearn: 0.4047582\ttotal: 34.4s\tremaining: 813ms\n",
            "846:\tlearn: 0.4047368\ttotal: 34.4s\tremaining: 772ms\n",
            "847:\tlearn: 0.4047135\ttotal: 34.4s\tremaining: 731ms\n",
            "848:\tlearn: 0.4046965\ttotal: 34.5s\tremaining: 691ms\n",
            "849:\tlearn: 0.4046756\ttotal: 34.5s\tremaining: 650ms\n",
            "850:\tlearn: 0.4046474\ttotal: 34.6s\tremaining: 609ms\n",
            "851:\tlearn: 0.4046237\ttotal: 34.6s\tremaining: 569ms\n",
            "852:\tlearn: 0.4045949\ttotal: 34.6s\tremaining: 528ms\n",
            "853:\tlearn: 0.4045830\ttotal: 34.7s\tremaining: 487ms\n",
            "854:\tlearn: 0.4045634\ttotal: 34.7s\tremaining: 447ms\n",
            "855:\tlearn: 0.4045440\ttotal: 34.8s\tremaining: 406ms\n",
            "856:\tlearn: 0.4045190\ttotal: 34.8s\tremaining: 365ms\n",
            "857:\tlearn: 0.4044936\ttotal: 34.8s\tremaining: 325ms\n",
            "858:\tlearn: 0.4044816\ttotal: 34.9s\tremaining: 284ms\n",
            "859:\tlearn: 0.4044582\ttotal: 34.9s\tremaining: 243ms\n",
            "860:\tlearn: 0.4044338\ttotal: 34.9s\tremaining: 203ms\n",
            "861:\tlearn: 0.4044164\ttotal: 35s\tremaining: 162ms\n",
            "862:\tlearn: 0.4043962\ttotal: 35s\tremaining: 122ms\n",
            "863:\tlearn: 0.4043675\ttotal: 35s\tremaining: 81.1ms\n",
            "864:\tlearn: 0.4043482\ttotal: 35.1s\tremaining: 40.6ms\n",
            "865:\tlearn: 0.4043325\ttotal: 35.1s\tremaining: 0us\n",
            "  28/3714 [..............................] - ETA: 7s - loss: 0.2995 - accuracy: 0.8594 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3714/3714 [==============================] - 8s 2ms/step - loss: 0.3119 - accuracy: 0.8698\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22997, number of negative: 95827\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002707 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 118824, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193538 -> initscore=-1.427181\n",
            "[LightGBM] [Info] Start training from score -1.427181\n",
            "929/929 [==============================] - 1s 1ms/step\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Voting Classifier Accuracy: 0.8712717969433784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probabilities = voting_clf.predict_proba(x_test)[:, 1]\n",
        "\n",
        "auc_roc = roc_auc_score(y_test, pred_probabilities)\n",
        "\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8cR2e5uZWoK",
        "outputId": "c5294631-25b6-4eff-b1cd-188670e6de9f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "929/929 [==============================] - 3s 3ms/step\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "AUC-ROC Score: 0.8909406252088755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rPWFpTBOZ5Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Define the models with specific parameters\n",
        "catboost_model = CatBoostClassifier(iterations=690, depth=4, learning_rate=0.05448177925552803, l2_leaf_reg=0.09165997221410027, scale_pos_weight=5.876546795296569)\n",
        "lgbm_model = LGBMClassifier()\n",
        "rfc = RandomForestClassifier(n_estimators=763, max_depth=10, min_samples_split=10, min_samples_leaf=13, max_features='log2', criterion='gini', bootstrap=False)\n",
        "\n",
        "\n",
        "# Define the voting classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('catboost', catboost_model),\n",
        "        ('lgbm', lgbm_model),\n",
        "        ('rfc', rfc)\n",
        "    ],\n",
        "    voting='soft'  # Use soft voting for probability voting\n",
        ")\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(x, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CJ16yRGAZiCw",
        "outputId": "ae97f309-e153-4396-a1c6-34a189c489cb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6641269\ttotal: 103ms\tremaining: 1m 11s\n",
            "1:\tlearn: 0.6403960\ttotal: 180ms\tremaining: 1m 1s\n",
            "2:\tlearn: 0.6182533\ttotal: 244ms\tremaining: 56s\n",
            "3:\tlearn: 0.5980074\ttotal: 349ms\tremaining: 59.9s\n",
            "4:\tlearn: 0.5817357\ttotal: 439ms\tremaining: 1m\n",
            "5:\tlearn: 0.5667366\ttotal: 507ms\tremaining: 57.8s\n",
            "6:\tlearn: 0.5527064\ttotal: 574ms\tremaining: 56s\n",
            "7:\tlearn: 0.5415214\ttotal: 637ms\tremaining: 54.3s\n",
            "8:\tlearn: 0.5316039\ttotal: 699ms\tremaining: 52.9s\n",
            "9:\tlearn: 0.5223286\ttotal: 765ms\tremaining: 52s\n",
            "10:\tlearn: 0.5138014\ttotal: 833ms\tremaining: 51.4s\n",
            "11:\tlearn: 0.5066864\ttotal: 896ms\tremaining: 50.6s\n",
            "12:\tlearn: 0.4998398\ttotal: 960ms\tremaining: 50s\n",
            "13:\tlearn: 0.4938746\ttotal: 1.04s\tremaining: 50.2s\n",
            "14:\tlearn: 0.4878549\ttotal: 1.1s\tremaining: 49.5s\n",
            "15:\tlearn: 0.4825495\ttotal: 1.18s\tremaining: 49.7s\n",
            "16:\tlearn: 0.4776903\ttotal: 1.24s\tremaining: 49.3s\n",
            "17:\tlearn: 0.4735573\ttotal: 1.27s\tremaining: 47.4s\n",
            "18:\tlearn: 0.4701468\ttotal: 1.3s\tremaining: 45.8s\n",
            "19:\tlearn: 0.4669814\ttotal: 1.33s\tremaining: 44.5s\n",
            "20:\tlearn: 0.4638583\ttotal: 1.36s\tremaining: 43.3s\n",
            "21:\tlearn: 0.4608885\ttotal: 1.39s\tremaining: 42.1s\n",
            "22:\tlearn: 0.4582008\ttotal: 1.41s\tremaining: 41s\n",
            "23:\tlearn: 0.4559162\ttotal: 1.44s\tremaining: 40s\n",
            "24:\tlearn: 0.4534298\ttotal: 1.47s\tremaining: 39.2s\n",
            "25:\tlearn: 0.4510075\ttotal: 1.5s\tremaining: 38.3s\n",
            "26:\tlearn: 0.4488484\ttotal: 1.52s\tremaining: 37.5s\n",
            "27:\tlearn: 0.4471822\ttotal: 1.55s\tremaining: 36.7s\n",
            "28:\tlearn: 0.4455269\ttotal: 1.57s\tremaining: 35.9s\n",
            "29:\tlearn: 0.4436988\ttotal: 1.6s\tremaining: 35.3s\n",
            "30:\tlearn: 0.4423234\ttotal: 1.63s\tremaining: 34.7s\n",
            "31:\tlearn: 0.4410925\ttotal: 1.66s\tremaining: 34.1s\n",
            "32:\tlearn: 0.4396872\ttotal: 1.69s\tremaining: 33.6s\n",
            "33:\tlearn: 0.4383710\ttotal: 1.71s\tremaining: 33.1s\n",
            "34:\tlearn: 0.4370989\ttotal: 1.74s\tremaining: 32.6s\n",
            "35:\tlearn: 0.4360220\ttotal: 1.76s\tremaining: 32.1s\n",
            "36:\tlearn: 0.4349741\ttotal: 1.79s\tremaining: 31.6s\n",
            "37:\tlearn: 0.4340969\ttotal: 1.82s\tremaining: 31.2s\n",
            "38:\tlearn: 0.4332060\ttotal: 1.85s\tremaining: 30.8s\n",
            "39:\tlearn: 0.4324930\ttotal: 1.88s\tremaining: 30.5s\n",
            "40:\tlearn: 0.4319535\ttotal: 1.9s\tremaining: 30.1s\n",
            "41:\tlearn: 0.4310175\ttotal: 1.93s\tremaining: 29.8s\n",
            "42:\tlearn: 0.4301202\ttotal: 1.96s\tremaining: 29.5s\n",
            "43:\tlearn: 0.4296619\ttotal: 1.99s\tremaining: 29.3s\n",
            "44:\tlearn: 0.4288569\ttotal: 2.02s\tremaining: 29s\n",
            "45:\tlearn: 0.4282371\ttotal: 2.05s\tremaining: 28.7s\n",
            "46:\tlearn: 0.4278787\ttotal: 2.07s\tremaining: 28.4s\n",
            "47:\tlearn: 0.4273340\ttotal: 2.11s\tremaining: 28.2s\n",
            "48:\tlearn: 0.4270137\ttotal: 2.13s\tremaining: 27.9s\n",
            "49:\tlearn: 0.4265080\ttotal: 2.17s\tremaining: 27.8s\n",
            "50:\tlearn: 0.4259588\ttotal: 2.21s\tremaining: 27.6s\n",
            "51:\tlearn: 0.4253953\ttotal: 2.24s\tremaining: 27.5s\n",
            "52:\tlearn: 0.4248680\ttotal: 2.27s\tremaining: 27.3s\n",
            "53:\tlearn: 0.4244768\ttotal: 2.29s\tremaining: 27s\n",
            "54:\tlearn: 0.4242420\ttotal: 2.33s\tremaining: 26.9s\n",
            "55:\tlearn: 0.4239233\ttotal: 2.35s\tremaining: 26.7s\n",
            "56:\tlearn: 0.4236317\ttotal: 2.38s\tremaining: 26.5s\n",
            "57:\tlearn: 0.4231952\ttotal: 2.41s\tremaining: 26.2s\n",
            "58:\tlearn: 0.4228942\ttotal: 2.43s\tremaining: 26s\n",
            "59:\tlearn: 0.4225937\ttotal: 2.46s\tremaining: 25.9s\n",
            "60:\tlearn: 0.4224291\ttotal: 2.49s\tremaining: 25.7s\n",
            "61:\tlearn: 0.4221426\ttotal: 2.51s\tremaining: 25.5s\n",
            "62:\tlearn: 0.4218224\ttotal: 2.54s\tremaining: 25.3s\n",
            "63:\tlearn: 0.4216608\ttotal: 2.57s\tremaining: 25.2s\n",
            "64:\tlearn: 0.4214252\ttotal: 2.6s\tremaining: 25s\n",
            "65:\tlearn: 0.4210522\ttotal: 2.63s\tremaining: 24.9s\n",
            "66:\tlearn: 0.4207818\ttotal: 2.66s\tremaining: 24.7s\n",
            "67:\tlearn: 0.4204515\ttotal: 2.68s\tremaining: 24.6s\n",
            "68:\tlearn: 0.4201735\ttotal: 2.71s\tremaining: 24.4s\n",
            "69:\tlearn: 0.4200847\ttotal: 2.75s\tremaining: 24.3s\n",
            "70:\tlearn: 0.4199974\ttotal: 2.78s\tremaining: 24.2s\n",
            "71:\tlearn: 0.4197962\ttotal: 2.8s\tremaining: 24s\n",
            "72:\tlearn: 0.4195860\ttotal: 2.83s\tremaining: 23.9s\n",
            "73:\tlearn: 0.4194670\ttotal: 2.85s\tremaining: 23.8s\n",
            "74:\tlearn: 0.4193708\ttotal: 2.88s\tremaining: 23.6s\n",
            "75:\tlearn: 0.4192296\ttotal: 2.91s\tremaining: 23.5s\n",
            "76:\tlearn: 0.4190731\ttotal: 2.94s\tremaining: 23.4s\n",
            "77:\tlearn: 0.4188718\ttotal: 2.97s\tremaining: 23.3s\n",
            "78:\tlearn: 0.4187918\ttotal: 3.01s\tremaining: 23.3s\n",
            "79:\tlearn: 0.4187247\ttotal: 3.03s\tremaining: 23.1s\n",
            "80:\tlearn: 0.4186672\ttotal: 3.05s\tremaining: 22.9s\n",
            "81:\tlearn: 0.4185838\ttotal: 3.08s\tremaining: 22.8s\n",
            "82:\tlearn: 0.4184842\ttotal: 3.1s\tremaining: 22.7s\n",
            "83:\tlearn: 0.4183669\ttotal: 3.12s\tremaining: 22.5s\n",
            "84:\tlearn: 0.4183220\ttotal: 3.15s\tremaining: 22.4s\n",
            "85:\tlearn: 0.4181996\ttotal: 3.19s\tremaining: 22.4s\n",
            "86:\tlearn: 0.4180808\ttotal: 3.22s\tremaining: 22.3s\n",
            "87:\tlearn: 0.4179943\ttotal: 3.25s\tremaining: 22.2s\n",
            "88:\tlearn: 0.4179560\ttotal: 3.27s\tremaining: 22.1s\n",
            "89:\tlearn: 0.4177901\ttotal: 3.3s\tremaining: 22s\n",
            "90:\tlearn: 0.4176868\ttotal: 3.33s\tremaining: 21.9s\n",
            "91:\tlearn: 0.4175760\ttotal: 3.35s\tremaining: 21.8s\n",
            "92:\tlearn: 0.4174901\ttotal: 3.38s\tremaining: 21.7s\n",
            "93:\tlearn: 0.4173270\ttotal: 3.41s\tremaining: 21.6s\n",
            "94:\tlearn: 0.4172788\ttotal: 3.44s\tremaining: 21.5s\n",
            "95:\tlearn: 0.4172184\ttotal: 3.46s\tremaining: 21.4s\n",
            "96:\tlearn: 0.4170688\ttotal: 3.48s\tremaining: 21.3s\n",
            "97:\tlearn: 0.4170310\ttotal: 3.51s\tremaining: 21.2s\n",
            "98:\tlearn: 0.4169775\ttotal: 3.54s\tremaining: 21.1s\n",
            "99:\tlearn: 0.4168404\ttotal: 3.56s\tremaining: 21s\n",
            "100:\tlearn: 0.4167886\ttotal: 3.6s\tremaining: 21s\n",
            "101:\tlearn: 0.4167526\ttotal: 3.62s\tremaining: 20.9s\n",
            "102:\tlearn: 0.4166884\ttotal: 3.65s\tremaining: 20.8s\n",
            "103:\tlearn: 0.4166374\ttotal: 3.67s\tremaining: 20.7s\n",
            "104:\tlearn: 0.4165766\ttotal: 3.7s\tremaining: 20.6s\n",
            "105:\tlearn: 0.4164486\ttotal: 3.73s\tremaining: 20.5s\n",
            "106:\tlearn: 0.4163498\ttotal: 3.75s\tremaining: 20.4s\n",
            "107:\tlearn: 0.4162872\ttotal: 3.78s\tremaining: 20.4s\n",
            "108:\tlearn: 0.4161750\ttotal: 3.81s\tremaining: 20.3s\n",
            "109:\tlearn: 0.4161446\ttotal: 3.84s\tremaining: 20.2s\n",
            "110:\tlearn: 0.4160717\ttotal: 3.86s\tremaining: 20.1s\n",
            "111:\tlearn: 0.4160288\ttotal: 3.88s\tremaining: 20s\n",
            "112:\tlearn: 0.4159806\ttotal: 3.91s\tremaining: 20s\n",
            "113:\tlearn: 0.4159383\ttotal: 3.93s\tremaining: 19.9s\n",
            "114:\tlearn: 0.4158950\ttotal: 3.96s\tremaining: 19.8s\n",
            "115:\tlearn: 0.4158486\ttotal: 3.99s\tremaining: 19.7s\n",
            "116:\tlearn: 0.4157893\ttotal: 4.02s\tremaining: 19.7s\n",
            "117:\tlearn: 0.4157695\ttotal: 4.04s\tremaining: 19.6s\n",
            "118:\tlearn: 0.4156745\ttotal: 4.07s\tremaining: 19.5s\n",
            "119:\tlearn: 0.4155908\ttotal: 4.09s\tremaining: 19.4s\n",
            "120:\tlearn: 0.4155594\ttotal: 4.12s\tremaining: 19.4s\n",
            "121:\tlearn: 0.4155190\ttotal: 4.14s\tremaining: 19.3s\n",
            "122:\tlearn: 0.4154909\ttotal: 4.17s\tremaining: 19.2s\n",
            "123:\tlearn: 0.4154162\ttotal: 4.22s\tremaining: 19.2s\n",
            "124:\tlearn: 0.4153920\ttotal: 4.24s\tremaining: 19.2s\n",
            "125:\tlearn: 0.4153543\ttotal: 4.27s\tremaining: 19.1s\n",
            "126:\tlearn: 0.4153074\ttotal: 4.3s\tremaining: 19.1s\n",
            "127:\tlearn: 0.4152780\ttotal: 4.32s\tremaining: 19s\n",
            "128:\tlearn: 0.4152413\ttotal: 4.35s\tremaining: 18.9s\n",
            "129:\tlearn: 0.4151792\ttotal: 4.37s\tremaining: 18.8s\n",
            "130:\tlearn: 0.4151359\ttotal: 4.4s\tremaining: 18.8s\n",
            "131:\tlearn: 0.4150471\ttotal: 4.42s\tremaining: 18.7s\n",
            "132:\tlearn: 0.4150187\ttotal: 4.45s\tremaining: 18.6s\n",
            "133:\tlearn: 0.4149868\ttotal: 4.48s\tremaining: 18.6s\n",
            "134:\tlearn: 0.4149214\ttotal: 4.5s\tremaining: 18.5s\n",
            "135:\tlearn: 0.4148905\ttotal: 4.53s\tremaining: 18.4s\n",
            "136:\tlearn: 0.4148645\ttotal: 4.55s\tremaining: 18.4s\n",
            "137:\tlearn: 0.4148302\ttotal: 4.58s\tremaining: 18.3s\n",
            "138:\tlearn: 0.4148087\ttotal: 4.6s\tremaining: 18.3s\n",
            "139:\tlearn: 0.4147563\ttotal: 4.63s\tremaining: 18.2s\n",
            "140:\tlearn: 0.4147295\ttotal: 4.66s\tremaining: 18.1s\n",
            "141:\tlearn: 0.4147107\ttotal: 4.68s\tremaining: 18.1s\n",
            "142:\tlearn: 0.4146785\ttotal: 4.71s\tremaining: 18s\n",
            "143:\tlearn: 0.4146564\ttotal: 4.75s\tremaining: 18s\n",
            "144:\tlearn: 0.4146226\ttotal: 4.77s\tremaining: 17.9s\n",
            "145:\tlearn: 0.4145963\ttotal: 4.79s\tremaining: 17.9s\n",
            "146:\tlearn: 0.4145692\ttotal: 4.82s\tremaining: 17.8s\n",
            "147:\tlearn: 0.4145514\ttotal: 4.84s\tremaining: 17.7s\n",
            "148:\tlearn: 0.4145216\ttotal: 4.87s\tremaining: 17.7s\n",
            "149:\tlearn: 0.4145043\ttotal: 4.9s\tremaining: 17.6s\n",
            "150:\tlearn: 0.4144834\ttotal: 4.93s\tremaining: 17.6s\n",
            "151:\tlearn: 0.4144575\ttotal: 4.96s\tremaining: 17.5s\n",
            "152:\tlearn: 0.4144200\ttotal: 4.99s\tremaining: 17.5s\n",
            "153:\tlearn: 0.4143868\ttotal: 5.02s\tremaining: 17.5s\n",
            "154:\tlearn: 0.4143500\ttotal: 5.04s\tremaining: 17.4s\n",
            "155:\tlearn: 0.4143350\ttotal: 5.07s\tremaining: 17.3s\n",
            "156:\tlearn: 0.4143069\ttotal: 5.1s\tremaining: 17.3s\n",
            "157:\tlearn: 0.4142750\ttotal: 5.13s\tremaining: 17.3s\n",
            "158:\tlearn: 0.4142494\ttotal: 5.15s\tremaining: 17.2s\n",
            "159:\tlearn: 0.4141922\ttotal: 5.18s\tremaining: 17.1s\n",
            "160:\tlearn: 0.4141504\ttotal: 5.2s\tremaining: 17.1s\n",
            "161:\tlearn: 0.4141134\ttotal: 5.25s\tremaining: 17.1s\n",
            "162:\tlearn: 0.4140977\ttotal: 5.29s\tremaining: 17.1s\n",
            "163:\tlearn: 0.4140704\ttotal: 5.31s\tremaining: 17s\n",
            "164:\tlearn: 0.4140365\ttotal: 5.34s\tremaining: 17s\n",
            "165:\tlearn: 0.4140071\ttotal: 5.37s\tremaining: 16.9s\n",
            "166:\tlearn: 0.4139890\ttotal: 5.39s\tremaining: 16.9s\n",
            "167:\tlearn: 0.4139789\ttotal: 5.42s\tremaining: 16.8s\n",
            "168:\tlearn: 0.4139492\ttotal: 5.44s\tremaining: 16.8s\n",
            "169:\tlearn: 0.4139120\ttotal: 5.47s\tremaining: 16.7s\n",
            "170:\tlearn: 0.4138910\ttotal: 5.5s\tremaining: 16.7s\n",
            "171:\tlearn: 0.4138614\ttotal: 5.52s\tremaining: 16.6s\n",
            "172:\tlearn: 0.4138208\ttotal: 5.56s\tremaining: 16.6s\n",
            "173:\tlearn: 0.4137884\ttotal: 5.58s\tremaining: 16.6s\n",
            "174:\tlearn: 0.4137590\ttotal: 5.61s\tremaining: 16.5s\n",
            "175:\tlearn: 0.4137312\ttotal: 5.63s\tremaining: 16.5s\n",
            "176:\tlearn: 0.4136938\ttotal: 5.66s\tremaining: 16.4s\n",
            "177:\tlearn: 0.4136651\ttotal: 5.68s\tremaining: 16.3s\n",
            "178:\tlearn: 0.4136377\ttotal: 5.71s\tremaining: 16.3s\n",
            "179:\tlearn: 0.4136195\ttotal: 5.74s\tremaining: 16.3s\n",
            "180:\tlearn: 0.4135777\ttotal: 5.76s\tremaining: 16.2s\n",
            "181:\tlearn: 0.4135611\ttotal: 5.79s\tremaining: 16.2s\n",
            "182:\tlearn: 0.4135414\ttotal: 5.82s\tremaining: 16.1s\n",
            "183:\tlearn: 0.4135206\ttotal: 5.84s\tremaining: 16.1s\n",
            "184:\tlearn: 0.4134943\ttotal: 5.87s\tremaining: 16s\n",
            "185:\tlearn: 0.4134747\ttotal: 5.89s\tremaining: 16s\n",
            "186:\tlearn: 0.4134390\ttotal: 5.92s\tremaining: 15.9s\n",
            "187:\tlearn: 0.4134130\ttotal: 5.95s\tremaining: 15.9s\n",
            "188:\tlearn: 0.4133514\ttotal: 5.98s\tremaining: 15.9s\n",
            "189:\tlearn: 0.4133303\ttotal: 6s\tremaining: 15.8s\n",
            "190:\tlearn: 0.4132946\ttotal: 6.03s\tremaining: 15.8s\n",
            "191:\tlearn: 0.4132685\ttotal: 6.05s\tremaining: 15.7s\n",
            "192:\tlearn: 0.4132431\ttotal: 6.08s\tremaining: 15.7s\n",
            "193:\tlearn: 0.4131897\ttotal: 6.1s\tremaining: 15.6s\n",
            "194:\tlearn: 0.4131766\ttotal: 6.13s\tremaining: 15.6s\n",
            "195:\tlearn: 0.4131619\ttotal: 6.15s\tremaining: 15.5s\n",
            "196:\tlearn: 0.4131112\ttotal: 6.18s\tremaining: 15.5s\n",
            "197:\tlearn: 0.4130770\ttotal: 6.21s\tremaining: 15.4s\n",
            "198:\tlearn: 0.4130560\ttotal: 6.26s\tremaining: 15.4s\n",
            "199:\tlearn: 0.4130090\ttotal: 6.29s\tremaining: 15.4s\n",
            "200:\tlearn: 0.4129923\ttotal: 6.31s\tremaining: 15.4s\n",
            "201:\tlearn: 0.4129547\ttotal: 6.33s\tremaining: 15.3s\n",
            "202:\tlearn: 0.4129237\ttotal: 6.36s\tremaining: 15.3s\n",
            "203:\tlearn: 0.4129066\ttotal: 6.39s\tremaining: 15.2s\n",
            "204:\tlearn: 0.4128623\ttotal: 6.42s\tremaining: 15.2s\n",
            "205:\tlearn: 0.4128419\ttotal: 6.44s\tremaining: 15.1s\n",
            "206:\tlearn: 0.4128139\ttotal: 6.47s\tremaining: 15.1s\n",
            "207:\tlearn: 0.4127819\ttotal: 6.5s\tremaining: 15.1s\n",
            "208:\tlearn: 0.4127447\ttotal: 6.52s\tremaining: 15s\n",
            "209:\tlearn: 0.4127305\ttotal: 6.55s\tremaining: 15s\n",
            "210:\tlearn: 0.4127053\ttotal: 6.57s\tremaining: 14.9s\n",
            "211:\tlearn: 0.4126936\ttotal: 6.6s\tremaining: 14.9s\n",
            "212:\tlearn: 0.4126611\ttotal: 6.63s\tremaining: 14.8s\n",
            "213:\tlearn: 0.4126456\ttotal: 6.66s\tremaining: 14.8s\n",
            "214:\tlearn: 0.4126302\ttotal: 6.68s\tremaining: 14.8s\n",
            "215:\tlearn: 0.4126044\ttotal: 6.71s\tremaining: 14.7s\n",
            "216:\tlearn: 0.4125650\ttotal: 6.73s\tremaining: 14.7s\n",
            "217:\tlearn: 0.4125205\ttotal: 6.76s\tremaining: 14.6s\n",
            "218:\tlearn: 0.4125013\ttotal: 6.79s\tremaining: 14.6s\n",
            "219:\tlearn: 0.4124734\ttotal: 6.81s\tremaining: 14.6s\n",
            "220:\tlearn: 0.4124427\ttotal: 6.85s\tremaining: 14.5s\n",
            "221:\tlearn: 0.4124191\ttotal: 6.88s\tremaining: 14.5s\n",
            "222:\tlearn: 0.4123952\ttotal: 6.9s\tremaining: 14.5s\n",
            "223:\tlearn: 0.4123704\ttotal: 6.93s\tremaining: 14.4s\n",
            "224:\tlearn: 0.4123418\ttotal: 6.96s\tremaining: 14.4s\n",
            "225:\tlearn: 0.4123072\ttotal: 6.98s\tremaining: 14.3s\n",
            "226:\tlearn: 0.4122818\ttotal: 7s\tremaining: 14.3s\n",
            "227:\tlearn: 0.4122577\ttotal: 7.03s\tremaining: 14.2s\n",
            "228:\tlearn: 0.4122372\ttotal: 7.06s\tremaining: 14.2s\n",
            "229:\tlearn: 0.4122136\ttotal: 7.09s\tremaining: 14.2s\n",
            "230:\tlearn: 0.4121710\ttotal: 7.11s\tremaining: 14.1s\n",
            "231:\tlearn: 0.4121397\ttotal: 7.14s\tremaining: 14.1s\n",
            "232:\tlearn: 0.4120984\ttotal: 7.17s\tremaining: 14.1s\n",
            "233:\tlearn: 0.4120796\ttotal: 7.2s\tremaining: 14s\n",
            "234:\tlearn: 0.4120524\ttotal: 7.22s\tremaining: 14s\n",
            "235:\tlearn: 0.4120204\ttotal: 7.27s\tremaining: 14s\n",
            "236:\tlearn: 0.4119909\ttotal: 7.3s\tremaining: 14s\n",
            "237:\tlearn: 0.4119591\ttotal: 7.33s\tremaining: 13.9s\n",
            "238:\tlearn: 0.4119154\ttotal: 7.35s\tremaining: 13.9s\n",
            "239:\tlearn: 0.4118854\ttotal: 7.38s\tremaining: 13.8s\n",
            "240:\tlearn: 0.4118645\ttotal: 7.4s\tremaining: 13.8s\n",
            "241:\tlearn: 0.4118301\ttotal: 7.43s\tremaining: 13.7s\n",
            "242:\tlearn: 0.4117989\ttotal: 7.45s\tremaining: 13.7s\n",
            "243:\tlearn: 0.4117579\ttotal: 7.48s\tremaining: 13.7s\n",
            "244:\tlearn: 0.4117291\ttotal: 7.5s\tremaining: 13.6s\n",
            "245:\tlearn: 0.4116990\ttotal: 7.53s\tremaining: 13.6s\n",
            "246:\tlearn: 0.4116566\ttotal: 7.56s\tremaining: 13.6s\n",
            "247:\tlearn: 0.4116323\ttotal: 7.58s\tremaining: 13.5s\n",
            "248:\tlearn: 0.4116110\ttotal: 7.61s\tremaining: 13.5s\n",
            "249:\tlearn: 0.4115861\ttotal: 7.63s\tremaining: 13.4s\n",
            "250:\tlearn: 0.4115491\ttotal: 7.66s\tremaining: 13.4s\n",
            "251:\tlearn: 0.4115205\ttotal: 7.68s\tremaining: 13.4s\n",
            "252:\tlearn: 0.4114979\ttotal: 7.71s\tremaining: 13.3s\n",
            "253:\tlearn: 0.4114724\ttotal: 7.73s\tremaining: 13.3s\n",
            "254:\tlearn: 0.4114330\ttotal: 7.76s\tremaining: 13.2s\n",
            "255:\tlearn: 0.4114083\ttotal: 7.79s\tremaining: 13.2s\n",
            "256:\tlearn: 0.4113784\ttotal: 7.82s\tremaining: 13.2s\n",
            "257:\tlearn: 0.4113553\ttotal: 7.85s\tremaining: 13.1s\n",
            "258:\tlearn: 0.4113267\ttotal: 7.88s\tremaining: 13.1s\n",
            "259:\tlearn: 0.4113072\ttotal: 7.91s\tremaining: 13.1s\n",
            "260:\tlearn: 0.4112767\ttotal: 7.94s\tremaining: 13s\n",
            "261:\tlearn: 0.4111924\ttotal: 7.96s\tremaining: 13s\n",
            "262:\tlearn: 0.4111593\ttotal: 7.99s\tremaining: 13s\n",
            "263:\tlearn: 0.4111220\ttotal: 8.02s\tremaining: 12.9s\n",
            "264:\tlearn: 0.4110926\ttotal: 8.04s\tremaining: 12.9s\n",
            "265:\tlearn: 0.4110650\ttotal: 8.07s\tremaining: 12.9s\n",
            "266:\tlearn: 0.4110408\ttotal: 8.1s\tremaining: 12.8s\n",
            "267:\tlearn: 0.4109973\ttotal: 8.13s\tremaining: 12.8s\n",
            "268:\tlearn: 0.4109765\ttotal: 8.15s\tremaining: 12.8s\n",
            "269:\tlearn: 0.4109575\ttotal: 8.18s\tremaining: 12.7s\n",
            "270:\tlearn: 0.4109265\ttotal: 8.2s\tremaining: 12.7s\n",
            "271:\tlearn: 0.4109020\ttotal: 8.23s\tremaining: 12.7s\n",
            "272:\tlearn: 0.4108686\ttotal: 8.27s\tremaining: 12.6s\n",
            "273:\tlearn: 0.4108385\ttotal: 8.31s\tremaining: 12.6s\n",
            "274:\tlearn: 0.4108106\ttotal: 8.33s\tremaining: 12.6s\n",
            "275:\tlearn: 0.4107713\ttotal: 8.36s\tremaining: 12.5s\n",
            "276:\tlearn: 0.4107511\ttotal: 8.38s\tremaining: 12.5s\n",
            "277:\tlearn: 0.4107326\ttotal: 8.41s\tremaining: 12.5s\n",
            "278:\tlearn: 0.4106976\ttotal: 8.43s\tremaining: 12.4s\n",
            "279:\tlearn: 0.4106661\ttotal: 8.46s\tremaining: 12.4s\n",
            "280:\tlearn: 0.4106352\ttotal: 8.49s\tremaining: 12.4s\n",
            "281:\tlearn: 0.4106084\ttotal: 8.52s\tremaining: 12.3s\n",
            "282:\tlearn: 0.4105768\ttotal: 8.54s\tremaining: 12.3s\n",
            "283:\tlearn: 0.4105578\ttotal: 8.57s\tremaining: 12.3s\n",
            "284:\tlearn: 0.4105323\ttotal: 8.59s\tremaining: 12.2s\n",
            "285:\tlearn: 0.4105030\ttotal: 8.62s\tremaining: 12.2s\n",
            "286:\tlearn: 0.4104719\ttotal: 8.64s\tremaining: 12.1s\n",
            "287:\tlearn: 0.4104470\ttotal: 8.66s\tremaining: 12.1s\n",
            "288:\tlearn: 0.4104173\ttotal: 8.7s\tremaining: 12.1s\n",
            "289:\tlearn: 0.4103913\ttotal: 8.72s\tremaining: 12s\n",
            "290:\tlearn: 0.4103631\ttotal: 8.75s\tremaining: 12s\n",
            "291:\tlearn: 0.4103330\ttotal: 8.78s\tremaining: 12s\n",
            "292:\tlearn: 0.4103096\ttotal: 8.81s\tremaining: 11.9s\n",
            "293:\tlearn: 0.4102885\ttotal: 8.84s\tremaining: 11.9s\n",
            "294:\tlearn: 0.4102698\ttotal: 8.86s\tremaining: 11.9s\n",
            "295:\tlearn: 0.4102402\ttotal: 8.89s\tremaining: 11.8s\n",
            "296:\tlearn: 0.4102076\ttotal: 8.92s\tremaining: 11.8s\n",
            "297:\tlearn: 0.4101842\ttotal: 8.94s\tremaining: 11.8s\n",
            "298:\tlearn: 0.4101617\ttotal: 8.97s\tremaining: 11.7s\n",
            "299:\tlearn: 0.4101422\ttotal: 8.99s\tremaining: 11.7s\n",
            "300:\tlearn: 0.4101209\ttotal: 9.03s\tremaining: 11.7s\n",
            "301:\tlearn: 0.4100998\ttotal: 9.06s\tremaining: 11.6s\n",
            "302:\tlearn: 0.4100728\ttotal: 9.09s\tremaining: 11.6s\n",
            "303:\tlearn: 0.4100538\ttotal: 9.11s\tremaining: 11.6s\n",
            "304:\tlearn: 0.4100302\ttotal: 9.13s\tremaining: 11.5s\n",
            "305:\tlearn: 0.4100030\ttotal: 9.16s\tremaining: 11.5s\n",
            "306:\tlearn: 0.4099833\ttotal: 9.2s\tremaining: 11.5s\n",
            "307:\tlearn: 0.4099579\ttotal: 9.23s\tremaining: 11.4s\n",
            "308:\tlearn: 0.4099271\ttotal: 9.26s\tremaining: 11.4s\n",
            "309:\tlearn: 0.4098972\ttotal: 9.3s\tremaining: 11.4s\n",
            "310:\tlearn: 0.4098730\ttotal: 9.33s\tremaining: 11.4s\n",
            "311:\tlearn: 0.4098483\ttotal: 9.36s\tremaining: 11.3s\n",
            "312:\tlearn: 0.4098292\ttotal: 9.38s\tremaining: 11.3s\n",
            "313:\tlearn: 0.4098049\ttotal: 9.41s\tremaining: 11.3s\n",
            "314:\tlearn: 0.4097745\ttotal: 9.45s\tremaining: 11.2s\n",
            "315:\tlearn: 0.4097492\ttotal: 9.47s\tremaining: 11.2s\n",
            "316:\tlearn: 0.4097299\ttotal: 9.5s\tremaining: 11.2s\n",
            "317:\tlearn: 0.4097101\ttotal: 9.53s\tremaining: 11.1s\n",
            "318:\tlearn: 0.4096866\ttotal: 9.55s\tremaining: 11.1s\n",
            "319:\tlearn: 0.4096665\ttotal: 9.58s\tremaining: 11.1s\n",
            "320:\tlearn: 0.4096436\ttotal: 9.61s\tremaining: 11s\n",
            "321:\tlearn: 0.4096238\ttotal: 9.64s\tremaining: 11s\n",
            "322:\tlearn: 0.4096020\ttotal: 9.67s\tremaining: 11s\n",
            "323:\tlearn: 0.4095808\ttotal: 9.69s\tremaining: 10.9s\n",
            "324:\tlearn: 0.4095536\ttotal: 9.72s\tremaining: 10.9s\n",
            "325:\tlearn: 0.4095281\ttotal: 9.74s\tremaining: 10.9s\n",
            "326:\tlearn: 0.4095014\ttotal: 9.77s\tremaining: 10.8s\n",
            "327:\tlearn: 0.4094748\ttotal: 9.8s\tremaining: 10.8s\n",
            "328:\tlearn: 0.4094503\ttotal: 9.82s\tremaining: 10.8s\n",
            "329:\tlearn: 0.4094312\ttotal: 9.86s\tremaining: 10.8s\n",
            "330:\tlearn: 0.4094094\ttotal: 9.88s\tremaining: 10.7s\n",
            "331:\tlearn: 0.4093885\ttotal: 9.91s\tremaining: 10.7s\n",
            "332:\tlearn: 0.4093684\ttotal: 9.94s\tremaining: 10.7s\n",
            "333:\tlearn: 0.4093376\ttotal: 9.97s\tremaining: 10.6s\n",
            "334:\tlearn: 0.4093195\ttotal: 10s\tremaining: 10.6s\n",
            "335:\tlearn: 0.4092989\ttotal: 10s\tremaining: 10.6s\n",
            "336:\tlearn: 0.4092719\ttotal: 10.1s\tremaining: 10.5s\n",
            "337:\tlearn: 0.4092468\ttotal: 10.1s\tremaining: 10.5s\n",
            "338:\tlearn: 0.4092195\ttotal: 10.1s\tremaining: 10.5s\n",
            "339:\tlearn: 0.4091991\ttotal: 10.1s\tremaining: 10.4s\n",
            "340:\tlearn: 0.4091741\ttotal: 10.2s\tremaining: 10.4s\n",
            "341:\tlearn: 0.4091509\ttotal: 10.2s\tremaining: 10.4s\n",
            "342:\tlearn: 0.4091325\ttotal: 10.2s\tremaining: 10.4s\n",
            "343:\tlearn: 0.4091141\ttotal: 10.3s\tremaining: 10.3s\n",
            "344:\tlearn: 0.4090891\ttotal: 10.3s\tremaining: 10.3s\n",
            "345:\tlearn: 0.4090669\ttotal: 10.4s\tremaining: 10.3s\n",
            "346:\tlearn: 0.4090392\ttotal: 10.4s\tremaining: 10.3s\n",
            "347:\tlearn: 0.4090171\ttotal: 10.5s\tremaining: 10.3s\n",
            "348:\tlearn: 0.4089957\ttotal: 10.5s\tremaining: 10.3s\n",
            "349:\tlearn: 0.4089699\ttotal: 10.6s\tremaining: 10.3s\n",
            "350:\tlearn: 0.4089490\ttotal: 10.6s\tremaining: 10.2s\n",
            "351:\tlearn: 0.4089269\ttotal: 10.7s\tremaining: 10.2s\n",
            "352:\tlearn: 0.4089027\ttotal: 10.7s\tremaining: 10.2s\n",
            "353:\tlearn: 0.4088812\ttotal: 10.8s\tremaining: 10.2s\n",
            "354:\tlearn: 0.4088598\ttotal: 10.8s\tremaining: 10.2s\n",
            "355:\tlearn: 0.4088317\ttotal: 10.9s\tremaining: 10.2s\n",
            "356:\tlearn: 0.4088044\ttotal: 10.9s\tremaining: 10.2s\n",
            "357:\tlearn: 0.4087816\ttotal: 11s\tremaining: 10.2s\n",
            "358:\tlearn: 0.4087513\ttotal: 11s\tremaining: 10.2s\n",
            "359:\tlearn: 0.4087254\ttotal: 11.1s\tremaining: 10.1s\n",
            "360:\tlearn: 0.4086882\ttotal: 11.1s\tremaining: 10.1s\n",
            "361:\tlearn: 0.4086593\ttotal: 11.1s\tremaining: 10.1s\n",
            "362:\tlearn: 0.4086357\ttotal: 11.2s\tremaining: 10.1s\n",
            "363:\tlearn: 0.4086147\ttotal: 11.3s\tremaining: 10.1s\n",
            "364:\tlearn: 0.4085987\ttotal: 11.3s\tremaining: 10.1s\n",
            "365:\tlearn: 0.4085799\ttotal: 11.4s\tremaining: 10.1s\n",
            "366:\tlearn: 0.4085588\ttotal: 11.5s\tremaining: 10.1s\n",
            "367:\tlearn: 0.4085421\ttotal: 11.5s\tremaining: 10.1s\n",
            "368:\tlearn: 0.4085192\ttotal: 11.6s\tremaining: 10.1s\n",
            "369:\tlearn: 0.4084809\ttotal: 11.7s\tremaining: 10.1s\n",
            "370:\tlearn: 0.4084512\ttotal: 11.7s\tremaining: 10.1s\n",
            "371:\tlearn: 0.4084162\ttotal: 11.8s\tremaining: 10.1s\n",
            "372:\tlearn: 0.4083956\ttotal: 11.9s\tremaining: 10.1s\n",
            "373:\tlearn: 0.4083773\ttotal: 11.9s\tremaining: 10.1s\n",
            "374:\tlearn: 0.4083564\ttotal: 12s\tremaining: 10s\n",
            "375:\tlearn: 0.4083287\ttotal: 12s\tremaining: 10s\n",
            "376:\tlearn: 0.4083056\ttotal: 12.1s\tremaining: 10s\n",
            "377:\tlearn: 0.4082878\ttotal: 12.1s\tremaining: 9.99s\n",
            "378:\tlearn: 0.4082646\ttotal: 12.2s\tremaining: 9.99s\n",
            "379:\tlearn: 0.4082481\ttotal: 12.2s\tremaining: 9.97s\n",
            "380:\tlearn: 0.4082333\ttotal: 12.3s\tremaining: 9.96s\n",
            "381:\tlearn: 0.4082088\ttotal: 12.3s\tremaining: 9.96s\n",
            "382:\tlearn: 0.4081878\ttotal: 12.4s\tremaining: 9.94s\n",
            "383:\tlearn: 0.4081644\ttotal: 12.4s\tremaining: 9.92s\n",
            "384:\tlearn: 0.4081433\ttotal: 12.5s\tremaining: 9.9s\n",
            "385:\tlearn: 0.4081242\ttotal: 12.6s\tremaining: 9.9s\n",
            "386:\tlearn: 0.4081113\ttotal: 12.6s\tremaining: 9.89s\n",
            "387:\tlearn: 0.4080924\ttotal: 12.7s\tremaining: 9.87s\n",
            "388:\tlearn: 0.4080549\ttotal: 12.7s\tremaining: 9.86s\n",
            "389:\tlearn: 0.4080332\ttotal: 12.8s\tremaining: 9.84s\n",
            "390:\tlearn: 0.4080142\ttotal: 12.8s\tremaining: 9.83s\n",
            "391:\tlearn: 0.4079924\ttotal: 12.9s\tremaining: 9.81s\n",
            "392:\tlearn: 0.4079752\ttotal: 13s\tremaining: 9.79s\n",
            "393:\tlearn: 0.4079497\ttotal: 13s\tremaining: 9.79s\n",
            "394:\tlearn: 0.4079236\ttotal: 13.1s\tremaining: 9.79s\n",
            "395:\tlearn: 0.4078988\ttotal: 13.2s\tremaining: 9.79s\n",
            "396:\tlearn: 0.4078791\ttotal: 13.3s\tremaining: 9.79s\n",
            "397:\tlearn: 0.4078595\ttotal: 13.3s\tremaining: 9.78s\n",
            "398:\tlearn: 0.4078379\ttotal: 13.4s\tremaining: 9.77s\n",
            "399:\tlearn: 0.4078175\ttotal: 13.4s\tremaining: 9.74s\n",
            "400:\tlearn: 0.4077994\ttotal: 13.5s\tremaining: 9.7s\n",
            "401:\tlearn: 0.4077744\ttotal: 13.5s\tremaining: 9.68s\n",
            "402:\tlearn: 0.4077558\ttotal: 13.5s\tremaining: 9.63s\n",
            "403:\tlearn: 0.4077384\ttotal: 13.6s\tremaining: 9.6s\n",
            "404:\tlearn: 0.4077199\ttotal: 13.6s\tremaining: 9.55s\n",
            "405:\tlearn: 0.4076989\ttotal: 13.6s\tremaining: 9.51s\n",
            "406:\tlearn: 0.4076718\ttotal: 13.6s\tremaining: 9.48s\n",
            "407:\tlearn: 0.4076537\ttotal: 13.7s\tremaining: 9.44s\n",
            "408:\tlearn: 0.4076365\ttotal: 13.7s\tremaining: 9.4s\n",
            "409:\tlearn: 0.4076140\ttotal: 13.7s\tremaining: 9.36s\n",
            "410:\tlearn: 0.4075967\ttotal: 13.7s\tremaining: 9.32s\n",
            "411:\tlearn: 0.4075698\ttotal: 13.8s\tremaining: 9.29s\n",
            "412:\tlearn: 0.4075509\ttotal: 13.8s\tremaining: 9.26s\n",
            "413:\tlearn: 0.4075323\ttotal: 13.8s\tremaining: 9.22s\n",
            "414:\tlearn: 0.4075067\ttotal: 13.9s\tremaining: 9.18s\n",
            "415:\tlearn: 0.4074717\ttotal: 13.9s\tremaining: 9.14s\n",
            "416:\tlearn: 0.4074517\ttotal: 13.9s\tremaining: 9.1s\n",
            "417:\tlearn: 0.4074378\ttotal: 13.9s\tremaining: 9.06s\n",
            "418:\tlearn: 0.4074186\ttotal: 14s\tremaining: 9.03s\n",
            "419:\tlearn: 0.4073994\ttotal: 14s\tremaining: 8.99s\n",
            "420:\tlearn: 0.4073757\ttotal: 14s\tremaining: 8.95s\n",
            "421:\tlearn: 0.4073553\ttotal: 14s\tremaining: 8.91s\n",
            "422:\tlearn: 0.4073228\ttotal: 14.1s\tremaining: 8.87s\n",
            "423:\tlearn: 0.4073044\ttotal: 14.1s\tremaining: 8.84s\n",
            "424:\tlearn: 0.4072822\ttotal: 14.1s\tremaining: 8.8s\n",
            "425:\tlearn: 0.4072655\ttotal: 14.1s\tremaining: 8.76s\n",
            "426:\tlearn: 0.4072459\ttotal: 14.2s\tremaining: 8.73s\n",
            "427:\tlearn: 0.4072239\ttotal: 14.2s\tremaining: 8.7s\n",
            "428:\tlearn: 0.4072045\ttotal: 14.2s\tremaining: 8.66s\n",
            "429:\tlearn: 0.4071844\ttotal: 14.3s\tremaining: 8.62s\n",
            "430:\tlearn: 0.4071554\ttotal: 14.3s\tremaining: 8.58s\n",
            "431:\tlearn: 0.4071369\ttotal: 14.3s\tremaining: 8.54s\n",
            "432:\tlearn: 0.4071174\ttotal: 14.3s\tremaining: 8.51s\n",
            "433:\tlearn: 0.4070988\ttotal: 14.4s\tremaining: 8.47s\n",
            "434:\tlearn: 0.4070777\ttotal: 14.4s\tremaining: 8.43s\n",
            "435:\tlearn: 0.4070539\ttotal: 14.4s\tremaining: 8.4s\n",
            "436:\tlearn: 0.4070330\ttotal: 14.4s\tremaining: 8.36s\n",
            "437:\tlearn: 0.4070143\ttotal: 14.5s\tremaining: 8.32s\n",
            "438:\tlearn: 0.4069938\ttotal: 14.5s\tremaining: 8.29s\n",
            "439:\tlearn: 0.4069743\ttotal: 14.5s\tremaining: 8.26s\n",
            "440:\tlearn: 0.4069555\ttotal: 14.6s\tremaining: 8.22s\n",
            "441:\tlearn: 0.4069338\ttotal: 14.6s\tremaining: 8.19s\n",
            "442:\tlearn: 0.4069093\ttotal: 14.6s\tremaining: 8.15s\n",
            "443:\tlearn: 0.4068891\ttotal: 14.7s\tremaining: 8.12s\n",
            "444:\tlearn: 0.4068718\ttotal: 14.7s\tremaining: 8.08s\n",
            "445:\tlearn: 0.4068590\ttotal: 14.7s\tremaining: 8.04s\n",
            "446:\tlearn: 0.4068397\ttotal: 14.7s\tremaining: 8.01s\n",
            "447:\tlearn: 0.4068200\ttotal: 14.8s\tremaining: 7.97s\n",
            "448:\tlearn: 0.4068041\ttotal: 14.8s\tremaining: 7.94s\n",
            "449:\tlearn: 0.4067887\ttotal: 14.8s\tremaining: 7.9s\n",
            "450:\tlearn: 0.4067721\ttotal: 14.8s\tremaining: 7.87s\n",
            "451:\tlearn: 0.4067518\ttotal: 14.9s\tremaining: 7.83s\n",
            "452:\tlearn: 0.4067271\ttotal: 14.9s\tremaining: 7.79s\n",
            "453:\tlearn: 0.4067086\ttotal: 14.9s\tremaining: 7.76s\n",
            "454:\tlearn: 0.4066936\ttotal: 14.9s\tremaining: 7.72s\n",
            "455:\tlearn: 0.4066728\ttotal: 15s\tremaining: 7.68s\n",
            "456:\tlearn: 0.4066562\ttotal: 15s\tremaining: 7.65s\n",
            "457:\tlearn: 0.4066381\ttotal: 15s\tremaining: 7.61s\n",
            "458:\tlearn: 0.4066211\ttotal: 15.1s\tremaining: 7.58s\n",
            "459:\tlearn: 0.4065987\ttotal: 15.1s\tremaining: 7.54s\n",
            "460:\tlearn: 0.4065823\ttotal: 15.1s\tremaining: 7.51s\n",
            "461:\tlearn: 0.4065642\ttotal: 15.1s\tremaining: 7.47s\n",
            "462:\tlearn: 0.4065476\ttotal: 15.2s\tremaining: 7.44s\n",
            "463:\tlearn: 0.4065322\ttotal: 15.2s\tremaining: 7.4s\n",
            "464:\tlearn: 0.4065177\ttotal: 15.2s\tremaining: 7.37s\n",
            "465:\tlearn: 0.4064958\ttotal: 15.2s\tremaining: 7.33s\n",
            "466:\tlearn: 0.4064777\ttotal: 15.3s\tremaining: 7.29s\n",
            "467:\tlearn: 0.4064491\ttotal: 15.3s\tremaining: 7.26s\n",
            "468:\tlearn: 0.4064272\ttotal: 15.3s\tremaining: 7.22s\n",
            "469:\tlearn: 0.4064041\ttotal: 15.4s\tremaining: 7.19s\n",
            "470:\tlearn: 0.4063888\ttotal: 15.4s\tremaining: 7.15s\n",
            "471:\tlearn: 0.4063637\ttotal: 15.4s\tremaining: 7.12s\n",
            "472:\tlearn: 0.4063446\ttotal: 15.4s\tremaining: 7.08s\n",
            "473:\tlearn: 0.4063269\ttotal: 15.5s\tremaining: 7.05s\n",
            "474:\tlearn: 0.4063018\ttotal: 15.5s\tremaining: 7.01s\n",
            "475:\tlearn: 0.4062852\ttotal: 15.5s\tremaining: 6.98s\n",
            "476:\tlearn: 0.4062539\ttotal: 15.6s\tremaining: 6.95s\n",
            "477:\tlearn: 0.4062346\ttotal: 15.6s\tremaining: 6.91s\n",
            "478:\tlearn: 0.4062065\ttotal: 15.6s\tremaining: 6.88s\n",
            "479:\tlearn: 0.4061891\ttotal: 15.6s\tremaining: 6.84s\n",
            "480:\tlearn: 0.4061718\ttotal: 15.7s\tremaining: 6.81s\n",
            "481:\tlearn: 0.4061522\ttotal: 15.7s\tremaining: 6.78s\n",
            "482:\tlearn: 0.4061304\ttotal: 15.7s\tremaining: 6.74s\n",
            "483:\tlearn: 0.4060936\ttotal: 15.8s\tremaining: 6.71s\n",
            "484:\tlearn: 0.4060719\ttotal: 15.8s\tremaining: 6.67s\n",
            "485:\tlearn: 0.4060524\ttotal: 15.8s\tremaining: 6.63s\n",
            "486:\tlearn: 0.4060327\ttotal: 15.8s\tremaining: 6.6s\n",
            "487:\tlearn: 0.4060147\ttotal: 15.9s\tremaining: 6.57s\n",
            "488:\tlearn: 0.4059951\ttotal: 15.9s\tremaining: 6.53s\n",
            "489:\tlearn: 0.4059756\ttotal: 15.9s\tremaining: 6.5s\n",
            "490:\tlearn: 0.4059621\ttotal: 16s\tremaining: 6.47s\n",
            "491:\tlearn: 0.4059391\ttotal: 16s\tremaining: 6.43s\n",
            "492:\tlearn: 0.4059246\ttotal: 16s\tremaining: 6.39s\n",
            "493:\tlearn: 0.4059070\ttotal: 16s\tremaining: 6.36s\n",
            "494:\tlearn: 0.4058870\ttotal: 16.1s\tremaining: 6.33s\n",
            "495:\tlearn: 0.4058703\ttotal: 16.1s\tremaining: 6.29s\n",
            "496:\tlearn: 0.4058536\ttotal: 16.1s\tremaining: 6.25s\n",
            "497:\tlearn: 0.4058301\ttotal: 16.1s\tremaining: 6.22s\n",
            "498:\tlearn: 0.4058138\ttotal: 16.2s\tremaining: 6.19s\n",
            "499:\tlearn: 0.4058003\ttotal: 16.2s\tremaining: 6.15s\n",
            "500:\tlearn: 0.4057784\ttotal: 16.2s\tremaining: 6.12s\n",
            "501:\tlearn: 0.4057515\ttotal: 16.2s\tremaining: 6.08s\n",
            "502:\tlearn: 0.4057296\ttotal: 16.3s\tremaining: 6.05s\n",
            "503:\tlearn: 0.4057126\ttotal: 16.3s\tremaining: 6.01s\n",
            "504:\tlearn: 0.4056998\ttotal: 16.3s\tremaining: 5.98s\n",
            "505:\tlearn: 0.4056839\ttotal: 16.3s\tremaining: 5.95s\n",
            "506:\tlearn: 0.4056696\ttotal: 16.4s\tremaining: 5.91s\n",
            "507:\tlearn: 0.4056547\ttotal: 16.4s\tremaining: 5.87s\n",
            "508:\tlearn: 0.4056360\ttotal: 16.4s\tremaining: 5.84s\n",
            "509:\tlearn: 0.4056223\ttotal: 16.4s\tremaining: 5.8s\n",
            "510:\tlearn: 0.4056051\ttotal: 16.5s\tremaining: 5.77s\n",
            "511:\tlearn: 0.4055869\ttotal: 16.5s\tremaining: 5.74s\n",
            "512:\tlearn: 0.4055767\ttotal: 16.5s\tremaining: 5.7s\n",
            "513:\tlearn: 0.4055472\ttotal: 16.6s\tremaining: 5.67s\n",
            "514:\tlearn: 0.4055279\ttotal: 16.6s\tremaining: 5.64s\n",
            "515:\tlearn: 0.4055053\ttotal: 16.6s\tremaining: 5.61s\n",
            "516:\tlearn: 0.4054911\ttotal: 16.7s\tremaining: 5.57s\n",
            "517:\tlearn: 0.4054779\ttotal: 16.7s\tremaining: 5.54s\n",
            "518:\tlearn: 0.4054611\ttotal: 16.7s\tremaining: 5.5s\n",
            "519:\tlearn: 0.4054438\ttotal: 16.7s\tremaining: 5.47s\n",
            "520:\tlearn: 0.4054235\ttotal: 16.8s\tremaining: 5.44s\n",
            "521:\tlearn: 0.4054114\ttotal: 16.8s\tremaining: 5.4s\n",
            "522:\tlearn: 0.4053946\ttotal: 16.8s\tremaining: 5.37s\n",
            "523:\tlearn: 0.4053787\ttotal: 16.8s\tremaining: 5.33s\n",
            "524:\tlearn: 0.4053591\ttotal: 16.9s\tremaining: 5.3s\n",
            "525:\tlearn: 0.4053419\ttotal: 16.9s\tremaining: 5.27s\n",
            "526:\tlearn: 0.4053196\ttotal: 16.9s\tremaining: 5.23s\n",
            "527:\tlearn: 0.4052983\ttotal: 16.9s\tremaining: 5.2s\n",
            "528:\tlearn: 0.4052772\ttotal: 17s\tremaining: 5.17s\n",
            "529:\tlearn: 0.4052588\ttotal: 17s\tremaining: 5.13s\n",
            "530:\tlearn: 0.4052401\ttotal: 17s\tremaining: 5.1s\n",
            "531:\tlearn: 0.4052226\ttotal: 17.1s\tremaining: 5.07s\n",
            "532:\tlearn: 0.4051937\ttotal: 17.1s\tremaining: 5.03s\n",
            "533:\tlearn: 0.4051768\ttotal: 17.1s\tremaining: 5s\n",
            "534:\tlearn: 0.4051483\ttotal: 17.1s\tremaining: 4.97s\n",
            "535:\tlearn: 0.4051257\ttotal: 17.2s\tremaining: 4.93s\n",
            "536:\tlearn: 0.4051029\ttotal: 17.2s\tremaining: 4.9s\n",
            "537:\tlearn: 0.4050795\ttotal: 17.2s\tremaining: 4.87s\n",
            "538:\tlearn: 0.4050617\ttotal: 17.2s\tremaining: 4.83s\n",
            "539:\tlearn: 0.4050402\ttotal: 17.3s\tremaining: 4.8s\n",
            "540:\tlearn: 0.4050263\ttotal: 17.3s\tremaining: 4.76s\n",
            "541:\tlearn: 0.4050096\ttotal: 17.3s\tremaining: 4.73s\n",
            "542:\tlearn: 0.4049921\ttotal: 17.4s\tremaining: 4.7s\n",
            "543:\tlearn: 0.4049710\ttotal: 17.4s\tremaining: 4.66s\n",
            "544:\tlearn: 0.4049570\ttotal: 17.4s\tremaining: 4.63s\n",
            "545:\tlearn: 0.4049365\ttotal: 17.4s\tremaining: 4.6s\n",
            "546:\tlearn: 0.4049202\ttotal: 17.5s\tremaining: 4.57s\n",
            "547:\tlearn: 0.4049005\ttotal: 17.5s\tremaining: 4.53s\n",
            "548:\tlearn: 0.4048850\ttotal: 17.5s\tremaining: 4.5s\n",
            "549:\tlearn: 0.4048663\ttotal: 17.5s\tremaining: 4.46s\n",
            "550:\tlearn: 0.4048452\ttotal: 17.6s\tremaining: 4.43s\n",
            "551:\tlearn: 0.4048261\ttotal: 17.6s\tremaining: 4.4s\n",
            "552:\tlearn: 0.4048075\ttotal: 17.6s\tremaining: 4.37s\n",
            "553:\tlearn: 0.4047914\ttotal: 17.7s\tremaining: 4.33s\n",
            "554:\tlearn: 0.4047798\ttotal: 17.7s\tremaining: 4.3s\n",
            "555:\tlearn: 0.4047642\ttotal: 17.7s\tremaining: 4.27s\n",
            "556:\tlearn: 0.4047457\ttotal: 17.7s\tremaining: 4.23s\n",
            "557:\tlearn: 0.4047273\ttotal: 17.8s\tremaining: 4.2s\n",
            "558:\tlearn: 0.4047089\ttotal: 17.8s\tremaining: 4.17s\n",
            "559:\tlearn: 0.4046891\ttotal: 17.8s\tremaining: 4.13s\n",
            "560:\tlearn: 0.4046699\ttotal: 17.8s\tremaining: 4.1s\n",
            "561:\tlearn: 0.4046494\ttotal: 17.9s\tremaining: 4.07s\n",
            "562:\tlearn: 0.4046283\ttotal: 17.9s\tremaining: 4.04s\n",
            "563:\tlearn: 0.4046136\ttotal: 17.9s\tremaining: 4s\n",
            "564:\tlearn: 0.4045960\ttotal: 18s\tremaining: 3.97s\n",
            "565:\tlearn: 0.4045819\ttotal: 18s\tremaining: 3.94s\n",
            "566:\tlearn: 0.4045618\ttotal: 18s\tremaining: 3.91s\n",
            "567:\tlearn: 0.4045477\ttotal: 18s\tremaining: 3.87s\n",
            "568:\tlearn: 0.4045295\ttotal: 18.1s\tremaining: 3.84s\n",
            "569:\tlearn: 0.4045159\ttotal: 18.1s\tremaining: 3.81s\n",
            "570:\tlearn: 0.4044922\ttotal: 18.1s\tremaining: 3.78s\n",
            "571:\tlearn: 0.4044767\ttotal: 18.1s\tremaining: 3.74s\n",
            "572:\tlearn: 0.4044585\ttotal: 18.2s\tremaining: 3.71s\n",
            "573:\tlearn: 0.4044264\ttotal: 18.2s\tremaining: 3.68s\n",
            "574:\tlearn: 0.4044024\ttotal: 18.2s\tremaining: 3.65s\n",
            "575:\tlearn: 0.4043895\ttotal: 18.3s\tremaining: 3.62s\n",
            "576:\tlearn: 0.4043644\ttotal: 18.3s\tremaining: 3.58s\n",
            "577:\tlearn: 0.4043521\ttotal: 18.3s\tremaining: 3.55s\n",
            "578:\tlearn: 0.4043393\ttotal: 18.3s\tremaining: 3.52s\n",
            "579:\tlearn: 0.4043155\ttotal: 18.4s\tremaining: 3.48s\n",
            "580:\tlearn: 0.4042997\ttotal: 18.4s\tremaining: 3.45s\n",
            "581:\tlearn: 0.4042878\ttotal: 18.4s\tremaining: 3.42s\n",
            "582:\tlearn: 0.4042726\ttotal: 18.5s\tremaining: 3.39s\n",
            "583:\tlearn: 0.4042557\ttotal: 18.5s\tremaining: 3.35s\n",
            "584:\tlearn: 0.4042359\ttotal: 18.5s\tremaining: 3.32s\n",
            "585:\tlearn: 0.4041966\ttotal: 18.5s\tremaining: 3.29s\n",
            "586:\tlearn: 0.4041798\ttotal: 18.6s\tremaining: 3.26s\n",
            "587:\tlearn: 0.4041628\ttotal: 18.6s\tremaining: 3.23s\n",
            "588:\tlearn: 0.4041437\ttotal: 18.6s\tremaining: 3.2s\n",
            "589:\tlearn: 0.4041225\ttotal: 18.7s\tremaining: 3.17s\n",
            "590:\tlearn: 0.4041021\ttotal: 18.7s\tremaining: 3.13s\n",
            "591:\tlearn: 0.4040765\ttotal: 18.7s\tremaining: 3.1s\n",
            "592:\tlearn: 0.4040537\ttotal: 18.8s\tremaining: 3.07s\n",
            "593:\tlearn: 0.4040392\ttotal: 18.8s\tremaining: 3.04s\n",
            "594:\tlearn: 0.4040201\ttotal: 18.8s\tremaining: 3s\n",
            "595:\tlearn: 0.4040064\ttotal: 18.8s\tremaining: 2.97s\n",
            "596:\tlearn: 0.4039930\ttotal: 18.9s\tremaining: 2.94s\n",
            "597:\tlearn: 0.4039700\ttotal: 18.9s\tremaining: 2.91s\n",
            "598:\tlearn: 0.4039525\ttotal: 18.9s\tremaining: 2.88s\n",
            "599:\tlearn: 0.4039411\ttotal: 19s\tremaining: 2.84s\n",
            "600:\tlearn: 0.4039229\ttotal: 19s\tremaining: 2.81s\n",
            "601:\tlearn: 0.4039075\ttotal: 19s\tremaining: 2.78s\n",
            "602:\tlearn: 0.4038854\ttotal: 19s\tremaining: 2.75s\n",
            "603:\tlearn: 0.4038720\ttotal: 19.1s\tremaining: 2.71s\n",
            "604:\tlearn: 0.4038571\ttotal: 19.1s\tremaining: 2.68s\n",
            "605:\tlearn: 0.4038364\ttotal: 19.1s\tremaining: 2.65s\n",
            "606:\tlearn: 0.4038200\ttotal: 19.1s\tremaining: 2.62s\n",
            "607:\tlearn: 0.4038015\ttotal: 19.2s\tremaining: 2.59s\n",
            "608:\tlearn: 0.4037841\ttotal: 19.2s\tremaining: 2.55s\n",
            "609:\tlearn: 0.4037669\ttotal: 19.2s\tremaining: 2.52s\n",
            "610:\tlearn: 0.4037516\ttotal: 19.2s\tremaining: 2.49s\n",
            "611:\tlearn: 0.4037412\ttotal: 19.3s\tremaining: 2.46s\n",
            "612:\tlearn: 0.4037249\ttotal: 19.3s\tremaining: 2.42s\n",
            "613:\tlearn: 0.4037088\ttotal: 19.3s\tremaining: 2.39s\n",
            "614:\tlearn: 0.4036579\ttotal: 19.4s\tremaining: 2.36s\n",
            "615:\tlearn: 0.4036416\ttotal: 19.4s\tremaining: 2.33s\n",
            "616:\tlearn: 0.4036254\ttotal: 19.4s\tremaining: 2.3s\n",
            "617:\tlearn: 0.4036041\ttotal: 19.4s\tremaining: 2.27s\n",
            "618:\tlearn: 0.4035898\ttotal: 19.5s\tremaining: 2.23s\n",
            "619:\tlearn: 0.4035743\ttotal: 19.5s\tremaining: 2.2s\n",
            "620:\tlearn: 0.4035588\ttotal: 19.5s\tremaining: 2.17s\n",
            "621:\tlearn: 0.4035439\ttotal: 19.5s\tremaining: 2.14s\n",
            "622:\tlearn: 0.4035252\ttotal: 19.6s\tremaining: 2.1s\n",
            "623:\tlearn: 0.4035124\ttotal: 19.6s\tremaining: 2.08s\n",
            "624:\tlearn: 0.4035012\ttotal: 19.6s\tremaining: 2.04s\n",
            "625:\tlearn: 0.4034833\ttotal: 19.7s\tremaining: 2.01s\n",
            "626:\tlearn: 0.4034679\ttotal: 19.7s\tremaining: 1.98s\n",
            "627:\tlearn: 0.4034459\ttotal: 19.7s\tremaining: 1.95s\n",
            "628:\tlearn: 0.4034301\ttotal: 19.8s\tremaining: 1.92s\n",
            "629:\tlearn: 0.4034077\ttotal: 19.8s\tremaining: 1.88s\n",
            "630:\tlearn: 0.4033843\ttotal: 19.8s\tremaining: 1.85s\n",
            "631:\tlearn: 0.4033689\ttotal: 19.8s\tremaining: 1.82s\n",
            "632:\tlearn: 0.4033514\ttotal: 19.9s\tremaining: 1.79s\n",
            "633:\tlearn: 0.4033317\ttotal: 19.9s\tremaining: 1.76s\n",
            "634:\tlearn: 0.4033151\ttotal: 19.9s\tremaining: 1.73s\n",
            "635:\tlearn: 0.4032992\ttotal: 19.9s\tremaining: 1.69s\n",
            "636:\tlearn: 0.4032874\ttotal: 20s\tremaining: 1.66s\n",
            "637:\tlearn: 0.4032703\ttotal: 20s\tremaining: 1.63s\n",
            "638:\tlearn: 0.4032539\ttotal: 20s\tremaining: 1.6s\n",
            "639:\tlearn: 0.4032423\ttotal: 20.1s\tremaining: 1.57s\n",
            "640:\tlearn: 0.4032252\ttotal: 20.1s\tremaining: 1.53s\n",
            "641:\tlearn: 0.4032128\ttotal: 20.1s\tremaining: 1.5s\n",
            "642:\tlearn: 0.4031959\ttotal: 20.2s\tremaining: 1.47s\n",
            "643:\tlearn: 0.4031798\ttotal: 20.2s\tremaining: 1.44s\n",
            "644:\tlearn: 0.4031610\ttotal: 20.2s\tremaining: 1.41s\n",
            "645:\tlearn: 0.4031371\ttotal: 20.2s\tremaining: 1.38s\n",
            "646:\tlearn: 0.4031217\ttotal: 20.3s\tremaining: 1.35s\n",
            "647:\tlearn: 0.4031080\ttotal: 20.3s\tremaining: 1.31s\n",
            "648:\tlearn: 0.4030940\ttotal: 20.3s\tremaining: 1.28s\n",
            "649:\tlearn: 0.4030772\ttotal: 20.3s\tremaining: 1.25s\n",
            "650:\tlearn: 0.4030640\ttotal: 20.4s\tremaining: 1.22s\n",
            "651:\tlearn: 0.4030369\ttotal: 20.4s\tremaining: 1.19s\n",
            "652:\tlearn: 0.4030198\ttotal: 20.4s\tremaining: 1.16s\n",
            "653:\tlearn: 0.4030016\ttotal: 20.4s\tremaining: 1.13s\n",
            "654:\tlearn: 0.4029867\ttotal: 20.5s\tremaining: 1.09s\n",
            "655:\tlearn: 0.4029703\ttotal: 20.5s\tremaining: 1.06s\n",
            "656:\tlearn: 0.4029507\ttotal: 20.5s\tremaining: 1.03s\n",
            "657:\tlearn: 0.4029316\ttotal: 20.6s\tremaining: 1000ms\n",
            "658:\tlearn: 0.4029040\ttotal: 20.6s\tremaining: 969ms\n",
            "659:\tlearn: 0.4028930\ttotal: 20.6s\tremaining: 938ms\n",
            "660:\tlearn: 0.4028729\ttotal: 20.7s\tremaining: 907ms\n",
            "661:\tlearn: 0.4028478\ttotal: 20.7s\tremaining: 875ms\n",
            "662:\tlearn: 0.4028300\ttotal: 20.7s\tremaining: 844ms\n",
            "663:\tlearn: 0.4028140\ttotal: 20.7s\tremaining: 812ms\n",
            "664:\tlearn: 0.4027959\ttotal: 20.8s\tremaining: 781ms\n",
            "665:\tlearn: 0.4027764\ttotal: 20.8s\tremaining: 750ms\n",
            "666:\tlearn: 0.4027619\ttotal: 20.8s\tremaining: 718ms\n",
            "667:\tlearn: 0.4027452\ttotal: 20.9s\tremaining: 687ms\n",
            "668:\tlearn: 0.4027286\ttotal: 20.9s\tremaining: 655ms\n",
            "669:\tlearn: 0.4027075\ttotal: 20.9s\tremaining: 624ms\n",
            "670:\tlearn: 0.4026928\ttotal: 20.9s\tremaining: 593ms\n",
            "671:\tlearn: 0.4026720\ttotal: 21s\tremaining: 562ms\n",
            "672:\tlearn: 0.4026526\ttotal: 21s\tremaining: 530ms\n",
            "673:\tlearn: 0.4026415\ttotal: 21s\tremaining: 499ms\n",
            "674:\tlearn: 0.4026285\ttotal: 21.1s\tremaining: 468ms\n",
            "675:\tlearn: 0.4026108\ttotal: 21.1s\tremaining: 437ms\n",
            "676:\tlearn: 0.4025905\ttotal: 21.1s\tremaining: 405ms\n",
            "677:\tlearn: 0.4025812\ttotal: 21.1s\tremaining: 374ms\n",
            "678:\tlearn: 0.4025641\ttotal: 21.2s\tremaining: 343ms\n",
            "679:\tlearn: 0.4025527\ttotal: 21.2s\tremaining: 312ms\n",
            "680:\tlearn: 0.4025422\ttotal: 21.2s\tremaining: 281ms\n",
            "681:\tlearn: 0.4025236\ttotal: 21.3s\tremaining: 249ms\n",
            "682:\tlearn: 0.4025011\ttotal: 21.3s\tremaining: 218ms\n",
            "683:\tlearn: 0.4024823\ttotal: 21.3s\tremaining: 187ms\n",
            "684:\tlearn: 0.4024606\ttotal: 21.3s\tremaining: 156ms\n",
            "685:\tlearn: 0.4024474\ttotal: 21.4s\tremaining: 125ms\n",
            "686:\tlearn: 0.4024352\ttotal: 21.4s\tremaining: 93.4ms\n",
            "687:\tlearn: 0.4024221\ttotal: 21.4s\tremaining: 62.3ms\n",
            "688:\tlearn: 0.4024056\ttotal: 21.4s\tremaining: 31.1ms\n",
            "689:\tlearn: 0.4023848\ttotal: 21.5s\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 24576, number of negative: 101737\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026559 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1123\n",
            "[LightGBM] [Info] Number of data points in the train set: 126313, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.194564 -> initscore=-1.420621\n",
            "[LightGBM] [Info] Start training from score -1.420621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('catboost',\n",
              "                              <catboost.core.CatBoostClassifier object at 0x7daabc43d6f0>),\n",
              "                             ('lgbm', LGBMClassifier()),\n",
              "                             ('rfc',\n",
              "                              RandomForestClassifier(bootstrap=False,\n",
              "                                                     max_depth=10,\n",
              "                                                     max_features='log2',\n",
              "                                                     min_samples_leaf=13,\n",
              "                                                     min_samples_split=10,\n",
              "                                                     n_estimators=763))],\n",
              "                 voting='soft')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;catboost&#x27;,\n",
              "                              &lt;catboost.core.CatBoostClassifier object at 0x7daabc43d6f0&gt;),\n",
              "                             (&#x27;lgbm&#x27;, LGBMClassifier()),\n",
              "                             (&#x27;rfc&#x27;,\n",
              "                              RandomForestClassifier(bootstrap=False,\n",
              "                                                     max_depth=10,\n",
              "                                                     max_features=&#x27;log2&#x27;,\n",
              "                                                     min_samples_leaf=13,\n",
              "                                                     min_samples_split=10,\n",
              "                                                     n_estimators=763))],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;catboost&#x27;,\n",
              "                              &lt;catboost.core.CatBoostClassifier object at 0x7daabc43d6f0&gt;),\n",
              "                             (&#x27;lgbm&#x27;, LGBMClassifier()),\n",
              "                             (&#x27;rfc&#x27;,\n",
              "                              RandomForestClassifier(bootstrap=False,\n",
              "                                                     max_depth=10,\n",
              "                                                     max_features=&#x27;log2&#x27;,\n",
              "                                                     min_samples_leaf=13,\n",
              "                                                     min_samples_split=10,\n",
              "                                                     n_estimators=763))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>catboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x7daabc43d6f0&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rfc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=10, max_features=&#x27;log2&#x27;,\n",
              "                       min_samples_leaf=13, min_samples_split=10,\n",
              "                       n_estimators=763)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probabilities1 = voting_clf.predict_proba(x_test)[:, 1]\n",
        "\n",
        "auc_roc = roc_auc_score(y_test, pred_probabilities1)\n",
        "\n",
        "print(\"AUC-ROC Score:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Whugxk6aTHs",
        "outputId": "72b8a03f-9cdb-42dc-abe4-0ef3fc20bc38"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC Score: 0.8876374405697155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W_koDR3g-GuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Submission VC2**"
      ],
      "metadata": {
        "id": "DF-aohUjb0NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df0_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "B5Z56wpybzWH",
        "outputId": "bd640e98-e9b4-458e-c499-a5b71aa52329"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
              "0             0.472  0.067568     0.2  0.000000       0.333333        0.0   \n",
              "1             0.666  0.378378     0.2  0.000000       0.000000        1.0   \n",
              "2             0.612  0.216216     0.7  0.000000       0.333333        1.0   \n",
              "3             0.662  0.243243     0.8  0.000000       0.000000        1.0   \n",
              "4             0.804  0.270270     1.0  0.483318       0.000000        1.0   \n",
              "...             ...       ...     ...       ...            ...        ...   \n",
              "110018        0.440  0.148649     0.7  0.462737       0.000000        1.0   \n",
              "110019        0.450  0.243243     0.4  0.709581       0.000000        1.0   \n",
              "110020        0.724  0.175676     0.2  0.000000       0.333333        1.0   \n",
              "110021        0.718  0.189189     0.3  0.000000       0.000000        1.0   \n",
              "110022        0.542  0.256757     0.7  0.350136       0.000000        1.0   \n",
              "\n",
              "        IsActiveMember  EstimatedSalary  Gender_Female  Gender_Male  \\\n",
              "0                  1.0         0.804903              1            0   \n",
              "1                  0.0         0.362723              1            0   \n",
              "2                  0.0         0.694419              1            0   \n",
              "3                  0.0         0.569654              0            1   \n",
              "4                  0.0         0.697164              0            1   \n",
              "...                ...              ...            ...          ...   \n",
              "110018             1.0         0.740451              0            1   \n",
              "110019             1.0         0.210871              1            0   \n",
              "110020             0.0         0.081387              0            1   \n",
              "110021             1.0         0.794101              1            0   \n",
              "110022             0.0         0.121006              1            0   \n",
              "\n",
              "        Geography_France  Geography_Germany  Geography_Spain  \\\n",
              "0                      1                  0                0   \n",
              "1                      1                  0                0   \n",
              "2                      1                  0                0   \n",
              "3                      1                  0                0   \n",
              "4                      0                  1                0   \n",
              "...                  ...                ...              ...   \n",
              "110018                 0                  0                1   \n",
              "110019                 1                  0                0   \n",
              "110020                 1                  0                0   \n",
              "110021                 1                  0                0   \n",
              "110022                 1                  0                0   \n",
              "\n",
              "        has_card_active_member  has_card_active_member_male  \\\n",
              "0                          0.0                          0.0   \n",
              "1                          0.0                          0.0   \n",
              "2                          0.0                          0.0   \n",
              "3                          0.0                          0.0   \n",
              "4                          0.0                          0.0   \n",
              "...                        ...                          ...   \n",
              "110018                     1.0                          1.0   \n",
              "110019                     1.0                          0.0   \n",
              "110020                     0.0                          0.0   \n",
              "110021                     1.0                          0.0   \n",
              "110022                     0.0                          0.0   \n",
              "\n",
              "        Estimated_salary/Tenure  age_cat  has_balance  \n",
              "0                      0.268299        1            0  \n",
              "1                      0.120914        2            0  \n",
              "2                      0.086798        1            0  \n",
              "3                      0.063291        1            0  \n",
              "4                      0.063373        1            1  \n",
              "...                         ...      ...          ...  \n",
              "110018                 0.092552        1            1  \n",
              "110019                 0.042176        1            1  \n",
              "110020                 0.027140        1            0  \n",
              "110021                 0.198522        1            0  \n",
              "110022                 0.015125        1            1  \n",
              "\n",
              "[110023 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e71716c3-d329-42b6-b313-fadfeee4d9b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Geography_France</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>has_card_active_member</th>\n",
              "      <th>has_card_active_member_male</th>\n",
              "      <th>Estimated_salary/Tenure</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>has_balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.472</td>\n",
              "      <td>0.067568</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.804903</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.268299</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.666</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.362723</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.120914</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.612</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.694419</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.086798</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.662</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.569654</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063291</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.804</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.483318</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.697164</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063373</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110018</th>\n",
              "      <td>0.440</td>\n",
              "      <td>0.148649</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.462737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.740451</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.092552</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110019</th>\n",
              "      <td>0.450</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.709581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.210871</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042176</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110020</th>\n",
              "      <td>0.724</td>\n",
              "      <td>0.175676</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.081387</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027140</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110021</th>\n",
              "      <td>0.718</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.794101</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.198522</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110022</th>\n",
              "      <td>0.542</td>\n",
              "      <td>0.256757</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.350136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.121006</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015125</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>110023 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e71716c3-d329-42b6-b313-fadfeee4d9b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e71716c3-d329-42b6-b313-fadfeee4d9b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e71716c3-d329-42b6-b313-fadfeee4d9b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2173286c-2a52-452a-abe8-b0889bd0f8c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2173286c-2a52-452a-abe8-b0889bd0f8c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2173286c-2a52-452a-abe8-b0889bd0f8c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df0_normalized"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Exited = voting_clf.predict_proba(test_df0_normalized)[:, 1]\n",
        "\n",
        "\n",
        "# Create a DataFrame with IDs and predicted probabilities\n",
        "result_df = pd.DataFrame({'id': test_df['id'], 'Exited': Exited})\n",
        "\n",
        "# Save the result to a CSV file\n",
        "result_df.to_csv('predicted_results_vc3.csv', index=False)"
      ],
      "metadata": {
        "id": "7kSN7NsQcDc2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "STpFktHid4D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA With Catboost**"
      ],
      "metadata": {
        "id": "zCu4NgV1pI9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhQO1S5Jq5xp",
        "outputId": "db5d74e7-7ad3-4797-9bb2-05e3a11d141b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118824, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbc= CatBoostClassifier()\n",
        "for n in range(1, 30):\n",
        "    pca = PCA(n_components=n)\n",
        "    xtrain = pca.fit_transform(x_train)\n",
        "    xtest = pca.transform(x_test)\n",
        "\n",
        "    cbc.fit(xtrain, y_train)\n",
        "    pred_prob = cbc.predict_proba(xtest)[:, 1]\n",
        "\n",
        "    auc = roc_auc_score(y_test, pred_prob)\n",
        "    print(n, ':', auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cn5nQ9OGpPpF",
        "outputId": "394658b1-bce2-40da-a070-e85f42d7b73e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "9:\tlearn: 0.3782113\ttotal: 693ms\tremaining: 1m 8s\n",
            "10:\tlearn: 0.3701262\ttotal: 769ms\tremaining: 1m 9s\n",
            "11:\tlearn: 0.3645896\ttotal: 835ms\tremaining: 1m 8s\n",
            "12:\tlearn: 0.3588367\ttotal: 921ms\tremaining: 1m 9s\n",
            "13:\tlearn: 0.3541489\ttotal: 993ms\tremaining: 1m 9s\n",
            "14:\tlearn: 0.3501372\ttotal: 1.06s\tremaining: 1m 9s\n",
            "15:\tlearn: 0.3464269\ttotal: 1.14s\tremaining: 1m 10s\n",
            "16:\tlearn: 0.3435173\ttotal: 1.22s\tremaining: 1m 10s\n",
            "17:\tlearn: 0.3415146\ttotal: 1.29s\tremaining: 1m 10s\n",
            "18:\tlearn: 0.3397550\ttotal: 1.37s\tremaining: 1m 10s\n",
            "19:\tlearn: 0.3376794\ttotal: 1.43s\tremaining: 1m 10s\n",
            "20:\tlearn: 0.3358215\ttotal: 1.51s\tremaining: 1m 10s\n",
            "21:\tlearn: 0.3342106\ttotal: 1.56s\tremaining: 1m 9s\n",
            "22:\tlearn: 0.3330573\ttotal: 1.64s\tremaining: 1m 9s\n",
            "23:\tlearn: 0.3319481\ttotal: 1.7s\tremaining: 1m 9s\n",
            "24:\tlearn: 0.3309890\ttotal: 1.78s\tremaining: 1m 9s\n",
            "25:\tlearn: 0.3297392\ttotal: 1.86s\tremaining: 1m 9s\n",
            "26:\tlearn: 0.3289876\ttotal: 1.95s\tremaining: 1m 10s\n",
            "27:\tlearn: 0.3283493\ttotal: 2.04s\tremaining: 1m 10s\n",
            "28:\tlearn: 0.3278672\ttotal: 2.12s\tremaining: 1m 11s\n",
            "29:\tlearn: 0.3271088\ttotal: 2.19s\tremaining: 1m 10s\n",
            "30:\tlearn: 0.3264190\ttotal: 2.22s\tremaining: 1m 9s\n",
            "31:\tlearn: 0.3259364\ttotal: 2.26s\tremaining: 1m 8s\n",
            "32:\tlearn: 0.3254505\ttotal: 2.29s\tremaining: 1m 7s\n",
            "33:\tlearn: 0.3251954\ttotal: 2.32s\tremaining: 1m 5s\n",
            "34:\tlearn: 0.3248497\ttotal: 2.36s\tremaining: 1m 5s\n",
            "35:\tlearn: 0.3244188\ttotal: 2.39s\tremaining: 1m 4s\n",
            "36:\tlearn: 0.3240846\ttotal: 2.42s\tremaining: 1m 3s\n",
            "37:\tlearn: 0.3236853\ttotal: 2.46s\tremaining: 1m 2s\n",
            "38:\tlearn: 0.3233587\ttotal: 2.48s\tremaining: 1m 1s\n",
            "39:\tlearn: 0.3231916\ttotal: 2.51s\tremaining: 1m\n",
            "40:\tlearn: 0.3229333\ttotal: 2.55s\tremaining: 59.7s\n",
            "41:\tlearn: 0.3227509\ttotal: 2.58s\tremaining: 58.9s\n",
            "42:\tlearn: 0.3224533\ttotal: 2.61s\tremaining: 58.1s\n",
            "43:\tlearn: 0.3222067\ttotal: 2.64s\tremaining: 57.4s\n",
            "44:\tlearn: 0.3220093\ttotal: 2.68s\tremaining: 56.8s\n",
            "45:\tlearn: 0.3217154\ttotal: 2.71s\tremaining: 56.1s\n",
            "46:\tlearn: 0.3214411\ttotal: 2.74s\tremaining: 55.5s\n",
            "47:\tlearn: 0.3212797\ttotal: 2.78s\tremaining: 55.1s\n",
            "48:\tlearn: 0.3211026\ttotal: 2.81s\tremaining: 54.5s\n",
            "49:\tlearn: 0.3209253\ttotal: 2.84s\tremaining: 53.9s\n",
            "50:\tlearn: 0.3207151\ttotal: 2.87s\tremaining: 53.3s\n",
            "51:\tlearn: 0.3205526\ttotal: 2.9s\tremaining: 52.8s\n",
            "52:\tlearn: 0.3203805\ttotal: 2.93s\tremaining: 52.3s\n",
            "53:\tlearn: 0.3202512\ttotal: 2.96s\tremaining: 51.9s\n",
            "54:\tlearn: 0.3200670\ttotal: 3.01s\tremaining: 51.7s\n",
            "55:\tlearn: 0.3199248\ttotal: 3.05s\tremaining: 51.4s\n",
            "56:\tlearn: 0.3198022\ttotal: 3.08s\tremaining: 50.9s\n",
            "57:\tlearn: 0.3196369\ttotal: 3.1s\tremaining: 50.4s\n",
            "58:\tlearn: 0.3193944\ttotal: 3.13s\tremaining: 50s\n",
            "59:\tlearn: 0.3193197\ttotal: 3.17s\tremaining: 49.6s\n",
            "60:\tlearn: 0.3191954\ttotal: 3.19s\tremaining: 49.2s\n",
            "61:\tlearn: 0.3190269\ttotal: 3.24s\tremaining: 49s\n",
            "62:\tlearn: 0.3189300\ttotal: 3.26s\tremaining: 48.6s\n",
            "63:\tlearn: 0.3187754\ttotal: 3.29s\tremaining: 48.2s\n",
            "64:\tlearn: 0.3187102\ttotal: 3.32s\tremaining: 47.8s\n",
            "65:\tlearn: 0.3186292\ttotal: 3.36s\tremaining: 47.5s\n",
            "66:\tlearn: 0.3185325\ttotal: 3.39s\tremaining: 47.2s\n",
            "67:\tlearn: 0.3184405\ttotal: 3.42s\tremaining: 46.8s\n",
            "68:\tlearn: 0.3183666\ttotal: 3.46s\tremaining: 46.7s\n",
            "69:\tlearn: 0.3182510\ttotal: 3.49s\tremaining: 46.4s\n",
            "70:\tlearn: 0.3180793\ttotal: 3.52s\tremaining: 46.1s\n",
            "71:\tlearn: 0.3180267\ttotal: 3.55s\tremaining: 45.8s\n",
            "72:\tlearn: 0.3179464\ttotal: 3.58s\tremaining: 45.5s\n",
            "73:\tlearn: 0.3178682\ttotal: 3.61s\tremaining: 45.2s\n",
            "74:\tlearn: 0.3178047\ttotal: 3.64s\tremaining: 44.9s\n",
            "75:\tlearn: 0.3176514\ttotal: 3.68s\tremaining: 44.8s\n",
            "76:\tlearn: 0.3175226\ttotal: 3.71s\tremaining: 44.5s\n",
            "77:\tlearn: 0.3174413\ttotal: 3.74s\tremaining: 44.2s\n",
            "78:\tlearn: 0.3173353\ttotal: 3.77s\tremaining: 44s\n",
            "79:\tlearn: 0.3172480\ttotal: 3.8s\tremaining: 43.7s\n",
            "80:\tlearn: 0.3171319\ttotal: 3.83s\tremaining: 43.5s\n",
            "81:\tlearn: 0.3170349\ttotal: 3.86s\tremaining: 43.2s\n",
            "82:\tlearn: 0.3169576\ttotal: 3.9s\tremaining: 43.1s\n",
            "83:\tlearn: 0.3168564\ttotal: 3.93s\tremaining: 42.8s\n",
            "84:\tlearn: 0.3167428\ttotal: 3.96s\tremaining: 42.6s\n",
            "85:\tlearn: 0.3166189\ttotal: 4s\tremaining: 42.5s\n",
            "86:\tlearn: 0.3165220\ttotal: 4.04s\tremaining: 42.4s\n",
            "87:\tlearn: 0.3164413\ttotal: 4.07s\tremaining: 42.2s\n",
            "88:\tlearn: 0.3163478\ttotal: 4.11s\tremaining: 42.1s\n",
            "89:\tlearn: 0.3162804\ttotal: 4.14s\tremaining: 41.9s\n",
            "90:\tlearn: 0.3162372\ttotal: 4.17s\tremaining: 41.7s\n",
            "91:\tlearn: 0.3161535\ttotal: 4.2s\tremaining: 41.5s\n",
            "92:\tlearn: 0.3160909\ttotal: 4.23s\tremaining: 41.3s\n",
            "93:\tlearn: 0.3160177\ttotal: 4.26s\tremaining: 41.1s\n",
            "94:\tlearn: 0.3159250\ttotal: 4.29s\tremaining: 40.9s\n",
            "95:\tlearn: 0.3158816\ttotal: 4.33s\tremaining: 40.8s\n",
            "96:\tlearn: 0.3157982\ttotal: 4.36s\tremaining: 40.6s\n",
            "97:\tlearn: 0.3157403\ttotal: 4.39s\tremaining: 40.4s\n",
            "98:\tlearn: 0.3156732\ttotal: 4.43s\tremaining: 40.3s\n",
            "99:\tlearn: 0.3156101\ttotal: 4.46s\tremaining: 40.1s\n",
            "100:\tlearn: 0.3155499\ttotal: 4.49s\tremaining: 39.9s\n",
            "101:\tlearn: 0.3154989\ttotal: 4.51s\tremaining: 39.8s\n",
            "102:\tlearn: 0.3153987\ttotal: 4.55s\tremaining: 39.6s\n",
            "103:\tlearn: 0.3152993\ttotal: 4.58s\tremaining: 39.5s\n",
            "104:\tlearn: 0.3152400\ttotal: 4.61s\tremaining: 39.3s\n",
            "105:\tlearn: 0.3151782\ttotal: 4.64s\tremaining: 39.2s\n",
            "106:\tlearn: 0.3151055\ttotal: 4.68s\tremaining: 39s\n",
            "107:\tlearn: 0.3150543\ttotal: 4.71s\tremaining: 38.9s\n",
            "108:\tlearn: 0.3149826\ttotal: 4.74s\tremaining: 38.7s\n",
            "109:\tlearn: 0.3149220\ttotal: 4.78s\tremaining: 38.7s\n",
            "110:\tlearn: 0.3148507\ttotal: 4.81s\tremaining: 38.5s\n",
            "111:\tlearn: 0.3147980\ttotal: 4.84s\tremaining: 38.4s\n",
            "112:\tlearn: 0.3147204\ttotal: 4.87s\tremaining: 38.3s\n",
            "113:\tlearn: 0.3146192\ttotal: 4.9s\tremaining: 38.1s\n",
            "114:\tlearn: 0.3145779\ttotal: 4.94s\tremaining: 38s\n",
            "115:\tlearn: 0.3145294\ttotal: 4.97s\tremaining: 37.9s\n",
            "116:\tlearn: 0.3144720\ttotal: 5.01s\tremaining: 37.8s\n",
            "117:\tlearn: 0.3144223\ttotal: 5.06s\tremaining: 37.8s\n",
            "118:\tlearn: 0.3143570\ttotal: 5.09s\tremaining: 37.7s\n",
            "119:\tlearn: 0.3143014\ttotal: 5.12s\tremaining: 37.5s\n",
            "120:\tlearn: 0.3142345\ttotal: 5.15s\tremaining: 37.4s\n",
            "121:\tlearn: 0.3141776\ttotal: 5.18s\tremaining: 37.3s\n",
            "122:\tlearn: 0.3141163\ttotal: 5.21s\tremaining: 37.1s\n",
            "123:\tlearn: 0.3140658\ttotal: 5.25s\tremaining: 37.1s\n",
            "124:\tlearn: 0.3140230\ttotal: 5.28s\tremaining: 37s\n",
            "125:\tlearn: 0.3139787\ttotal: 5.32s\tremaining: 36.9s\n",
            "126:\tlearn: 0.3138565\ttotal: 5.34s\tremaining: 36.7s\n",
            "127:\tlearn: 0.3138072\ttotal: 5.37s\tremaining: 36.6s\n",
            "128:\tlearn: 0.3137627\ttotal: 5.4s\tremaining: 36.5s\n",
            "129:\tlearn: 0.3136956\ttotal: 5.43s\tremaining: 36.4s\n",
            "130:\tlearn: 0.3136382\ttotal: 5.47s\tremaining: 36.3s\n",
            "131:\tlearn: 0.3135901\ttotal: 5.5s\tremaining: 36.2s\n",
            "132:\tlearn: 0.3135500\ttotal: 5.53s\tremaining: 36.1s\n",
            "133:\tlearn: 0.3134652\ttotal: 5.56s\tremaining: 35.9s\n",
            "134:\tlearn: 0.3133967\ttotal: 5.59s\tremaining: 35.8s\n",
            "135:\tlearn: 0.3133399\ttotal: 5.62s\tremaining: 35.7s\n",
            "136:\tlearn: 0.3133063\ttotal: 5.65s\tremaining: 35.6s\n",
            "137:\tlearn: 0.3132667\ttotal: 5.69s\tremaining: 35.5s\n",
            "138:\tlearn: 0.3132186\ttotal: 5.72s\tremaining: 35.5s\n",
            "139:\tlearn: 0.3131473\ttotal: 5.75s\tremaining: 35.3s\n",
            "140:\tlearn: 0.3131114\ttotal: 5.78s\tremaining: 35.2s\n",
            "141:\tlearn: 0.3130580\ttotal: 5.81s\tremaining: 35.1s\n",
            "142:\tlearn: 0.3130048\ttotal: 5.84s\tremaining: 35s\n",
            "143:\tlearn: 0.3129715\ttotal: 5.87s\tremaining: 34.9s\n",
            "144:\tlearn: 0.3129232\ttotal: 5.91s\tremaining: 34.9s\n",
            "145:\tlearn: 0.3128541\ttotal: 5.95s\tremaining: 34.8s\n",
            "146:\tlearn: 0.3128044\ttotal: 5.98s\tremaining: 34.7s\n",
            "147:\tlearn: 0.3127615\ttotal: 6.01s\tremaining: 34.6s\n",
            "148:\tlearn: 0.3127023\ttotal: 6.04s\tremaining: 34.5s\n",
            "149:\tlearn: 0.3126521\ttotal: 6.08s\tremaining: 34.5s\n",
            "150:\tlearn: 0.3126091\ttotal: 6.11s\tremaining: 34.4s\n",
            "151:\tlearn: 0.3125319\ttotal: 6.15s\tremaining: 34.3s\n",
            "152:\tlearn: 0.3124440\ttotal: 6.18s\tremaining: 34.2s\n",
            "153:\tlearn: 0.3123969\ttotal: 6.21s\tremaining: 34.1s\n",
            "154:\tlearn: 0.3123520\ttotal: 6.24s\tremaining: 34s\n",
            "155:\tlearn: 0.3122791\ttotal: 6.27s\tremaining: 33.9s\n",
            "156:\tlearn: 0.3122038\ttotal: 6.3s\tremaining: 33.8s\n",
            "157:\tlearn: 0.3121532\ttotal: 6.34s\tremaining: 33.8s\n",
            "158:\tlearn: 0.3121018\ttotal: 6.37s\tremaining: 33.7s\n",
            "159:\tlearn: 0.3120513\ttotal: 6.4s\tremaining: 33.6s\n",
            "160:\tlearn: 0.3119839\ttotal: 6.43s\tremaining: 33.5s\n",
            "161:\tlearn: 0.3119513\ttotal: 6.46s\tremaining: 33.4s\n",
            "162:\tlearn: 0.3118710\ttotal: 6.49s\tremaining: 33.3s\n",
            "163:\tlearn: 0.3118210\ttotal: 6.52s\tremaining: 33.2s\n",
            "164:\tlearn: 0.3117522\ttotal: 6.55s\tremaining: 33.2s\n",
            "165:\tlearn: 0.3116936\ttotal: 6.59s\tremaining: 33.1s\n",
            "166:\tlearn: 0.3116459\ttotal: 6.62s\tremaining: 33s\n",
            "167:\tlearn: 0.3115888\ttotal: 6.65s\tremaining: 32.9s\n",
            "168:\tlearn: 0.3115358\ttotal: 6.68s\tremaining: 32.8s\n",
            "169:\tlearn: 0.3114767\ttotal: 6.71s\tremaining: 32.8s\n",
            "170:\tlearn: 0.3114181\ttotal: 6.74s\tremaining: 32.7s\n",
            "171:\tlearn: 0.3113410\ttotal: 6.78s\tremaining: 32.6s\n",
            "172:\tlearn: 0.3112534\ttotal: 6.8s\tremaining: 32.5s\n",
            "173:\tlearn: 0.3111931\ttotal: 6.83s\tremaining: 32.4s\n",
            "174:\tlearn: 0.3111479\ttotal: 6.86s\tremaining: 32.3s\n",
            "175:\tlearn: 0.3110924\ttotal: 6.89s\tremaining: 32.3s\n",
            "176:\tlearn: 0.3110378\ttotal: 6.92s\tremaining: 32.2s\n",
            "177:\tlearn: 0.3109703\ttotal: 6.95s\tremaining: 32.1s\n",
            "178:\tlearn: 0.3109110\ttotal: 6.99s\tremaining: 32.1s\n",
            "179:\tlearn: 0.3108626\ttotal: 7.02s\tremaining: 32s\n",
            "180:\tlearn: 0.3107938\ttotal: 7.06s\tremaining: 31.9s\n",
            "181:\tlearn: 0.3107246\ttotal: 7.09s\tremaining: 31.9s\n",
            "182:\tlearn: 0.3106714\ttotal: 7.12s\tremaining: 31.8s\n",
            "183:\tlearn: 0.3106019\ttotal: 7.15s\tremaining: 31.7s\n",
            "184:\tlearn: 0.3105627\ttotal: 7.18s\tremaining: 31.6s\n",
            "185:\tlearn: 0.3105081\ttotal: 7.22s\tremaining: 31.6s\n",
            "186:\tlearn: 0.3104497\ttotal: 7.25s\tremaining: 31.5s\n",
            "187:\tlearn: 0.3103916\ttotal: 7.28s\tremaining: 31.5s\n",
            "188:\tlearn: 0.3103243\ttotal: 7.31s\tremaining: 31.4s\n",
            "189:\tlearn: 0.3102770\ttotal: 7.34s\tremaining: 31.3s\n",
            "190:\tlearn: 0.3102310\ttotal: 7.37s\tremaining: 31.2s\n",
            "191:\tlearn: 0.3101577\ttotal: 7.41s\tremaining: 31.2s\n",
            "192:\tlearn: 0.3101030\ttotal: 7.45s\tremaining: 31.1s\n",
            "193:\tlearn: 0.3100497\ttotal: 7.47s\tremaining: 31.1s\n",
            "194:\tlearn: 0.3099975\ttotal: 7.5s\tremaining: 31s\n",
            "195:\tlearn: 0.3099436\ttotal: 7.53s\tremaining: 30.9s\n",
            "196:\tlearn: 0.3098759\ttotal: 7.56s\tremaining: 30.8s\n",
            "197:\tlearn: 0.3098327\ttotal: 7.59s\tremaining: 30.7s\n",
            "198:\tlearn: 0.3097802\ttotal: 7.62s\tremaining: 30.7s\n",
            "199:\tlearn: 0.3097143\ttotal: 7.65s\tremaining: 30.6s\n",
            "200:\tlearn: 0.3096389\ttotal: 7.69s\tremaining: 30.6s\n",
            "201:\tlearn: 0.3095680\ttotal: 7.72s\tremaining: 30.5s\n",
            "202:\tlearn: 0.3095173\ttotal: 7.75s\tremaining: 30.4s\n",
            "203:\tlearn: 0.3094764\ttotal: 7.77s\tremaining: 30.3s\n",
            "204:\tlearn: 0.3094213\ttotal: 7.8s\tremaining: 30.3s\n",
            "205:\tlearn: 0.3093716\ttotal: 7.83s\tremaining: 30.2s\n",
            "206:\tlearn: 0.3093033\ttotal: 7.88s\tremaining: 30.2s\n",
            "207:\tlearn: 0.3092305\ttotal: 7.91s\tremaining: 30.1s\n",
            "208:\tlearn: 0.3091846\ttotal: 7.94s\tremaining: 30.1s\n",
            "209:\tlearn: 0.3091389\ttotal: 7.97s\tremaining: 30s\n",
            "210:\tlearn: 0.3090699\ttotal: 8s\tremaining: 29.9s\n",
            "211:\tlearn: 0.3090229\ttotal: 8.03s\tremaining: 29.8s\n",
            "212:\tlearn: 0.3089526\ttotal: 8.06s\tremaining: 29.8s\n",
            "213:\tlearn: 0.3089095\ttotal: 8.11s\tremaining: 29.8s\n",
            "214:\tlearn: 0.3088633\ttotal: 8.14s\tremaining: 29.7s\n",
            "215:\tlearn: 0.3088241\ttotal: 8.17s\tremaining: 29.6s\n",
            "216:\tlearn: 0.3087524\ttotal: 8.2s\tremaining: 29.6s\n",
            "217:\tlearn: 0.3086958\ttotal: 8.23s\tremaining: 29.5s\n",
            "218:\tlearn: 0.3086484\ttotal: 8.26s\tremaining: 29.5s\n",
            "219:\tlearn: 0.3085950\ttotal: 8.29s\tremaining: 29.4s\n",
            "220:\tlearn: 0.3085371\ttotal: 8.33s\tremaining: 29.4s\n",
            "221:\tlearn: 0.3085047\ttotal: 8.36s\tremaining: 29.3s\n",
            "222:\tlearn: 0.3084574\ttotal: 8.39s\tremaining: 29.2s\n",
            "223:\tlearn: 0.3084112\ttotal: 8.42s\tremaining: 29.2s\n",
            "224:\tlearn: 0.3083580\ttotal: 8.45s\tremaining: 29.1s\n",
            "225:\tlearn: 0.3083019\ttotal: 8.48s\tremaining: 29s\n",
            "226:\tlearn: 0.3082200\ttotal: 8.51s\tremaining: 29s\n",
            "227:\tlearn: 0.3081628\ttotal: 8.55s\tremaining: 29s\n",
            "228:\tlearn: 0.3081012\ttotal: 8.59s\tremaining: 28.9s\n",
            "229:\tlearn: 0.3080349\ttotal: 8.61s\tremaining: 28.8s\n",
            "230:\tlearn: 0.3079807\ttotal: 8.64s\tremaining: 28.8s\n",
            "231:\tlearn: 0.3079083\ttotal: 8.68s\tremaining: 28.7s\n",
            "232:\tlearn: 0.3078610\ttotal: 8.71s\tremaining: 28.7s\n",
            "233:\tlearn: 0.3078016\ttotal: 8.73s\tremaining: 28.6s\n",
            "234:\tlearn: 0.3077422\ttotal: 8.78s\tremaining: 28.6s\n",
            "235:\tlearn: 0.3076971\ttotal: 8.81s\tremaining: 28.5s\n",
            "236:\tlearn: 0.3076522\ttotal: 8.84s\tremaining: 28.5s\n",
            "237:\tlearn: 0.3076124\ttotal: 8.87s\tremaining: 28.4s\n",
            "238:\tlearn: 0.3075757\ttotal: 8.9s\tremaining: 28.3s\n",
            "239:\tlearn: 0.3075317\ttotal: 8.93s\tremaining: 28.3s\n",
            "240:\tlearn: 0.3074853\ttotal: 8.96s\tremaining: 28.2s\n",
            "241:\tlearn: 0.3074420\ttotal: 9s\tremaining: 28.2s\n",
            "242:\tlearn: 0.3073884\ttotal: 9.03s\tremaining: 28.1s\n",
            "243:\tlearn: 0.3073182\ttotal: 9.06s\tremaining: 28.1s\n",
            "244:\tlearn: 0.3072745\ttotal: 9.09s\tremaining: 28s\n",
            "245:\tlearn: 0.3072126\ttotal: 9.13s\tremaining: 28s\n",
            "246:\tlearn: 0.3071595\ttotal: 9.16s\tremaining: 27.9s\n",
            "247:\tlearn: 0.3071035\ttotal: 9.19s\tremaining: 27.9s\n",
            "248:\tlearn: 0.3070497\ttotal: 9.23s\tremaining: 27.9s\n",
            "249:\tlearn: 0.3069946\ttotal: 9.27s\tremaining: 27.8s\n",
            "250:\tlearn: 0.3069252\ttotal: 9.3s\tremaining: 27.7s\n",
            "251:\tlearn: 0.3068687\ttotal: 9.32s\tremaining: 27.7s\n",
            "252:\tlearn: 0.3068196\ttotal: 9.36s\tremaining: 27.6s\n",
            "253:\tlearn: 0.3067721\ttotal: 9.39s\tremaining: 27.6s\n",
            "254:\tlearn: 0.3067092\ttotal: 9.42s\tremaining: 27.5s\n",
            "255:\tlearn: 0.3066656\ttotal: 9.46s\tremaining: 27.5s\n",
            "256:\tlearn: 0.3066108\ttotal: 9.48s\tremaining: 27.4s\n",
            "257:\tlearn: 0.3065556\ttotal: 9.51s\tremaining: 27.4s\n",
            "258:\tlearn: 0.3065198\ttotal: 9.55s\tremaining: 27.3s\n",
            "259:\tlearn: 0.3064715\ttotal: 9.57s\tremaining: 27.3s\n",
            "260:\tlearn: 0.3064188\ttotal: 9.61s\tremaining: 27.2s\n",
            "261:\tlearn: 0.3063684\ttotal: 9.63s\tremaining: 27.1s\n",
            "262:\tlearn: 0.3063255\ttotal: 9.68s\tremaining: 27.1s\n",
            "263:\tlearn: 0.3062960\ttotal: 9.7s\tremaining: 27.1s\n",
            "264:\tlearn: 0.3062407\ttotal: 9.73s\tremaining: 27s\n",
            "265:\tlearn: 0.3061931\ttotal: 9.76s\tremaining: 26.9s\n",
            "266:\tlearn: 0.3061536\ttotal: 9.79s\tremaining: 26.9s\n",
            "267:\tlearn: 0.3061121\ttotal: 9.82s\tremaining: 26.8s\n",
            "268:\tlearn: 0.3060606\ttotal: 9.85s\tremaining: 26.8s\n",
            "269:\tlearn: 0.3060015\ttotal: 9.89s\tremaining: 26.7s\n",
            "270:\tlearn: 0.3059445\ttotal: 9.93s\tremaining: 26.7s\n",
            "271:\tlearn: 0.3059038\ttotal: 9.96s\tremaining: 26.7s\n",
            "272:\tlearn: 0.3058547\ttotal: 9.99s\tremaining: 26.6s\n",
            "273:\tlearn: 0.3058153\ttotal: 10s\tremaining: 26.5s\n",
            "274:\tlearn: 0.3057574\ttotal: 10.1s\tremaining: 26.5s\n",
            "275:\tlearn: 0.3057041\ttotal: 10.1s\tremaining: 26.4s\n",
            "276:\tlearn: 0.3056557\ttotal: 10.1s\tremaining: 26.5s\n",
            "277:\tlearn: 0.3055952\ttotal: 10.2s\tremaining: 26.4s\n",
            "278:\tlearn: 0.3055271\ttotal: 10.2s\tremaining: 26.4s\n",
            "279:\tlearn: 0.3054749\ttotal: 10.2s\tremaining: 26.3s\n",
            "280:\tlearn: 0.3054136\ttotal: 10.3s\tremaining: 26.3s\n",
            "281:\tlearn: 0.3053353\ttotal: 10.3s\tremaining: 26.2s\n",
            "282:\tlearn: 0.3052919\ttotal: 10.3s\tremaining: 26.2s\n",
            "283:\tlearn: 0.3052387\ttotal: 10.4s\tremaining: 26.2s\n",
            "284:\tlearn: 0.3051803\ttotal: 10.4s\tremaining: 26.1s\n",
            "285:\tlearn: 0.3050999\ttotal: 10.4s\tremaining: 26.1s\n",
            "286:\tlearn: 0.3050542\ttotal: 10.5s\tremaining: 26s\n",
            "287:\tlearn: 0.3050067\ttotal: 10.5s\tremaining: 25.9s\n",
            "288:\tlearn: 0.3049568\ttotal: 10.5s\tremaining: 25.9s\n",
            "289:\tlearn: 0.3049100\ttotal: 10.6s\tremaining: 25.9s\n",
            "290:\tlearn: 0.3048540\ttotal: 10.6s\tremaining: 25.8s\n",
            "291:\tlearn: 0.3047944\ttotal: 10.6s\tremaining: 25.8s\n",
            "292:\tlearn: 0.3047501\ttotal: 10.7s\tremaining: 25.7s\n",
            "293:\tlearn: 0.3046960\ttotal: 10.7s\tremaining: 25.7s\n",
            "294:\tlearn: 0.3046427\ttotal: 10.7s\tremaining: 25.6s\n",
            "295:\tlearn: 0.3046091\ttotal: 10.8s\tremaining: 25.6s\n",
            "296:\tlearn: 0.3045695\ttotal: 10.8s\tremaining: 25.5s\n",
            "297:\tlearn: 0.3045296\ttotal: 10.8s\tremaining: 25.5s\n",
            "298:\tlearn: 0.3044863\ttotal: 10.9s\tremaining: 25.5s\n",
            "299:\tlearn: 0.3044493\ttotal: 10.9s\tremaining: 25.4s\n",
            "300:\tlearn: 0.3044145\ttotal: 10.9s\tremaining: 25.3s\n",
            "301:\tlearn: 0.3043728\ttotal: 10.9s\tremaining: 25.3s\n",
            "302:\tlearn: 0.3043268\ttotal: 11s\tremaining: 25.2s\n",
            "303:\tlearn: 0.3042609\ttotal: 11s\tremaining: 25.2s\n",
            "304:\tlearn: 0.3042129\ttotal: 11s\tremaining: 25.2s\n",
            "305:\tlearn: 0.3041474\ttotal: 11.1s\tremaining: 25.1s\n",
            "306:\tlearn: 0.3040814\ttotal: 11.1s\tremaining: 25.1s\n",
            "307:\tlearn: 0.3040251\ttotal: 11.2s\tremaining: 25.1s\n",
            "308:\tlearn: 0.3039838\ttotal: 11.2s\tremaining: 25s\n",
            "309:\tlearn: 0.3039478\ttotal: 11.2s\tremaining: 25s\n",
            "310:\tlearn: 0.3039006\ttotal: 11.3s\tremaining: 25s\n",
            "311:\tlearn: 0.3038495\ttotal: 11.3s\tremaining: 24.9s\n",
            "312:\tlearn: 0.3037965\ttotal: 11.3s\tremaining: 24.9s\n",
            "313:\tlearn: 0.3037665\ttotal: 11.4s\tremaining: 24.8s\n",
            "314:\tlearn: 0.3037115\ttotal: 11.4s\tremaining: 24.8s\n",
            "315:\tlearn: 0.3036533\ttotal: 11.4s\tremaining: 24.7s\n",
            "316:\tlearn: 0.3036173\ttotal: 11.4s\tremaining: 24.7s\n",
            "317:\tlearn: 0.3035850\ttotal: 11.5s\tremaining: 24.6s\n",
            "318:\tlearn: 0.3035430\ttotal: 11.5s\tremaining: 24.6s\n",
            "319:\tlearn: 0.3034896\ttotal: 11.5s\tremaining: 24.5s\n",
            "320:\tlearn: 0.3034574\ttotal: 11.6s\tremaining: 24.5s\n",
            "321:\tlearn: 0.3034103\ttotal: 11.6s\tremaining: 24.4s\n",
            "322:\tlearn: 0.3033820\ttotal: 11.6s\tremaining: 24.4s\n",
            "323:\tlearn: 0.3033468\ttotal: 11.7s\tremaining: 24.3s\n",
            "324:\tlearn: 0.3032934\ttotal: 11.7s\tremaining: 24.3s\n",
            "325:\tlearn: 0.3032481\ttotal: 11.7s\tremaining: 24.3s\n",
            "326:\tlearn: 0.3032027\ttotal: 11.8s\tremaining: 24.2s\n",
            "327:\tlearn: 0.3031509\ttotal: 11.8s\tremaining: 24.2s\n",
            "328:\tlearn: 0.3031079\ttotal: 11.8s\tremaining: 24.1s\n",
            "329:\tlearn: 0.3030464\ttotal: 11.9s\tremaining: 24.1s\n",
            "330:\tlearn: 0.3029903\ttotal: 11.9s\tremaining: 24s\n",
            "331:\tlearn: 0.3029522\ttotal: 11.9s\tremaining: 24s\n",
            "332:\tlearn: 0.3029059\ttotal: 12s\tremaining: 23.9s\n",
            "333:\tlearn: 0.3028561\ttotal: 12s\tremaining: 23.9s\n",
            "334:\tlearn: 0.3028109\ttotal: 12s\tremaining: 23.8s\n",
            "335:\tlearn: 0.3027582\ttotal: 12s\tremaining: 23.8s\n",
            "336:\tlearn: 0.3027252\ttotal: 12.1s\tremaining: 23.8s\n",
            "337:\tlearn: 0.3026928\ttotal: 12.2s\tremaining: 23.8s\n",
            "338:\tlearn: 0.3026490\ttotal: 12.2s\tremaining: 23.8s\n",
            "339:\tlearn: 0.3026006\ttotal: 12.3s\tremaining: 23.8s\n",
            "340:\tlearn: 0.3025516\ttotal: 12.3s\tremaining: 23.9s\n",
            "341:\tlearn: 0.3025016\ttotal: 12.4s\tremaining: 23.9s\n",
            "342:\tlearn: 0.3024543\ttotal: 12.5s\tremaining: 23.9s\n",
            "343:\tlearn: 0.3024145\ttotal: 12.6s\tremaining: 23.9s\n",
            "344:\tlearn: 0.3023947\ttotal: 12.6s\tremaining: 24s\n",
            "345:\tlearn: 0.3023394\ttotal: 12.7s\tremaining: 24s\n",
            "346:\tlearn: 0.3022927\ttotal: 12.8s\tremaining: 24.1s\n",
            "347:\tlearn: 0.3022591\ttotal: 12.9s\tremaining: 24.1s\n",
            "348:\tlearn: 0.3022130\ttotal: 12.9s\tremaining: 24.1s\n",
            "349:\tlearn: 0.3021665\ttotal: 13s\tremaining: 24.1s\n",
            "350:\tlearn: 0.3021353\ttotal: 13.1s\tremaining: 24.2s\n",
            "351:\tlearn: 0.3020987\ttotal: 13.1s\tremaining: 24.2s\n",
            "352:\tlearn: 0.3020511\ttotal: 13.2s\tremaining: 24.2s\n",
            "353:\tlearn: 0.3020135\ttotal: 13.3s\tremaining: 24.2s\n",
            "354:\tlearn: 0.3019694\ttotal: 13.4s\tremaining: 24.3s\n",
            "355:\tlearn: 0.3019209\ttotal: 13.4s\tremaining: 24.3s\n",
            "356:\tlearn: 0.3018812\ttotal: 13.5s\tremaining: 24.3s\n",
            "357:\tlearn: 0.3018299\ttotal: 13.5s\tremaining: 24.3s\n",
            "358:\tlearn: 0.3017850\ttotal: 13.6s\tremaining: 24.3s\n",
            "359:\tlearn: 0.3017435\ttotal: 13.7s\tremaining: 24.3s\n",
            "360:\tlearn: 0.3017068\ttotal: 13.7s\tremaining: 24.3s\n",
            "361:\tlearn: 0.3016704\ttotal: 13.8s\tremaining: 24.3s\n",
            "362:\tlearn: 0.3016211\ttotal: 13.9s\tremaining: 24.4s\n",
            "363:\tlearn: 0.3015713\ttotal: 13.9s\tremaining: 24.4s\n",
            "364:\tlearn: 0.3015226\ttotal: 14s\tremaining: 24.4s\n",
            "365:\tlearn: 0.3014909\ttotal: 14.1s\tremaining: 24.4s\n",
            "366:\tlearn: 0.3014509\ttotal: 14.1s\tremaining: 24.4s\n",
            "367:\tlearn: 0.3014164\ttotal: 14.2s\tremaining: 24.4s\n",
            "368:\tlearn: 0.3013689\ttotal: 14.3s\tremaining: 24.4s\n",
            "369:\tlearn: 0.3013325\ttotal: 14.3s\tremaining: 24.4s\n",
            "370:\tlearn: 0.3012897\ttotal: 14.4s\tremaining: 24.5s\n",
            "371:\tlearn: 0.3012545\ttotal: 14.5s\tremaining: 24.5s\n",
            "372:\tlearn: 0.3012081\ttotal: 14.6s\tremaining: 24.5s\n",
            "373:\tlearn: 0.3011752\ttotal: 14.6s\tremaining: 24.5s\n",
            "374:\tlearn: 0.3011313\ttotal: 14.7s\tremaining: 24.4s\n",
            "375:\tlearn: 0.3010999\ttotal: 14.7s\tremaining: 24.4s\n",
            "376:\tlearn: 0.3010320\ttotal: 14.7s\tremaining: 24.3s\n",
            "377:\tlearn: 0.3009874\ttotal: 14.8s\tremaining: 24.3s\n",
            "378:\tlearn: 0.3009378\ttotal: 14.8s\tremaining: 24.2s\n",
            "379:\tlearn: 0.3008828\ttotal: 14.8s\tremaining: 24.2s\n",
            "380:\tlearn: 0.3008625\ttotal: 14.8s\tremaining: 24.1s\n",
            "381:\tlearn: 0.3008139\ttotal: 14.9s\tremaining: 24.1s\n",
            "382:\tlearn: 0.3007737\ttotal: 14.9s\tremaining: 24s\n",
            "383:\tlearn: 0.3007236\ttotal: 14.9s\tremaining: 24s\n",
            "384:\tlearn: 0.3006812\ttotal: 15s\tremaining: 23.9s\n",
            "385:\tlearn: 0.3006457\ttotal: 15s\tremaining: 23.9s\n",
            "386:\tlearn: 0.3006166\ttotal: 15s\tremaining: 23.8s\n",
            "387:\tlearn: 0.3005786\ttotal: 15.1s\tremaining: 23.8s\n",
            "388:\tlearn: 0.3005358\ttotal: 15.1s\tremaining: 23.7s\n",
            "389:\tlearn: 0.3004993\ttotal: 15.1s\tremaining: 23.7s\n",
            "390:\tlearn: 0.3004693\ttotal: 15.2s\tremaining: 23.6s\n",
            "391:\tlearn: 0.3004259\ttotal: 15.2s\tremaining: 23.6s\n",
            "392:\tlearn: 0.3003794\ttotal: 15.2s\tremaining: 23.5s\n",
            "393:\tlearn: 0.3003283\ttotal: 15.3s\tremaining: 23.5s\n",
            "394:\tlearn: 0.3002924\ttotal: 15.3s\tremaining: 23.4s\n",
            "395:\tlearn: 0.3002497\ttotal: 15.3s\tremaining: 23.4s\n",
            "396:\tlearn: 0.3002013\ttotal: 15.4s\tremaining: 23.3s\n",
            "397:\tlearn: 0.3001527\ttotal: 15.4s\tremaining: 23.3s\n",
            "398:\tlearn: 0.3001170\ttotal: 15.4s\tremaining: 23.2s\n",
            "399:\tlearn: 0.3000767\ttotal: 15.5s\tremaining: 23.2s\n",
            "400:\tlearn: 0.3000395\ttotal: 15.5s\tremaining: 23.1s\n",
            "401:\tlearn: 0.2999973\ttotal: 15.5s\tremaining: 23.1s\n",
            "402:\tlearn: 0.2999435\ttotal: 15.6s\tremaining: 23s\n",
            "403:\tlearn: 0.2999047\ttotal: 15.6s\tremaining: 23s\n",
            "404:\tlearn: 0.2998624\ttotal: 15.6s\tremaining: 22.9s\n",
            "405:\tlearn: 0.2998291\ttotal: 15.6s\tremaining: 22.9s\n",
            "406:\tlearn: 0.2997745\ttotal: 15.7s\tremaining: 22.8s\n",
            "407:\tlearn: 0.2997360\ttotal: 15.7s\tremaining: 22.8s\n",
            "408:\tlearn: 0.2996832\ttotal: 15.7s\tremaining: 22.7s\n",
            "409:\tlearn: 0.2996496\ttotal: 15.8s\tremaining: 22.7s\n",
            "410:\tlearn: 0.2996067\ttotal: 15.8s\tremaining: 22.7s\n",
            "411:\tlearn: 0.2995667\ttotal: 15.8s\tremaining: 22.6s\n",
            "412:\tlearn: 0.2995193\ttotal: 15.9s\tremaining: 22.6s\n",
            "413:\tlearn: 0.2994660\ttotal: 15.9s\tremaining: 22.5s\n",
            "414:\tlearn: 0.2994200\ttotal: 15.9s\tremaining: 22.5s\n",
            "415:\tlearn: 0.2993825\ttotal: 16s\tremaining: 22.4s\n",
            "416:\tlearn: 0.2993398\ttotal: 16s\tremaining: 22.4s\n",
            "417:\tlearn: 0.2992969\ttotal: 16s\tremaining: 22.3s\n",
            "418:\tlearn: 0.2992507\ttotal: 16.1s\tremaining: 22.3s\n",
            "419:\tlearn: 0.2992070\ttotal: 16.1s\tremaining: 22.2s\n",
            "420:\tlearn: 0.2991845\ttotal: 16.1s\tremaining: 22.2s\n",
            "421:\tlearn: 0.2991644\ttotal: 16.1s\tremaining: 22.1s\n",
            "422:\tlearn: 0.2991078\ttotal: 16.2s\tremaining: 22.1s\n",
            "423:\tlearn: 0.2990766\ttotal: 16.2s\tremaining: 22s\n",
            "424:\tlearn: 0.2990392\ttotal: 16.2s\tremaining: 22s\n",
            "425:\tlearn: 0.2989801\ttotal: 16.3s\tremaining: 21.9s\n",
            "426:\tlearn: 0.2989427\ttotal: 16.3s\tremaining: 21.9s\n",
            "427:\tlearn: 0.2988841\ttotal: 16.3s\tremaining: 21.8s\n",
            "428:\tlearn: 0.2988403\ttotal: 16.4s\tremaining: 21.8s\n",
            "429:\tlearn: 0.2987849\ttotal: 16.4s\tremaining: 21.7s\n",
            "430:\tlearn: 0.2987427\ttotal: 16.4s\tremaining: 21.7s\n",
            "431:\tlearn: 0.2987039\ttotal: 16.5s\tremaining: 21.7s\n",
            "432:\tlearn: 0.2986567\ttotal: 16.5s\tremaining: 21.6s\n",
            "433:\tlearn: 0.2986200\ttotal: 16.5s\tremaining: 21.6s\n",
            "434:\tlearn: 0.2985782\ttotal: 16.6s\tremaining: 21.5s\n",
            "435:\tlearn: 0.2985446\ttotal: 16.6s\tremaining: 21.5s\n",
            "436:\tlearn: 0.2984991\ttotal: 16.6s\tremaining: 21.4s\n",
            "437:\tlearn: 0.2984539\ttotal: 16.7s\tremaining: 21.4s\n",
            "438:\tlearn: 0.2984031\ttotal: 16.7s\tremaining: 21.3s\n",
            "439:\tlearn: 0.2983708\ttotal: 16.7s\tremaining: 21.3s\n",
            "440:\tlearn: 0.2983247\ttotal: 16.8s\tremaining: 21.2s\n",
            "441:\tlearn: 0.2982845\ttotal: 16.8s\tremaining: 21.2s\n",
            "442:\tlearn: 0.2982487\ttotal: 16.8s\tremaining: 21.1s\n",
            "443:\tlearn: 0.2982012\ttotal: 16.9s\tremaining: 21.1s\n",
            "444:\tlearn: 0.2981703\ttotal: 16.9s\tremaining: 21.1s\n",
            "445:\tlearn: 0.2981307\ttotal: 16.9s\tremaining: 21s\n",
            "446:\tlearn: 0.2980940\ttotal: 17s\tremaining: 21s\n",
            "447:\tlearn: 0.2980397\ttotal: 17s\tremaining: 20.9s\n",
            "448:\tlearn: 0.2979927\ttotal: 17s\tremaining: 20.9s\n",
            "449:\tlearn: 0.2979567\ttotal: 17.1s\tremaining: 20.8s\n",
            "450:\tlearn: 0.2979231\ttotal: 17.1s\tremaining: 20.8s\n",
            "451:\tlearn: 0.2978921\ttotal: 17.1s\tremaining: 20.8s\n",
            "452:\tlearn: 0.2978544\ttotal: 17.1s\tremaining: 20.7s\n",
            "453:\tlearn: 0.2978237\ttotal: 17.2s\tremaining: 20.7s\n",
            "454:\tlearn: 0.2977763\ttotal: 17.2s\tremaining: 20.6s\n",
            "455:\tlearn: 0.2977363\ttotal: 17.2s\tremaining: 20.6s\n",
            "456:\tlearn: 0.2976962\ttotal: 17.3s\tremaining: 20.5s\n",
            "457:\tlearn: 0.2976554\ttotal: 17.3s\tremaining: 20.5s\n",
            "458:\tlearn: 0.2976295\ttotal: 17.4s\tremaining: 20.5s\n",
            "459:\tlearn: 0.2975907\ttotal: 17.4s\tremaining: 20.4s\n",
            "460:\tlearn: 0.2975583\ttotal: 17.4s\tremaining: 20.4s\n",
            "461:\tlearn: 0.2975045\ttotal: 17.4s\tremaining: 20.3s\n",
            "462:\tlearn: 0.2974732\ttotal: 17.5s\tremaining: 20.3s\n",
            "463:\tlearn: 0.2974337\ttotal: 17.5s\tremaining: 20.2s\n",
            "464:\tlearn: 0.2973859\ttotal: 17.5s\tremaining: 20.2s\n",
            "465:\tlearn: 0.2973434\ttotal: 17.6s\tremaining: 20.1s\n",
            "466:\tlearn: 0.2973050\ttotal: 17.6s\tremaining: 20.1s\n",
            "467:\tlearn: 0.2972862\ttotal: 17.6s\tremaining: 20s\n",
            "468:\tlearn: 0.2972491\ttotal: 17.7s\tremaining: 20s\n",
            "469:\tlearn: 0.2972132\ttotal: 17.7s\tremaining: 20s\n",
            "470:\tlearn: 0.2971811\ttotal: 17.7s\tremaining: 19.9s\n",
            "471:\tlearn: 0.2971420\ttotal: 17.8s\tremaining: 19.9s\n",
            "472:\tlearn: 0.2971074\ttotal: 17.8s\tremaining: 19.8s\n",
            "473:\tlearn: 0.2970674\ttotal: 17.8s\tremaining: 19.8s\n",
            "474:\tlearn: 0.2970428\ttotal: 17.9s\tremaining: 19.7s\n",
            "475:\tlearn: 0.2970138\ttotal: 17.9s\tremaining: 19.7s\n",
            "476:\tlearn: 0.2969814\ttotal: 17.9s\tremaining: 19.6s\n",
            "477:\tlearn: 0.2969446\ttotal: 17.9s\tremaining: 19.6s\n",
            "478:\tlearn: 0.2969006\ttotal: 18s\tremaining: 19.6s\n",
            "479:\tlearn: 0.2968529\ttotal: 18s\tremaining: 19.5s\n",
            "480:\tlearn: 0.2968147\ttotal: 18s\tremaining: 19.5s\n",
            "481:\tlearn: 0.2967758\ttotal: 18.1s\tremaining: 19.4s\n",
            "482:\tlearn: 0.2967433\ttotal: 18.1s\tremaining: 19.4s\n",
            "483:\tlearn: 0.2967030\ttotal: 18.1s\tremaining: 19.3s\n",
            "484:\tlearn: 0.2966651\ttotal: 18.2s\tremaining: 19.3s\n",
            "485:\tlearn: 0.2966335\ttotal: 18.2s\tremaining: 19.2s\n",
            "486:\tlearn: 0.2965980\ttotal: 18.2s\tremaining: 19.2s\n",
            "487:\tlearn: 0.2965604\ttotal: 18.3s\tremaining: 19.2s\n",
            "488:\tlearn: 0.2965223\ttotal: 18.3s\tremaining: 19.1s\n",
            "489:\tlearn: 0.2964880\ttotal: 18.3s\tremaining: 19.1s\n",
            "490:\tlearn: 0.2964576\ttotal: 18.4s\tremaining: 19s\n",
            "491:\tlearn: 0.2964274\ttotal: 18.4s\tremaining: 19s\n",
            "492:\tlearn: 0.2963935\ttotal: 18.4s\tremaining: 19s\n",
            "493:\tlearn: 0.2963513\ttotal: 18.5s\tremaining: 18.9s\n",
            "494:\tlearn: 0.2963187\ttotal: 18.5s\tremaining: 18.9s\n",
            "495:\tlearn: 0.2962828\ttotal: 18.5s\tremaining: 18.8s\n",
            "496:\tlearn: 0.2962401\ttotal: 18.6s\tremaining: 18.8s\n",
            "497:\tlearn: 0.2961959\ttotal: 18.6s\tremaining: 18.7s\n",
            "498:\tlearn: 0.2961555\ttotal: 18.6s\tremaining: 18.7s\n",
            "499:\tlearn: 0.2961212\ttotal: 18.7s\tremaining: 18.7s\n",
            "500:\tlearn: 0.2960844\ttotal: 18.7s\tremaining: 18.6s\n",
            "501:\tlearn: 0.2960435\ttotal: 18.7s\tremaining: 18.6s\n",
            "502:\tlearn: 0.2959983\ttotal: 18.7s\tremaining: 18.5s\n",
            "503:\tlearn: 0.2959676\ttotal: 18.8s\tremaining: 18.5s\n",
            "504:\tlearn: 0.2959324\ttotal: 18.8s\tremaining: 18.4s\n",
            "505:\tlearn: 0.2958906\ttotal: 18.8s\tremaining: 18.4s\n",
            "506:\tlearn: 0.2958439\ttotal: 18.9s\tremaining: 18.4s\n",
            "507:\tlearn: 0.2958150\ttotal: 18.9s\tremaining: 18.3s\n",
            "508:\tlearn: 0.2957900\ttotal: 18.9s\tremaining: 18.3s\n",
            "509:\tlearn: 0.2957379\ttotal: 19s\tremaining: 18.2s\n",
            "510:\tlearn: 0.2957040\ttotal: 19s\tremaining: 18.2s\n",
            "511:\tlearn: 0.2956631\ttotal: 19s\tremaining: 18.1s\n",
            "512:\tlearn: 0.2956259\ttotal: 19.1s\tremaining: 18.1s\n",
            "513:\tlearn: 0.2955831\ttotal: 19.1s\tremaining: 18.1s\n",
            "514:\tlearn: 0.2955353\ttotal: 19.1s\tremaining: 18s\n",
            "515:\tlearn: 0.2955117\ttotal: 19.2s\tremaining: 18s\n",
            "516:\tlearn: 0.2954849\ttotal: 19.2s\tremaining: 17.9s\n",
            "517:\tlearn: 0.2954565\ttotal: 19.2s\tremaining: 17.9s\n",
            "518:\tlearn: 0.2954102\ttotal: 19.2s\tremaining: 17.8s\n",
            "519:\tlearn: 0.2953710\ttotal: 19.3s\tremaining: 17.8s\n",
            "520:\tlearn: 0.2953316\ttotal: 19.3s\tremaining: 17.8s\n",
            "521:\tlearn: 0.2952897\ttotal: 19.4s\tremaining: 17.7s\n",
            "522:\tlearn: 0.2952578\ttotal: 19.4s\tremaining: 17.7s\n",
            "523:\tlearn: 0.2952334\ttotal: 19.4s\tremaining: 17.7s\n",
            "524:\tlearn: 0.2951981\ttotal: 19.5s\tremaining: 17.6s\n",
            "525:\tlearn: 0.2951547\ttotal: 19.5s\tremaining: 17.6s\n",
            "526:\tlearn: 0.2951280\ttotal: 19.5s\tremaining: 17.5s\n",
            "527:\tlearn: 0.2950890\ttotal: 19.6s\tremaining: 17.5s\n",
            "528:\tlearn: 0.2950489\ttotal: 19.6s\tremaining: 17.4s\n",
            "529:\tlearn: 0.2950025\ttotal: 19.6s\tremaining: 17.4s\n",
            "530:\tlearn: 0.2949593\ttotal: 19.7s\tremaining: 17.4s\n",
            "531:\tlearn: 0.2949222\ttotal: 19.7s\tremaining: 17.3s\n",
            "532:\tlearn: 0.2948848\ttotal: 19.7s\tremaining: 17.3s\n",
            "533:\tlearn: 0.2948440\ttotal: 19.8s\tremaining: 17.2s\n",
            "534:\tlearn: 0.2947931\ttotal: 19.8s\tremaining: 17.2s\n",
            "535:\tlearn: 0.2947499\ttotal: 19.8s\tremaining: 17.2s\n",
            "536:\tlearn: 0.2947203\ttotal: 19.8s\tremaining: 17.1s\n",
            "537:\tlearn: 0.2946917\ttotal: 19.9s\tremaining: 17.1s\n",
            "538:\tlearn: 0.2946644\ttotal: 19.9s\tremaining: 17s\n",
            "539:\tlearn: 0.2946299\ttotal: 19.9s\tremaining: 17s\n",
            "540:\tlearn: 0.2945918\ttotal: 20s\tremaining: 17s\n",
            "541:\tlearn: 0.2945554\ttotal: 20s\tremaining: 16.9s\n",
            "542:\tlearn: 0.2945277\ttotal: 20.1s\tremaining: 16.9s\n",
            "543:\tlearn: 0.2944860\ttotal: 20.1s\tremaining: 16.8s\n",
            "544:\tlearn: 0.2944537\ttotal: 20.1s\tremaining: 16.8s\n",
            "545:\tlearn: 0.2944204\ttotal: 20.1s\tremaining: 16.7s\n",
            "546:\tlearn: 0.2943844\ttotal: 20.2s\tremaining: 16.7s\n",
            "547:\tlearn: 0.2943528\ttotal: 20.2s\tremaining: 16.7s\n",
            "548:\tlearn: 0.2943143\ttotal: 20.2s\tremaining: 16.6s\n",
            "549:\tlearn: 0.2942890\ttotal: 20.3s\tremaining: 16.6s\n",
            "550:\tlearn: 0.2942529\ttotal: 20.3s\tremaining: 16.5s\n",
            "551:\tlearn: 0.2942204\ttotal: 20.3s\tremaining: 16.5s\n",
            "552:\tlearn: 0.2941737\ttotal: 20.4s\tremaining: 16.5s\n",
            "553:\tlearn: 0.2941338\ttotal: 20.4s\tremaining: 16.4s\n",
            "554:\tlearn: 0.2941037\ttotal: 20.4s\tremaining: 16.4s\n",
            "555:\tlearn: 0.2940811\ttotal: 20.5s\tremaining: 16.4s\n",
            "556:\tlearn: 0.2940574\ttotal: 20.5s\tremaining: 16.3s\n",
            "557:\tlearn: 0.2940231\ttotal: 20.5s\tremaining: 16.3s\n",
            "558:\tlearn: 0.2939893\ttotal: 20.6s\tremaining: 16.2s\n",
            "559:\tlearn: 0.2939622\ttotal: 20.6s\tremaining: 16.2s\n",
            "560:\tlearn: 0.2939370\ttotal: 20.6s\tremaining: 16.1s\n",
            "561:\tlearn: 0.2938907\ttotal: 20.7s\tremaining: 16.1s\n",
            "562:\tlearn: 0.2938421\ttotal: 20.7s\tremaining: 16.1s\n",
            "563:\tlearn: 0.2938160\ttotal: 20.7s\tremaining: 16s\n",
            "564:\tlearn: 0.2937774\ttotal: 20.7s\tremaining: 16s\n",
            "565:\tlearn: 0.2937494\ttotal: 20.8s\tremaining: 15.9s\n",
            "566:\tlearn: 0.2937107\ttotal: 20.8s\tremaining: 15.9s\n",
            "567:\tlearn: 0.2936745\ttotal: 20.8s\tremaining: 15.9s\n",
            "568:\tlearn: 0.2936478\ttotal: 20.9s\tremaining: 15.8s\n",
            "569:\tlearn: 0.2936128\ttotal: 20.9s\tremaining: 15.8s\n",
            "570:\tlearn: 0.2935898\ttotal: 20.9s\tremaining: 15.7s\n",
            "571:\tlearn: 0.2935508\ttotal: 21s\tremaining: 15.7s\n",
            "572:\tlearn: 0.2935223\ttotal: 21s\tremaining: 15.6s\n",
            "573:\tlearn: 0.2934908\ttotal: 21s\tremaining: 15.6s\n",
            "574:\tlearn: 0.2934610\ttotal: 21.1s\tremaining: 15.6s\n",
            "575:\tlearn: 0.2934138\ttotal: 21.1s\tremaining: 15.5s\n",
            "576:\tlearn: 0.2933859\ttotal: 21.1s\tremaining: 15.5s\n",
            "577:\tlearn: 0.2933565\ttotal: 21.1s\tremaining: 15.4s\n",
            "578:\tlearn: 0.2933153\ttotal: 21.2s\tremaining: 15.4s\n",
            "579:\tlearn: 0.2932764\ttotal: 21.2s\tremaining: 15.4s\n",
            "580:\tlearn: 0.2932448\ttotal: 21.2s\tremaining: 15.3s\n",
            "581:\tlearn: 0.2932163\ttotal: 21.3s\tremaining: 15.3s\n",
            "582:\tlearn: 0.2931759\ttotal: 21.3s\tremaining: 15.2s\n",
            "583:\tlearn: 0.2931311\ttotal: 21.3s\tremaining: 15.2s\n",
            "584:\tlearn: 0.2930843\ttotal: 21.4s\tremaining: 15.2s\n",
            "585:\tlearn: 0.2930531\ttotal: 21.4s\tremaining: 15.1s\n",
            "586:\tlearn: 0.2930207\ttotal: 21.4s\tremaining: 15.1s\n",
            "587:\tlearn: 0.2929786\ttotal: 21.5s\tremaining: 15s\n",
            "588:\tlearn: 0.2929384\ttotal: 21.5s\tremaining: 15s\n",
            "589:\tlearn: 0.2929076\ttotal: 21.5s\tremaining: 15s\n",
            "590:\tlearn: 0.2928763\ttotal: 21.6s\tremaining: 14.9s\n",
            "591:\tlearn: 0.2928444\ttotal: 21.6s\tremaining: 14.9s\n",
            "592:\tlearn: 0.2927994\ttotal: 21.6s\tremaining: 14.8s\n",
            "593:\tlearn: 0.2927612\ttotal: 21.7s\tremaining: 14.8s\n",
            "594:\tlearn: 0.2927269\ttotal: 21.7s\tremaining: 14.8s\n",
            "595:\tlearn: 0.2926974\ttotal: 21.7s\tremaining: 14.7s\n",
            "596:\tlearn: 0.2926663\ttotal: 21.8s\tremaining: 14.7s\n",
            "597:\tlearn: 0.2926353\ttotal: 21.8s\tremaining: 14.7s\n",
            "598:\tlearn: 0.2925975\ttotal: 21.8s\tremaining: 14.6s\n",
            "599:\tlearn: 0.2925551\ttotal: 21.9s\tremaining: 14.6s\n",
            "600:\tlearn: 0.2925208\ttotal: 21.9s\tremaining: 14.5s\n",
            "601:\tlearn: 0.2924738\ttotal: 21.9s\tremaining: 14.5s\n",
            "602:\tlearn: 0.2924436\ttotal: 22s\tremaining: 14.5s\n",
            "603:\tlearn: 0.2924080\ttotal: 22s\tremaining: 14.4s\n",
            "604:\tlearn: 0.2923797\ttotal: 22s\tremaining: 14.4s\n",
            "605:\tlearn: 0.2923365\ttotal: 22s\tremaining: 14.3s\n",
            "606:\tlearn: 0.2922967\ttotal: 22.1s\tremaining: 14.3s\n",
            "607:\tlearn: 0.2922686\ttotal: 22.1s\tremaining: 14.3s\n",
            "608:\tlearn: 0.2922391\ttotal: 22.1s\tremaining: 14.2s\n",
            "609:\tlearn: 0.2922131\ttotal: 22.2s\tremaining: 14.2s\n",
            "610:\tlearn: 0.2921836\ttotal: 22.2s\tremaining: 14.1s\n",
            "611:\tlearn: 0.2921497\ttotal: 22.2s\tremaining: 14.1s\n",
            "612:\tlearn: 0.2921095\ttotal: 22.3s\tremaining: 14.1s\n",
            "613:\tlearn: 0.2920704\ttotal: 22.3s\tremaining: 14s\n",
            "614:\tlearn: 0.2920360\ttotal: 22.3s\tremaining: 14s\n",
            "615:\tlearn: 0.2920022\ttotal: 22.4s\tremaining: 13.9s\n",
            "616:\tlearn: 0.2919651\ttotal: 22.4s\tremaining: 13.9s\n",
            "617:\tlearn: 0.2919283\ttotal: 22.4s\tremaining: 13.9s\n",
            "618:\tlearn: 0.2918828\ttotal: 22.5s\tremaining: 13.8s\n",
            "619:\tlearn: 0.2918386\ttotal: 22.5s\tremaining: 13.8s\n",
            "620:\tlearn: 0.2918115\ttotal: 22.5s\tremaining: 13.7s\n",
            "621:\tlearn: 0.2917686\ttotal: 22.6s\tremaining: 13.7s\n",
            "622:\tlearn: 0.2917363\ttotal: 22.6s\tremaining: 13.7s\n",
            "623:\tlearn: 0.2917055\ttotal: 22.6s\tremaining: 13.6s\n",
            "624:\tlearn: 0.2916729\ttotal: 22.7s\tremaining: 13.6s\n",
            "625:\tlearn: 0.2916123\ttotal: 22.7s\tremaining: 13.6s\n",
            "626:\tlearn: 0.2915723\ttotal: 22.7s\tremaining: 13.5s\n",
            "627:\tlearn: 0.2915381\ttotal: 22.7s\tremaining: 13.5s\n",
            "628:\tlearn: 0.2914965\ttotal: 22.8s\tremaining: 13.4s\n",
            "629:\tlearn: 0.2914639\ttotal: 22.8s\tremaining: 13.4s\n",
            "630:\tlearn: 0.2914259\ttotal: 22.8s\tremaining: 13.4s\n",
            "631:\tlearn: 0.2913927\ttotal: 22.9s\tremaining: 13.3s\n",
            "632:\tlearn: 0.2913706\ttotal: 22.9s\tremaining: 13.3s\n",
            "633:\tlearn: 0.2913320\ttotal: 22.9s\tremaining: 13.2s\n",
            "634:\tlearn: 0.2913072\ttotal: 23s\tremaining: 13.2s\n",
            "635:\tlearn: 0.2912703\ttotal: 23s\tremaining: 13.2s\n",
            "636:\tlearn: 0.2912478\ttotal: 23s\tremaining: 13.1s\n",
            "637:\tlearn: 0.2912180\ttotal: 23.1s\tremaining: 13.1s\n",
            "638:\tlearn: 0.2911810\ttotal: 23.1s\tremaining: 13s\n",
            "639:\tlearn: 0.2911514\ttotal: 23.1s\tremaining: 13s\n",
            "640:\tlearn: 0.2911253\ttotal: 23.1s\tremaining: 13s\n",
            "641:\tlearn: 0.2910936\ttotal: 23.2s\tremaining: 12.9s\n",
            "642:\tlearn: 0.2910597\ttotal: 23.2s\tremaining: 12.9s\n",
            "643:\tlearn: 0.2910281\ttotal: 23.3s\tremaining: 12.9s\n",
            "644:\tlearn: 0.2909919\ttotal: 23.3s\tremaining: 12.8s\n",
            "645:\tlearn: 0.2909762\ttotal: 23.3s\tremaining: 12.8s\n",
            "646:\tlearn: 0.2909454\ttotal: 23.3s\tremaining: 12.7s\n",
            "647:\tlearn: 0.2909050\ttotal: 23.4s\tremaining: 12.7s\n",
            "648:\tlearn: 0.2908819\ttotal: 23.4s\tremaining: 12.7s\n",
            "649:\tlearn: 0.2908454\ttotal: 23.4s\tremaining: 12.6s\n",
            "650:\tlearn: 0.2908072\ttotal: 23.5s\tremaining: 12.6s\n",
            "651:\tlearn: 0.2907684\ttotal: 23.5s\tremaining: 12.6s\n",
            "652:\tlearn: 0.2907493\ttotal: 23.5s\tremaining: 12.5s\n",
            "653:\tlearn: 0.2907197\ttotal: 23.6s\tremaining: 12.5s\n",
            "654:\tlearn: 0.2906913\ttotal: 23.6s\tremaining: 12.4s\n",
            "655:\tlearn: 0.2906665\ttotal: 23.6s\tremaining: 12.4s\n",
            "656:\tlearn: 0.2906328\ttotal: 23.7s\tremaining: 12.3s\n",
            "657:\tlearn: 0.2905993\ttotal: 23.7s\tremaining: 12.3s\n",
            "658:\tlearn: 0.2905768\ttotal: 23.7s\tremaining: 12.3s\n",
            "659:\tlearn: 0.2905436\ttotal: 23.8s\tremaining: 12.2s\n",
            "660:\tlearn: 0.2905150\ttotal: 23.8s\tremaining: 12.2s\n",
            "661:\tlearn: 0.2904866\ttotal: 23.8s\tremaining: 12.2s\n",
            "662:\tlearn: 0.2904545\ttotal: 23.8s\tremaining: 12.1s\n",
            "663:\tlearn: 0.2904232\ttotal: 23.9s\tremaining: 12.1s\n",
            "664:\tlearn: 0.2903821\ttotal: 23.9s\tremaining: 12s\n",
            "665:\tlearn: 0.2903464\ttotal: 23.9s\tremaining: 12s\n",
            "666:\tlearn: 0.2903073\ttotal: 24s\tremaining: 12s\n",
            "667:\tlearn: 0.2902750\ttotal: 24s\tremaining: 11.9s\n",
            "668:\tlearn: 0.2902416\ttotal: 24s\tremaining: 11.9s\n",
            "669:\tlearn: 0.2902077\ttotal: 24.1s\tremaining: 11.8s\n",
            "670:\tlearn: 0.2901868\ttotal: 24.1s\tremaining: 11.8s\n",
            "671:\tlearn: 0.2901536\ttotal: 24.1s\tremaining: 11.8s\n",
            "672:\tlearn: 0.2901228\ttotal: 24.2s\tremaining: 11.7s\n",
            "673:\tlearn: 0.2900826\ttotal: 24.2s\tremaining: 11.7s\n",
            "674:\tlearn: 0.2900491\ttotal: 24.2s\tremaining: 11.7s\n",
            "675:\tlearn: 0.2900205\ttotal: 24.2s\tremaining: 11.6s\n",
            "676:\tlearn: 0.2899846\ttotal: 24.3s\tremaining: 11.6s\n",
            "677:\tlearn: 0.2899598\ttotal: 24.3s\tremaining: 11.5s\n",
            "678:\tlearn: 0.2899274\ttotal: 24.3s\tremaining: 11.5s\n",
            "679:\tlearn: 0.2898858\ttotal: 24.4s\tremaining: 11.5s\n",
            "680:\tlearn: 0.2898622\ttotal: 24.4s\tremaining: 11.4s\n",
            "681:\tlearn: 0.2898325\ttotal: 24.4s\tremaining: 11.4s\n",
            "682:\tlearn: 0.2898026\ttotal: 24.5s\tremaining: 11.4s\n",
            "683:\tlearn: 0.2897684\ttotal: 24.5s\tremaining: 11.3s\n",
            "684:\tlearn: 0.2897415\ttotal: 24.6s\tremaining: 11.3s\n",
            "685:\tlearn: 0.2897095\ttotal: 24.7s\tremaining: 11.3s\n",
            "686:\tlearn: 0.2896651\ttotal: 24.7s\tremaining: 11.3s\n",
            "687:\tlearn: 0.2896365\ttotal: 24.8s\tremaining: 11.2s\n",
            "688:\tlearn: 0.2895951\ttotal: 24.8s\tremaining: 11.2s\n",
            "689:\tlearn: 0.2895716\ttotal: 24.9s\tremaining: 11.2s\n",
            "690:\tlearn: 0.2895485\ttotal: 25s\tremaining: 11.2s\n",
            "691:\tlearn: 0.2895290\ttotal: 25s\tremaining: 11.1s\n",
            "692:\tlearn: 0.2894817\ttotal: 25.1s\tremaining: 11.1s\n",
            "693:\tlearn: 0.2894524\ttotal: 25.1s\tremaining: 11.1s\n",
            "694:\tlearn: 0.2894150\ttotal: 25.2s\tremaining: 11s\n",
            "695:\tlearn: 0.2893862\ttotal: 25.2s\tremaining: 11s\n",
            "696:\tlearn: 0.2893477\ttotal: 25.3s\tremaining: 11s\n",
            "697:\tlearn: 0.2893263\ttotal: 25.4s\tremaining: 11s\n",
            "698:\tlearn: 0.2892945\ttotal: 25.5s\tremaining: 11s\n",
            "699:\tlearn: 0.2892516\ttotal: 25.5s\tremaining: 10.9s\n",
            "700:\tlearn: 0.2892183\ttotal: 25.6s\tremaining: 10.9s\n",
            "701:\tlearn: 0.2891909\ttotal: 25.7s\tremaining: 10.9s\n",
            "702:\tlearn: 0.2891737\ttotal: 25.7s\tremaining: 10.9s\n",
            "703:\tlearn: 0.2891496\ttotal: 25.8s\tremaining: 10.9s\n",
            "704:\tlearn: 0.2891090\ttotal: 25.9s\tremaining: 10.8s\n",
            "705:\tlearn: 0.2890774\ttotal: 26s\tremaining: 10.8s\n",
            "706:\tlearn: 0.2890375\ttotal: 26s\tremaining: 10.8s\n",
            "707:\tlearn: 0.2889915\ttotal: 26.1s\tremaining: 10.8s\n",
            "708:\tlearn: 0.2889577\ttotal: 26.2s\tremaining: 10.7s\n",
            "709:\tlearn: 0.2889242\ttotal: 26.2s\tremaining: 10.7s\n",
            "710:\tlearn: 0.2888910\ttotal: 26.3s\tremaining: 10.7s\n",
            "711:\tlearn: 0.2888386\ttotal: 26.4s\tremaining: 10.7s\n",
            "712:\tlearn: 0.2888177\ttotal: 26.5s\tremaining: 10.7s\n",
            "713:\tlearn: 0.2887792\ttotal: 26.6s\tremaining: 10.6s\n",
            "714:\tlearn: 0.2887477\ttotal: 26.6s\tremaining: 10.6s\n",
            "715:\tlearn: 0.2887153\ttotal: 26.7s\tremaining: 10.6s\n",
            "716:\tlearn: 0.2886926\ttotal: 26.8s\tremaining: 10.6s\n",
            "717:\tlearn: 0.2886618\ttotal: 26.9s\tremaining: 10.5s\n",
            "718:\tlearn: 0.2886394\ttotal: 26.9s\tremaining: 10.5s\n",
            "719:\tlearn: 0.2886013\ttotal: 27s\tremaining: 10.5s\n",
            "720:\tlearn: 0.2885578\ttotal: 27.1s\tremaining: 10.5s\n",
            "721:\tlearn: 0.2885342\ttotal: 27.1s\tremaining: 10.4s\n",
            "722:\tlearn: 0.2884974\ttotal: 27.1s\tremaining: 10.4s\n",
            "723:\tlearn: 0.2884549\ttotal: 27.1s\tremaining: 10.3s\n",
            "724:\tlearn: 0.2884099\ttotal: 27.2s\tremaining: 10.3s\n",
            "725:\tlearn: 0.2883831\ttotal: 27.2s\tremaining: 10.3s\n",
            "726:\tlearn: 0.2883444\ttotal: 27.2s\tremaining: 10.2s\n",
            "727:\tlearn: 0.2883023\ttotal: 27.3s\tremaining: 10.2s\n",
            "728:\tlearn: 0.2882750\ttotal: 27.3s\tremaining: 10.1s\n",
            "729:\tlearn: 0.2882457\ttotal: 27.3s\tremaining: 10.1s\n",
            "730:\tlearn: 0.2882091\ttotal: 27.4s\tremaining: 10.1s\n",
            "731:\tlearn: 0.2881694\ttotal: 27.4s\tremaining: 10s\n",
            "732:\tlearn: 0.2881394\ttotal: 27.4s\tremaining: 9.99s\n",
            "733:\tlearn: 0.2881146\ttotal: 27.5s\tremaining: 9.95s\n",
            "734:\tlearn: 0.2880901\ttotal: 27.5s\tremaining: 9.92s\n",
            "735:\tlearn: 0.2880578\ttotal: 27.5s\tremaining: 9.88s\n",
            "736:\tlearn: 0.2880429\ttotal: 27.6s\tremaining: 9.84s\n",
            "737:\tlearn: 0.2880152\ttotal: 27.6s\tremaining: 9.8s\n",
            "738:\tlearn: 0.2879870\ttotal: 27.6s\tremaining: 9.76s\n",
            "739:\tlearn: 0.2879604\ttotal: 27.7s\tremaining: 9.72s\n",
            "740:\tlearn: 0.2879263\ttotal: 27.7s\tremaining: 9.68s\n",
            "741:\tlearn: 0.2878922\ttotal: 27.7s\tremaining: 9.64s\n",
            "742:\tlearn: 0.2878637\ttotal: 27.8s\tremaining: 9.6s\n",
            "743:\tlearn: 0.2878266\ttotal: 27.8s\tremaining: 9.56s\n",
            "744:\tlearn: 0.2877892\ttotal: 27.8s\tremaining: 9.52s\n",
            "745:\tlearn: 0.2877565\ttotal: 27.8s\tremaining: 9.48s\n",
            "746:\tlearn: 0.2877288\ttotal: 27.9s\tremaining: 9.45s\n",
            "747:\tlearn: 0.2877006\ttotal: 27.9s\tremaining: 9.41s\n",
            "748:\tlearn: 0.2876590\ttotal: 28s\tremaining: 9.37s\n",
            "749:\tlearn: 0.2876297\ttotal: 28s\tremaining: 9.33s\n",
            "750:\tlearn: 0.2875972\ttotal: 28s\tremaining: 9.29s\n",
            "751:\tlearn: 0.2875756\ttotal: 28s\tremaining: 9.25s\n",
            "752:\tlearn: 0.2875287\ttotal: 28.1s\tremaining: 9.21s\n",
            "753:\tlearn: 0.2874986\ttotal: 28.1s\tremaining: 9.17s\n",
            "754:\tlearn: 0.2874624\ttotal: 28.1s\tremaining: 9.13s\n",
            "755:\tlearn: 0.2874377\ttotal: 28.2s\tremaining: 9.09s\n",
            "756:\tlearn: 0.2874149\ttotal: 28.2s\tremaining: 9.05s\n",
            "757:\tlearn: 0.2873891\ttotal: 28.2s\tremaining: 9.01s\n",
            "758:\tlearn: 0.2873572\ttotal: 28.3s\tremaining: 8.97s\n",
            "759:\tlearn: 0.2873230\ttotal: 28.3s\tremaining: 8.93s\n",
            "760:\tlearn: 0.2872899\ttotal: 28.3s\tremaining: 8.9s\n",
            "761:\tlearn: 0.2872720\ttotal: 28.4s\tremaining: 8.86s\n",
            "762:\tlearn: 0.2872316\ttotal: 28.4s\tremaining: 8.82s\n",
            "763:\tlearn: 0.2871939\ttotal: 28.4s\tremaining: 8.78s\n",
            "764:\tlearn: 0.2871707\ttotal: 28.4s\tremaining: 8.74s\n",
            "765:\tlearn: 0.2871577\ttotal: 28.5s\tremaining: 8.7s\n",
            "766:\tlearn: 0.2871193\ttotal: 28.5s\tremaining: 8.66s\n",
            "767:\tlearn: 0.2870759\ttotal: 28.6s\tremaining: 8.63s\n",
            "768:\tlearn: 0.2870518\ttotal: 28.6s\tremaining: 8.59s\n",
            "769:\tlearn: 0.2870197\ttotal: 28.6s\tremaining: 8.55s\n",
            "770:\tlearn: 0.2869866\ttotal: 28.6s\tremaining: 8.51s\n",
            "771:\tlearn: 0.2869465\ttotal: 28.7s\tremaining: 8.47s\n",
            "772:\tlearn: 0.2869146\ttotal: 28.7s\tremaining: 8.43s\n",
            "773:\tlearn: 0.2868754\ttotal: 28.7s\tremaining: 8.39s\n",
            "774:\tlearn: 0.2868351\ttotal: 28.8s\tremaining: 8.36s\n",
            "775:\tlearn: 0.2868030\ttotal: 28.8s\tremaining: 8.32s\n",
            "776:\tlearn: 0.2867746\ttotal: 28.8s\tremaining: 8.28s\n",
            "777:\tlearn: 0.2867353\ttotal: 28.9s\tremaining: 8.24s\n",
            "778:\tlearn: 0.2866986\ttotal: 28.9s\tremaining: 8.2s\n",
            "779:\tlearn: 0.2866650\ttotal: 28.9s\tremaining: 8.16s\n",
            "780:\tlearn: 0.2866239\ttotal: 29s\tremaining: 8.12s\n",
            "781:\tlearn: 0.2866051\ttotal: 29s\tremaining: 8.09s\n",
            "782:\tlearn: 0.2865769\ttotal: 29s\tremaining: 8.05s\n",
            "783:\tlearn: 0.2865417\ttotal: 29.1s\tremaining: 8.01s\n",
            "784:\tlearn: 0.2865060\ttotal: 29.1s\tremaining: 7.97s\n",
            "785:\tlearn: 0.2864623\ttotal: 29.1s\tremaining: 7.93s\n",
            "786:\tlearn: 0.2864411\ttotal: 29.2s\tremaining: 7.89s\n",
            "787:\tlearn: 0.2864192\ttotal: 29.2s\tremaining: 7.85s\n",
            "788:\tlearn: 0.2863898\ttotal: 29.2s\tremaining: 7.82s\n",
            "789:\tlearn: 0.2863611\ttotal: 29.3s\tremaining: 7.78s\n",
            "790:\tlearn: 0.2863361\ttotal: 29.3s\tremaining: 7.74s\n",
            "791:\tlearn: 0.2863013\ttotal: 29.3s\tremaining: 7.7s\n",
            "792:\tlearn: 0.2862668\ttotal: 29.3s\tremaining: 7.66s\n",
            "793:\tlearn: 0.2862450\ttotal: 29.4s\tremaining: 7.62s\n",
            "794:\tlearn: 0.2862117\ttotal: 29.4s\tremaining: 7.58s\n",
            "795:\tlearn: 0.2861837\ttotal: 29.5s\tremaining: 7.55s\n",
            "796:\tlearn: 0.2861551\ttotal: 29.5s\tremaining: 7.51s\n",
            "797:\tlearn: 0.2861348\ttotal: 29.5s\tremaining: 7.47s\n",
            "798:\tlearn: 0.2861058\ttotal: 29.6s\tremaining: 7.43s\n",
            "799:\tlearn: 0.2860682\ttotal: 29.6s\tremaining: 7.4s\n",
            "800:\tlearn: 0.2860363\ttotal: 29.6s\tremaining: 7.36s\n",
            "801:\tlearn: 0.2860011\ttotal: 29.6s\tremaining: 7.32s\n",
            "802:\tlearn: 0.2859661\ttotal: 29.7s\tremaining: 7.28s\n",
            "803:\tlearn: 0.2859250\ttotal: 29.7s\tremaining: 7.24s\n",
            "804:\tlearn: 0.2859003\ttotal: 29.7s\tremaining: 7.21s\n",
            "805:\tlearn: 0.2858695\ttotal: 29.8s\tremaining: 7.17s\n",
            "806:\tlearn: 0.2858454\ttotal: 29.8s\tremaining: 7.13s\n",
            "807:\tlearn: 0.2858140\ttotal: 29.8s\tremaining: 7.09s\n",
            "808:\tlearn: 0.2857745\ttotal: 29.9s\tremaining: 7.05s\n",
            "809:\tlearn: 0.2857464\ttotal: 29.9s\tremaining: 7.01s\n",
            "810:\tlearn: 0.2857142\ttotal: 29.9s\tremaining: 6.98s\n",
            "811:\tlearn: 0.2856921\ttotal: 30s\tremaining: 6.94s\n",
            "812:\tlearn: 0.2856640\ttotal: 30s\tremaining: 6.9s\n",
            "813:\tlearn: 0.2856333\ttotal: 30s\tremaining: 6.86s\n",
            "814:\tlearn: 0.2856083\ttotal: 30.1s\tremaining: 6.82s\n",
            "815:\tlearn: 0.2855756\ttotal: 30.1s\tremaining: 6.79s\n",
            "816:\tlearn: 0.2855394\ttotal: 30.1s\tremaining: 6.75s\n",
            "817:\tlearn: 0.2855189\ttotal: 30.2s\tremaining: 6.71s\n",
            "818:\tlearn: 0.2854886\ttotal: 30.2s\tremaining: 6.67s\n",
            "819:\tlearn: 0.2854557\ttotal: 30.2s\tremaining: 6.63s\n",
            "820:\tlearn: 0.2854273\ttotal: 30.2s\tremaining: 6.59s\n",
            "821:\tlearn: 0.2853890\ttotal: 30.3s\tremaining: 6.56s\n",
            "822:\tlearn: 0.2853592\ttotal: 30.3s\tremaining: 6.52s\n",
            "823:\tlearn: 0.2853340\ttotal: 30.3s\tremaining: 6.48s\n",
            "824:\tlearn: 0.2853050\ttotal: 30.4s\tremaining: 6.44s\n",
            "825:\tlearn: 0.2852805\ttotal: 30.4s\tremaining: 6.4s\n",
            "826:\tlearn: 0.2852565\ttotal: 30.4s\tremaining: 6.37s\n",
            "827:\tlearn: 0.2852257\ttotal: 30.5s\tremaining: 6.33s\n",
            "828:\tlearn: 0.2851976\ttotal: 30.5s\tremaining: 6.29s\n",
            "829:\tlearn: 0.2851710\ttotal: 30.5s\tremaining: 6.25s\n",
            "830:\tlearn: 0.2851278\ttotal: 30.6s\tremaining: 6.22s\n",
            "831:\tlearn: 0.2851045\ttotal: 30.6s\tremaining: 6.18s\n",
            "832:\tlearn: 0.2850835\ttotal: 30.6s\tremaining: 6.14s\n",
            "833:\tlearn: 0.2850560\ttotal: 30.7s\tremaining: 6.1s\n",
            "834:\tlearn: 0.2850207\ttotal: 30.7s\tremaining: 6.06s\n",
            "835:\tlearn: 0.2849865\ttotal: 30.7s\tremaining: 6.03s\n",
            "836:\tlearn: 0.2849640\ttotal: 30.7s\tremaining: 5.99s\n",
            "837:\tlearn: 0.2849298\ttotal: 30.8s\tremaining: 5.95s\n",
            "838:\tlearn: 0.2848872\ttotal: 30.8s\tremaining: 5.91s\n",
            "839:\tlearn: 0.2848581\ttotal: 30.9s\tremaining: 5.88s\n",
            "840:\tlearn: 0.2848191\ttotal: 30.9s\tremaining: 5.84s\n",
            "841:\tlearn: 0.2847946\ttotal: 30.9s\tremaining: 5.8s\n",
            "842:\tlearn: 0.2847711\ttotal: 30.9s\tremaining: 5.76s\n",
            "843:\tlearn: 0.2847402\ttotal: 31s\tremaining: 5.72s\n",
            "844:\tlearn: 0.2847168\ttotal: 31s\tremaining: 5.69s\n",
            "845:\tlearn: 0.2846868\ttotal: 31s\tremaining: 5.65s\n",
            "846:\tlearn: 0.2846567\ttotal: 31.1s\tremaining: 5.61s\n",
            "847:\tlearn: 0.2846214\ttotal: 31.1s\tremaining: 5.57s\n",
            "848:\tlearn: 0.2846000\ttotal: 31.1s\tremaining: 5.54s\n",
            "849:\tlearn: 0.2845633\ttotal: 31.2s\tremaining: 5.5s\n",
            "850:\tlearn: 0.2845236\ttotal: 31.2s\tremaining: 5.46s\n",
            "851:\tlearn: 0.2844985\ttotal: 31.2s\tremaining: 5.42s\n",
            "852:\tlearn: 0.2844694\ttotal: 31.3s\tremaining: 5.39s\n",
            "853:\tlearn: 0.2844361\ttotal: 31.3s\tremaining: 5.35s\n",
            "854:\tlearn: 0.2844056\ttotal: 31.3s\tremaining: 5.31s\n",
            "855:\tlearn: 0.2843800\ttotal: 31.3s\tremaining: 5.27s\n",
            "856:\tlearn: 0.2843523\ttotal: 31.4s\tremaining: 5.23s\n",
            "857:\tlearn: 0.2843279\ttotal: 31.4s\tremaining: 5.2s\n",
            "858:\tlearn: 0.2843094\ttotal: 31.4s\tremaining: 5.16s\n",
            "859:\tlearn: 0.2842797\ttotal: 31.5s\tremaining: 5.12s\n",
            "860:\tlearn: 0.2842587\ttotal: 31.5s\tremaining: 5.09s\n",
            "861:\tlearn: 0.2842320\ttotal: 31.5s\tremaining: 5.05s\n",
            "862:\tlearn: 0.2842040\ttotal: 31.6s\tremaining: 5.01s\n",
            "863:\tlearn: 0.2841661\ttotal: 31.6s\tremaining: 4.98s\n",
            "864:\tlearn: 0.2841456\ttotal: 31.6s\tremaining: 4.94s\n",
            "865:\tlearn: 0.2841159\ttotal: 31.7s\tremaining: 4.9s\n",
            "866:\tlearn: 0.2840894\ttotal: 31.7s\tremaining: 4.86s\n",
            "867:\tlearn: 0.2840582\ttotal: 31.7s\tremaining: 4.83s\n",
            "868:\tlearn: 0.2840238\ttotal: 31.8s\tremaining: 4.79s\n",
            "869:\tlearn: 0.2839891\ttotal: 31.8s\tremaining: 4.75s\n",
            "870:\tlearn: 0.2839606\ttotal: 31.8s\tremaining: 4.71s\n",
            "871:\tlearn: 0.2839234\ttotal: 31.9s\tremaining: 4.68s\n",
            "872:\tlearn: 0.2838888\ttotal: 31.9s\tremaining: 4.64s\n",
            "873:\tlearn: 0.2838498\ttotal: 31.9s\tremaining: 4.6s\n",
            "874:\tlearn: 0.2838167\ttotal: 32s\tremaining: 4.57s\n",
            "875:\tlearn: 0.2837862\ttotal: 32s\tremaining: 4.53s\n",
            "876:\tlearn: 0.2837474\ttotal: 32s\tremaining: 4.49s\n",
            "877:\tlearn: 0.2837158\ttotal: 32s\tremaining: 4.45s\n",
            "878:\tlearn: 0.2836713\ttotal: 32.1s\tremaining: 4.42s\n",
            "879:\tlearn: 0.2836331\ttotal: 32.1s\tremaining: 4.38s\n",
            "880:\tlearn: 0.2836044\ttotal: 32.2s\tremaining: 4.34s\n",
            "881:\tlearn: 0.2835645\ttotal: 32.2s\tremaining: 4.31s\n",
            "882:\tlearn: 0.2835339\ttotal: 32.2s\tremaining: 4.27s\n",
            "883:\tlearn: 0.2834952\ttotal: 32.2s\tremaining: 4.23s\n",
            "884:\tlearn: 0.2834657\ttotal: 32.3s\tremaining: 4.19s\n",
            "885:\tlearn: 0.2834428\ttotal: 32.3s\tremaining: 4.16s\n",
            "886:\tlearn: 0.2834049\ttotal: 32.3s\tremaining: 4.12s\n",
            "887:\tlearn: 0.2833727\ttotal: 32.4s\tremaining: 4.08s\n",
            "888:\tlearn: 0.2833537\ttotal: 32.4s\tremaining: 4.04s\n",
            "889:\tlearn: 0.2833199\ttotal: 32.4s\tremaining: 4.01s\n",
            "890:\tlearn: 0.2832958\ttotal: 32.5s\tremaining: 3.97s\n",
            "891:\tlearn: 0.2832609\ttotal: 32.5s\tremaining: 3.93s\n",
            "892:\tlearn: 0.2832299\ttotal: 32.5s\tremaining: 3.9s\n",
            "893:\tlearn: 0.2832002\ttotal: 32.6s\tremaining: 3.86s\n",
            "894:\tlearn: 0.2831701\ttotal: 32.6s\tremaining: 3.83s\n",
            "895:\tlearn: 0.2831332\ttotal: 32.6s\tremaining: 3.79s\n",
            "896:\tlearn: 0.2831190\ttotal: 32.7s\tremaining: 3.75s\n",
            "897:\tlearn: 0.2830884\ttotal: 32.7s\tremaining: 3.71s\n",
            "898:\tlearn: 0.2830461\ttotal: 32.7s\tremaining: 3.68s\n",
            "899:\tlearn: 0.2830253\ttotal: 32.8s\tremaining: 3.64s\n",
            "900:\tlearn: 0.2829896\ttotal: 32.8s\tremaining: 3.6s\n",
            "901:\tlearn: 0.2829536\ttotal: 32.8s\tremaining: 3.57s\n",
            "902:\tlearn: 0.2829300\ttotal: 32.9s\tremaining: 3.53s\n",
            "903:\tlearn: 0.2828989\ttotal: 32.9s\tremaining: 3.49s\n",
            "904:\tlearn: 0.2828601\ttotal: 32.9s\tremaining: 3.46s\n",
            "905:\tlearn: 0.2828465\ttotal: 33s\tremaining: 3.42s\n",
            "906:\tlearn: 0.2828022\ttotal: 33s\tremaining: 3.38s\n",
            "907:\tlearn: 0.2827713\ttotal: 33s\tremaining: 3.35s\n",
            "908:\tlearn: 0.2827321\ttotal: 33.1s\tremaining: 3.31s\n",
            "909:\tlearn: 0.2826920\ttotal: 33.1s\tremaining: 3.27s\n",
            "910:\tlearn: 0.2826613\ttotal: 33.1s\tremaining: 3.23s\n",
            "911:\tlearn: 0.2826291\ttotal: 33.1s\tremaining: 3.2s\n",
            "912:\tlearn: 0.2825911\ttotal: 33.2s\tremaining: 3.16s\n",
            "913:\tlearn: 0.2825735\ttotal: 33.2s\tremaining: 3.12s\n",
            "914:\tlearn: 0.2825432\ttotal: 33.2s\tremaining: 3.09s\n",
            "915:\tlearn: 0.2824991\ttotal: 33.3s\tremaining: 3.05s\n",
            "916:\tlearn: 0.2824738\ttotal: 33.3s\tremaining: 3.01s\n",
            "917:\tlearn: 0.2824401\ttotal: 33.3s\tremaining: 2.98s\n",
            "918:\tlearn: 0.2824073\ttotal: 33.4s\tremaining: 2.94s\n",
            "919:\tlearn: 0.2823882\ttotal: 33.4s\tremaining: 2.9s\n",
            "920:\tlearn: 0.2823703\ttotal: 33.4s\tremaining: 2.87s\n",
            "921:\tlearn: 0.2823365\ttotal: 33.5s\tremaining: 2.83s\n",
            "922:\tlearn: 0.2822995\ttotal: 33.5s\tremaining: 2.79s\n",
            "923:\tlearn: 0.2822773\ttotal: 33.5s\tremaining: 2.76s\n",
            "924:\tlearn: 0.2822586\ttotal: 33.5s\tremaining: 2.72s\n",
            "925:\tlearn: 0.2822388\ttotal: 33.6s\tremaining: 2.68s\n",
            "926:\tlearn: 0.2822077\ttotal: 33.6s\tremaining: 2.65s\n",
            "927:\tlearn: 0.2821713\ttotal: 33.6s\tremaining: 2.61s\n",
            "928:\tlearn: 0.2821277\ttotal: 33.7s\tremaining: 2.57s\n",
            "929:\tlearn: 0.2820894\ttotal: 33.7s\tremaining: 2.54s\n",
            "930:\tlearn: 0.2820545\ttotal: 33.7s\tremaining: 2.5s\n",
            "931:\tlearn: 0.2820203\ttotal: 33.8s\tremaining: 2.46s\n",
            "932:\tlearn: 0.2820012\ttotal: 33.8s\tremaining: 2.43s\n",
            "933:\tlearn: 0.2819685\ttotal: 33.8s\tremaining: 2.39s\n",
            "934:\tlearn: 0.2819423\ttotal: 33.9s\tremaining: 2.35s\n",
            "935:\tlearn: 0.2819097\ttotal: 33.9s\tremaining: 2.32s\n",
            "936:\tlearn: 0.2818852\ttotal: 33.9s\tremaining: 2.28s\n",
            "937:\tlearn: 0.2818574\ttotal: 34s\tremaining: 2.24s\n",
            "938:\tlearn: 0.2818361\ttotal: 34s\tremaining: 2.21s\n",
            "939:\tlearn: 0.2818063\ttotal: 34s\tremaining: 2.17s\n",
            "940:\tlearn: 0.2817829\ttotal: 34.1s\tremaining: 2.13s\n",
            "941:\tlearn: 0.2817455\ttotal: 34.1s\tremaining: 2.1s\n",
            "942:\tlearn: 0.2817133\ttotal: 34.1s\tremaining: 2.06s\n",
            "943:\tlearn: 0.2816781\ttotal: 34.2s\tremaining: 2.03s\n",
            "944:\tlearn: 0.2816689\ttotal: 34.2s\tremaining: 1.99s\n",
            "945:\tlearn: 0.2816388\ttotal: 34.2s\tremaining: 1.95s\n",
            "946:\tlearn: 0.2816053\ttotal: 34.2s\tremaining: 1.92s\n",
            "947:\tlearn: 0.2815661\ttotal: 34.3s\tremaining: 1.88s\n",
            "948:\tlearn: 0.2815359\ttotal: 34.3s\tremaining: 1.84s\n",
            "949:\tlearn: 0.2814959\ttotal: 34.3s\tremaining: 1.81s\n",
            "950:\tlearn: 0.2814655\ttotal: 34.4s\tremaining: 1.77s\n",
            "951:\tlearn: 0.2814319\ttotal: 34.4s\tremaining: 1.73s\n",
            "952:\tlearn: 0.2814032\ttotal: 34.4s\tremaining: 1.7s\n",
            "953:\tlearn: 0.2813776\ttotal: 34.5s\tremaining: 1.66s\n",
            "954:\tlearn: 0.2813521\ttotal: 34.5s\tremaining: 1.63s\n",
            "955:\tlearn: 0.2813220\ttotal: 34.5s\tremaining: 1.59s\n",
            "956:\tlearn: 0.2812978\ttotal: 34.6s\tremaining: 1.55s\n",
            "957:\tlearn: 0.2812672\ttotal: 34.6s\tremaining: 1.52s\n",
            "958:\tlearn: 0.2812469\ttotal: 34.6s\tremaining: 1.48s\n",
            "959:\tlearn: 0.2812160\ttotal: 34.7s\tremaining: 1.44s\n",
            "960:\tlearn: 0.2811818\ttotal: 34.7s\tremaining: 1.41s\n",
            "961:\tlearn: 0.2811469\ttotal: 34.7s\tremaining: 1.37s\n",
            "962:\tlearn: 0.2811137\ttotal: 34.8s\tremaining: 1.33s\n",
            "963:\tlearn: 0.2810827\ttotal: 34.8s\tremaining: 1.3s\n",
            "964:\tlearn: 0.2810470\ttotal: 34.8s\tremaining: 1.26s\n",
            "965:\tlearn: 0.2810178\ttotal: 34.9s\tremaining: 1.23s\n",
            "966:\tlearn: 0.2809933\ttotal: 34.9s\tremaining: 1.19s\n",
            "967:\tlearn: 0.2809683\ttotal: 34.9s\tremaining: 1.15s\n",
            "968:\tlearn: 0.2809353\ttotal: 34.9s\tremaining: 1.12s\n",
            "969:\tlearn: 0.2808920\ttotal: 35s\tremaining: 1.08s\n",
            "970:\tlearn: 0.2808606\ttotal: 35s\tremaining: 1.04s\n",
            "971:\tlearn: 0.2808327\ttotal: 35s\tremaining: 1.01s\n",
            "972:\tlearn: 0.2808002\ttotal: 35.1s\tremaining: 973ms\n",
            "973:\tlearn: 0.2807733\ttotal: 35.1s\tremaining: 937ms\n",
            "974:\tlearn: 0.2807478\ttotal: 35.1s\tremaining: 901ms\n",
            "975:\tlearn: 0.2807201\ttotal: 35.2s\tremaining: 865ms\n",
            "976:\tlearn: 0.2806964\ttotal: 35.2s\tremaining: 829ms\n",
            "977:\tlearn: 0.2806683\ttotal: 35.2s\tremaining: 793ms\n",
            "978:\tlearn: 0.2806308\ttotal: 35.3s\tremaining: 757ms\n",
            "979:\tlearn: 0.2806011\ttotal: 35.3s\tremaining: 720ms\n",
            "980:\tlearn: 0.2805651\ttotal: 35.3s\tremaining: 684ms\n",
            "981:\tlearn: 0.2805249\ttotal: 35.4s\tremaining: 648ms\n",
            "982:\tlearn: 0.2804916\ttotal: 35.4s\tremaining: 612ms\n",
            "983:\tlearn: 0.2804587\ttotal: 35.4s\tremaining: 576ms\n",
            "984:\tlearn: 0.2804350\ttotal: 35.5s\tremaining: 540ms\n",
            "985:\tlearn: 0.2804073\ttotal: 35.5s\tremaining: 504ms\n",
            "986:\tlearn: 0.2803843\ttotal: 35.5s\tremaining: 468ms\n",
            "987:\tlearn: 0.2803632\ttotal: 35.5s\tremaining: 432ms\n",
            "988:\tlearn: 0.2803384\ttotal: 35.6s\tremaining: 396ms\n",
            "989:\tlearn: 0.2803090\ttotal: 35.6s\tremaining: 360ms\n",
            "990:\tlearn: 0.2802794\ttotal: 35.7s\tremaining: 324ms\n",
            "991:\tlearn: 0.2802558\ttotal: 35.7s\tremaining: 288ms\n",
            "992:\tlearn: 0.2802341\ttotal: 35.7s\tremaining: 252ms\n",
            "993:\tlearn: 0.2802090\ttotal: 35.7s\tremaining: 216ms\n",
            "994:\tlearn: 0.2801916\ttotal: 35.8s\tremaining: 180ms\n",
            "995:\tlearn: 0.2801639\ttotal: 35.8s\tremaining: 144ms\n",
            "996:\tlearn: 0.2801256\ttotal: 35.8s\tremaining: 108ms\n",
            "997:\tlearn: 0.2801041\ttotal: 35.9s\tremaining: 71.9ms\n",
            "998:\tlearn: 0.2800840\ttotal: 35.9s\tremaining: 35.9ms\n",
            "999:\tlearn: 0.2800574\ttotal: 35.9s\tremaining: 0us\n",
            "14 : 0.8789425061500364\n",
            "Learning rate set to 0.079235\n",
            "0:\tlearn: 0.6203386\ttotal: 28.3ms\tremaining: 28.2s\n",
            "1:\tlearn: 0.5648560\ttotal: 71.7ms\tremaining: 35.8s\n",
            "2:\tlearn: 0.5209861\ttotal: 102ms\tremaining: 33.9s\n",
            "3:\tlearn: 0.4871357\ttotal: 134ms\tremaining: 33.4s\n",
            "4:\tlearn: 0.4576021\ttotal: 165ms\tremaining: 32.8s\n",
            "5:\tlearn: 0.4332257\ttotal: 209ms\tremaining: 34.6s\n",
            "6:\tlearn: 0.4150794\ttotal: 245ms\tremaining: 34.8s\n",
            "7:\tlearn: 0.4000486\ttotal: 276ms\tremaining: 34.2s\n",
            "8:\tlearn: 0.3886226\ttotal: 308ms\tremaining: 33.9s\n",
            "9:\tlearn: 0.3789285\ttotal: 358ms\tremaining: 35.5s\n",
            "10:\tlearn: 0.3704026\ttotal: 406ms\tremaining: 36.5s\n",
            "11:\tlearn: 0.3635033\ttotal: 474ms\tremaining: 39s\n",
            "12:\tlearn: 0.3576114\ttotal: 520ms\tremaining: 39.5s\n",
            "13:\tlearn: 0.3526233\ttotal: 564ms\tremaining: 39.7s\n",
            "14:\tlearn: 0.3482612\ttotal: 604ms\tremaining: 39.7s\n",
            "15:\tlearn: 0.3448699\ttotal: 654ms\tremaining: 40.2s\n",
            "16:\tlearn: 0.3418973\ttotal: 751ms\tremaining: 43.4s\n",
            "17:\tlearn: 0.3390886\ttotal: 824ms\tremaining: 45s\n",
            "18:\tlearn: 0.3368317\ttotal: 905ms\tremaining: 46.7s\n",
            "19:\tlearn: 0.3343588\ttotal: 998ms\tremaining: 48.9s\n",
            "20:\tlearn: 0.3327065\ttotal: 1.08s\tremaining: 50.4s\n",
            "21:\tlearn: 0.3309615\ttotal: 1.16s\tremaining: 51.6s\n",
            "22:\tlearn: 0.3296383\ttotal: 1.24s\tremaining: 52.7s\n",
            "23:\tlearn: 0.3283688\ttotal: 1.3s\tremaining: 53s\n",
            "24:\tlearn: 0.3275781\ttotal: 1.37s\tremaining: 53.6s\n",
            "25:\tlearn: 0.3264281\ttotal: 1.45s\tremaining: 54.3s\n",
            "26:\tlearn: 0.3257763\ttotal: 1.52s\tremaining: 54.8s\n",
            "27:\tlearn: 0.3248774\ttotal: 1.59s\tremaining: 55.4s\n",
            "28:\tlearn: 0.3239385\ttotal: 1.68s\tremaining: 56.3s\n",
            "29:\tlearn: 0.3233293\ttotal: 1.75s\tremaining: 56.7s\n",
            "30:\tlearn: 0.3225090\ttotal: 1.81s\tremaining: 56.7s\n",
            "31:\tlearn: 0.3217270\ttotal: 1.89s\tremaining: 57.3s\n",
            "32:\tlearn: 0.3209729\ttotal: 1.96s\tremaining: 57.3s\n",
            "33:\tlearn: 0.3204499\ttotal: 2.03s\tremaining: 57.8s\n",
            "34:\tlearn: 0.3200584\ttotal: 2.09s\tremaining: 57.6s\n",
            "35:\tlearn: 0.3196842\ttotal: 2.17s\tremaining: 58.1s\n",
            "36:\tlearn: 0.3191485\ttotal: 2.24s\tremaining: 58.3s\n",
            "37:\tlearn: 0.3186606\ttotal: 2.32s\tremaining: 58.8s\n",
            "38:\tlearn: 0.3183852\ttotal: 2.41s\tremaining: 59.5s\n",
            "39:\tlearn: 0.3181419\ttotal: 2.49s\tremaining: 59.7s\n",
            "40:\tlearn: 0.3178077\ttotal: 2.57s\tremaining: 1m\n",
            "41:\tlearn: 0.3175136\ttotal: 2.65s\tremaining: 1m\n",
            "42:\tlearn: 0.3172175\ttotal: 2.74s\tremaining: 1m\n",
            "43:\tlearn: 0.3169266\ttotal: 2.81s\tremaining: 1m\n",
            "44:\tlearn: 0.3166690\ttotal: 2.87s\tremaining: 1m\n",
            "45:\tlearn: 0.3164280\ttotal: 2.9s\tremaining: 1m\n",
            "46:\tlearn: 0.3161680\ttotal: 2.94s\tremaining: 59.6s\n",
            "47:\tlearn: 0.3159131\ttotal: 2.97s\tremaining: 58.9s\n",
            "48:\tlearn: 0.3156994\ttotal: 3s\tremaining: 58.2s\n",
            "49:\tlearn: 0.3155517\ttotal: 3.03s\tremaining: 57.6s\n",
            "50:\tlearn: 0.3153011\ttotal: 3.06s\tremaining: 57s\n",
            "51:\tlearn: 0.3151458\ttotal: 3.1s\tremaining: 56.6s\n",
            "52:\tlearn: 0.3149619\ttotal: 3.14s\tremaining: 56s\n",
            "53:\tlearn: 0.3148147\ttotal: 3.18s\tremaining: 55.8s\n",
            "54:\tlearn: 0.3146247\ttotal: 3.21s\tremaining: 55.2s\n",
            "55:\tlearn: 0.3144423\ttotal: 3.25s\tremaining: 54.7s\n",
            "56:\tlearn: 0.3143095\ttotal: 3.28s\tremaining: 54.3s\n",
            "57:\tlearn: 0.3142022\ttotal: 3.32s\tremaining: 54s\n",
            "58:\tlearn: 0.3141076\ttotal: 3.35s\tremaining: 53.5s\n",
            "59:\tlearn: 0.3139516\ttotal: 3.39s\tremaining: 53.1s\n",
            "60:\tlearn: 0.3138203\ttotal: 3.42s\tremaining: 52.6s\n",
            "61:\tlearn: 0.3137124\ttotal: 3.45s\tremaining: 52.2s\n",
            "62:\tlearn: 0.3135841\ttotal: 3.48s\tremaining: 51.8s\n",
            "63:\tlearn: 0.3134728\ttotal: 3.51s\tremaining: 51.3s\n",
            "64:\tlearn: 0.3133639\ttotal: 3.55s\tremaining: 51.1s\n",
            "65:\tlearn: 0.3132523\ttotal: 3.58s\tremaining: 50.7s\n",
            "66:\tlearn: 0.3131309\ttotal: 3.61s\tremaining: 50.3s\n",
            "67:\tlearn: 0.3130294\ttotal: 3.64s\tremaining: 50s\n",
            "68:\tlearn: 0.3129250\ttotal: 3.67s\tremaining: 49.6s\n",
            "69:\tlearn: 0.3127927\ttotal: 3.71s\tremaining: 49.3s\n",
            "70:\tlearn: 0.3127046\ttotal: 3.74s\tremaining: 48.9s\n",
            "71:\tlearn: 0.3126108\ttotal: 3.78s\tremaining: 48.7s\n",
            "72:\tlearn: 0.3124673\ttotal: 3.81s\tremaining: 48.4s\n",
            "73:\tlearn: 0.3123670\ttotal: 3.84s\tremaining: 48.1s\n",
            "74:\tlearn: 0.3123030\ttotal: 3.88s\tremaining: 47.8s\n",
            "75:\tlearn: 0.3121672\ttotal: 3.91s\tremaining: 47.5s\n",
            "76:\tlearn: 0.3120808\ttotal: 3.94s\tremaining: 47.2s\n",
            "77:\tlearn: 0.3120085\ttotal: 3.97s\tremaining: 47s\n",
            "78:\tlearn: 0.3119057\ttotal: 4.01s\tremaining: 46.8s\n",
            "79:\tlearn: 0.3117934\ttotal: 4.04s\tremaining: 46.5s\n",
            "80:\tlearn: 0.3117045\ttotal: 4.08s\tremaining: 46.2s\n",
            "81:\tlearn: 0.3116179\ttotal: 4.11s\tremaining: 46s\n",
            "82:\tlearn: 0.3115529\ttotal: 4.15s\tremaining: 45.8s\n",
            "83:\tlearn: 0.3114660\ttotal: 4.2s\tremaining: 45.8s\n",
            "84:\tlearn: 0.3113948\ttotal: 4.24s\tremaining: 45.7s\n",
            "85:\tlearn: 0.3113165\ttotal: 4.27s\tremaining: 45.4s\n",
            "86:\tlearn: 0.3112513\ttotal: 4.3s\tremaining: 45.2s\n",
            "87:\tlearn: 0.3111598\ttotal: 4.34s\tremaining: 44.9s\n",
            "88:\tlearn: 0.3111085\ttotal: 4.37s\tremaining: 44.7s\n",
            "89:\tlearn: 0.3110446\ttotal: 4.4s\tremaining: 44.5s\n",
            "90:\tlearn: 0.3109763\ttotal: 4.43s\tremaining: 44.2s\n",
            "91:\tlearn: 0.3109289\ttotal: 4.47s\tremaining: 44.1s\n",
            "92:\tlearn: 0.3108703\ttotal: 4.5s\tremaining: 43.9s\n",
            "93:\tlearn: 0.3107940\ttotal: 4.53s\tremaining: 43.7s\n",
            "94:\tlearn: 0.3107253\ttotal: 4.56s\tremaining: 43.5s\n",
            "95:\tlearn: 0.3106381\ttotal: 4.59s\tremaining: 43.3s\n",
            "96:\tlearn: 0.3105670\ttotal: 4.62s\tremaining: 43s\n",
            "97:\tlearn: 0.3104754\ttotal: 4.65s\tremaining: 42.8s\n",
            "98:\tlearn: 0.3103967\ttotal: 4.7s\tremaining: 42.8s\n",
            "99:\tlearn: 0.3103342\ttotal: 4.73s\tremaining: 42.5s\n",
            "100:\tlearn: 0.3102461\ttotal: 4.76s\tremaining: 42.4s\n",
            "101:\tlearn: 0.3101719\ttotal: 4.79s\tremaining: 42.2s\n",
            "102:\tlearn: 0.3101282\ttotal: 4.82s\tremaining: 42s\n",
            "103:\tlearn: 0.3100096\ttotal: 4.86s\tremaining: 41.8s\n",
            "104:\tlearn: 0.3099511\ttotal: 4.88s\tremaining: 41.6s\n",
            "105:\tlearn: 0.3098679\ttotal: 4.93s\tremaining: 41.6s\n",
            "106:\tlearn: 0.3098075\ttotal: 4.96s\tremaining: 41.4s\n",
            "107:\tlearn: 0.3097546\ttotal: 4.99s\tremaining: 41.2s\n",
            "108:\tlearn: 0.3096854\ttotal: 5.02s\tremaining: 41s\n",
            "109:\tlearn: 0.3096277\ttotal: 5.05s\tremaining: 40.8s\n",
            "110:\tlearn: 0.3095669\ttotal: 5.08s\tremaining: 40.7s\n",
            "111:\tlearn: 0.3095014\ttotal: 5.11s\tremaining: 40.5s\n",
            "112:\tlearn: 0.3094235\ttotal: 5.15s\tremaining: 40.4s\n",
            "113:\tlearn: 0.3093576\ttotal: 5.21s\tremaining: 40.5s\n",
            "114:\tlearn: 0.3092989\ttotal: 5.24s\tremaining: 40.3s\n",
            "115:\tlearn: 0.3092047\ttotal: 5.27s\tremaining: 40.1s\n",
            "116:\tlearn: 0.3091404\ttotal: 5.29s\tremaining: 40s\n",
            "117:\tlearn: 0.3090791\ttotal: 5.32s\tremaining: 39.8s\n",
            "118:\tlearn: 0.3090139\ttotal: 5.36s\tremaining: 39.7s\n",
            "119:\tlearn: 0.3089770\ttotal: 5.39s\tremaining: 39.6s\n",
            "120:\tlearn: 0.3089129\ttotal: 5.42s\tremaining: 39.4s\n",
            "121:\tlearn: 0.3088663\ttotal: 5.46s\tremaining: 39.3s\n",
            "122:\tlearn: 0.3087985\ttotal: 5.49s\tremaining: 39.1s\n",
            "123:\tlearn: 0.3087385\ttotal: 5.52s\tremaining: 39s\n",
            "124:\tlearn: 0.3087055\ttotal: 5.55s\tremaining: 38.9s\n",
            "125:\tlearn: 0.3086558\ttotal: 5.59s\tremaining: 38.8s\n",
            "126:\tlearn: 0.3085920\ttotal: 5.63s\tremaining: 38.7s\n",
            "127:\tlearn: 0.3085495\ttotal: 5.66s\tremaining: 38.5s\n",
            "128:\tlearn: 0.3084879\ttotal: 5.69s\tremaining: 38.4s\n",
            "129:\tlearn: 0.3084478\ttotal: 5.72s\tremaining: 38.3s\n",
            "130:\tlearn: 0.3084039\ttotal: 5.75s\tremaining: 38.1s\n",
            "131:\tlearn: 0.3083426\ttotal: 5.78s\tremaining: 38s\n",
            "132:\tlearn: 0.3082910\ttotal: 5.82s\tremaining: 38s\n",
            "133:\tlearn: 0.3082369\ttotal: 5.85s\tremaining: 37.8s\n",
            "134:\tlearn: 0.3081638\ttotal: 5.89s\tremaining: 37.7s\n",
            "135:\tlearn: 0.3081188\ttotal: 5.92s\tremaining: 37.6s\n",
            "136:\tlearn: 0.3080412\ttotal: 5.95s\tremaining: 37.5s\n",
            "137:\tlearn: 0.3079682\ttotal: 5.98s\tremaining: 37.4s\n",
            "138:\tlearn: 0.3079059\ttotal: 6.01s\tremaining: 37.2s\n",
            "139:\tlearn: 0.3078287\ttotal: 6.05s\tremaining: 37.2s\n",
            "140:\tlearn: 0.3077666\ttotal: 6.08s\tremaining: 37.1s\n",
            "141:\tlearn: 0.3076990\ttotal: 6.11s\tremaining: 36.9s\n",
            "142:\tlearn: 0.3076487\ttotal: 6.14s\tremaining: 36.8s\n",
            "143:\tlearn: 0.3075847\ttotal: 6.18s\tremaining: 36.7s\n",
            "144:\tlearn: 0.3075209\ttotal: 6.23s\tremaining: 36.7s\n",
            "145:\tlearn: 0.3074617\ttotal: 6.26s\tremaining: 36.6s\n",
            "146:\tlearn: 0.3073742\ttotal: 6.3s\tremaining: 36.5s\n",
            "147:\tlearn: 0.3073239\ttotal: 6.33s\tremaining: 36.4s\n",
            "148:\tlearn: 0.3072728\ttotal: 6.36s\tremaining: 36.3s\n",
            "149:\tlearn: 0.3072210\ttotal: 6.39s\tremaining: 36.2s\n",
            "150:\tlearn: 0.3071478\ttotal: 6.42s\tremaining: 36.1s\n",
            "151:\tlearn: 0.3071094\ttotal: 6.45s\tremaining: 36s\n",
            "152:\tlearn: 0.3070326\ttotal: 6.5s\tremaining: 36s\n",
            "153:\tlearn: 0.3069849\ttotal: 6.53s\tremaining: 35.9s\n",
            "154:\tlearn: 0.3069100\ttotal: 6.56s\tremaining: 35.8s\n",
            "155:\tlearn: 0.3068363\ttotal: 6.59s\tremaining: 35.6s\n",
            "156:\tlearn: 0.3067935\ttotal: 6.62s\tremaining: 35.5s\n",
            "157:\tlearn: 0.3067336\ttotal: 6.65s\tremaining: 35.4s\n",
            "158:\tlearn: 0.3066694\ttotal: 6.68s\tremaining: 35.3s\n",
            "159:\tlearn: 0.3066099\ttotal: 6.72s\tremaining: 35.3s\n",
            "160:\tlearn: 0.3065631\ttotal: 6.75s\tremaining: 35.2s\n",
            "161:\tlearn: 0.3064873\ttotal: 6.78s\tremaining: 35.1s\n",
            "162:\tlearn: 0.3064260\ttotal: 6.81s\tremaining: 35s\n",
            "163:\tlearn: 0.3063642\ttotal: 6.84s\tremaining: 34.9s\n",
            "164:\tlearn: 0.3062830\ttotal: 6.87s\tremaining: 34.8s\n",
            "165:\tlearn: 0.3062156\ttotal: 6.9s\tremaining: 34.7s\n",
            "166:\tlearn: 0.3061618\ttotal: 6.95s\tremaining: 34.7s\n",
            "167:\tlearn: 0.3061043\ttotal: 6.98s\tremaining: 34.6s\n",
            "168:\tlearn: 0.3060523\ttotal: 7.01s\tremaining: 34.5s\n",
            "169:\tlearn: 0.3059993\ttotal: 7.04s\tremaining: 34.4s\n",
            "170:\tlearn: 0.3059483\ttotal: 7.07s\tremaining: 34.3s\n",
            "171:\tlearn: 0.3058809\ttotal: 7.1s\tremaining: 34.2s\n",
            "172:\tlearn: 0.3058244\ttotal: 7.13s\tremaining: 34.1s\n",
            "173:\tlearn: 0.3057588\ttotal: 7.17s\tremaining: 34.1s\n",
            "174:\tlearn: 0.3056882\ttotal: 7.22s\tremaining: 34s\n",
            "175:\tlearn: 0.3056099\ttotal: 7.25s\tremaining: 34s\n",
            "176:\tlearn: 0.3055396\ttotal: 7.28s\tremaining: 33.8s\n",
            "177:\tlearn: 0.3054861\ttotal: 7.31s\tremaining: 33.7s\n",
            "178:\tlearn: 0.3054334\ttotal: 7.34s\tremaining: 33.7s\n",
            "179:\tlearn: 0.3053705\ttotal: 7.37s\tremaining: 33.6s\n",
            "180:\tlearn: 0.3053051\ttotal: 7.41s\tremaining: 33.5s\n",
            "181:\tlearn: 0.3052256\ttotal: 7.44s\tremaining: 33.4s\n",
            "182:\tlearn: 0.3051738\ttotal: 7.47s\tremaining: 33.4s\n",
            "183:\tlearn: 0.3051257\ttotal: 7.5s\tremaining: 33.3s\n",
            "184:\tlearn: 0.3050512\ttotal: 7.53s\tremaining: 33.2s\n",
            "185:\tlearn: 0.3049773\ttotal: 7.56s\tremaining: 33.1s\n",
            "186:\tlearn: 0.3049178\ttotal: 7.59s\tremaining: 33s\n",
            "187:\tlearn: 0.3048441\ttotal: 7.63s\tremaining: 33s\n",
            "188:\tlearn: 0.3047789\ttotal: 7.66s\tremaining: 32.9s\n",
            "189:\tlearn: 0.3047117\ttotal: 7.69s\tremaining: 32.8s\n",
            "190:\tlearn: 0.3046561\ttotal: 7.72s\tremaining: 32.7s\n",
            "191:\tlearn: 0.3046069\ttotal: 7.75s\tremaining: 32.6s\n",
            "192:\tlearn: 0.3045514\ttotal: 7.78s\tremaining: 32.5s\n",
            "193:\tlearn: 0.3045017\ttotal: 7.81s\tremaining: 32.4s\n",
            "194:\tlearn: 0.3044411\ttotal: 7.85s\tremaining: 32.4s\n",
            "195:\tlearn: 0.3043765\ttotal: 7.88s\tremaining: 32.3s\n",
            "196:\tlearn: 0.3043264\ttotal: 7.91s\tremaining: 32.2s\n",
            "197:\tlearn: 0.3042709\ttotal: 7.94s\tremaining: 32.2s\n",
            "198:\tlearn: 0.3042090\ttotal: 7.97s\tremaining: 32.1s\n",
            "199:\tlearn: 0.3041484\ttotal: 8s\tremaining: 32s\n",
            "200:\tlearn: 0.3040751\ttotal: 8.03s\tremaining: 31.9s\n",
            "201:\tlearn: 0.3040188\ttotal: 8.07s\tremaining: 31.9s\n",
            "202:\tlearn: 0.3039483\ttotal: 8.1s\tremaining: 31.8s\n",
            "203:\tlearn: 0.3038865\ttotal: 8.13s\tremaining: 31.7s\n",
            "204:\tlearn: 0.3038265\ttotal: 8.17s\tremaining: 31.7s\n",
            "205:\tlearn: 0.3037839\ttotal: 8.2s\tremaining: 31.6s\n",
            "206:\tlearn: 0.3037257\ttotal: 8.24s\tremaining: 31.6s\n",
            "207:\tlearn: 0.3036646\ttotal: 8.27s\tremaining: 31.5s\n",
            "208:\tlearn: 0.3035898\ttotal: 8.31s\tremaining: 31.5s\n",
            "209:\tlearn: 0.3035222\ttotal: 8.34s\tremaining: 31.4s\n",
            "210:\tlearn: 0.3034755\ttotal: 8.37s\tremaining: 31.3s\n",
            "211:\tlearn: 0.3034182\ttotal: 8.4s\tremaining: 31.2s\n",
            "212:\tlearn: 0.3033673\ttotal: 8.43s\tremaining: 31.2s\n",
            "213:\tlearn: 0.3033271\ttotal: 8.46s\tremaining: 31.1s\n",
            "214:\tlearn: 0.3032675\ttotal: 8.49s\tremaining: 31s\n",
            "215:\tlearn: 0.3032317\ttotal: 8.53s\tremaining: 31s\n",
            "216:\tlearn: 0.3031736\ttotal: 8.56s\tremaining: 30.9s\n",
            "217:\tlearn: 0.3031181\ttotal: 8.6s\tremaining: 30.8s\n",
            "218:\tlearn: 0.3030581\ttotal: 8.63s\tremaining: 30.8s\n",
            "219:\tlearn: 0.3030074\ttotal: 8.66s\tremaining: 30.7s\n",
            "220:\tlearn: 0.3029449\ttotal: 8.69s\tremaining: 30.6s\n",
            "221:\tlearn: 0.3029057\ttotal: 8.72s\tremaining: 30.6s\n",
            "222:\tlearn: 0.3028538\ttotal: 8.76s\tremaining: 30.5s\n",
            "223:\tlearn: 0.3027959\ttotal: 8.79s\tremaining: 30.5s\n",
            "224:\tlearn: 0.3027337\ttotal: 8.82s\tremaining: 30.4s\n",
            "225:\tlearn: 0.3026616\ttotal: 8.86s\tremaining: 30.3s\n",
            "226:\tlearn: 0.3026043\ttotal: 8.88s\tremaining: 30.3s\n",
            "227:\tlearn: 0.3025675\ttotal: 8.92s\tremaining: 30.2s\n",
            "228:\tlearn: 0.3025173\ttotal: 8.95s\tremaining: 30.1s\n",
            "229:\tlearn: 0.3024552\ttotal: 8.99s\tremaining: 30.1s\n",
            "230:\tlearn: 0.3024015\ttotal: 9.02s\tremaining: 30s\n",
            "231:\tlearn: 0.3023670\ttotal: 9.05s\tremaining: 30s\n",
            "232:\tlearn: 0.3023217\ttotal: 9.08s\tremaining: 29.9s\n",
            "233:\tlearn: 0.3022742\ttotal: 9.11s\tremaining: 29.8s\n",
            "234:\tlearn: 0.3022246\ttotal: 9.14s\tremaining: 29.8s\n",
            "235:\tlearn: 0.3021641\ttotal: 9.17s\tremaining: 29.7s\n",
            "236:\tlearn: 0.3021039\ttotal: 9.23s\tremaining: 29.7s\n",
            "237:\tlearn: 0.3020453\ttotal: 9.27s\tremaining: 29.7s\n",
            "238:\tlearn: 0.3019928\ttotal: 9.3s\tremaining: 29.6s\n",
            "239:\tlearn: 0.3019428\ttotal: 9.33s\tremaining: 29.6s\n",
            "240:\tlearn: 0.3018909\ttotal: 9.36s\tremaining: 29.5s\n",
            "241:\tlearn: 0.3018498\ttotal: 9.39s\tremaining: 29.4s\n",
            "242:\tlearn: 0.3017947\ttotal: 9.42s\tremaining: 29.4s\n",
            "243:\tlearn: 0.3017373\ttotal: 9.46s\tremaining: 29.3s\n",
            "244:\tlearn: 0.3016948\ttotal: 9.49s\tremaining: 29.2s\n",
            "245:\tlearn: 0.3016406\ttotal: 9.52s\tremaining: 29.2s\n",
            "246:\tlearn: 0.3016100\ttotal: 9.55s\tremaining: 29.1s\n",
            "247:\tlearn: 0.3015581\ttotal: 9.59s\tremaining: 29.1s\n",
            "248:\tlearn: 0.3015071\ttotal: 9.62s\tremaining: 29s\n",
            "249:\tlearn: 0.3014546\ttotal: 9.64s\tremaining: 28.9s\n",
            "250:\tlearn: 0.3014068\ttotal: 9.69s\tremaining: 28.9s\n",
            "251:\tlearn: 0.3013576\ttotal: 9.72s\tremaining: 28.8s\n",
            "252:\tlearn: 0.3013188\ttotal: 9.75s\tremaining: 28.8s\n",
            "253:\tlearn: 0.3012670\ttotal: 9.78s\tremaining: 28.7s\n",
            "254:\tlearn: 0.3012223\ttotal: 9.81s\tremaining: 28.6s\n",
            "255:\tlearn: 0.3011598\ttotal: 9.84s\tremaining: 28.6s\n",
            "256:\tlearn: 0.3010983\ttotal: 9.87s\tremaining: 28.5s\n",
            "257:\tlearn: 0.3010472\ttotal: 9.91s\tremaining: 28.5s\n",
            "258:\tlearn: 0.3009873\ttotal: 9.94s\tremaining: 28.4s\n",
            "259:\tlearn: 0.3009346\ttotal: 9.97s\tremaining: 28.4s\n",
            "260:\tlearn: 0.3008686\ttotal: 10s\tremaining: 28.3s\n",
            "261:\tlearn: 0.3008262\ttotal: 10s\tremaining: 28.3s\n",
            "262:\tlearn: 0.3007685\ttotal: 10.1s\tremaining: 28.2s\n",
            "263:\tlearn: 0.3007167\ttotal: 10.1s\tremaining: 28.1s\n",
            "264:\tlearn: 0.3006697\ttotal: 10.1s\tremaining: 28.1s\n",
            "265:\tlearn: 0.3006235\ttotal: 10.2s\tremaining: 28.1s\n",
            "266:\tlearn: 0.3005669\ttotal: 10.2s\tremaining: 28s\n",
            "267:\tlearn: 0.3005186\ttotal: 10.2s\tremaining: 28s\n",
            "268:\tlearn: 0.3004651\ttotal: 10.3s\tremaining: 27.9s\n",
            "269:\tlearn: 0.3004049\ttotal: 10.3s\tremaining: 27.9s\n",
            "270:\tlearn: 0.3003559\ttotal: 10.3s\tremaining: 27.8s\n",
            "271:\tlearn: 0.3003130\ttotal: 10.4s\tremaining: 27.8s\n",
            "272:\tlearn: 0.3002629\ttotal: 10.4s\tremaining: 27.7s\n",
            "273:\tlearn: 0.3002267\ttotal: 10.4s\tremaining: 27.7s\n",
            "274:\tlearn: 0.3001744\ttotal: 10.5s\tremaining: 27.6s\n",
            "275:\tlearn: 0.3001144\ttotal: 10.5s\tremaining: 27.6s\n",
            "276:\tlearn: 0.3000683\ttotal: 10.5s\tremaining: 27.5s\n",
            "277:\tlearn: 0.3000042\ttotal: 10.6s\tremaining: 27.5s\n",
            "278:\tlearn: 0.2999509\ttotal: 10.6s\tremaining: 27.4s\n",
            "279:\tlearn: 0.2999069\ttotal: 10.6s\tremaining: 27.4s\n",
            "280:\tlearn: 0.2998617\ttotal: 10.7s\tremaining: 27.3s\n",
            "281:\tlearn: 0.2998163\ttotal: 10.7s\tremaining: 27.2s\n",
            "282:\tlearn: 0.2997607\ttotal: 10.7s\tremaining: 27.2s\n",
            "283:\tlearn: 0.2997105\ttotal: 10.8s\tremaining: 27.2s\n",
            "284:\tlearn: 0.2996579\ttotal: 10.8s\tremaining: 27.1s\n",
            "285:\tlearn: 0.2996275\ttotal: 10.8s\tremaining: 27.1s\n",
            "286:\tlearn: 0.2995813\ttotal: 10.9s\tremaining: 27s\n",
            "287:\tlearn: 0.2995235\ttotal: 10.9s\tremaining: 26.9s\n",
            "288:\tlearn: 0.2994771\ttotal: 10.9s\tremaining: 26.9s\n",
            "289:\tlearn: 0.2994314\ttotal: 11s\tremaining: 26.8s\n",
            "290:\tlearn: 0.2993714\ttotal: 11s\tremaining: 26.8s\n",
            "291:\tlearn: 0.2993265\ttotal: 11s\tremaining: 26.7s\n",
            "292:\tlearn: 0.2992708\ttotal: 11.1s\tremaining: 26.7s\n",
            "293:\tlearn: 0.2992352\ttotal: 11.1s\tremaining: 26.6s\n",
            "294:\tlearn: 0.2991892\ttotal: 11.1s\tremaining: 26.6s\n",
            "295:\tlearn: 0.2991407\ttotal: 11.1s\tremaining: 26.5s\n",
            "296:\tlearn: 0.2990874\ttotal: 11.2s\tremaining: 26.5s\n",
            "297:\tlearn: 0.2990429\ttotal: 11.2s\tremaining: 26.4s\n",
            "298:\tlearn: 0.2990048\ttotal: 11.3s\tremaining: 26.4s\n",
            "299:\tlearn: 0.2989420\ttotal: 11.3s\tremaining: 26.4s\n",
            "300:\tlearn: 0.2989046\ttotal: 11.3s\tremaining: 26.3s\n",
            "301:\tlearn: 0.2988462\ttotal: 11.4s\tremaining: 26.3s\n",
            "302:\tlearn: 0.2987943\ttotal: 11.4s\tremaining: 26.2s\n",
            "303:\tlearn: 0.2987499\ttotal: 11.4s\tremaining: 26.1s\n",
            "304:\tlearn: 0.2987118\ttotal: 11.5s\tremaining: 26.1s\n",
            "305:\tlearn: 0.2986675\ttotal: 11.5s\tremaining: 26.1s\n",
            "306:\tlearn: 0.2986413\ttotal: 11.5s\tremaining: 26s\n",
            "307:\tlearn: 0.2985892\ttotal: 11.6s\tremaining: 26s\n",
            "308:\tlearn: 0.2985485\ttotal: 11.6s\tremaining: 25.9s\n",
            "309:\tlearn: 0.2985072\ttotal: 11.6s\tremaining: 25.8s\n",
            "310:\tlearn: 0.2984597\ttotal: 11.6s\tremaining: 25.8s\n",
            "311:\tlearn: 0.2983992\ttotal: 11.7s\tremaining: 25.8s\n",
            "312:\tlearn: 0.2983587\ttotal: 11.7s\tremaining: 25.7s\n",
            "313:\tlearn: 0.2983195\ttotal: 11.7s\tremaining: 25.6s\n",
            "314:\tlearn: 0.2982766\ttotal: 11.8s\tremaining: 25.6s\n",
            "315:\tlearn: 0.2982395\ttotal: 11.8s\tremaining: 25.5s\n",
            "316:\tlearn: 0.2981865\ttotal: 11.8s\tremaining: 25.5s\n",
            "317:\tlearn: 0.2981318\ttotal: 11.9s\tremaining: 25.4s\n",
            "318:\tlearn: 0.2980861\ttotal: 11.9s\tremaining: 25.4s\n",
            "319:\tlearn: 0.2980335\ttotal: 11.9s\tremaining: 25.4s\n",
            "320:\tlearn: 0.2979959\ttotal: 12s\tremaining: 25.3s\n",
            "321:\tlearn: 0.2979365\ttotal: 12s\tremaining: 25.3s\n",
            "322:\tlearn: 0.2978935\ttotal: 12s\tremaining: 25.2s\n",
            "323:\tlearn: 0.2978539\ttotal: 12.1s\tremaining: 25.1s\n",
            "324:\tlearn: 0.2978055\ttotal: 12.1s\tremaining: 25.1s\n",
            "325:\tlearn: 0.2977556\ttotal: 12.1s\tremaining: 25.1s\n",
            "326:\tlearn: 0.2977010\ttotal: 12.2s\tremaining: 25s\n",
            "327:\tlearn: 0.2976575\ttotal: 12.2s\tremaining: 25s\n",
            "328:\tlearn: 0.2976137\ttotal: 12.2s\tremaining: 24.9s\n",
            "329:\tlearn: 0.2975677\ttotal: 12.3s\tremaining: 24.9s\n",
            "330:\tlearn: 0.2975325\ttotal: 12.3s\tremaining: 24.9s\n",
            "331:\tlearn: 0.2974960\ttotal: 12.3s\tremaining: 24.8s\n",
            "332:\tlearn: 0.2974544\ttotal: 12.4s\tremaining: 24.8s\n",
            "333:\tlearn: 0.2974083\ttotal: 12.4s\tremaining: 24.7s\n",
            "334:\tlearn: 0.2973697\ttotal: 12.4s\tremaining: 24.7s\n",
            "335:\tlearn: 0.2973311\ttotal: 12.5s\tremaining: 24.6s\n",
            "336:\tlearn: 0.2972810\ttotal: 12.5s\tremaining: 24.6s\n",
            "337:\tlearn: 0.2972419\ttotal: 12.5s\tremaining: 24.6s\n",
            "338:\tlearn: 0.2971923\ttotal: 12.6s\tremaining: 24.5s\n",
            "339:\tlearn: 0.2971362\ttotal: 12.6s\tremaining: 24.5s\n",
            "340:\tlearn: 0.2970883\ttotal: 12.6s\tremaining: 24.4s\n",
            "341:\tlearn: 0.2970656\ttotal: 12.7s\tremaining: 24.4s\n",
            "342:\tlearn: 0.2970221\ttotal: 12.7s\tremaining: 24.3s\n",
            "343:\tlearn: 0.2969747\ttotal: 12.8s\tremaining: 24.3s\n",
            "344:\tlearn: 0.2969180\ttotal: 12.8s\tremaining: 24.3s\n",
            "345:\tlearn: 0.2968727\ttotal: 12.9s\tremaining: 24.3s\n",
            "346:\tlearn: 0.2968271\ttotal: 12.9s\tremaining: 24.4s\n",
            "347:\tlearn: 0.2967782\ttotal: 13s\tremaining: 24.3s\n",
            "348:\tlearn: 0.2967335\ttotal: 13.1s\tremaining: 24.4s\n",
            "349:\tlearn: 0.2966935\ttotal: 13.1s\tremaining: 24.4s\n",
            "350:\tlearn: 0.2966564\ttotal: 13.2s\tremaining: 24.4s\n",
            "351:\tlearn: 0.2966139\ttotal: 13.2s\tremaining: 24.4s\n",
            "352:\tlearn: 0.2965780\ttotal: 13.3s\tremaining: 24.4s\n",
            "353:\tlearn: 0.2965335\ttotal: 13.4s\tremaining: 24.4s\n",
            "354:\tlearn: 0.2964965\ttotal: 13.5s\tremaining: 24.5s\n",
            "355:\tlearn: 0.2964597\ttotal: 13.5s\tremaining: 24.5s\n",
            "356:\tlearn: 0.2964165\ttotal: 13.6s\tremaining: 24.5s\n",
            "357:\tlearn: 0.2963726\ttotal: 13.7s\tremaining: 24.6s\n",
            "358:\tlearn: 0.2963353\ttotal: 13.8s\tremaining: 24.6s\n",
            "359:\tlearn: 0.2962893\ttotal: 13.8s\tremaining: 24.6s\n",
            "360:\tlearn: 0.2962385\ttotal: 13.9s\tremaining: 24.6s\n",
            "361:\tlearn: 0.2961992\ttotal: 14s\tremaining: 24.6s\n",
            "362:\tlearn: 0.2961539\ttotal: 14.1s\tremaining: 24.7s\n",
            "363:\tlearn: 0.2961192\ttotal: 14.1s\tremaining: 24.7s\n",
            "364:\tlearn: 0.2960918\ttotal: 14.2s\tremaining: 24.7s\n",
            "365:\tlearn: 0.2960562\ttotal: 14.3s\tremaining: 24.7s\n",
            "366:\tlearn: 0.2960149\ttotal: 14.3s\tremaining: 24.7s\n",
            "367:\tlearn: 0.2959852\ttotal: 14.4s\tremaining: 24.7s\n",
            "368:\tlearn: 0.2959602\ttotal: 14.5s\tremaining: 24.8s\n",
            "369:\tlearn: 0.2959188\ttotal: 14.5s\tremaining: 24.8s\n",
            "370:\tlearn: 0.2958621\ttotal: 14.6s\tremaining: 24.8s\n",
            "371:\tlearn: 0.2958078\ttotal: 14.7s\tremaining: 24.8s\n",
            "372:\tlearn: 0.2957515\ttotal: 14.8s\tremaining: 24.8s\n",
            "373:\tlearn: 0.2956927\ttotal: 14.8s\tremaining: 24.8s\n",
            "374:\tlearn: 0.2956369\ttotal: 14.9s\tremaining: 24.9s\n",
            "375:\tlearn: 0.2955991\ttotal: 15s\tremaining: 24.9s\n",
            "376:\tlearn: 0.2955460\ttotal: 15.1s\tremaining: 24.9s\n",
            "377:\tlearn: 0.2955059\ttotal: 15.2s\tremaining: 25s\n",
            "378:\tlearn: 0.2954706\ttotal: 15.2s\tremaining: 25s\n",
            "379:\tlearn: 0.2954305\ttotal: 15.3s\tremaining: 24.9s\n",
            "380:\tlearn: 0.2953806\ttotal: 15.3s\tremaining: 24.9s\n",
            "381:\tlearn: 0.2953370\ttotal: 15.3s\tremaining: 24.8s\n",
            "382:\tlearn: 0.2952887\ttotal: 15.4s\tremaining: 24.8s\n",
            "383:\tlearn: 0.2952571\ttotal: 15.4s\tremaining: 24.7s\n",
            "384:\tlearn: 0.2952184\ttotal: 15.5s\tremaining: 24.7s\n",
            "385:\tlearn: 0.2951807\ttotal: 15.5s\tremaining: 24.6s\n",
            "386:\tlearn: 0.2951451\ttotal: 15.5s\tremaining: 24.6s\n",
            "387:\tlearn: 0.2951190\ttotal: 15.5s\tremaining: 24.5s\n",
            "388:\tlearn: 0.2950697\ttotal: 15.6s\tremaining: 24.5s\n",
            "389:\tlearn: 0.2950248\ttotal: 15.6s\tremaining: 24.4s\n",
            "390:\tlearn: 0.2949836\ttotal: 15.6s\tremaining: 24.3s\n",
            "391:\tlearn: 0.2949403\ttotal: 15.7s\tremaining: 24.3s\n",
            "392:\tlearn: 0.2949062\ttotal: 15.7s\tremaining: 24.3s\n",
            "393:\tlearn: 0.2948558\ttotal: 15.7s\tremaining: 24.2s\n",
            "394:\tlearn: 0.2948083\ttotal: 15.8s\tremaining: 24.2s\n",
            "395:\tlearn: 0.2947637\ttotal: 15.8s\tremaining: 24.1s\n",
            "396:\tlearn: 0.2947256\ttotal: 15.8s\tremaining: 24s\n",
            "397:\tlearn: 0.2946810\ttotal: 15.9s\tremaining: 24s\n",
            "398:\tlearn: 0.2946522\ttotal: 15.9s\tremaining: 24s\n",
            "399:\tlearn: 0.2946148\ttotal: 15.9s\tremaining: 23.9s\n",
            "400:\tlearn: 0.2945846\ttotal: 16s\tremaining: 23.8s\n",
            "401:\tlearn: 0.2945367\ttotal: 16s\tremaining: 23.8s\n",
            "402:\tlearn: 0.2944800\ttotal: 16s\tremaining: 23.7s\n",
            "403:\tlearn: 0.2944396\ttotal: 16.1s\tremaining: 23.7s\n",
            "404:\tlearn: 0.2943970\ttotal: 16.1s\tremaining: 23.6s\n",
            "405:\tlearn: 0.2943620\ttotal: 16.1s\tremaining: 23.6s\n",
            "406:\tlearn: 0.2943202\ttotal: 16.2s\tremaining: 23.5s\n",
            "407:\tlearn: 0.2942935\ttotal: 16.2s\tremaining: 23.5s\n",
            "408:\tlearn: 0.2942477\ttotal: 16.2s\tremaining: 23.4s\n",
            "409:\tlearn: 0.2941939\ttotal: 16.3s\tremaining: 23.4s\n",
            "410:\tlearn: 0.2941549\ttotal: 16.3s\tremaining: 23.3s\n",
            "411:\tlearn: 0.2941056\ttotal: 16.3s\tremaining: 23.3s\n",
            "412:\tlearn: 0.2940563\ttotal: 16.4s\tremaining: 23.2s\n",
            "413:\tlearn: 0.2940304\ttotal: 16.4s\tremaining: 23.2s\n",
            "414:\tlearn: 0.2940021\ttotal: 16.4s\tremaining: 23.2s\n",
            "415:\tlearn: 0.2939692\ttotal: 16.5s\tremaining: 23.1s\n",
            "416:\tlearn: 0.2939212\ttotal: 16.5s\tremaining: 23.1s\n",
            "417:\tlearn: 0.2938777\ttotal: 16.5s\tremaining: 23s\n",
            "418:\tlearn: 0.2938338\ttotal: 16.6s\tremaining: 23s\n",
            "419:\tlearn: 0.2937909\ttotal: 16.6s\tremaining: 22.9s\n",
            "420:\tlearn: 0.2937417\ttotal: 16.6s\tremaining: 22.9s\n",
            "421:\tlearn: 0.2937039\ttotal: 16.7s\tremaining: 22.8s\n",
            "422:\tlearn: 0.2936525\ttotal: 16.7s\tremaining: 22.8s\n",
            "423:\tlearn: 0.2936205\ttotal: 16.7s\tremaining: 22.7s\n",
            "424:\tlearn: 0.2935676\ttotal: 16.7s\tremaining: 22.7s\n",
            "425:\tlearn: 0.2935303\ttotal: 16.8s\tremaining: 22.6s\n",
            "426:\tlearn: 0.2934893\ttotal: 16.8s\tremaining: 22.6s\n",
            "427:\tlearn: 0.2934427\ttotal: 16.8s\tremaining: 22.5s\n",
            "428:\tlearn: 0.2933913\ttotal: 16.9s\tremaining: 22.5s\n",
            "429:\tlearn: 0.2933496\ttotal: 16.9s\tremaining: 22.4s\n",
            "430:\tlearn: 0.2933202\ttotal: 16.9s\tremaining: 22.4s\n",
            "431:\tlearn: 0.2932794\ttotal: 17s\tremaining: 22.3s\n",
            "432:\tlearn: 0.2932336\ttotal: 17s\tremaining: 22.3s\n",
            "433:\tlearn: 0.2931872\ttotal: 17s\tremaining: 22.2s\n",
            "434:\tlearn: 0.2931597\ttotal: 17.1s\tremaining: 22.2s\n",
            "435:\tlearn: 0.2931366\ttotal: 17.1s\tremaining: 22.1s\n",
            "436:\tlearn: 0.2930928\ttotal: 17.1s\tremaining: 22.1s\n",
            "437:\tlearn: 0.2930587\ttotal: 17.2s\tremaining: 22s\n",
            "438:\tlearn: 0.2930185\ttotal: 17.2s\tremaining: 22s\n",
            "439:\tlearn: 0.2929730\ttotal: 17.2s\tremaining: 21.9s\n",
            "440:\tlearn: 0.2929334\ttotal: 17.3s\tremaining: 21.9s\n",
            "441:\tlearn: 0.2929019\ttotal: 17.3s\tremaining: 21.8s\n",
            "442:\tlearn: 0.2928670\ttotal: 17.3s\tremaining: 21.8s\n",
            "443:\tlearn: 0.2928275\ttotal: 17.4s\tremaining: 21.8s\n",
            "444:\tlearn: 0.2927881\ttotal: 17.4s\tremaining: 21.7s\n",
            "445:\tlearn: 0.2927340\ttotal: 17.4s\tremaining: 21.7s\n",
            "446:\tlearn: 0.2926931\ttotal: 17.5s\tremaining: 21.6s\n",
            "447:\tlearn: 0.2926547\ttotal: 17.5s\tremaining: 21.6s\n",
            "448:\tlearn: 0.2926264\ttotal: 17.6s\tremaining: 21.5s\n",
            "449:\tlearn: 0.2925851\ttotal: 17.6s\tremaining: 21.5s\n",
            "450:\tlearn: 0.2925485\ttotal: 17.6s\tremaining: 21.4s\n",
            "451:\tlearn: 0.2925118\ttotal: 17.6s\tremaining: 21.4s\n",
            "452:\tlearn: 0.2924745\ttotal: 17.7s\tremaining: 21.3s\n",
            "453:\tlearn: 0.2924377\ttotal: 17.7s\tremaining: 21.3s\n",
            "454:\tlearn: 0.2924048\ttotal: 17.7s\tremaining: 21.3s\n",
            "455:\tlearn: 0.2923651\ttotal: 17.8s\tremaining: 21.2s\n",
            "456:\tlearn: 0.2923181\ttotal: 17.8s\tremaining: 21.2s\n",
            "457:\tlearn: 0.2922771\ttotal: 17.8s\tremaining: 21.1s\n",
            "458:\tlearn: 0.2922365\ttotal: 17.9s\tremaining: 21.1s\n",
            "459:\tlearn: 0.2921898\ttotal: 17.9s\tremaining: 21s\n",
            "460:\tlearn: 0.2921554\ttotal: 17.9s\tremaining: 21s\n",
            "461:\tlearn: 0.2921185\ttotal: 18s\tremaining: 20.9s\n",
            "462:\tlearn: 0.2920842\ttotal: 18s\tremaining: 20.9s\n",
            "463:\tlearn: 0.2920481\ttotal: 18s\tremaining: 20.8s\n",
            "464:\tlearn: 0.2920044\ttotal: 18.1s\tremaining: 20.8s\n",
            "465:\tlearn: 0.2919567\ttotal: 18.1s\tremaining: 20.7s\n",
            "466:\tlearn: 0.2919179\ttotal: 18.1s\tremaining: 20.7s\n",
            "467:\tlearn: 0.2918800\ttotal: 18.2s\tremaining: 20.6s\n",
            "468:\tlearn: 0.2918403\ttotal: 18.2s\tremaining: 20.6s\n",
            "469:\tlearn: 0.2917957\ttotal: 18.2s\tremaining: 20.6s\n",
            "470:\tlearn: 0.2917543\ttotal: 18.3s\tremaining: 20.5s\n",
            "471:\tlearn: 0.2917262\ttotal: 18.3s\tremaining: 20.5s\n",
            "472:\tlearn: 0.2916891\ttotal: 18.3s\tremaining: 20.4s\n",
            "473:\tlearn: 0.2916423\ttotal: 18.3s\tremaining: 20.4s\n",
            "474:\tlearn: 0.2916017\ttotal: 18.4s\tremaining: 20.3s\n",
            "475:\tlearn: 0.2915664\ttotal: 18.4s\tremaining: 20.3s\n",
            "476:\tlearn: 0.2915311\ttotal: 18.5s\tremaining: 20.2s\n",
            "477:\tlearn: 0.2914913\ttotal: 18.5s\tremaining: 20.2s\n",
            "478:\tlearn: 0.2914467\ttotal: 18.5s\tremaining: 20.1s\n",
            "479:\tlearn: 0.2913966\ttotal: 18.6s\tremaining: 20.1s\n",
            "480:\tlearn: 0.2913517\ttotal: 18.6s\tremaining: 20.1s\n",
            "481:\tlearn: 0.2913153\ttotal: 18.6s\tremaining: 20s\n",
            "482:\tlearn: 0.2912784\ttotal: 18.7s\tremaining: 20s\n",
            "483:\tlearn: 0.2912426\ttotal: 18.7s\tremaining: 19.9s\n",
            "484:\tlearn: 0.2912196\ttotal: 18.7s\tremaining: 19.9s\n",
            "485:\tlearn: 0.2911913\ttotal: 18.7s\tremaining: 19.8s\n",
            "486:\tlearn: 0.2911537\ttotal: 18.8s\tremaining: 19.8s\n",
            "487:\tlearn: 0.2911158\ttotal: 18.8s\tremaining: 19.7s\n",
            "488:\tlearn: 0.2910708\ttotal: 18.8s\tremaining: 19.7s\n",
            "489:\tlearn: 0.2910400\ttotal: 18.9s\tremaining: 19.7s\n",
            "490:\tlearn: 0.2910098\ttotal: 18.9s\tremaining: 19.6s\n",
            "491:\tlearn: 0.2909807\ttotal: 18.9s\tremaining: 19.6s\n",
            "492:\tlearn: 0.2909444\ttotal: 19s\tremaining: 19.5s\n",
            "493:\tlearn: 0.2909078\ttotal: 19s\tremaining: 19.5s\n",
            "494:\tlearn: 0.2908562\ttotal: 19s\tremaining: 19.4s\n",
            "495:\tlearn: 0.2908160\ttotal: 19.1s\tremaining: 19.4s\n",
            "496:\tlearn: 0.2907759\ttotal: 19.1s\tremaining: 19.3s\n",
            "497:\tlearn: 0.2907443\ttotal: 19.1s\tremaining: 19.3s\n",
            "498:\tlearn: 0.2907007\ttotal: 19.2s\tremaining: 19.2s\n",
            "499:\tlearn: 0.2906569\ttotal: 19.2s\tremaining: 19.2s\n",
            "500:\tlearn: 0.2906165\ttotal: 19.2s\tremaining: 19.2s\n",
            "501:\tlearn: 0.2905755\ttotal: 19.3s\tremaining: 19.1s\n",
            "502:\tlearn: 0.2905389\ttotal: 19.3s\tremaining: 19.1s\n",
            "503:\tlearn: 0.2905153\ttotal: 19.3s\tremaining: 19s\n",
            "504:\tlearn: 0.2904800\ttotal: 19.4s\tremaining: 19s\n",
            "505:\tlearn: 0.2904360\ttotal: 19.4s\tremaining: 18.9s\n",
            "506:\tlearn: 0.2904000\ttotal: 19.4s\tremaining: 18.9s\n",
            "507:\tlearn: 0.2903628\ttotal: 19.5s\tremaining: 18.9s\n",
            "508:\tlearn: 0.2903275\ttotal: 19.5s\tremaining: 18.8s\n",
            "509:\tlearn: 0.2902694\ttotal: 19.5s\tremaining: 18.8s\n",
            "510:\tlearn: 0.2902216\ttotal: 19.6s\tremaining: 18.7s\n",
            "511:\tlearn: 0.2901744\ttotal: 19.6s\tremaining: 18.7s\n",
            "512:\tlearn: 0.2901390\ttotal: 19.6s\tremaining: 18.6s\n",
            "513:\tlearn: 0.2901018\ttotal: 19.7s\tremaining: 18.6s\n",
            "514:\tlearn: 0.2900682\ttotal: 19.7s\tremaining: 18.6s\n",
            "515:\tlearn: 0.2900195\ttotal: 19.7s\tremaining: 18.5s\n",
            "516:\tlearn: 0.2899867\ttotal: 19.8s\tremaining: 18.5s\n",
            "517:\tlearn: 0.2899553\ttotal: 19.8s\tremaining: 18.4s\n",
            "518:\tlearn: 0.2899245\ttotal: 19.8s\tremaining: 18.4s\n",
            "519:\tlearn: 0.2898855\ttotal: 19.9s\tremaining: 18.3s\n",
            "520:\tlearn: 0.2898632\ttotal: 19.9s\tremaining: 18.3s\n",
            "521:\tlearn: 0.2898146\ttotal: 19.9s\tremaining: 18.3s\n",
            "522:\tlearn: 0.2897771\ttotal: 20s\tremaining: 18.2s\n",
            "523:\tlearn: 0.2897344\ttotal: 20s\tremaining: 18.2s\n",
            "524:\tlearn: 0.2897045\ttotal: 20s\tremaining: 18.1s\n",
            "525:\tlearn: 0.2896628\ttotal: 20s\tremaining: 18.1s\n",
            "526:\tlearn: 0.2896232\ttotal: 20.1s\tremaining: 18s\n",
            "527:\tlearn: 0.2895910\ttotal: 20.1s\tremaining: 18s\n",
            "528:\tlearn: 0.2895497\ttotal: 20.2s\tremaining: 17.9s\n",
            "529:\tlearn: 0.2894989\ttotal: 20.2s\tremaining: 17.9s\n",
            "530:\tlearn: 0.2894699\ttotal: 20.2s\tremaining: 17.9s\n",
            "531:\tlearn: 0.2894328\ttotal: 20.2s\tremaining: 17.8s\n",
            "532:\tlearn: 0.2893992\ttotal: 20.3s\tremaining: 17.8s\n",
            "533:\tlearn: 0.2893561\ttotal: 20.3s\tremaining: 17.7s\n",
            "534:\tlearn: 0.2893082\ttotal: 20.4s\tremaining: 17.7s\n",
            "535:\tlearn: 0.2892742\ttotal: 20.4s\tremaining: 17.6s\n",
            "536:\tlearn: 0.2892187\ttotal: 20.4s\tremaining: 17.6s\n",
            "537:\tlearn: 0.2891698\ttotal: 20.4s\tremaining: 17.6s\n",
            "538:\tlearn: 0.2891326\ttotal: 20.5s\tremaining: 17.5s\n",
            "539:\tlearn: 0.2891092\ttotal: 20.5s\tremaining: 17.5s\n",
            "540:\tlearn: 0.2890730\ttotal: 20.6s\tremaining: 17.4s\n",
            "541:\tlearn: 0.2890416\ttotal: 20.6s\tremaining: 17.4s\n",
            "542:\tlearn: 0.2890064\ttotal: 20.6s\tremaining: 17.4s\n",
            "543:\tlearn: 0.2889747\ttotal: 20.7s\tremaining: 17.3s\n",
            "544:\tlearn: 0.2889370\ttotal: 20.7s\tremaining: 17.3s\n",
            "545:\tlearn: 0.2889031\ttotal: 20.7s\tremaining: 17.2s\n",
            "546:\tlearn: 0.2888718\ttotal: 20.7s\tremaining: 17.2s\n",
            "547:\tlearn: 0.2888395\ttotal: 20.8s\tremaining: 17.1s\n",
            "548:\tlearn: 0.2887957\ttotal: 20.8s\tremaining: 17.1s\n",
            "549:\tlearn: 0.2887499\ttotal: 20.9s\tremaining: 17.1s\n",
            "550:\tlearn: 0.2887221\ttotal: 20.9s\tremaining: 17s\n",
            "551:\tlearn: 0.2886760\ttotal: 20.9s\tremaining: 17s\n",
            "552:\tlearn: 0.2886414\ttotal: 20.9s\tremaining: 16.9s\n",
            "553:\tlearn: 0.2886206\ttotal: 21s\tremaining: 16.9s\n",
            "554:\tlearn: 0.2885878\ttotal: 21s\tremaining: 16.8s\n",
            "555:\tlearn: 0.2885416\ttotal: 21s\tremaining: 16.8s\n",
            "556:\tlearn: 0.2885030\ttotal: 21.1s\tremaining: 16.8s\n",
            "557:\tlearn: 0.2884540\ttotal: 21.1s\tremaining: 16.7s\n",
            "558:\tlearn: 0.2884097\ttotal: 21.1s\tremaining: 16.7s\n",
            "559:\tlearn: 0.2883605\ttotal: 21.2s\tremaining: 16.6s\n",
            "560:\tlearn: 0.2883182\ttotal: 21.2s\tremaining: 16.6s\n",
            "561:\tlearn: 0.2882684\ttotal: 21.2s\tremaining: 16.6s\n",
            "562:\tlearn: 0.2882421\ttotal: 21.3s\tremaining: 16.5s\n",
            "563:\tlearn: 0.2882127\ttotal: 21.3s\tremaining: 16.5s\n",
            "564:\tlearn: 0.2881708\ttotal: 21.3s\tremaining: 16.4s\n",
            "565:\tlearn: 0.2881341\ttotal: 21.4s\tremaining: 16.4s\n",
            "566:\tlearn: 0.2880999\ttotal: 21.4s\tremaining: 16.3s\n",
            "567:\tlearn: 0.2880701\ttotal: 21.4s\tremaining: 16.3s\n",
            "568:\tlearn: 0.2880214\ttotal: 21.5s\tremaining: 16.3s\n",
            "569:\tlearn: 0.2879770\ttotal: 21.5s\tremaining: 16.2s\n",
            "570:\tlearn: 0.2879316\ttotal: 21.5s\tremaining: 16.2s\n",
            "571:\tlearn: 0.2879055\ttotal: 21.6s\tremaining: 16.1s\n",
            "572:\tlearn: 0.2878686\ttotal: 21.6s\tremaining: 16.1s\n",
            "573:\tlearn: 0.2878213\ttotal: 21.6s\tremaining: 16.1s\n",
            "574:\tlearn: 0.2877878\ttotal: 21.7s\tremaining: 16s\n",
            "575:\tlearn: 0.2877557\ttotal: 21.7s\tremaining: 16s\n",
            "576:\tlearn: 0.2877240\ttotal: 21.7s\tremaining: 15.9s\n",
            "577:\tlearn: 0.2876817\ttotal: 21.8s\tremaining: 15.9s\n",
            "578:\tlearn: 0.2876402\ttotal: 21.8s\tremaining: 15.8s\n",
            "579:\tlearn: 0.2875945\ttotal: 21.8s\tremaining: 15.8s\n",
            "580:\tlearn: 0.2875594\ttotal: 21.9s\tremaining: 15.8s\n",
            "581:\tlearn: 0.2875298\ttotal: 21.9s\tremaining: 15.7s\n",
            "582:\tlearn: 0.2875069\ttotal: 21.9s\tremaining: 15.7s\n",
            "583:\tlearn: 0.2874579\ttotal: 22s\tremaining: 15.6s\n",
            "584:\tlearn: 0.2874249\ttotal: 22s\tremaining: 15.6s\n",
            "585:\tlearn: 0.2873816\ttotal: 22s\tremaining: 15.6s\n",
            "586:\tlearn: 0.2873527\ttotal: 22.1s\tremaining: 15.5s\n",
            "587:\tlearn: 0.2873205\ttotal: 22.1s\tremaining: 15.5s\n",
            "588:\tlearn: 0.2872769\ttotal: 22.1s\tremaining: 15.4s\n",
            "589:\tlearn: 0.2872329\ttotal: 22.1s\tremaining: 15.4s\n",
            "590:\tlearn: 0.2872004\ttotal: 22.2s\tremaining: 15.4s\n",
            "591:\tlearn: 0.2871608\ttotal: 22.2s\tremaining: 15.3s\n",
            "592:\tlearn: 0.2871140\ttotal: 22.2s\tremaining: 15.3s\n",
            "593:\tlearn: 0.2870780\ttotal: 22.3s\tremaining: 15.2s\n",
            "594:\tlearn: 0.2870454\ttotal: 22.3s\tremaining: 15.2s\n",
            "595:\tlearn: 0.2870042\ttotal: 22.3s\tremaining: 15.1s\n",
            "596:\tlearn: 0.2869725\ttotal: 22.4s\tremaining: 15.1s\n",
            "597:\tlearn: 0.2869285\ttotal: 22.4s\tremaining: 15.1s\n",
            "598:\tlearn: 0.2868942\ttotal: 22.4s\tremaining: 15s\n",
            "599:\tlearn: 0.2868665\ttotal: 22.5s\tremaining: 15s\n",
            "600:\tlearn: 0.2868302\ttotal: 22.5s\tremaining: 14.9s\n",
            "601:\tlearn: 0.2867988\ttotal: 22.5s\tremaining: 14.9s\n",
            "602:\tlearn: 0.2867545\ttotal: 22.6s\tremaining: 14.9s\n",
            "603:\tlearn: 0.2867198\ttotal: 22.6s\tremaining: 14.8s\n",
            "604:\tlearn: 0.2866873\ttotal: 22.7s\tremaining: 14.8s\n",
            "605:\tlearn: 0.2866682\ttotal: 22.7s\tremaining: 14.7s\n",
            "606:\tlearn: 0.2866232\ttotal: 22.7s\tremaining: 14.7s\n",
            "607:\tlearn: 0.2865899\ttotal: 22.7s\tremaining: 14.7s\n",
            "608:\tlearn: 0.2865571\ttotal: 22.8s\tremaining: 14.6s\n",
            "609:\tlearn: 0.2865165\ttotal: 22.8s\tremaining: 14.6s\n",
            "610:\tlearn: 0.2864797\ttotal: 22.8s\tremaining: 14.5s\n",
            "611:\tlearn: 0.2864450\ttotal: 22.9s\tremaining: 14.5s\n",
            "612:\tlearn: 0.2864023\ttotal: 22.9s\tremaining: 14.5s\n",
            "613:\tlearn: 0.2863713\ttotal: 22.9s\tremaining: 14.4s\n",
            "614:\tlearn: 0.2863396\ttotal: 23s\tremaining: 14.4s\n",
            "615:\tlearn: 0.2862962\ttotal: 23s\tremaining: 14.3s\n",
            "616:\tlearn: 0.2862535\ttotal: 23s\tremaining: 14.3s\n",
            "617:\tlearn: 0.2862163\ttotal: 23.1s\tremaining: 14.3s\n",
            "618:\tlearn: 0.2861833\ttotal: 23.1s\tremaining: 14.2s\n",
            "619:\tlearn: 0.2861496\ttotal: 23.1s\tremaining: 14.2s\n",
            "620:\tlearn: 0.2861206\ttotal: 23.2s\tremaining: 14.1s\n",
            "621:\tlearn: 0.2860864\ttotal: 23.2s\tremaining: 14.1s\n",
            "622:\tlearn: 0.2860579\ttotal: 23.2s\tremaining: 14.1s\n",
            "623:\tlearn: 0.2860182\ttotal: 23.3s\tremaining: 14s\n",
            "624:\tlearn: 0.2859732\ttotal: 23.3s\tremaining: 14s\n",
            "625:\tlearn: 0.2859444\ttotal: 23.3s\tremaining: 13.9s\n",
            "626:\tlearn: 0.2858962\ttotal: 23.4s\tremaining: 13.9s\n",
            "627:\tlearn: 0.2858638\ttotal: 23.4s\tremaining: 13.8s\n",
            "628:\tlearn: 0.2858340\ttotal: 23.4s\tremaining: 13.8s\n",
            "629:\tlearn: 0.2857991\ttotal: 23.4s\tremaining: 13.8s\n",
            "630:\tlearn: 0.2857729\ttotal: 23.5s\tremaining: 13.7s\n",
            "631:\tlearn: 0.2857402\ttotal: 23.5s\tremaining: 13.7s\n",
            "632:\tlearn: 0.2856872\ttotal: 23.6s\tremaining: 13.7s\n",
            "633:\tlearn: 0.2856399\ttotal: 23.6s\tremaining: 13.6s\n",
            "634:\tlearn: 0.2856089\ttotal: 23.6s\tremaining: 13.6s\n",
            "635:\tlearn: 0.2855769\ttotal: 23.6s\tremaining: 13.5s\n",
            "636:\tlearn: 0.2855306\ttotal: 23.7s\tremaining: 13.5s\n",
            "637:\tlearn: 0.2854918\ttotal: 23.7s\tremaining: 13.5s\n",
            "638:\tlearn: 0.2854526\ttotal: 23.7s\tremaining: 13.4s\n",
            "639:\tlearn: 0.2854281\ttotal: 23.8s\tremaining: 13.4s\n",
            "640:\tlearn: 0.2854034\ttotal: 23.8s\tremaining: 13.3s\n",
            "641:\tlearn: 0.2853729\ttotal: 23.8s\tremaining: 13.3s\n",
            "642:\tlearn: 0.2853357\ttotal: 23.9s\tremaining: 13.3s\n",
            "643:\tlearn: 0.2852971\ttotal: 23.9s\tremaining: 13.2s\n",
            "644:\tlearn: 0.2852558\ttotal: 23.9s\tremaining: 13.2s\n",
            "645:\tlearn: 0.2852235\ttotal: 24s\tremaining: 13.1s\n",
            "646:\tlearn: 0.2851887\ttotal: 24s\tremaining: 13.1s\n",
            "647:\tlearn: 0.2851562\ttotal: 24s\tremaining: 13.1s\n",
            "648:\tlearn: 0.2851386\ttotal: 24.1s\tremaining: 13s\n",
            "649:\tlearn: 0.2851070\ttotal: 24.1s\tremaining: 13s\n",
            "650:\tlearn: 0.2850688\ttotal: 24.1s\tremaining: 12.9s\n",
            "651:\tlearn: 0.2850320\ttotal: 24.2s\tremaining: 12.9s\n",
            "652:\tlearn: 0.2849919\ttotal: 24.2s\tremaining: 12.9s\n",
            "653:\tlearn: 0.2849683\ttotal: 24.2s\tremaining: 12.8s\n",
            "654:\tlearn: 0.2849404\ttotal: 24.3s\tremaining: 12.8s\n",
            "655:\tlearn: 0.2849140\ttotal: 24.3s\tremaining: 12.7s\n",
            "656:\tlearn: 0.2848759\ttotal: 24.3s\tremaining: 12.7s\n",
            "657:\tlearn: 0.2848486\ttotal: 24.4s\tremaining: 12.7s\n",
            "658:\tlearn: 0.2848042\ttotal: 24.4s\tremaining: 12.6s\n",
            "659:\tlearn: 0.2847783\ttotal: 24.4s\tremaining: 12.6s\n",
            "660:\tlearn: 0.2847353\ttotal: 24.5s\tremaining: 12.5s\n",
            "661:\tlearn: 0.2847065\ttotal: 24.5s\tremaining: 12.5s\n",
            "662:\tlearn: 0.2846640\ttotal: 24.5s\tremaining: 12.5s\n",
            "663:\tlearn: 0.2846286\ttotal: 24.6s\tremaining: 12.4s\n",
            "664:\tlearn: 0.2845875\ttotal: 24.6s\tremaining: 12.4s\n",
            "665:\tlearn: 0.2845530\ttotal: 24.6s\tremaining: 12.3s\n",
            "666:\tlearn: 0.2845241\ttotal: 24.7s\tremaining: 12.3s\n",
            "667:\tlearn: 0.2844876\ttotal: 24.7s\tremaining: 12.3s\n",
            "668:\tlearn: 0.2844455\ttotal: 24.7s\tremaining: 12.2s\n",
            "669:\tlearn: 0.2844116\ttotal: 24.8s\tremaining: 12.2s\n",
            "670:\tlearn: 0.2843712\ttotal: 24.8s\tremaining: 12.2s\n",
            "671:\tlearn: 0.2843333\ttotal: 24.8s\tremaining: 12.1s\n",
            "672:\tlearn: 0.2842903\ttotal: 24.9s\tremaining: 12.1s\n",
            "673:\tlearn: 0.2842509\ttotal: 24.9s\tremaining: 12s\n",
            "674:\tlearn: 0.2842073\ttotal: 24.9s\tremaining: 12s\n",
            "675:\tlearn: 0.2841607\ttotal: 25s\tremaining: 12s\n",
            "676:\tlearn: 0.2841202\ttotal: 25s\tremaining: 11.9s\n",
            "677:\tlearn: 0.2840905\ttotal: 25s\tremaining: 11.9s\n",
            "678:\tlearn: 0.2840516\ttotal: 25.1s\tremaining: 11.9s\n",
            "679:\tlearn: 0.2840116\ttotal: 25.1s\tremaining: 11.8s\n",
            "680:\tlearn: 0.2839834\ttotal: 25.2s\tremaining: 11.8s\n",
            "681:\tlearn: 0.2839549\ttotal: 25.2s\tremaining: 11.8s\n",
            "682:\tlearn: 0.2839073\ttotal: 25.3s\tremaining: 11.7s\n",
            "683:\tlearn: 0.2838641\ttotal: 25.3s\tremaining: 11.7s\n",
            "684:\tlearn: 0.2838341\ttotal: 25.4s\tremaining: 11.7s\n",
            "685:\tlearn: 0.2838054\ttotal: 25.4s\tremaining: 11.6s\n",
            "686:\tlearn: 0.2837738\ttotal: 25.5s\tremaining: 11.6s\n",
            "687:\tlearn: 0.2837480\ttotal: 25.6s\tremaining: 11.6s\n",
            "688:\tlearn: 0.2836958\ttotal: 25.6s\tremaining: 11.6s\n",
            "689:\tlearn: 0.2836587\ttotal: 25.7s\tremaining: 11.5s\n",
            "690:\tlearn: 0.2836201\ttotal: 25.7s\tremaining: 11.5s\n",
            "691:\tlearn: 0.2835754\ttotal: 25.8s\tremaining: 11.5s\n",
            "692:\tlearn: 0.2835337\ttotal: 25.9s\tremaining: 11.5s\n",
            "693:\tlearn: 0.2834933\ttotal: 25.9s\tremaining: 11.4s\n",
            "694:\tlearn: 0.2834630\ttotal: 26s\tremaining: 11.4s\n",
            "695:\tlearn: 0.2834267\ttotal: 26s\tremaining: 11.4s\n",
            "696:\tlearn: 0.2833862\ttotal: 26.1s\tremaining: 11.4s\n",
            "697:\tlearn: 0.2833320\ttotal: 26.2s\tremaining: 11.3s\n",
            "698:\tlearn: 0.2833175\ttotal: 26.3s\tremaining: 11.3s\n",
            "699:\tlearn: 0.2832786\ttotal: 26.3s\tremaining: 11.3s\n",
            "700:\tlearn: 0.2832517\ttotal: 26.4s\tremaining: 11.3s\n",
            "701:\tlearn: 0.2832115\ttotal: 26.5s\tremaining: 11.2s\n",
            "702:\tlearn: 0.2831826\ttotal: 26.6s\tremaining: 11.2s\n",
            "703:\tlearn: 0.2831408\ttotal: 26.6s\tremaining: 11.2s\n",
            "704:\tlearn: 0.2831062\ttotal: 26.7s\tremaining: 11.2s\n",
            "705:\tlearn: 0.2830802\ttotal: 26.8s\tremaining: 11.1s\n",
            "706:\tlearn: 0.2830486\ttotal: 26.8s\tremaining: 11.1s\n",
            "707:\tlearn: 0.2830113\ttotal: 26.9s\tremaining: 11.1s\n",
            "708:\tlearn: 0.2829768\ttotal: 26.9s\tremaining: 11.1s\n",
            "709:\tlearn: 0.2829317\ttotal: 27s\tremaining: 11s\n",
            "710:\tlearn: 0.2828992\ttotal: 27.1s\tremaining: 11s\n",
            "711:\tlearn: 0.2828512\ttotal: 27.1s\tremaining: 11s\n",
            "712:\tlearn: 0.2828110\ttotal: 27.2s\tremaining: 11s\n",
            "713:\tlearn: 0.2827816\ttotal: 27.3s\tremaining: 10.9s\n",
            "714:\tlearn: 0.2827459\ttotal: 27.3s\tremaining: 10.9s\n",
            "715:\tlearn: 0.2827180\ttotal: 27.4s\tremaining: 10.9s\n",
            "716:\tlearn: 0.2826884\ttotal: 27.5s\tremaining: 10.8s\n",
            "717:\tlearn: 0.2826594\ttotal: 27.5s\tremaining: 10.8s\n",
            "718:\tlearn: 0.2826268\ttotal: 27.6s\tremaining: 10.8s\n",
            "719:\tlearn: 0.2826007\ttotal: 27.7s\tremaining: 10.8s\n",
            "720:\tlearn: 0.2825708\ttotal: 27.8s\tremaining: 10.7s\n",
            "721:\tlearn: 0.2825380\ttotal: 27.8s\tremaining: 10.7s\n",
            "722:\tlearn: 0.2824947\ttotal: 27.8s\tremaining: 10.7s\n",
            "723:\tlearn: 0.2824621\ttotal: 27.9s\tremaining: 10.6s\n",
            "724:\tlearn: 0.2824331\ttotal: 27.9s\tremaining: 10.6s\n",
            "725:\tlearn: 0.2824072\ttotal: 27.9s\tremaining: 10.5s\n",
            "726:\tlearn: 0.2823678\ttotal: 28s\tremaining: 10.5s\n",
            "727:\tlearn: 0.2823270\ttotal: 28s\tremaining: 10.5s\n",
            "728:\tlearn: 0.2822876\ttotal: 28s\tremaining: 10.4s\n",
            "729:\tlearn: 0.2822612\ttotal: 28.1s\tremaining: 10.4s\n",
            "730:\tlearn: 0.2822269\ttotal: 28.1s\tremaining: 10.3s\n",
            "731:\tlearn: 0.2821868\ttotal: 28.1s\tremaining: 10.3s\n",
            "732:\tlearn: 0.2821465\ttotal: 28.2s\tremaining: 10.3s\n",
            "733:\tlearn: 0.2821082\ttotal: 28.2s\tremaining: 10.2s\n",
            "734:\tlearn: 0.2820686\ttotal: 28.2s\tremaining: 10.2s\n",
            "735:\tlearn: 0.2820216\ttotal: 28.3s\tremaining: 10.1s\n",
            "736:\tlearn: 0.2819872\ttotal: 28.3s\tremaining: 10.1s\n",
            "737:\tlearn: 0.2819594\ttotal: 28.3s\tremaining: 10.1s\n",
            "738:\tlearn: 0.2819257\ttotal: 28.4s\tremaining: 10s\n",
            "739:\tlearn: 0.2818972\ttotal: 28.4s\tremaining: 9.98s\n",
            "740:\tlearn: 0.2818644\ttotal: 28.4s\tremaining: 9.94s\n",
            "741:\tlearn: 0.2818407\ttotal: 28.5s\tremaining: 9.89s\n",
            "742:\tlearn: 0.2817972\ttotal: 28.5s\tremaining: 9.85s\n",
            "743:\tlearn: 0.2817595\ttotal: 28.5s\tremaining: 9.81s\n",
            "744:\tlearn: 0.2817270\ttotal: 28.5s\tremaining: 9.77s\n",
            "745:\tlearn: 0.2816923\ttotal: 28.6s\tremaining: 9.73s\n",
            "746:\tlearn: 0.2816600\ttotal: 28.6s\tremaining: 9.69s\n",
            "747:\tlearn: 0.2816180\ttotal: 28.7s\tremaining: 9.66s\n",
            "748:\tlearn: 0.2815834\ttotal: 28.7s\tremaining: 9.62s\n",
            "749:\tlearn: 0.2815548\ttotal: 28.7s\tremaining: 9.58s\n",
            "750:\tlearn: 0.2815218\ttotal: 28.8s\tremaining: 9.54s\n",
            "751:\tlearn: 0.2814816\ttotal: 28.8s\tremaining: 9.49s\n",
            "752:\tlearn: 0.2814570\ttotal: 28.8s\tremaining: 9.46s\n",
            "753:\tlearn: 0.2814269\ttotal: 28.9s\tremaining: 9.42s\n",
            "754:\tlearn: 0.2813892\ttotal: 28.9s\tremaining: 9.38s\n",
            "755:\tlearn: 0.2813469\ttotal: 28.9s\tremaining: 9.34s\n",
            "756:\tlearn: 0.2813135\ttotal: 29s\tremaining: 9.3s\n",
            "757:\tlearn: 0.2812739\ttotal: 29s\tremaining: 9.26s\n",
            "758:\tlearn: 0.2812222\ttotal: 29s\tremaining: 9.21s\n",
            "759:\tlearn: 0.2811852\ttotal: 29.1s\tremaining: 9.18s\n",
            "760:\tlearn: 0.2811570\ttotal: 29.1s\tremaining: 9.14s\n",
            "761:\tlearn: 0.2811259\ttotal: 29.1s\tremaining: 9.1s\n",
            "762:\tlearn: 0.2810779\ttotal: 29.2s\tremaining: 9.06s\n",
            "763:\tlearn: 0.2810505\ttotal: 29.2s\tremaining: 9.02s\n",
            "764:\tlearn: 0.2810110\ttotal: 29.2s\tremaining: 8.98s\n",
            "765:\tlearn: 0.2809790\ttotal: 29.3s\tremaining: 8.94s\n",
            "766:\tlearn: 0.2809480\ttotal: 29.3s\tremaining: 8.9s\n",
            "767:\tlearn: 0.2809162\ttotal: 29.3s\tremaining: 8.86s\n",
            "768:\tlearn: 0.2808897\ttotal: 29.4s\tremaining: 8.82s\n",
            "769:\tlearn: 0.2808524\ttotal: 29.4s\tremaining: 8.78s\n",
            "770:\tlearn: 0.2808169\ttotal: 29.4s\tremaining: 8.74s\n",
            "771:\tlearn: 0.2807855\ttotal: 29.4s\tremaining: 8.7s\n",
            "772:\tlearn: 0.2807605\ttotal: 29.5s\tremaining: 8.66s\n",
            "773:\tlearn: 0.2807295\ttotal: 29.5s\tremaining: 8.62s\n",
            "774:\tlearn: 0.2806886\ttotal: 29.6s\tremaining: 8.58s\n",
            "775:\tlearn: 0.2806524\ttotal: 29.6s\tremaining: 8.54s\n",
            "776:\tlearn: 0.2806204\ttotal: 29.6s\tremaining: 8.5s\n",
            "777:\tlearn: 0.2805811\ttotal: 29.7s\tremaining: 8.46s\n",
            "778:\tlearn: 0.2805395\ttotal: 29.7s\tremaining: 8.43s\n",
            "779:\tlearn: 0.2805134\ttotal: 29.7s\tremaining: 8.39s\n",
            "780:\tlearn: 0.2804686\ttotal: 29.8s\tremaining: 8.35s\n",
            "781:\tlearn: 0.2804208\ttotal: 29.8s\tremaining: 8.31s\n",
            "782:\tlearn: 0.2803872\ttotal: 29.8s\tremaining: 8.27s\n",
            "783:\tlearn: 0.2803461\ttotal: 29.9s\tremaining: 8.23s\n",
            "784:\tlearn: 0.2803264\ttotal: 29.9s\tremaining: 8.19s\n",
            "785:\tlearn: 0.2802910\ttotal: 29.9s\tremaining: 8.15s\n",
            "786:\tlearn: 0.2802603\ttotal: 30s\tremaining: 8.11s\n",
            "787:\tlearn: 0.2802345\ttotal: 30s\tremaining: 8.07s\n",
            "788:\tlearn: 0.2801971\ttotal: 30s\tremaining: 8.03s\n",
            "789:\tlearn: 0.2801729\ttotal: 30.1s\tremaining: 7.99s\n",
            "790:\tlearn: 0.2801446\ttotal: 30.1s\tremaining: 7.95s\n",
            "791:\tlearn: 0.2801138\ttotal: 30.1s\tremaining: 7.91s\n",
            "792:\tlearn: 0.2800880\ttotal: 30.2s\tremaining: 7.87s\n",
            "793:\tlearn: 0.2800606\ttotal: 30.2s\tremaining: 7.83s\n",
            "794:\tlearn: 0.2800341\ttotal: 30.2s\tremaining: 7.79s\n",
            "795:\tlearn: 0.2800003\ttotal: 30.3s\tremaining: 7.75s\n",
            "796:\tlearn: 0.2799601\ttotal: 30.3s\tremaining: 7.71s\n",
            "797:\tlearn: 0.2799178\ttotal: 30.3s\tremaining: 7.67s\n",
            "798:\tlearn: 0.2798858\ttotal: 30.3s\tremaining: 7.63s\n",
            "799:\tlearn: 0.2798434\ttotal: 30.4s\tremaining: 7.59s\n",
            "800:\tlearn: 0.2798065\ttotal: 30.4s\tremaining: 7.55s\n",
            "801:\tlearn: 0.2797658\ttotal: 30.4s\tremaining: 7.52s\n",
            "802:\tlearn: 0.2797233\ttotal: 30.5s\tremaining: 7.48s\n",
            "803:\tlearn: 0.2796858\ttotal: 30.5s\tremaining: 7.44s\n",
            "804:\tlearn: 0.2796532\ttotal: 30.5s\tremaining: 7.4s\n",
            "805:\tlearn: 0.2796149\ttotal: 30.6s\tremaining: 7.36s\n",
            "806:\tlearn: 0.2795715\ttotal: 30.6s\tremaining: 7.32s\n",
            "807:\tlearn: 0.2795270\ttotal: 30.6s\tremaining: 7.28s\n",
            "808:\tlearn: 0.2794882\ttotal: 30.7s\tremaining: 7.24s\n",
            "809:\tlearn: 0.2794635\ttotal: 30.7s\tremaining: 7.2s\n",
            "810:\tlearn: 0.2794383\ttotal: 30.7s\tremaining: 7.17s\n",
            "811:\tlearn: 0.2794111\ttotal: 30.8s\tremaining: 7.13s\n",
            "812:\tlearn: 0.2793797\ttotal: 30.8s\tremaining: 7.09s\n",
            "813:\tlearn: 0.2793546\ttotal: 30.8s\tremaining: 7.05s\n",
            "814:\tlearn: 0.2793212\ttotal: 30.9s\tremaining: 7.01s\n",
            "815:\tlearn: 0.2792900\ttotal: 30.9s\tremaining: 6.97s\n",
            "816:\tlearn: 0.2792589\ttotal: 30.9s\tremaining: 6.93s\n",
            "817:\tlearn: 0.2792319\ttotal: 31s\tremaining: 6.89s\n",
            "818:\tlearn: 0.2792109\ttotal: 31s\tremaining: 6.85s\n",
            "819:\tlearn: 0.2791800\ttotal: 31s\tremaining: 6.81s\n",
            "820:\tlearn: 0.2791369\ttotal: 31.1s\tremaining: 6.77s\n",
            "821:\tlearn: 0.2791062\ttotal: 31.1s\tremaining: 6.73s\n",
            "822:\tlearn: 0.2790682\ttotal: 31.1s\tremaining: 6.69s\n",
            "823:\tlearn: 0.2790442\ttotal: 31.2s\tremaining: 6.65s\n",
            "824:\tlearn: 0.2790107\ttotal: 31.2s\tremaining: 6.62s\n",
            "825:\tlearn: 0.2789710\ttotal: 31.2s\tremaining: 6.58s\n",
            "826:\tlearn: 0.2789448\ttotal: 31.2s\tremaining: 6.54s\n",
            "827:\tlearn: 0.2789053\ttotal: 31.3s\tremaining: 6.5s\n",
            "828:\tlearn: 0.2788769\ttotal: 31.3s\tremaining: 6.46s\n",
            "829:\tlearn: 0.2788390\ttotal: 31.3s\tremaining: 6.42s\n",
            "830:\tlearn: 0.2787901\ttotal: 31.4s\tremaining: 6.38s\n",
            "831:\tlearn: 0.2787624\ttotal: 31.4s\tremaining: 6.34s\n",
            "832:\tlearn: 0.2787340\ttotal: 31.4s\tremaining: 6.3s\n",
            "833:\tlearn: 0.2786837\ttotal: 31.5s\tremaining: 6.26s\n",
            "834:\tlearn: 0.2786526\ttotal: 31.5s\tremaining: 6.22s\n",
            "835:\tlearn: 0.2786187\ttotal: 31.5s\tremaining: 6.19s\n",
            "836:\tlearn: 0.2785891\ttotal: 31.6s\tremaining: 6.15s\n",
            "837:\tlearn: 0.2785628\ttotal: 31.6s\tremaining: 6.11s\n",
            "838:\tlearn: 0.2785386\ttotal: 31.6s\tremaining: 6.07s\n",
            "839:\tlearn: 0.2785002\ttotal: 31.7s\tremaining: 6.03s\n",
            "840:\tlearn: 0.2784685\ttotal: 31.7s\tremaining: 6s\n",
            "841:\tlearn: 0.2784193\ttotal: 31.8s\tremaining: 5.96s\n",
            "842:\tlearn: 0.2783925\ttotal: 31.8s\tremaining: 5.92s\n",
            "843:\tlearn: 0.2783549\ttotal: 31.8s\tremaining: 5.88s\n",
            "844:\tlearn: 0.2783066\ttotal: 31.8s\tremaining: 5.84s\n",
            "845:\tlearn: 0.2782694\ttotal: 31.9s\tremaining: 5.8s\n",
            "846:\tlearn: 0.2782355\ttotal: 31.9s\tremaining: 5.76s\n",
            "847:\tlearn: 0.2782078\ttotal: 31.9s\tremaining: 5.72s\n",
            "848:\tlearn: 0.2781728\ttotal: 32s\tremaining: 5.69s\n",
            "849:\tlearn: 0.2781438\ttotal: 32s\tremaining: 5.65s\n",
            "850:\tlearn: 0.2781142\ttotal: 32s\tremaining: 5.61s\n",
            "851:\tlearn: 0.2780837\ttotal: 32.1s\tremaining: 5.57s\n",
            "852:\tlearn: 0.2780622\ttotal: 32.1s\tremaining: 5.53s\n",
            "853:\tlearn: 0.2780410\ttotal: 32.1s\tremaining: 5.49s\n",
            "854:\tlearn: 0.2779998\ttotal: 32.2s\tremaining: 5.45s\n",
            "855:\tlearn: 0.2779731\ttotal: 32.2s\tremaining: 5.42s\n",
            "856:\tlearn: 0.2779375\ttotal: 32.2s\tremaining: 5.38s\n",
            "857:\tlearn: 0.2779100\ttotal: 32.3s\tremaining: 5.34s\n",
            "858:\tlearn: 0.2778737\ttotal: 32.3s\tremaining: 5.3s\n",
            "859:\tlearn: 0.2778374\ttotal: 32.3s\tremaining: 5.26s\n",
            "860:\tlearn: 0.2777931\ttotal: 32.4s\tremaining: 5.22s\n",
            "861:\tlearn: 0.2777603\ttotal: 32.4s\tremaining: 5.18s\n",
            "862:\tlearn: 0.2777192\ttotal: 32.4s\tremaining: 5.15s\n",
            "863:\tlearn: 0.2776907\ttotal: 32.5s\tremaining: 5.11s\n",
            "864:\tlearn: 0.2776570\ttotal: 32.5s\tremaining: 5.07s\n",
            "865:\tlearn: 0.2776344\ttotal: 32.5s\tremaining: 5.03s\n",
            "866:\tlearn: 0.2775949\ttotal: 32.5s\tremaining: 4.99s\n",
            "867:\tlearn: 0.2775549\ttotal: 32.6s\tremaining: 4.95s\n",
            "868:\tlearn: 0.2775231\ttotal: 32.6s\tremaining: 4.92s\n",
            "869:\tlearn: 0.2774875\ttotal: 32.6s\tremaining: 4.88s\n",
            "870:\tlearn: 0.2774522\ttotal: 32.7s\tremaining: 4.84s\n",
            "871:\tlearn: 0.2774213\ttotal: 32.7s\tremaining: 4.8s\n",
            "872:\tlearn: 0.2773915\ttotal: 32.8s\tremaining: 4.76s\n",
            "873:\tlearn: 0.2773464\ttotal: 32.8s\tremaining: 4.73s\n",
            "874:\tlearn: 0.2773100\ttotal: 32.8s\tremaining: 4.69s\n",
            "875:\tlearn: 0.2772687\ttotal: 32.8s\tremaining: 4.65s\n",
            "876:\tlearn: 0.2772474\ttotal: 32.9s\tremaining: 4.61s\n",
            "877:\tlearn: 0.2772026\ttotal: 32.9s\tremaining: 4.57s\n",
            "878:\tlearn: 0.2771732\ttotal: 32.9s\tremaining: 4.53s\n",
            "879:\tlearn: 0.2771392\ttotal: 33s\tremaining: 4.5s\n",
            "880:\tlearn: 0.2770962\ttotal: 33s\tremaining: 4.46s\n",
            "881:\tlearn: 0.2770491\ttotal: 33s\tremaining: 4.42s\n",
            "882:\tlearn: 0.2770160\ttotal: 33.1s\tremaining: 4.38s\n",
            "883:\tlearn: 0.2769766\ttotal: 33.1s\tremaining: 4.34s\n",
            "884:\tlearn: 0.2769346\ttotal: 33.1s\tremaining: 4.31s\n",
            "885:\tlearn: 0.2769058\ttotal: 33.2s\tremaining: 4.27s\n",
            "886:\tlearn: 0.2768713\ttotal: 33.2s\tremaining: 4.23s\n",
            "887:\tlearn: 0.2768334\ttotal: 33.2s\tremaining: 4.19s\n",
            "888:\tlearn: 0.2767980\ttotal: 33.3s\tremaining: 4.15s\n",
            "889:\tlearn: 0.2767559\ttotal: 33.3s\tremaining: 4.11s\n",
            "890:\tlearn: 0.2767128\ttotal: 33.3s\tremaining: 4.08s\n",
            "891:\tlearn: 0.2766836\ttotal: 33.4s\tremaining: 4.04s\n",
            "892:\tlearn: 0.2766606\ttotal: 33.4s\tremaining: 4s\n",
            "893:\tlearn: 0.2766148\ttotal: 33.4s\tremaining: 3.96s\n",
            "894:\tlearn: 0.2765810\ttotal: 33.5s\tremaining: 3.92s\n",
            "895:\tlearn: 0.2765537\ttotal: 33.5s\tremaining: 3.89s\n",
            "896:\tlearn: 0.2765113\ttotal: 33.5s\tremaining: 3.85s\n",
            "897:\tlearn: 0.2764873\ttotal: 33.6s\tremaining: 3.81s\n",
            "898:\tlearn: 0.2764488\ttotal: 33.6s\tremaining: 3.77s\n",
            "899:\tlearn: 0.2764224\ttotal: 33.6s\tremaining: 3.73s\n",
            "900:\tlearn: 0.2763841\ttotal: 33.7s\tremaining: 3.7s\n",
            "901:\tlearn: 0.2763597\ttotal: 33.7s\tremaining: 3.66s\n",
            "902:\tlearn: 0.2763230\ttotal: 33.7s\tremaining: 3.62s\n",
            "903:\tlearn: 0.2762915\ttotal: 33.8s\tremaining: 3.59s\n",
            "904:\tlearn: 0.2762465\ttotal: 33.8s\tremaining: 3.55s\n",
            "905:\tlearn: 0.2762120\ttotal: 33.8s\tremaining: 3.51s\n",
            "906:\tlearn: 0.2761728\ttotal: 33.9s\tremaining: 3.47s\n",
            "907:\tlearn: 0.2761386\ttotal: 33.9s\tremaining: 3.44s\n",
            "908:\tlearn: 0.2761059\ttotal: 33.9s\tremaining: 3.4s\n",
            "909:\tlearn: 0.2760748\ttotal: 34s\tremaining: 3.36s\n",
            "910:\tlearn: 0.2760412\ttotal: 34s\tremaining: 3.32s\n",
            "911:\tlearn: 0.2759986\ttotal: 34s\tremaining: 3.28s\n",
            "912:\tlearn: 0.2759638\ttotal: 34.1s\tremaining: 3.25s\n",
            "913:\tlearn: 0.2759373\ttotal: 34.1s\tremaining: 3.21s\n",
            "914:\tlearn: 0.2759058\ttotal: 34.1s\tremaining: 3.17s\n",
            "915:\tlearn: 0.2758647\ttotal: 34.2s\tremaining: 3.13s\n",
            "916:\tlearn: 0.2758352\ttotal: 34.2s\tremaining: 3.1s\n",
            "917:\tlearn: 0.2757990\ttotal: 34.2s\tremaining: 3.06s\n",
            "918:\tlearn: 0.2757639\ttotal: 34.3s\tremaining: 3.02s\n",
            "919:\tlearn: 0.2757334\ttotal: 34.3s\tremaining: 2.98s\n",
            "920:\tlearn: 0.2756954\ttotal: 34.3s\tremaining: 2.94s\n",
            "921:\tlearn: 0.2756553\ttotal: 34.4s\tremaining: 2.91s\n",
            "922:\tlearn: 0.2756217\ttotal: 34.4s\tremaining: 2.87s\n",
            "923:\tlearn: 0.2755938\ttotal: 34.4s\tremaining: 2.83s\n",
            "924:\tlearn: 0.2755766\ttotal: 34.5s\tremaining: 2.79s\n",
            "925:\tlearn: 0.2755524\ttotal: 34.5s\tremaining: 2.76s\n",
            "926:\tlearn: 0.2755291\ttotal: 34.5s\tremaining: 2.72s\n",
            "927:\tlearn: 0.2754985\ttotal: 34.6s\tremaining: 2.68s\n",
            "928:\tlearn: 0.2754725\ttotal: 34.6s\tremaining: 2.64s\n",
            "929:\tlearn: 0.2754332\ttotal: 34.6s\tremaining: 2.6s\n",
            "930:\tlearn: 0.2754024\ttotal: 34.6s\tremaining: 2.57s\n",
            "931:\tlearn: 0.2753740\ttotal: 34.7s\tremaining: 2.53s\n",
            "932:\tlearn: 0.2753386\ttotal: 34.7s\tremaining: 2.49s\n",
            "933:\tlearn: 0.2753013\ttotal: 34.8s\tremaining: 2.46s\n",
            "934:\tlearn: 0.2752661\ttotal: 34.8s\tremaining: 2.42s\n",
            "935:\tlearn: 0.2752320\ttotal: 34.8s\tremaining: 2.38s\n",
            "936:\tlearn: 0.2752012\ttotal: 34.9s\tremaining: 2.34s\n",
            "937:\tlearn: 0.2751656\ttotal: 34.9s\tremaining: 2.31s\n",
            "938:\tlearn: 0.2751406\ttotal: 34.9s\tremaining: 2.27s\n",
            "939:\tlearn: 0.2751079\ttotal: 35s\tremaining: 2.23s\n",
            "940:\tlearn: 0.2750765\ttotal: 35s\tremaining: 2.19s\n",
            "941:\tlearn: 0.2750295\ttotal: 35s\tremaining: 2.15s\n",
            "942:\tlearn: 0.2749992\ttotal: 35s\tremaining: 2.12s\n",
            "943:\tlearn: 0.2749731\ttotal: 35.1s\tremaining: 2.08s\n",
            "944:\tlearn: 0.2749333\ttotal: 35.1s\tremaining: 2.04s\n",
            "945:\tlearn: 0.2748892\ttotal: 35.2s\tremaining: 2.01s\n",
            "946:\tlearn: 0.2748618\ttotal: 35.2s\tremaining: 1.97s\n",
            "947:\tlearn: 0.2748349\ttotal: 35.2s\tremaining: 1.93s\n",
            "948:\tlearn: 0.2748100\ttotal: 35.2s\tremaining: 1.89s\n",
            "949:\tlearn: 0.2747814\ttotal: 35.3s\tremaining: 1.86s\n",
            "950:\tlearn: 0.2747375\ttotal: 35.3s\tremaining: 1.82s\n",
            "951:\tlearn: 0.2747040\ttotal: 35.3s\tremaining: 1.78s\n",
            "952:\tlearn: 0.2746687\ttotal: 35.4s\tremaining: 1.74s\n",
            "953:\tlearn: 0.2746389\ttotal: 35.4s\tremaining: 1.71s\n",
            "954:\tlearn: 0.2745978\ttotal: 35.4s\tremaining: 1.67s\n",
            "955:\tlearn: 0.2745654\ttotal: 35.5s\tremaining: 1.63s\n",
            "956:\tlearn: 0.2745395\ttotal: 35.5s\tremaining: 1.59s\n",
            "957:\tlearn: 0.2745083\ttotal: 35.5s\tremaining: 1.56s\n",
            "958:\tlearn: 0.2744879\ttotal: 35.6s\tremaining: 1.52s\n",
            "959:\tlearn: 0.2744555\ttotal: 35.6s\tremaining: 1.48s\n",
            "960:\tlearn: 0.2744242\ttotal: 35.6s\tremaining: 1.45s\n",
            "961:\tlearn: 0.2743974\ttotal: 35.7s\tremaining: 1.41s\n",
            "962:\tlearn: 0.2743649\ttotal: 35.7s\tremaining: 1.37s\n",
            "963:\tlearn: 0.2743390\ttotal: 35.7s\tremaining: 1.33s\n",
            "964:\tlearn: 0.2743086\ttotal: 35.8s\tremaining: 1.3s\n",
            "965:\tlearn: 0.2742899\ttotal: 35.8s\tremaining: 1.26s\n",
            "966:\tlearn: 0.2742615\ttotal: 35.8s\tremaining: 1.22s\n",
            "967:\tlearn: 0.2742283\ttotal: 35.9s\tremaining: 1.19s\n",
            "968:\tlearn: 0.2741985\ttotal: 35.9s\tremaining: 1.15s\n",
            "969:\tlearn: 0.2741756\ttotal: 35.9s\tremaining: 1.11s\n",
            "970:\tlearn: 0.2741490\ttotal: 36s\tremaining: 1.07s\n",
            "971:\tlearn: 0.2741194\ttotal: 36s\tremaining: 1.04s\n",
            "972:\tlearn: 0.2740761\ttotal: 36s\tremaining: 1s\n",
            "973:\tlearn: 0.2740415\ttotal: 36.1s\tremaining: 963ms\n",
            "974:\tlearn: 0.2740140\ttotal: 36.1s\tremaining: 926ms\n",
            "975:\tlearn: 0.2739715\ttotal: 36.1s\tremaining: 889ms\n",
            "976:\tlearn: 0.2739344\ttotal: 36.2s\tremaining: 851ms\n",
            "977:\tlearn: 0.2739029\ttotal: 36.2s\tremaining: 814ms\n",
            "978:\tlearn: 0.2738640\ttotal: 36.2s\tremaining: 777ms\n",
            "979:\tlearn: 0.2738308\ttotal: 36.3s\tremaining: 740ms\n",
            "980:\tlearn: 0.2738000\ttotal: 36.3s\tremaining: 703ms\n",
            "981:\tlearn: 0.2737666\ttotal: 36.3s\tremaining: 666ms\n",
            "982:\tlearn: 0.2737370\ttotal: 36.4s\tremaining: 629ms\n",
            "983:\tlearn: 0.2737047\ttotal: 36.4s\tremaining: 592ms\n",
            "984:\tlearn: 0.2736795\ttotal: 36.4s\tremaining: 555ms\n",
            "985:\tlearn: 0.2736515\ttotal: 36.5s\tremaining: 518ms\n",
            "986:\tlearn: 0.2736041\ttotal: 36.5s\tremaining: 481ms\n",
            "987:\tlearn: 0.2735750\ttotal: 36.5s\tremaining: 444ms\n",
            "988:\tlearn: 0.2735359\ttotal: 36.6s\tremaining: 407ms\n",
            "989:\tlearn: 0.2735033\ttotal: 36.6s\tremaining: 370ms\n",
            "990:\tlearn: 0.2734748\ttotal: 36.6s\tremaining: 333ms\n",
            "991:\tlearn: 0.2734281\ttotal: 36.6s\tremaining: 296ms\n",
            "992:\tlearn: 0.2733887\ttotal: 36.7s\tremaining: 259ms\n",
            "993:\tlearn: 0.2733567\ttotal: 36.7s\tremaining: 222ms\n",
            "994:\tlearn: 0.2733394\ttotal: 36.7s\tremaining: 185ms\n",
            "995:\tlearn: 0.2733137\ttotal: 36.8s\tremaining: 148ms\n",
            "996:\tlearn: 0.2732724\ttotal: 36.8s\tremaining: 111ms\n",
            "997:\tlearn: 0.2732353\ttotal: 36.9s\tremaining: 73.9ms\n",
            "998:\tlearn: 0.2731874\ttotal: 36.9s\tremaining: 36.9ms\n",
            "999:\tlearn: 0.2731470\ttotal: 36.9s\tremaining: 0us\n",
            "15 : 0.8801188978391484\n",
            "Learning rate set to 0.079235\n",
            "0:\tlearn: 0.6239698\ttotal: 31.8ms\tremaining: 31.7s\n",
            "1:\tlearn: 0.5644664\ttotal: 69.8ms\tremaining: 34.9s\n",
            "2:\tlearn: 0.5202763\ttotal: 139ms\tremaining: 46.1s\n",
            "3:\tlearn: 0.4818244\ttotal: 203ms\tremaining: 50.7s\n",
            "4:\tlearn: 0.4535864\ttotal: 270ms\tremaining: 53.7s\n",
            "5:\tlearn: 0.4318711\ttotal: 347ms\tremaining: 57.4s\n",
            "6:\tlearn: 0.4133792\ttotal: 396ms\tremaining: 56.1s\n",
            "7:\tlearn: 0.3969100\ttotal: 479ms\tremaining: 59.4s\n",
            "8:\tlearn: 0.3855463\ttotal: 530ms\tremaining: 58.4s\n",
            "9:\tlearn: 0.3755443\ttotal: 613ms\tremaining: 1m\n",
            "10:\tlearn: 0.3664253\ttotal: 661ms\tremaining: 59.4s\n",
            "11:\tlearn: 0.3600528\ttotal: 723ms\tremaining: 59.5s\n",
            "12:\tlearn: 0.3541721\ttotal: 771ms\tremaining: 58.5s\n",
            "13:\tlearn: 0.3492045\ttotal: 827ms\tremaining: 58.2s\n",
            "14:\tlearn: 0.3448693\ttotal: 912ms\tremaining: 59.9s\n",
            "15:\tlearn: 0.3414687\ttotal: 1s\tremaining: 1m 1s\n",
            "16:\tlearn: 0.3387432\ttotal: 1.06s\tremaining: 1m 1s\n",
            "17:\tlearn: 0.3360328\ttotal: 1.11s\tremaining: 1m\n",
            "18:\tlearn: 0.3336519\ttotal: 1.16s\tremaining: 59.7s\n",
            "19:\tlearn: 0.3315082\ttotal: 1.23s\tremaining: 1m\n",
            "20:\tlearn: 0.3298629\ttotal: 1.31s\tremaining: 1m\n",
            "21:\tlearn: 0.3284601\ttotal: 1.38s\tremaining: 1m 1s\n",
            "22:\tlearn: 0.3271478\ttotal: 1.43s\tremaining: 1m\n",
            "23:\tlearn: 0.3255959\ttotal: 1.48s\tremaining: 1m\n",
            "24:\tlearn: 0.3244694\ttotal: 1.52s\tremaining: 59.5s\n",
            "25:\tlearn: 0.3233861\ttotal: 1.59s\tremaining: 59.5s\n",
            "26:\tlearn: 0.3224574\ttotal: 1.67s\tremaining: 1m\n",
            "27:\tlearn: 0.3215874\ttotal: 1.72s\tremaining: 59.6s\n",
            "28:\tlearn: 0.3207870\ttotal: 1.79s\tremaining: 59.9s\n",
            "29:\tlearn: 0.3201373\ttotal: 1.84s\tremaining: 59.5s\n",
            "30:\tlearn: 0.3195138\ttotal: 1.9s\tremaining: 59.5s\n",
            "31:\tlearn: 0.3189863\ttotal: 1.96s\tremaining: 59.2s\n",
            "32:\tlearn: 0.3183729\ttotal: 2.02s\tremaining: 59.2s\n",
            "33:\tlearn: 0.3178960\ttotal: 2.1s\tremaining: 59.8s\n",
            "34:\tlearn: 0.3174444\ttotal: 2.18s\tremaining: 1m\n",
            "35:\tlearn: 0.3169997\ttotal: 2.24s\tremaining: 1m\n",
            "36:\tlearn: 0.3166537\ttotal: 2.29s\tremaining: 59.6s\n",
            "37:\tlearn: 0.3163149\ttotal: 2.38s\tremaining: 1m\n",
            "38:\tlearn: 0.3159243\ttotal: 2.46s\tremaining: 1m\n",
            "39:\tlearn: 0.3155584\ttotal: 2.54s\tremaining: 1m\n",
            "40:\tlearn: 0.3152449\ttotal: 2.63s\tremaining: 1m 1s\n",
            "41:\tlearn: 0.3149020\ttotal: 2.7s\tremaining: 1m 1s\n",
            "42:\tlearn: 0.3146695\ttotal: 2.79s\tremaining: 1m 2s\n",
            "43:\tlearn: 0.3143849\ttotal: 2.83s\tremaining: 1m 1s\n",
            "44:\tlearn: 0.3141892\ttotal: 2.87s\tremaining: 1m\n",
            "45:\tlearn: 0.3139502\ttotal: 2.9s\tremaining: 1m\n",
            "46:\tlearn: 0.3136788\ttotal: 2.93s\tremaining: 59.5s\n",
            "47:\tlearn: 0.3134643\ttotal: 2.96s\tremaining: 58.8s\n",
            "48:\tlearn: 0.3132219\ttotal: 3s\tremaining: 58.1s\n",
            "49:\tlearn: 0.3130080\ttotal: 3.03s\tremaining: 57.5s\n",
            "50:\tlearn: 0.3126908\ttotal: 3.07s\tremaining: 57.1s\n",
            "51:\tlearn: 0.3124885\ttotal: 3.1s\tremaining: 56.5s\n",
            "52:\tlearn: 0.3123169\ttotal: 3.13s\tremaining: 56s\n",
            "53:\tlearn: 0.3121621\ttotal: 3.17s\tremaining: 55.5s\n",
            "54:\tlearn: 0.3120169\ttotal: 3.2s\tremaining: 55s\n",
            "55:\tlearn: 0.3118278\ttotal: 3.23s\tremaining: 54.4s\n",
            "56:\tlearn: 0.3116658\ttotal: 3.26s\tremaining: 53.9s\n",
            "57:\tlearn: 0.3115011\ttotal: 3.3s\tremaining: 53.6s\n",
            "58:\tlearn: 0.3113690\ttotal: 3.33s\tremaining: 53.1s\n",
            "59:\tlearn: 0.3112229\ttotal: 3.36s\tremaining: 52.7s\n",
            "60:\tlearn: 0.3110640\ttotal: 3.4s\tremaining: 52.4s\n",
            "61:\tlearn: 0.3109646\ttotal: 3.44s\tremaining: 52.1s\n",
            "62:\tlearn: 0.3108474\ttotal: 3.48s\tremaining: 51.7s\n",
            "63:\tlearn: 0.3107127\ttotal: 3.52s\tremaining: 51.4s\n",
            "64:\tlearn: 0.3105907\ttotal: 3.55s\tremaining: 51s\n",
            "65:\tlearn: 0.3104796\ttotal: 3.58s\tremaining: 50.6s\n",
            "66:\tlearn: 0.3103183\ttotal: 3.61s\tremaining: 50.3s\n",
            "67:\tlearn: 0.3102129\ttotal: 3.64s\tremaining: 49.9s\n",
            "68:\tlearn: 0.3100766\ttotal: 3.67s\tremaining: 49.6s\n",
            "69:\tlearn: 0.3100005\ttotal: 3.7s\tremaining: 49.2s\n",
            "70:\tlearn: 0.3098965\ttotal: 3.75s\tremaining: 49s\n",
            "71:\tlearn: 0.3097712\ttotal: 3.78s\tremaining: 48.7s\n",
            "72:\tlearn: 0.3096525\ttotal: 3.81s\tremaining: 48.3s\n",
            "73:\tlearn: 0.3095347\ttotal: 3.84s\tremaining: 48s\n",
            "74:\tlearn: 0.3094625\ttotal: 3.87s\tremaining: 47.7s\n",
            "75:\tlearn: 0.3093403\ttotal: 3.9s\tremaining: 47.4s\n",
            "76:\tlearn: 0.3092290\ttotal: 3.93s\tremaining: 47.1s\n",
            "77:\tlearn: 0.3091179\ttotal: 3.97s\tremaining: 46.9s\n",
            "78:\tlearn: 0.3089965\ttotal: 4s\tremaining: 46.6s\n",
            "79:\tlearn: 0.3088963\ttotal: 4.03s\tremaining: 46.4s\n",
            "80:\tlearn: 0.3088024\ttotal: 4.07s\tremaining: 46.1s\n",
            "81:\tlearn: 0.3087177\ttotal: 4.1s\tremaining: 45.9s\n",
            "82:\tlearn: 0.3086400\ttotal: 4.13s\tremaining: 45.6s\n",
            "83:\tlearn: 0.3085577\ttotal: 4.16s\tremaining: 45.4s\n",
            "84:\tlearn: 0.3084841\ttotal: 4.2s\tremaining: 45.2s\n",
            "85:\tlearn: 0.3084060\ttotal: 4.23s\tremaining: 45s\n",
            "86:\tlearn: 0.3083270\ttotal: 4.26s\tremaining: 44.7s\n",
            "87:\tlearn: 0.3082159\ttotal: 4.29s\tremaining: 44.5s\n",
            "88:\tlearn: 0.3081423\ttotal: 4.32s\tremaining: 44.2s\n",
            "89:\tlearn: 0.3080911\ttotal: 4.35s\tremaining: 44s\n",
            "90:\tlearn: 0.3080321\ttotal: 4.38s\tremaining: 43.8s\n",
            "91:\tlearn: 0.3079359\ttotal: 4.45s\tremaining: 43.9s\n",
            "92:\tlearn: 0.3078519\ttotal: 4.48s\tremaining: 43.7s\n",
            "93:\tlearn: 0.3077834\ttotal: 4.51s\tremaining: 43.5s\n",
            "94:\tlearn: 0.3077019\ttotal: 4.54s\tremaining: 43.3s\n",
            "95:\tlearn: 0.3076123\ttotal: 4.59s\tremaining: 43.2s\n",
            "96:\tlearn: 0.3075502\ttotal: 4.62s\tremaining: 43s\n",
            "97:\tlearn: 0.3074786\ttotal: 4.66s\tremaining: 42.9s\n",
            "98:\tlearn: 0.3074140\ttotal: 4.7s\tremaining: 42.7s\n",
            "99:\tlearn: 0.3073479\ttotal: 4.73s\tremaining: 42.6s\n",
            "100:\tlearn: 0.3072722\ttotal: 4.76s\tremaining: 42.4s\n",
            "101:\tlearn: 0.3072205\ttotal: 4.79s\tremaining: 42.2s\n",
            "102:\tlearn: 0.3071155\ttotal: 4.83s\tremaining: 42s\n",
            "103:\tlearn: 0.3070487\ttotal: 4.86s\tremaining: 41.8s\n",
            "104:\tlearn: 0.3069813\ttotal: 4.9s\tremaining: 41.7s\n",
            "105:\tlearn: 0.3069238\ttotal: 4.93s\tremaining: 41.6s\n",
            "106:\tlearn: 0.3068608\ttotal: 4.96s\tremaining: 41.4s\n",
            "107:\tlearn: 0.3067943\ttotal: 4.99s\tremaining: 41.2s\n",
            "108:\tlearn: 0.3067498\ttotal: 5.02s\tremaining: 41.1s\n",
            "109:\tlearn: 0.3066993\ttotal: 5.05s\tremaining: 40.9s\n",
            "110:\tlearn: 0.3066324\ttotal: 5.08s\tremaining: 40.7s\n",
            "111:\tlearn: 0.3065767\ttotal: 5.13s\tremaining: 40.7s\n",
            "112:\tlearn: 0.3065137\ttotal: 5.16s\tremaining: 40.5s\n",
            "113:\tlearn: 0.3064480\ttotal: 5.19s\tremaining: 40.3s\n",
            "114:\tlearn: 0.3063862\ttotal: 5.22s\tremaining: 40.2s\n",
            "115:\tlearn: 0.3063349\ttotal: 5.25s\tremaining: 40s\n",
            "116:\tlearn: 0.3062679\ttotal: 5.28s\tremaining: 39.9s\n",
            "117:\tlearn: 0.3062020\ttotal: 5.33s\tremaining: 39.8s\n",
            "118:\tlearn: 0.3061624\ttotal: 5.37s\tremaining: 39.7s\n",
            "119:\tlearn: 0.3060827\ttotal: 5.4s\tremaining: 39.6s\n",
            "120:\tlearn: 0.3060173\ttotal: 5.43s\tremaining: 39.4s\n",
            "121:\tlearn: 0.3059638\ttotal: 5.47s\tremaining: 39.4s\n",
            "122:\tlearn: 0.3059118\ttotal: 5.51s\tremaining: 39.3s\n",
            "123:\tlearn: 0.3058677\ttotal: 5.54s\tremaining: 39.1s\n",
            "124:\tlearn: 0.3058220\ttotal: 5.57s\tremaining: 39s\n",
            "125:\tlearn: 0.3057765\ttotal: 5.6s\tremaining: 38.9s\n",
            "126:\tlearn: 0.3057139\ttotal: 5.64s\tremaining: 38.8s\n",
            "127:\tlearn: 0.3056387\ttotal: 5.67s\tremaining: 38.6s\n",
            "128:\tlearn: 0.3055821\ttotal: 5.7s\tremaining: 38.5s\n",
            "129:\tlearn: 0.3055260\ttotal: 5.73s\tremaining: 38.4s\n",
            "130:\tlearn: 0.3054680\ttotal: 5.76s\tremaining: 38.2s\n",
            "131:\tlearn: 0.3054118\ttotal: 5.8s\tremaining: 38.1s\n",
            "132:\tlearn: 0.3053608\ttotal: 5.83s\tremaining: 38s\n",
            "133:\tlearn: 0.3053066\ttotal: 5.86s\tremaining: 37.9s\n",
            "134:\tlearn: 0.3052662\ttotal: 5.89s\tremaining: 37.7s\n",
            "135:\tlearn: 0.3052418\ttotal: 5.92s\tremaining: 37.6s\n",
            "136:\tlearn: 0.3051757\ttotal: 5.95s\tremaining: 37.5s\n",
            "137:\tlearn: 0.3051319\ttotal: 5.98s\tremaining: 37.4s\n",
            "138:\tlearn: 0.3050541\ttotal: 6.02s\tremaining: 37.3s\n",
            "139:\tlearn: 0.3049935\ttotal: 6.05s\tremaining: 37.2s\n",
            "140:\tlearn: 0.3049580\ttotal: 6.08s\tremaining: 37.1s\n",
            "141:\tlearn: 0.3048923\ttotal: 6.11s\tremaining: 36.9s\n",
            "142:\tlearn: 0.3048472\ttotal: 6.14s\tremaining: 36.8s\n",
            "143:\tlearn: 0.3048069\ttotal: 6.17s\tremaining: 36.7s\n",
            "144:\tlearn: 0.3047349\ttotal: 6.2s\tremaining: 36.6s\n",
            "145:\tlearn: 0.3046931\ttotal: 6.24s\tremaining: 36.5s\n",
            "146:\tlearn: 0.3046278\ttotal: 6.28s\tremaining: 36.4s\n",
            "147:\tlearn: 0.3045618\ttotal: 6.3s\tremaining: 36.3s\n",
            "148:\tlearn: 0.3045125\ttotal: 6.33s\tremaining: 36.2s\n",
            "149:\tlearn: 0.3044428\ttotal: 6.37s\tremaining: 36.1s\n",
            "150:\tlearn: 0.3043837\ttotal: 6.4s\tremaining: 36s\n",
            "151:\tlearn: 0.3043190\ttotal: 6.43s\tremaining: 35.9s\n",
            "152:\tlearn: 0.3042814\ttotal: 6.48s\tremaining: 35.9s\n",
            "153:\tlearn: 0.3042124\ttotal: 6.52s\tremaining: 35.8s\n",
            "154:\tlearn: 0.3041637\ttotal: 6.55s\tremaining: 35.7s\n",
            "155:\tlearn: 0.3041051\ttotal: 6.59s\tremaining: 35.6s\n",
            "156:\tlearn: 0.3040414\ttotal: 6.62s\tremaining: 35.5s\n",
            "157:\tlearn: 0.3039832\ttotal: 6.65s\tremaining: 35.4s\n",
            "158:\tlearn: 0.3039239\ttotal: 6.68s\tremaining: 35.3s\n",
            "159:\tlearn: 0.3038681\ttotal: 6.72s\tremaining: 35.3s\n",
            "160:\tlearn: 0.3038130\ttotal: 6.75s\tremaining: 35.2s\n",
            "161:\tlearn: 0.3037608\ttotal: 6.78s\tremaining: 35.1s\n",
            "162:\tlearn: 0.3037087\ttotal: 6.81s\tremaining: 35s\n",
            "163:\tlearn: 0.3036613\ttotal: 6.84s\tremaining: 34.9s\n",
            "164:\tlearn: 0.3036132\ttotal: 6.87s\tremaining: 34.8s\n",
            "165:\tlearn: 0.3035671\ttotal: 6.9s\tremaining: 34.7s\n",
            "166:\tlearn: 0.3035133\ttotal: 6.95s\tremaining: 34.6s\n",
            "167:\tlearn: 0.3034548\ttotal: 6.98s\tremaining: 34.5s\n",
            "168:\tlearn: 0.3033971\ttotal: 7.01s\tremaining: 34.5s\n",
            "169:\tlearn: 0.3033284\ttotal: 7.04s\tremaining: 34.4s\n",
            "170:\tlearn: 0.3032698\ttotal: 7.07s\tremaining: 34.3s\n",
            "171:\tlearn: 0.3032148\ttotal: 7.1s\tremaining: 34.2s\n",
            "172:\tlearn: 0.3031581\ttotal: 7.13s\tremaining: 34.1s\n",
            "173:\tlearn: 0.3030987\ttotal: 7.17s\tremaining: 34s\n",
            "174:\tlearn: 0.3030664\ttotal: 7.19s\tremaining: 33.9s\n",
            "175:\tlearn: 0.3030119\ttotal: 7.23s\tremaining: 33.9s\n",
            "176:\tlearn: 0.3029664\ttotal: 7.26s\tremaining: 33.8s\n",
            "177:\tlearn: 0.3029137\ttotal: 7.29s\tremaining: 33.7s\n",
            "178:\tlearn: 0.3028439\ttotal: 7.32s\tremaining: 33.6s\n",
            "179:\tlearn: 0.3027913\ttotal: 7.35s\tremaining: 33.5s\n",
            "180:\tlearn: 0.3027389\ttotal: 7.39s\tremaining: 33.4s\n",
            "181:\tlearn: 0.3026949\ttotal: 7.42s\tremaining: 33.4s\n",
            "182:\tlearn: 0.3026427\ttotal: 7.45s\tremaining: 33.3s\n",
            "183:\tlearn: 0.3025904\ttotal: 7.49s\tremaining: 33.2s\n",
            "184:\tlearn: 0.3025367\ttotal: 7.53s\tremaining: 33.2s\n",
            "185:\tlearn: 0.3024726\ttotal: 7.56s\tremaining: 33.1s\n",
            "186:\tlearn: 0.3024079\ttotal: 7.59s\tremaining: 33s\n",
            "187:\tlearn: 0.3023591\ttotal: 7.64s\tremaining: 33s\n",
            "188:\tlearn: 0.3023067\ttotal: 7.67s\tremaining: 32.9s\n",
            "189:\tlearn: 0.3022460\ttotal: 7.7s\tremaining: 32.8s\n",
            "190:\tlearn: 0.3021758\ttotal: 7.72s\tremaining: 32.7s\n",
            "191:\tlearn: 0.3020972\ttotal: 7.75s\tremaining: 32.6s\n",
            "192:\tlearn: 0.3020508\ttotal: 7.78s\tremaining: 32.5s\n",
            "193:\tlearn: 0.3020104\ttotal: 7.82s\tremaining: 32.5s\n",
            "194:\tlearn: 0.3019570\ttotal: 7.85s\tremaining: 32.4s\n",
            "195:\tlearn: 0.3018851\ttotal: 7.88s\tremaining: 32.3s\n",
            "196:\tlearn: 0.3018484\ttotal: 7.91s\tremaining: 32.2s\n",
            "197:\tlearn: 0.3017973\ttotal: 7.94s\tremaining: 32.2s\n",
            "198:\tlearn: 0.3017531\ttotal: 7.97s\tremaining: 32.1s\n",
            "199:\tlearn: 0.3016818\ttotal: 8s\tremaining: 32s\n",
            "200:\tlearn: 0.3016269\ttotal: 8.04s\tremaining: 32s\n",
            "201:\tlearn: 0.3015703\ttotal: 8.07s\tremaining: 31.9s\n",
            "202:\tlearn: 0.3015231\ttotal: 8.1s\tremaining: 31.8s\n",
            "203:\tlearn: 0.3014729\ttotal: 8.15s\tremaining: 31.8s\n",
            "204:\tlearn: 0.3014132\ttotal: 8.18s\tremaining: 31.7s\n",
            "205:\tlearn: 0.3013660\ttotal: 8.21s\tremaining: 31.6s\n",
            "206:\tlearn: 0.3013056\ttotal: 8.24s\tremaining: 31.6s\n",
            "207:\tlearn: 0.3012563\ttotal: 8.28s\tremaining: 31.5s\n",
            "208:\tlearn: 0.3012030\ttotal: 8.31s\tremaining: 31.5s\n",
            "209:\tlearn: 0.3011597\ttotal: 8.34s\tremaining: 31.4s\n",
            "210:\tlearn: 0.3011192\ttotal: 8.37s\tremaining: 31.3s\n",
            "211:\tlearn: 0.3010534\ttotal: 8.4s\tremaining: 31.2s\n",
            "212:\tlearn: 0.3009974\ttotal: 8.43s\tremaining: 31.1s\n",
            "213:\tlearn: 0.3009487\ttotal: 8.47s\tremaining: 31.1s\n",
            "214:\tlearn: 0.3009059\ttotal: 8.51s\tremaining: 31.1s\n",
            "215:\tlearn: 0.3008554\ttotal: 8.55s\tremaining: 31s\n",
            "216:\tlearn: 0.3007985\ttotal: 8.58s\tremaining: 31s\n",
            "217:\tlearn: 0.3007551\ttotal: 8.61s\tremaining: 30.9s\n",
            "218:\tlearn: 0.3006989\ttotal: 8.64s\tremaining: 30.8s\n",
            "219:\tlearn: 0.3006619\ttotal: 8.67s\tremaining: 30.8s\n",
            "220:\tlearn: 0.3006251\ttotal: 8.71s\tremaining: 30.7s\n",
            "221:\tlearn: 0.3005650\ttotal: 8.74s\tremaining: 30.6s\n",
            "222:\tlearn: 0.3005049\ttotal: 8.77s\tremaining: 30.6s\n",
            "223:\tlearn: 0.3004560\ttotal: 8.8s\tremaining: 30.5s\n",
            "224:\tlearn: 0.3004029\ttotal: 8.83s\tremaining: 30.4s\n",
            "225:\tlearn: 0.3003729\ttotal: 8.86s\tremaining: 30.3s\n",
            "226:\tlearn: 0.3003184\ttotal: 8.9s\tremaining: 30.3s\n",
            "227:\tlearn: 0.3002721\ttotal: 8.93s\tremaining: 30.2s\n",
            "228:\tlearn: 0.3002222\ttotal: 8.96s\tremaining: 30.2s\n",
            "229:\tlearn: 0.3001763\ttotal: 8.99s\tremaining: 30.1s\n",
            "230:\tlearn: 0.3001184\ttotal: 9.02s\tremaining: 30s\n",
            "231:\tlearn: 0.3000656\ttotal: 9.05s\tremaining: 30s\n",
            "232:\tlearn: 0.3000084\ttotal: 9.08s\tremaining: 29.9s\n",
            "233:\tlearn: 0.2999480\ttotal: 9.13s\tremaining: 29.9s\n",
            "234:\tlearn: 0.2998960\ttotal: 9.16s\tremaining: 29.8s\n",
            "235:\tlearn: 0.2998488\ttotal: 9.19s\tremaining: 29.8s\n",
            "236:\tlearn: 0.2998020\ttotal: 9.22s\tremaining: 29.7s\n",
            "237:\tlearn: 0.2997453\ttotal: 9.25s\tremaining: 29.6s\n",
            "238:\tlearn: 0.2996871\ttotal: 9.28s\tremaining: 29.6s\n",
            "239:\tlearn: 0.2996429\ttotal: 9.31s\tremaining: 29.5s\n",
            "240:\tlearn: 0.2996061\ttotal: 9.36s\tremaining: 29.5s\n",
            "241:\tlearn: 0.2995472\ttotal: 9.38s\tremaining: 29.4s\n",
            "242:\tlearn: 0.2995032\ttotal: 9.41s\tremaining: 29.3s\n",
            "243:\tlearn: 0.2994526\ttotal: 9.44s\tremaining: 29.3s\n",
            "244:\tlearn: 0.2994144\ttotal: 9.48s\tremaining: 29.2s\n",
            "245:\tlearn: 0.2993727\ttotal: 9.52s\tremaining: 29.2s\n",
            "246:\tlearn: 0.2993236\ttotal: 9.57s\tremaining: 29.2s\n",
            "247:\tlearn: 0.2992641\ttotal: 9.6s\tremaining: 29.1s\n",
            "248:\tlearn: 0.2992274\ttotal: 9.63s\tremaining: 29s\n",
            "249:\tlearn: 0.2991846\ttotal: 9.66s\tremaining: 29s\n",
            "250:\tlearn: 0.2991420\ttotal: 9.69s\tremaining: 28.9s\n",
            "251:\tlearn: 0.2990896\ttotal: 9.72s\tremaining: 28.8s\n",
            "252:\tlearn: 0.2990477\ttotal: 9.75s\tremaining: 28.8s\n",
            "253:\tlearn: 0.2990024\ttotal: 9.79s\tremaining: 28.8s\n",
            "254:\tlearn: 0.2989606\ttotal: 9.82s\tremaining: 28.7s\n",
            "255:\tlearn: 0.2989222\ttotal: 9.85s\tremaining: 28.6s\n",
            "256:\tlearn: 0.2988767\ttotal: 9.88s\tremaining: 28.6s\n",
            "257:\tlearn: 0.2988244\ttotal: 9.91s\tremaining: 28.5s\n",
            "258:\tlearn: 0.2987770\ttotal: 9.94s\tremaining: 28.4s\n",
            "259:\tlearn: 0.2987305\ttotal: 9.97s\tremaining: 28.4s\n",
            "260:\tlearn: 0.2986823\ttotal: 10s\tremaining: 28.3s\n",
            "261:\tlearn: 0.2986406\ttotal: 10s\tremaining: 28.3s\n",
            "262:\tlearn: 0.2985894\ttotal: 10.1s\tremaining: 28.2s\n",
            "263:\tlearn: 0.2985375\ttotal: 10.1s\tremaining: 28.2s\n",
            "264:\tlearn: 0.2984886\ttotal: 10.1s\tremaining: 28.1s\n",
            "265:\tlearn: 0.2984518\ttotal: 10.2s\tremaining: 28s\n",
            "266:\tlearn: 0.2983978\ttotal: 10.2s\tremaining: 28s\n",
            "267:\tlearn: 0.2983417\ttotal: 10.2s\tremaining: 27.9s\n",
            "268:\tlearn: 0.2982809\ttotal: 10.3s\tremaining: 27.9s\n",
            "269:\tlearn: 0.2982269\ttotal: 10.3s\tremaining: 27.8s\n",
            "270:\tlearn: 0.2981714\ttotal: 10.3s\tremaining: 27.8s\n",
            "271:\tlearn: 0.2981255\ttotal: 10.4s\tremaining: 27.7s\n",
            "272:\tlearn: 0.2980637\ttotal: 10.4s\tremaining: 27.6s\n",
            "273:\tlearn: 0.2980177\ttotal: 10.4s\tremaining: 27.6s\n",
            "274:\tlearn: 0.2979619\ttotal: 10.5s\tremaining: 27.6s\n",
            "275:\tlearn: 0.2979100\ttotal: 10.5s\tremaining: 27.5s\n",
            "276:\tlearn: 0.2978790\ttotal: 10.5s\tremaining: 27.5s\n",
            "277:\tlearn: 0.2978454\ttotal: 10.6s\tremaining: 27.4s\n",
            "278:\tlearn: 0.2978066\ttotal: 10.6s\tremaining: 27.4s\n",
            "279:\tlearn: 0.2977650\ttotal: 10.6s\tremaining: 27.3s\n",
            "280:\tlearn: 0.2977097\ttotal: 10.7s\tremaining: 27.3s\n",
            "281:\tlearn: 0.2976656\ttotal: 10.7s\tremaining: 27.2s\n",
            "282:\tlearn: 0.2976192\ttotal: 10.7s\tremaining: 27.2s\n",
            "283:\tlearn: 0.2975809\ttotal: 10.8s\tremaining: 27.1s\n",
            "284:\tlearn: 0.2975400\ttotal: 10.8s\tremaining: 27.1s\n",
            "285:\tlearn: 0.2974962\ttotal: 10.8s\tremaining: 27s\n",
            "286:\tlearn: 0.2974534\ttotal: 10.9s\tremaining: 27s\n",
            "287:\tlearn: 0.2974019\ttotal: 10.9s\tremaining: 26.9s\n",
            "288:\tlearn: 0.2973610\ttotal: 10.9s\tremaining: 26.9s\n",
            "289:\tlearn: 0.2973053\ttotal: 11s\tremaining: 26.8s\n",
            "290:\tlearn: 0.2972657\ttotal: 11s\tremaining: 26.8s\n",
            "291:\tlearn: 0.2972183\ttotal: 11s\tremaining: 26.7s\n",
            "292:\tlearn: 0.2971648\ttotal: 11s\tremaining: 26.6s\n",
            "293:\tlearn: 0.2971040\ttotal: 11.1s\tremaining: 26.6s\n",
            "294:\tlearn: 0.2970599\ttotal: 11.1s\tremaining: 26.5s\n",
            "295:\tlearn: 0.2970052\ttotal: 11.2s\tremaining: 26.5s\n",
            "296:\tlearn: 0.2969519\ttotal: 11.2s\tremaining: 26.5s\n",
            "297:\tlearn: 0.2968965\ttotal: 11.2s\tremaining: 26.4s\n",
            "298:\tlearn: 0.2968599\ttotal: 11.2s\tremaining: 26.4s\n",
            "299:\tlearn: 0.2968122\ttotal: 11.3s\tremaining: 26.3s\n",
            "300:\tlearn: 0.2967875\ttotal: 11.3s\tremaining: 26.2s\n",
            "301:\tlearn: 0.2967469\ttotal: 11.3s\tremaining: 26.2s\n",
            "302:\tlearn: 0.2967142\ttotal: 11.4s\tremaining: 26.2s\n",
            "303:\tlearn: 0.2966637\ttotal: 11.4s\tremaining: 26.1s\n",
            "304:\tlearn: 0.2966144\ttotal: 11.4s\tremaining: 26.1s\n",
            "305:\tlearn: 0.2965741\ttotal: 11.5s\tremaining: 26s\n",
            "306:\tlearn: 0.2965252\ttotal: 11.5s\tremaining: 25.9s\n",
            "307:\tlearn: 0.2964726\ttotal: 11.5s\tremaining: 25.9s\n",
            "308:\tlearn: 0.2964340\ttotal: 11.6s\tremaining: 25.9s\n",
            "309:\tlearn: 0.2963880\ttotal: 11.6s\tremaining: 25.8s\n",
            "310:\tlearn: 0.2963421\ttotal: 11.6s\tremaining: 25.8s\n",
            "311:\tlearn: 0.2963022\ttotal: 11.7s\tremaining: 25.7s\n",
            "312:\tlearn: 0.2962638\ttotal: 11.7s\tremaining: 25.7s\n",
            "313:\tlearn: 0.2962321\ttotal: 11.7s\tremaining: 25.6s\n",
            "314:\tlearn: 0.2961879\ttotal: 11.8s\tremaining: 25.6s\n",
            "315:\tlearn: 0.2961340\ttotal: 11.8s\tremaining: 25.5s\n",
            "316:\tlearn: 0.2960958\ttotal: 11.8s\tremaining: 25.5s\n",
            "317:\tlearn: 0.2960573\ttotal: 11.9s\tremaining: 25.5s\n",
            "318:\tlearn: 0.2960136\ttotal: 11.9s\tremaining: 25.4s\n",
            "319:\tlearn: 0.2959735\ttotal: 11.9s\tremaining: 25.4s\n",
            "320:\tlearn: 0.2959231\ttotal: 12s\tremaining: 25.3s\n",
            "321:\tlearn: 0.2958808\ttotal: 12s\tremaining: 25.2s\n",
            "322:\tlearn: 0.2958367\ttotal: 12s\tremaining: 25.2s\n",
            "323:\tlearn: 0.2957979\ttotal: 12.1s\tremaining: 25.2s\n",
            "324:\tlearn: 0.2957530\ttotal: 12.1s\tremaining: 25.1s\n",
            "325:\tlearn: 0.2957104\ttotal: 12.1s\tremaining: 25.1s\n",
            "326:\tlearn: 0.2956537\ttotal: 12.2s\tremaining: 25s\n",
            "327:\tlearn: 0.2956038\ttotal: 12.2s\tremaining: 25s\n",
            "328:\tlearn: 0.2955672\ttotal: 12.2s\tremaining: 24.9s\n",
            "329:\tlearn: 0.2955216\ttotal: 12.2s\tremaining: 24.9s\n",
            "330:\tlearn: 0.2954788\ttotal: 12.3s\tremaining: 24.8s\n",
            "331:\tlearn: 0.2954399\ttotal: 12.3s\tremaining: 24.8s\n",
            "332:\tlearn: 0.2953999\ttotal: 12.3s\tremaining: 24.7s\n",
            "333:\tlearn: 0.2953637\ttotal: 12.4s\tremaining: 24.7s\n",
            "334:\tlearn: 0.2953243\ttotal: 12.4s\tremaining: 24.6s\n",
            "335:\tlearn: 0.2952882\ttotal: 12.4s\tremaining: 24.6s\n",
            "336:\tlearn: 0.2952539\ttotal: 12.5s\tremaining: 24.5s\n",
            "337:\tlearn: 0.2952070\ttotal: 12.5s\tremaining: 24.5s\n",
            "338:\tlearn: 0.2951721\ttotal: 12.5s\tremaining: 24.5s\n",
            "339:\tlearn: 0.2951337\ttotal: 12.6s\tremaining: 24.4s\n",
            "340:\tlearn: 0.2950910\ttotal: 12.6s\tremaining: 24.4s\n",
            "341:\tlearn: 0.2950447\ttotal: 12.7s\tremaining: 24.3s\n",
            "342:\tlearn: 0.2950126\ttotal: 12.7s\tremaining: 24.3s\n",
            "343:\tlearn: 0.2949640\ttotal: 12.8s\tremaining: 24.3s\n",
            "344:\tlearn: 0.2949162\ttotal: 12.8s\tremaining: 24.3s\n",
            "345:\tlearn: 0.2948658\ttotal: 12.9s\tremaining: 24.3s\n",
            "346:\tlearn: 0.2948219\ttotal: 12.9s\tremaining: 24.3s\n",
            "347:\tlearn: 0.2947711\ttotal: 13s\tremaining: 24.4s\n",
            "348:\tlearn: 0.2947270\ttotal: 13.1s\tremaining: 24.4s\n",
            "349:\tlearn: 0.2946910\ttotal: 13.1s\tremaining: 24.4s\n",
            "350:\tlearn: 0.2946427\ttotal: 13.2s\tremaining: 24.4s\n",
            "351:\tlearn: 0.2945965\ttotal: 13.2s\tremaining: 24.4s\n",
            "352:\tlearn: 0.2945283\ttotal: 13.3s\tremaining: 24.3s\n",
            "353:\tlearn: 0.2944956\ttotal: 13.3s\tremaining: 24.3s\n",
            "354:\tlearn: 0.2944471\ttotal: 13.4s\tremaining: 24.3s\n",
            "355:\tlearn: 0.2943930\ttotal: 13.4s\tremaining: 24.3s\n",
            "356:\tlearn: 0.2943476\ttotal: 13.5s\tremaining: 24.4s\n",
            "357:\tlearn: 0.2943097\ttotal: 13.6s\tremaining: 24.4s\n",
            "358:\tlearn: 0.2942718\ttotal: 13.6s\tremaining: 24.4s\n",
            "359:\tlearn: 0.2942181\ttotal: 13.7s\tremaining: 24.3s\n",
            "360:\tlearn: 0.2941831\ttotal: 13.7s\tremaining: 24.3s\n",
            "361:\tlearn: 0.2941419\ttotal: 13.8s\tremaining: 24.3s\n",
            "362:\tlearn: 0.2940990\ttotal: 13.9s\tremaining: 24.3s\n",
            "363:\tlearn: 0.2940374\ttotal: 13.9s\tremaining: 24.4s\n",
            "364:\tlearn: 0.2940045\ttotal: 14s\tremaining: 24.4s\n",
            "365:\tlearn: 0.2939524\ttotal: 14.1s\tremaining: 24.4s\n",
            "366:\tlearn: 0.2938988\ttotal: 14.2s\tremaining: 24.4s\n",
            "367:\tlearn: 0.2938630\ttotal: 14.3s\tremaining: 24.5s\n",
            "368:\tlearn: 0.2938284\ttotal: 14.3s\tremaining: 24.5s\n",
            "369:\tlearn: 0.2937969\ttotal: 14.4s\tremaining: 24.5s\n",
            "370:\tlearn: 0.2937477\ttotal: 14.4s\tremaining: 24.5s\n",
            "371:\tlearn: 0.2937002\ttotal: 14.5s\tremaining: 24.5s\n",
            "372:\tlearn: 0.2936640\ttotal: 14.6s\tremaining: 24.5s\n",
            "373:\tlearn: 0.2936192\ttotal: 14.6s\tremaining: 24.5s\n",
            "374:\tlearn: 0.2935634\ttotal: 14.7s\tremaining: 24.5s\n",
            "375:\tlearn: 0.2935248\ttotal: 14.8s\tremaining: 24.6s\n",
            "376:\tlearn: 0.2934735\ttotal: 14.8s\tremaining: 24.5s\n",
            "377:\tlearn: 0.2934409\ttotal: 14.9s\tremaining: 24.6s\n",
            "378:\tlearn: 0.2934102\ttotal: 15s\tremaining: 24.6s\n",
            "379:\tlearn: 0.2933623\ttotal: 15.1s\tremaining: 24.6s\n",
            "380:\tlearn: 0.2933087\ttotal: 15.1s\tremaining: 24.6s\n",
            "381:\tlearn: 0.2932672\ttotal: 15.2s\tremaining: 24.6s\n",
            "382:\tlearn: 0.2932211\ttotal: 15.3s\tremaining: 24.7s\n",
            "383:\tlearn: 0.2931839\ttotal: 15.4s\tremaining: 24.7s\n",
            "384:\tlearn: 0.2931382\ttotal: 15.4s\tremaining: 24.6s\n",
            "385:\tlearn: 0.2930748\ttotal: 15.4s\tremaining: 24.6s\n",
            "386:\tlearn: 0.2930276\ttotal: 15.5s\tremaining: 24.5s\n",
            "387:\tlearn: 0.2929833\ttotal: 15.5s\tremaining: 24.5s\n",
            "388:\tlearn: 0.2929556\ttotal: 15.5s\tremaining: 24.4s\n",
            "389:\tlearn: 0.2929071\ttotal: 15.6s\tremaining: 24.4s\n",
            "390:\tlearn: 0.2928601\ttotal: 15.6s\tremaining: 24.3s\n",
            "391:\tlearn: 0.2928213\ttotal: 15.6s\tremaining: 24.3s\n",
            "392:\tlearn: 0.2927627\ttotal: 15.7s\tremaining: 24.2s\n",
            "393:\tlearn: 0.2927268\ttotal: 15.7s\tremaining: 24.2s\n",
            "394:\tlearn: 0.2926884\ttotal: 15.8s\tremaining: 24.1s\n",
            "395:\tlearn: 0.2926483\ttotal: 15.8s\tremaining: 24.1s\n",
            "396:\tlearn: 0.2926019\ttotal: 15.8s\tremaining: 24s\n",
            "397:\tlearn: 0.2925632\ttotal: 15.9s\tremaining: 24s\n",
            "398:\tlearn: 0.2925284\ttotal: 15.9s\tremaining: 23.9s\n",
            "399:\tlearn: 0.2924857\ttotal: 15.9s\tremaining: 23.9s\n",
            "400:\tlearn: 0.2924469\ttotal: 15.9s\tremaining: 23.8s\n",
            "401:\tlearn: 0.2924159\ttotal: 16s\tremaining: 23.8s\n",
            "402:\tlearn: 0.2923660\ttotal: 16s\tremaining: 23.7s\n",
            "403:\tlearn: 0.2923259\ttotal: 16s\tremaining: 23.7s\n",
            "404:\tlearn: 0.2922867\ttotal: 16.1s\tremaining: 23.6s\n",
            "405:\tlearn: 0.2922481\ttotal: 16.1s\tremaining: 23.6s\n",
            "406:\tlearn: 0.2922058\ttotal: 16.1s\tremaining: 23.5s\n",
            "407:\tlearn: 0.2921625\ttotal: 16.2s\tremaining: 23.5s\n",
            "408:\tlearn: 0.2921368\ttotal: 16.2s\tremaining: 23.4s\n",
            "409:\tlearn: 0.2921097\ttotal: 16.2s\tremaining: 23.4s\n",
            "410:\tlearn: 0.2920829\ttotal: 16.3s\tremaining: 23.3s\n",
            "411:\tlearn: 0.2920438\ttotal: 16.3s\tremaining: 23.3s\n",
            "412:\tlearn: 0.2919886\ttotal: 16.3s\tremaining: 23.2s\n",
            "413:\tlearn: 0.2919594\ttotal: 16.4s\tremaining: 23.2s\n",
            "414:\tlearn: 0.2919155\ttotal: 16.4s\tremaining: 23.1s\n",
            "415:\tlearn: 0.2918873\ttotal: 16.4s\tremaining: 23.1s\n",
            "416:\tlearn: 0.2918344\ttotal: 16.5s\tremaining: 23s\n",
            "417:\tlearn: 0.2917938\ttotal: 16.5s\tremaining: 23s\n",
            "418:\tlearn: 0.2917453\ttotal: 16.5s\tremaining: 22.9s\n",
            "419:\tlearn: 0.2917138\ttotal: 16.6s\tremaining: 22.9s\n",
            "420:\tlearn: 0.2916751\ttotal: 16.6s\tremaining: 22.8s\n",
            "421:\tlearn: 0.2916381\ttotal: 16.6s\tremaining: 22.8s\n",
            "422:\tlearn: 0.2916041\ttotal: 16.7s\tremaining: 22.7s\n",
            "423:\tlearn: 0.2915510\ttotal: 16.7s\tremaining: 22.7s\n",
            "424:\tlearn: 0.2915102\ttotal: 16.7s\tremaining: 22.6s\n",
            "425:\tlearn: 0.2914647\ttotal: 16.8s\tremaining: 22.6s\n",
            "426:\tlearn: 0.2914263\ttotal: 16.8s\tremaining: 22.6s\n",
            "427:\tlearn: 0.2913932\ttotal: 16.8s\tremaining: 22.5s\n",
            "428:\tlearn: 0.2913504\ttotal: 16.9s\tremaining: 22.5s\n",
            "429:\tlearn: 0.2912960\ttotal: 16.9s\tremaining: 22.4s\n",
            "430:\tlearn: 0.2912551\ttotal: 16.9s\tremaining: 22.3s\n",
            "431:\tlearn: 0.2912230\ttotal: 17s\tremaining: 22.3s\n",
            "432:\tlearn: 0.2911807\ttotal: 17s\tremaining: 22.3s\n",
            "433:\tlearn: 0.2911427\ttotal: 17s\tremaining: 22.2s\n",
            "434:\tlearn: 0.2911052\ttotal: 17.1s\tremaining: 22.2s\n",
            "435:\tlearn: 0.2910611\ttotal: 17.1s\tremaining: 22.1s\n",
            "436:\tlearn: 0.2910153\ttotal: 17.1s\tremaining: 22.1s\n",
            "437:\tlearn: 0.2909656\ttotal: 17.2s\tremaining: 22s\n",
            "438:\tlearn: 0.2909199\ttotal: 17.2s\tremaining: 22s\n",
            "439:\tlearn: 0.2908781\ttotal: 17.2s\tremaining: 21.9s\n",
            "440:\tlearn: 0.2908325\ttotal: 17.3s\tremaining: 21.9s\n",
            "441:\tlearn: 0.2907883\ttotal: 17.3s\tremaining: 21.8s\n",
            "442:\tlearn: 0.2907264\ttotal: 17.3s\tremaining: 21.8s\n",
            "443:\tlearn: 0.2906850\ttotal: 17.3s\tremaining: 21.7s\n",
            "444:\tlearn: 0.2906424\ttotal: 17.4s\tremaining: 21.7s\n",
            "445:\tlearn: 0.2906033\ttotal: 17.4s\tremaining: 21.6s\n",
            "446:\tlearn: 0.2905629\ttotal: 17.4s\tremaining: 21.6s\n",
            "447:\tlearn: 0.2905319\ttotal: 17.5s\tremaining: 21.5s\n",
            "448:\tlearn: 0.2904943\ttotal: 17.5s\tremaining: 21.5s\n",
            "449:\tlearn: 0.2904498\ttotal: 17.5s\tremaining: 21.4s\n",
            "450:\tlearn: 0.2904178\ttotal: 17.6s\tremaining: 21.4s\n",
            "451:\tlearn: 0.2903658\ttotal: 17.6s\tremaining: 21.3s\n",
            "452:\tlearn: 0.2903175\ttotal: 17.6s\tremaining: 21.3s\n",
            "453:\tlearn: 0.2902784\ttotal: 17.7s\tremaining: 21.2s\n",
            "454:\tlearn: 0.2902292\ttotal: 17.7s\tremaining: 21.2s\n",
            "455:\tlearn: 0.2901992\ttotal: 17.8s\tremaining: 21.2s\n",
            "456:\tlearn: 0.2901511\ttotal: 17.8s\tremaining: 21.1s\n",
            "457:\tlearn: 0.2901233\ttotal: 17.8s\tremaining: 21.1s\n",
            "458:\tlearn: 0.2900956\ttotal: 17.8s\tremaining: 21s\n",
            "459:\tlearn: 0.2900422\ttotal: 17.9s\tremaining: 21s\n",
            "460:\tlearn: 0.2899948\ttotal: 17.9s\tremaining: 20.9s\n",
            "461:\tlearn: 0.2899549\ttotal: 17.9s\tremaining: 20.9s\n",
            "462:\tlearn: 0.2899137\ttotal: 18s\tremaining: 20.8s\n",
            "463:\tlearn: 0.2898725\ttotal: 18s\tremaining: 20.8s\n",
            "464:\tlearn: 0.2898200\ttotal: 18s\tremaining: 20.8s\n",
            "465:\tlearn: 0.2897695\ttotal: 18.1s\tremaining: 20.7s\n",
            "466:\tlearn: 0.2897375\ttotal: 18.1s\tremaining: 20.7s\n",
            "467:\tlearn: 0.2896990\ttotal: 18.1s\tremaining: 20.6s\n",
            "468:\tlearn: 0.2896631\ttotal: 18.2s\tremaining: 20.6s\n",
            "469:\tlearn: 0.2896223\ttotal: 18.2s\tremaining: 20.5s\n",
            "470:\tlearn: 0.2895829\ttotal: 18.2s\tremaining: 20.5s\n",
            "471:\tlearn: 0.2895445\ttotal: 18.3s\tremaining: 20.4s\n",
            "472:\tlearn: 0.2894999\ttotal: 18.3s\tremaining: 20.4s\n",
            "473:\tlearn: 0.2894556\ttotal: 18.3s\tremaining: 20.3s\n",
            "474:\tlearn: 0.2894182\ttotal: 18.4s\tremaining: 20.3s\n",
            "475:\tlearn: 0.2893752\ttotal: 18.4s\tremaining: 20.2s\n",
            "476:\tlearn: 0.2893329\ttotal: 18.4s\tremaining: 20.2s\n",
            "477:\tlearn: 0.2892840\ttotal: 18.4s\tremaining: 20.1s\n",
            "478:\tlearn: 0.2892468\ttotal: 18.5s\tremaining: 20.1s\n",
            "479:\tlearn: 0.2892077\ttotal: 18.5s\tremaining: 20.1s\n",
            "480:\tlearn: 0.2891910\ttotal: 18.5s\tremaining: 20s\n",
            "481:\tlearn: 0.2891417\ttotal: 18.6s\tremaining: 20s\n",
            "482:\tlearn: 0.2891043\ttotal: 18.6s\tremaining: 19.9s\n",
            "483:\tlearn: 0.2890677\ttotal: 18.6s\tremaining: 19.9s\n",
            "484:\tlearn: 0.2890271\ttotal: 18.7s\tremaining: 19.8s\n",
            "485:\tlearn: 0.2889850\ttotal: 18.7s\tremaining: 19.8s\n",
            "486:\tlearn: 0.2889543\ttotal: 18.7s\tremaining: 19.7s\n",
            "487:\tlearn: 0.2889123\ttotal: 18.8s\tremaining: 19.7s\n",
            "488:\tlearn: 0.2888682\ttotal: 18.8s\tremaining: 19.7s\n",
            "489:\tlearn: 0.2888357\ttotal: 18.8s\tremaining: 19.6s\n",
            "490:\tlearn: 0.2887979\ttotal: 18.9s\tremaining: 19.6s\n",
            "491:\tlearn: 0.2887673\ttotal: 18.9s\tremaining: 19.5s\n",
            "492:\tlearn: 0.2887209\ttotal: 18.9s\tremaining: 19.5s\n",
            "493:\tlearn: 0.2886775\ttotal: 19s\tremaining: 19.4s\n",
            "494:\tlearn: 0.2886356\ttotal: 19s\tremaining: 19.4s\n",
            "495:\tlearn: 0.2886043\ttotal: 19s\tremaining: 19.3s\n",
            "496:\tlearn: 0.2885520\ttotal: 19.1s\tremaining: 19.3s\n",
            "497:\tlearn: 0.2885227\ttotal: 19.1s\tremaining: 19.2s\n",
            "498:\tlearn: 0.2884841\ttotal: 19.1s\tremaining: 19.2s\n",
            "499:\tlearn: 0.2884530\ttotal: 19.1s\tremaining: 19.1s\n",
            "500:\tlearn: 0.2884045\ttotal: 19.2s\tremaining: 19.1s\n",
            "501:\tlearn: 0.2883507\ttotal: 19.2s\tremaining: 19.1s\n",
            "502:\tlearn: 0.2883073\ttotal: 19.3s\tremaining: 19s\n",
            "503:\tlearn: 0.2882642\ttotal: 19.3s\tremaining: 19s\n",
            "504:\tlearn: 0.2882239\ttotal: 19.3s\tremaining: 18.9s\n",
            "505:\tlearn: 0.2881839\ttotal: 19.4s\tremaining: 18.9s\n",
            "506:\tlearn: 0.2881531\ttotal: 19.4s\tremaining: 18.8s\n",
            "507:\tlearn: 0.2881080\ttotal: 19.4s\tremaining: 18.8s\n",
            "508:\tlearn: 0.2880699\ttotal: 19.5s\tremaining: 18.8s\n",
            "509:\tlearn: 0.2880236\ttotal: 19.5s\tremaining: 18.7s\n",
            "510:\tlearn: 0.2879861\ttotal: 19.5s\tremaining: 18.7s\n",
            "511:\tlearn: 0.2879540\ttotal: 19.5s\tremaining: 18.6s\n",
            "512:\tlearn: 0.2879156\ttotal: 19.6s\tremaining: 18.6s\n",
            "513:\tlearn: 0.2878839\ttotal: 19.6s\tremaining: 18.5s\n",
            "514:\tlearn: 0.2878540\ttotal: 19.6s\tremaining: 18.5s\n",
            "515:\tlearn: 0.2878084\ttotal: 19.7s\tremaining: 18.5s\n",
            "516:\tlearn: 0.2877797\ttotal: 19.7s\tremaining: 18.4s\n",
            "517:\tlearn: 0.2877533\ttotal: 19.8s\tremaining: 18.4s\n",
            "518:\tlearn: 0.2877230\ttotal: 19.8s\tremaining: 18.3s\n",
            "519:\tlearn: 0.2876911\ttotal: 19.8s\tremaining: 18.3s\n",
            "520:\tlearn: 0.2876451\ttotal: 19.8s\tremaining: 18.2s\n",
            "521:\tlearn: 0.2876090\ttotal: 19.9s\tremaining: 18.2s\n",
            "522:\tlearn: 0.2875642\ttotal: 19.9s\tremaining: 18.2s\n",
            "523:\tlearn: 0.2875419\ttotal: 19.9s\tremaining: 18.1s\n",
            "524:\tlearn: 0.2875091\ttotal: 20s\tremaining: 18.1s\n",
            "525:\tlearn: 0.2874610\ttotal: 20s\tremaining: 18s\n",
            "526:\tlearn: 0.2874303\ttotal: 20s\tremaining: 18s\n",
            "527:\tlearn: 0.2873999\ttotal: 20.1s\tremaining: 17.9s\n",
            "528:\tlearn: 0.2873608\ttotal: 20.1s\tremaining: 17.9s\n",
            "529:\tlearn: 0.2873347\ttotal: 20.1s\tremaining: 17.9s\n",
            "530:\tlearn: 0.2872991\ttotal: 20.2s\tremaining: 17.8s\n",
            "531:\tlearn: 0.2872689\ttotal: 20.2s\tremaining: 17.8s\n",
            "532:\tlearn: 0.2872370\ttotal: 20.2s\tremaining: 17.7s\n",
            "533:\tlearn: 0.2872139\ttotal: 20.3s\tremaining: 17.7s\n",
            "534:\tlearn: 0.2871824\ttotal: 20.3s\tremaining: 17.6s\n",
            "535:\tlearn: 0.2871373\ttotal: 20.3s\tremaining: 17.6s\n",
            "536:\tlearn: 0.2870901\ttotal: 20.4s\tremaining: 17.6s\n",
            "537:\tlearn: 0.2870588\ttotal: 20.4s\tremaining: 17.5s\n",
            "538:\tlearn: 0.2870202\ttotal: 20.4s\tremaining: 17.5s\n",
            "539:\tlearn: 0.2869855\ttotal: 20.5s\tremaining: 17.4s\n",
            "540:\tlearn: 0.2869380\ttotal: 20.5s\tremaining: 17.4s\n",
            "541:\tlearn: 0.2868968\ttotal: 20.5s\tremaining: 17.3s\n",
            "542:\tlearn: 0.2868629\ttotal: 20.5s\tremaining: 17.3s\n",
            "543:\tlearn: 0.2868140\ttotal: 20.6s\tremaining: 17.3s\n",
            "544:\tlearn: 0.2867857\ttotal: 20.6s\tremaining: 17.2s\n",
            "545:\tlearn: 0.2867431\ttotal: 20.6s\tremaining: 17.2s\n",
            "546:\tlearn: 0.2867065\ttotal: 20.7s\tremaining: 17.1s\n",
            "547:\tlearn: 0.2866735\ttotal: 20.7s\tremaining: 17.1s\n",
            "548:\tlearn: 0.2866450\ttotal: 20.8s\tremaining: 17s\n",
            "549:\tlearn: 0.2866074\ttotal: 20.8s\tremaining: 17s\n",
            "550:\tlearn: 0.2865747\ttotal: 20.8s\tremaining: 17s\n",
            "551:\tlearn: 0.2865406\ttotal: 20.9s\tremaining: 16.9s\n",
            "552:\tlearn: 0.2865024\ttotal: 20.9s\tremaining: 16.9s\n",
            "553:\tlearn: 0.2864520\ttotal: 20.9s\tremaining: 16.8s\n",
            "554:\tlearn: 0.2864090\ttotal: 20.9s\tremaining: 16.8s\n",
            "555:\tlearn: 0.2863646\ttotal: 21s\tremaining: 16.8s\n",
            "556:\tlearn: 0.2863388\ttotal: 21s\tremaining: 16.7s\n",
            "557:\tlearn: 0.2863045\ttotal: 21s\tremaining: 16.7s\n",
            "558:\tlearn: 0.2862602\ttotal: 21.1s\tremaining: 16.6s\n",
            "559:\tlearn: 0.2862249\ttotal: 21.1s\tremaining: 16.6s\n",
            "560:\tlearn: 0.2861915\ttotal: 21.1s\tremaining: 16.5s\n",
            "561:\tlearn: 0.2861542\ttotal: 21.2s\tremaining: 16.5s\n",
            "562:\tlearn: 0.2861071\ttotal: 21.2s\tremaining: 16.5s\n",
            "563:\tlearn: 0.2860693\ttotal: 21.2s\tremaining: 16.4s\n",
            "564:\tlearn: 0.2860264\ttotal: 21.3s\tremaining: 16.4s\n",
            "565:\tlearn: 0.2859962\ttotal: 21.3s\tremaining: 16.3s\n",
            "566:\tlearn: 0.2859737\ttotal: 21.3s\tremaining: 16.3s\n",
            "567:\tlearn: 0.2859260\ttotal: 21.4s\tremaining: 16.3s\n",
            "568:\tlearn: 0.2858842\ttotal: 21.4s\tremaining: 16.2s\n",
            "569:\tlearn: 0.2858426\ttotal: 21.4s\tremaining: 16.2s\n",
            "570:\tlearn: 0.2858154\ttotal: 21.5s\tremaining: 16.1s\n",
            "571:\tlearn: 0.2857782\ttotal: 21.5s\tremaining: 16.1s\n",
            "572:\tlearn: 0.2857466\ttotal: 21.5s\tremaining: 16s\n",
            "573:\tlearn: 0.2857167\ttotal: 21.6s\tremaining: 16s\n",
            "574:\tlearn: 0.2856681\ttotal: 21.6s\tremaining: 16s\n",
            "575:\tlearn: 0.2856363\ttotal: 21.6s\tremaining: 15.9s\n",
            "576:\tlearn: 0.2856073\ttotal: 21.7s\tremaining: 15.9s\n",
            "577:\tlearn: 0.2855745\ttotal: 21.7s\tremaining: 15.8s\n",
            "578:\tlearn: 0.2855346\ttotal: 21.7s\tremaining: 15.8s\n",
            "579:\tlearn: 0.2855039\ttotal: 21.8s\tremaining: 15.8s\n",
            "580:\tlearn: 0.2854493\ttotal: 21.8s\tremaining: 15.7s\n",
            "581:\tlearn: 0.2854015\ttotal: 21.8s\tremaining: 15.7s\n",
            "582:\tlearn: 0.2853557\ttotal: 21.9s\tremaining: 15.6s\n",
            "583:\tlearn: 0.2853167\ttotal: 21.9s\tremaining: 15.6s\n",
            "584:\tlearn: 0.2852830\ttotal: 21.9s\tremaining: 15.6s\n",
            "585:\tlearn: 0.2852444\ttotal: 22s\tremaining: 15.5s\n",
            "586:\tlearn: 0.2852157\ttotal: 22s\tremaining: 15.5s\n",
            "587:\tlearn: 0.2851679\ttotal: 22s\tremaining: 15.4s\n",
            "588:\tlearn: 0.2851221\ttotal: 22.1s\tremaining: 15.4s\n",
            "589:\tlearn: 0.2850787\ttotal: 22.1s\tremaining: 15.3s\n",
            "590:\tlearn: 0.2850343\ttotal: 22.1s\tremaining: 15.3s\n",
            "591:\tlearn: 0.2850072\ttotal: 22.2s\tremaining: 15.3s\n",
            "592:\tlearn: 0.2849711\ttotal: 22.2s\tremaining: 15.2s\n",
            "593:\tlearn: 0.2849315\ttotal: 22.2s\tremaining: 15.2s\n",
            "594:\tlearn: 0.2849005\ttotal: 22.3s\tremaining: 15.1s\n",
            "595:\tlearn: 0.2848588\ttotal: 22.3s\tremaining: 15.1s\n",
            "596:\tlearn: 0.2848327\ttotal: 22.3s\tremaining: 15.1s\n",
            "597:\tlearn: 0.2847888\ttotal: 22.3s\tremaining: 15s\n",
            "598:\tlearn: 0.2847494\ttotal: 22.4s\tremaining: 15s\n",
            "599:\tlearn: 0.2847140\ttotal: 22.4s\tremaining: 14.9s\n",
            "600:\tlearn: 0.2846819\ttotal: 22.4s\tremaining: 14.9s\n",
            "601:\tlearn: 0.2846403\ttotal: 22.5s\tremaining: 14.9s\n",
            "602:\tlearn: 0.2845830\ttotal: 22.5s\tremaining: 14.8s\n",
            "603:\tlearn: 0.2845508\ttotal: 22.5s\tremaining: 14.8s\n",
            "604:\tlearn: 0.2845111\ttotal: 22.6s\tremaining: 14.7s\n",
            "605:\tlearn: 0.2844640\ttotal: 22.6s\tremaining: 14.7s\n",
            "606:\tlearn: 0.2844186\ttotal: 22.6s\tremaining: 14.7s\n",
            "607:\tlearn: 0.2843695\ttotal: 22.7s\tremaining: 14.6s\n",
            "608:\tlearn: 0.2843174\ttotal: 22.7s\tremaining: 14.6s\n",
            "609:\tlearn: 0.2842791\ttotal: 22.7s\tremaining: 14.5s\n",
            "610:\tlearn: 0.2842431\ttotal: 22.8s\tremaining: 14.5s\n",
            "611:\tlearn: 0.2842211\ttotal: 22.8s\tremaining: 14.5s\n",
            "612:\tlearn: 0.2841790\ttotal: 22.9s\tremaining: 14.4s\n",
            "613:\tlearn: 0.2841337\ttotal: 22.9s\tremaining: 14.4s\n",
            "614:\tlearn: 0.2840804\ttotal: 22.9s\tremaining: 14.3s\n",
            "615:\tlearn: 0.2840522\ttotal: 22.9s\tremaining: 14.3s\n",
            "616:\tlearn: 0.2840138\ttotal: 23s\tremaining: 14.3s\n",
            "617:\tlearn: 0.2839826\ttotal: 23s\tremaining: 14.2s\n",
            "618:\tlearn: 0.2839324\ttotal: 23.1s\tremaining: 14.2s\n",
            "619:\tlearn: 0.2839018\ttotal: 23.1s\tremaining: 14.1s\n",
            "620:\tlearn: 0.2838745\ttotal: 23.1s\tremaining: 14.1s\n",
            "621:\tlearn: 0.2838317\ttotal: 23.1s\tremaining: 14.1s\n",
            "622:\tlearn: 0.2838081\ttotal: 23.2s\tremaining: 14s\n",
            "623:\tlearn: 0.2837753\ttotal: 23.2s\tremaining: 14s\n",
            "624:\tlearn: 0.2837492\ttotal: 23.2s\tremaining: 13.9s\n",
            "625:\tlearn: 0.2837158\ttotal: 23.3s\tremaining: 13.9s\n",
            "626:\tlearn: 0.2836731\ttotal: 23.3s\tremaining: 13.9s\n",
            "627:\tlearn: 0.2836392\ttotal: 23.3s\tremaining: 13.8s\n",
            "628:\tlearn: 0.2836087\ttotal: 23.4s\tremaining: 13.8s\n",
            "629:\tlearn: 0.2835816\ttotal: 23.4s\tremaining: 13.7s\n",
            "630:\tlearn: 0.2835452\ttotal: 23.4s\tremaining: 13.7s\n",
            "631:\tlearn: 0.2835126\ttotal: 23.5s\tremaining: 13.7s\n",
            "632:\tlearn: 0.2834783\ttotal: 23.5s\tremaining: 13.6s\n",
            "633:\tlearn: 0.2834442\ttotal: 23.5s\tremaining: 13.6s\n",
            "634:\tlearn: 0.2834108\ttotal: 23.6s\tremaining: 13.5s\n",
            "635:\tlearn: 0.2833765\ttotal: 23.6s\tremaining: 13.5s\n",
            "636:\tlearn: 0.2833501\ttotal: 23.6s\tremaining: 13.5s\n",
            "637:\tlearn: 0.2833211\ttotal: 23.7s\tremaining: 13.4s\n",
            "638:\tlearn: 0.2832908\ttotal: 23.7s\tremaining: 13.4s\n",
            "639:\tlearn: 0.2832499\ttotal: 23.7s\tremaining: 13.3s\n",
            "640:\tlearn: 0.2832037\ttotal: 23.8s\tremaining: 13.3s\n",
            "641:\tlearn: 0.2831698\ttotal: 23.8s\tremaining: 13.3s\n",
            "642:\tlearn: 0.2831295\ttotal: 23.8s\tremaining: 13.2s\n",
            "643:\tlearn: 0.2831028\ttotal: 23.9s\tremaining: 13.2s\n",
            "644:\tlearn: 0.2830477\ttotal: 23.9s\tremaining: 13.2s\n",
            "645:\tlearn: 0.2830134\ttotal: 23.9s\tremaining: 13.1s\n",
            "646:\tlearn: 0.2829730\ttotal: 24s\tremaining: 13.1s\n",
            "647:\tlearn: 0.2829259\ttotal: 24s\tremaining: 13s\n",
            "648:\tlearn: 0.2828826\ttotal: 24s\tremaining: 13s\n",
            "649:\tlearn: 0.2828414\ttotal: 24.1s\tremaining: 13s\n",
            "650:\tlearn: 0.2828139\ttotal: 24.1s\tremaining: 12.9s\n",
            "651:\tlearn: 0.2827618\ttotal: 24.1s\tremaining: 12.9s\n",
            "652:\tlearn: 0.2827154\ttotal: 24.2s\tremaining: 12.8s\n",
            "653:\tlearn: 0.2826864\ttotal: 24.2s\tremaining: 12.8s\n",
            "654:\tlearn: 0.2826522\ttotal: 24.2s\tremaining: 12.8s\n",
            "655:\tlearn: 0.2826160\ttotal: 24.3s\tremaining: 12.7s\n",
            "656:\tlearn: 0.2825727\ttotal: 24.3s\tremaining: 12.7s\n",
            "657:\tlearn: 0.2825374\ttotal: 24.3s\tremaining: 12.6s\n",
            "658:\tlearn: 0.2824970\ttotal: 24.4s\tremaining: 12.6s\n",
            "659:\tlearn: 0.2824751\ttotal: 24.4s\tremaining: 12.6s\n",
            "660:\tlearn: 0.2824317\ttotal: 24.4s\tremaining: 12.5s\n",
            "661:\tlearn: 0.2824043\ttotal: 24.5s\tremaining: 12.5s\n",
            "662:\tlearn: 0.2823653\ttotal: 24.5s\tremaining: 12.5s\n",
            "663:\tlearn: 0.2823249\ttotal: 24.5s\tremaining: 12.4s\n",
            "664:\tlearn: 0.2823022\ttotal: 24.6s\tremaining: 12.4s\n",
            "665:\tlearn: 0.2822592\ttotal: 24.6s\tremaining: 12.3s\n",
            "666:\tlearn: 0.2822321\ttotal: 24.6s\tremaining: 12.3s\n",
            "667:\tlearn: 0.2821865\ttotal: 24.7s\tremaining: 12.3s\n",
            "668:\tlearn: 0.2821597\ttotal: 24.7s\tremaining: 12.2s\n",
            "669:\tlearn: 0.2821202\ttotal: 24.7s\tremaining: 12.2s\n",
            "670:\tlearn: 0.2820866\ttotal: 24.7s\tremaining: 12.1s\n",
            "671:\tlearn: 0.2820490\ttotal: 24.8s\tremaining: 12.1s\n",
            "672:\tlearn: 0.2820133\ttotal: 24.8s\tremaining: 12.1s\n",
            "673:\tlearn: 0.2819763\ttotal: 24.9s\tremaining: 12s\n",
            "674:\tlearn: 0.2819458\ttotal: 24.9s\tremaining: 12s\n",
            "675:\tlearn: 0.2819170\ttotal: 24.9s\tremaining: 11.9s\n",
            "676:\tlearn: 0.2818860\ttotal: 25s\tremaining: 11.9s\n",
            "677:\tlearn: 0.2818551\ttotal: 25s\tremaining: 11.9s\n",
            "678:\tlearn: 0.2818103\ttotal: 25s\tremaining: 11.8s\n",
            "679:\tlearn: 0.2817672\ttotal: 25.1s\tremaining: 11.8s\n",
            "680:\tlearn: 0.2817423\ttotal: 25.1s\tremaining: 11.8s\n",
            "681:\tlearn: 0.2817056\ttotal: 25.1s\tremaining: 11.7s\n",
            "682:\tlearn: 0.2816720\ttotal: 25.2s\tremaining: 11.7s\n",
            "683:\tlearn: 0.2816390\ttotal: 25.2s\tremaining: 11.6s\n",
            "684:\tlearn: 0.2815967\ttotal: 25.2s\tremaining: 11.6s\n",
            "685:\tlearn: 0.2815621\ttotal: 25.2s\tremaining: 11.6s\n",
            "686:\tlearn: 0.2815316\ttotal: 25.3s\tremaining: 11.5s\n",
            "687:\tlearn: 0.2815018\ttotal: 25.4s\tremaining: 11.5s\n",
            "688:\tlearn: 0.2814650\ttotal: 25.4s\tremaining: 11.5s\n",
            "689:\tlearn: 0.2814198\ttotal: 25.5s\tremaining: 11.4s\n",
            "690:\tlearn: 0.2813815\ttotal: 25.5s\tremaining: 11.4s\n",
            "691:\tlearn: 0.2813312\ttotal: 25.6s\tremaining: 11.4s\n",
            "692:\tlearn: 0.2813001\ttotal: 25.7s\tremaining: 11.4s\n",
            "693:\tlearn: 0.2812707\ttotal: 25.8s\tremaining: 11.4s\n",
            "694:\tlearn: 0.2812415\ttotal: 25.8s\tremaining: 11.3s\n",
            "695:\tlearn: 0.2811986\ttotal: 25.9s\tremaining: 11.3s\n",
            "696:\tlearn: 0.2811753\ttotal: 26s\tremaining: 11.3s\n",
            "697:\tlearn: 0.2811411\ttotal: 26.1s\tremaining: 11.3s\n",
            "698:\tlearn: 0.2811054\ttotal: 26.2s\tremaining: 11.3s\n",
            "699:\tlearn: 0.2810741\ttotal: 26.2s\tremaining: 11.2s\n",
            "700:\tlearn: 0.2810503\ttotal: 26.3s\tremaining: 11.2s\n",
            "701:\tlearn: 0.2810160\ttotal: 26.3s\tremaining: 11.2s\n",
            "702:\tlearn: 0.2809808\ttotal: 26.4s\tremaining: 11.1s\n",
            "703:\tlearn: 0.2809539\ttotal: 26.4s\tremaining: 11.1s\n",
            "704:\tlearn: 0.2809171\ttotal: 26.5s\tremaining: 11.1s\n",
            "705:\tlearn: 0.2808943\ttotal: 26.5s\tremaining: 11.1s\n",
            "706:\tlearn: 0.2808657\ttotal: 26.6s\tremaining: 11s\n",
            "707:\tlearn: 0.2808308\ttotal: 26.7s\tremaining: 11s\n",
            "708:\tlearn: 0.2808015\ttotal: 26.8s\tremaining: 11s\n",
            "709:\tlearn: 0.2807634\ttotal: 26.8s\tremaining: 11s\n",
            "710:\tlearn: 0.2807345\ttotal: 26.9s\tremaining: 10.9s\n",
            "711:\tlearn: 0.2806983\ttotal: 27s\tremaining: 10.9s\n",
            "712:\tlearn: 0.2806685\ttotal: 27s\tremaining: 10.9s\n",
            "713:\tlearn: 0.2806266\ttotal: 27.1s\tremaining: 10.9s\n",
            "714:\tlearn: 0.2806006\ttotal: 27.2s\tremaining: 10.8s\n",
            "715:\tlearn: 0.2805744\ttotal: 27.2s\tremaining: 10.8s\n",
            "716:\tlearn: 0.2805441\ttotal: 27.3s\tremaining: 10.8s\n",
            "717:\tlearn: 0.2805210\ttotal: 27.3s\tremaining: 10.7s\n",
            "718:\tlearn: 0.2804772\ttotal: 27.4s\tremaining: 10.7s\n",
            "719:\tlearn: 0.2804221\ttotal: 27.5s\tremaining: 10.7s\n",
            "720:\tlearn: 0.2803996\ttotal: 27.6s\tremaining: 10.7s\n",
            "721:\tlearn: 0.2803672\ttotal: 27.6s\tremaining: 10.6s\n",
            "722:\tlearn: 0.2803355\ttotal: 27.7s\tremaining: 10.6s\n",
            "723:\tlearn: 0.2802932\ttotal: 27.8s\tremaining: 10.6s\n",
            "724:\tlearn: 0.2802640\ttotal: 27.9s\tremaining: 10.6s\n",
            "725:\tlearn: 0.2802346\ttotal: 27.9s\tremaining: 10.5s\n",
            "726:\tlearn: 0.2801995\ttotal: 28s\tremaining: 10.5s\n",
            "727:\tlearn: 0.2801664\ttotal: 28s\tremaining: 10.5s\n",
            "728:\tlearn: 0.2801381\ttotal: 28s\tremaining: 10.4s\n",
            "729:\tlearn: 0.2800975\ttotal: 28.1s\tremaining: 10.4s\n",
            "730:\tlearn: 0.2800545\ttotal: 28.1s\tremaining: 10.3s\n",
            "731:\tlearn: 0.2800282\ttotal: 28.1s\tremaining: 10.3s\n",
            "732:\tlearn: 0.2799878\ttotal: 28.2s\tremaining: 10.3s\n",
            "733:\tlearn: 0.2799544\ttotal: 28.2s\tremaining: 10.2s\n",
            "734:\tlearn: 0.2799268\ttotal: 28.2s\tremaining: 10.2s\n",
            "735:\tlearn: 0.2798908\ttotal: 28.3s\tremaining: 10.1s\n",
            "736:\tlearn: 0.2798394\ttotal: 28.3s\tremaining: 10.1s\n",
            "737:\tlearn: 0.2798005\ttotal: 28.3s\tremaining: 10.1s\n",
            "738:\tlearn: 0.2797770\ttotal: 28.4s\tremaining: 10s\n",
            "739:\tlearn: 0.2797302\ttotal: 28.4s\tremaining: 9.98s\n",
            "740:\tlearn: 0.2796821\ttotal: 28.4s\tremaining: 9.94s\n",
            "741:\tlearn: 0.2796457\ttotal: 28.5s\tremaining: 9.9s\n",
            "742:\tlearn: 0.2796178\ttotal: 28.5s\tremaining: 9.86s\n",
            "743:\tlearn: 0.2795879\ttotal: 28.5s\tremaining: 9.81s\n",
            "744:\tlearn: 0.2795612\ttotal: 28.6s\tremaining: 9.78s\n",
            "745:\tlearn: 0.2795118\ttotal: 28.6s\tremaining: 9.73s\n",
            "746:\tlearn: 0.2794572\ttotal: 28.6s\tremaining: 9.69s\n",
            "747:\tlearn: 0.2794319\ttotal: 28.7s\tremaining: 9.65s\n",
            "748:\tlearn: 0.2793874\ttotal: 28.7s\tremaining: 9.61s\n",
            "749:\tlearn: 0.2793461\ttotal: 28.7s\tremaining: 9.57s\n",
            "750:\tlearn: 0.2793064\ttotal: 28.8s\tremaining: 9.53s\n",
            "751:\tlearn: 0.2792798\ttotal: 28.8s\tremaining: 9.49s\n",
            "752:\tlearn: 0.2792572\ttotal: 28.8s\tremaining: 9.45s\n",
            "753:\tlearn: 0.2792174\ttotal: 28.9s\tremaining: 9.41s\n",
            "754:\tlearn: 0.2791992\ttotal: 28.9s\tremaining: 9.37s\n",
            "755:\tlearn: 0.2791657\ttotal: 28.9s\tremaining: 9.34s\n",
            "756:\tlearn: 0.2791191\ttotal: 29s\tremaining: 9.29s\n",
            "757:\tlearn: 0.2790827\ttotal: 29s\tremaining: 9.25s\n",
            "758:\tlearn: 0.2790508\ttotal: 29s\tremaining: 9.22s\n",
            "759:\tlearn: 0.2790052\ttotal: 29.1s\tremaining: 9.18s\n",
            "760:\tlearn: 0.2789735\ttotal: 29.1s\tremaining: 9.14s\n",
            "761:\tlearn: 0.2789384\ttotal: 29.1s\tremaining: 9.1s\n",
            "762:\tlearn: 0.2788973\ttotal: 29.2s\tremaining: 9.05s\n",
            "763:\tlearn: 0.2788663\ttotal: 29.2s\tremaining: 9.01s\n",
            "764:\tlearn: 0.2788401\ttotal: 29.2s\tremaining: 8.97s\n",
            "765:\tlearn: 0.2788063\ttotal: 29.3s\tremaining: 8.94s\n",
            "766:\tlearn: 0.2787722\ttotal: 29.3s\tremaining: 8.9s\n",
            "767:\tlearn: 0.2787328\ttotal: 29.3s\tremaining: 8.86s\n",
            "768:\tlearn: 0.2787137\ttotal: 29.3s\tremaining: 8.81s\n",
            "769:\tlearn: 0.2786705\ttotal: 29.4s\tremaining: 8.78s\n",
            "770:\tlearn: 0.2786374\ttotal: 29.4s\tremaining: 8.74s\n",
            "771:\tlearn: 0.2785985\ttotal: 29.4s\tremaining: 8.7s\n",
            "772:\tlearn: 0.2785632\ttotal: 29.5s\tremaining: 8.66s\n",
            "773:\tlearn: 0.2785296\ttotal: 29.5s\tremaining: 8.62s\n",
            "774:\tlearn: 0.2785010\ttotal: 29.5s\tremaining: 8.58s\n",
            "775:\tlearn: 0.2784722\ttotal: 29.6s\tremaining: 8.54s\n",
            "776:\tlearn: 0.2784383\ttotal: 29.6s\tremaining: 8.5s\n",
            "777:\tlearn: 0.2784061\ttotal: 29.6s\tremaining: 8.46s\n",
            "778:\tlearn: 0.2783753\ttotal: 29.7s\tremaining: 8.41s\n",
            "779:\tlearn: 0.2783220\ttotal: 29.7s\tremaining: 8.38s\n",
            "780:\tlearn: 0.2782815\ttotal: 29.7s\tremaining: 8.34s\n",
            "781:\tlearn: 0.2782514\ttotal: 29.8s\tremaining: 8.3s\n",
            "782:\tlearn: 0.2782196\ttotal: 29.8s\tremaining: 8.26s\n",
            "783:\tlearn: 0.2781768\ttotal: 29.8s\tremaining: 8.22s\n",
            "784:\tlearn: 0.2781459\ttotal: 29.9s\tremaining: 8.18s\n",
            "785:\tlearn: 0.2781203\ttotal: 29.9s\tremaining: 8.14s\n",
            "786:\tlearn: 0.2780847\ttotal: 29.9s\tremaining: 8.11s\n",
            "787:\tlearn: 0.2780477\ttotal: 30s\tremaining: 8.06s\n",
            "788:\tlearn: 0.2780220\ttotal: 30s\tremaining: 8.03s\n",
            "789:\tlearn: 0.2779944\ttotal: 30s\tremaining: 7.99s\n",
            "790:\tlearn: 0.2779482\ttotal: 30.1s\tremaining: 7.95s\n",
            "791:\tlearn: 0.2779083\ttotal: 30.1s\tremaining: 7.91s\n",
            "792:\tlearn: 0.2778809\ttotal: 30.1s\tremaining: 7.87s\n",
            "793:\tlearn: 0.2778511\ttotal: 30.2s\tremaining: 7.83s\n",
            "794:\tlearn: 0.2778137\ttotal: 30.2s\tremaining: 7.79s\n",
            "795:\tlearn: 0.2777589\ttotal: 30.2s\tremaining: 7.75s\n",
            "796:\tlearn: 0.2777263\ttotal: 30.3s\tremaining: 7.71s\n",
            "797:\tlearn: 0.2776839\ttotal: 30.3s\tremaining: 7.67s\n",
            "798:\tlearn: 0.2776474\ttotal: 30.3s\tremaining: 7.63s\n",
            "799:\tlearn: 0.2776157\ttotal: 30.4s\tremaining: 7.59s\n",
            "800:\tlearn: 0.2775944\ttotal: 30.4s\tremaining: 7.55s\n",
            "801:\tlearn: 0.2775595\ttotal: 30.4s\tremaining: 7.51s\n",
            "802:\tlearn: 0.2775266\ttotal: 30.5s\tremaining: 7.47s\n",
            "803:\tlearn: 0.2774834\ttotal: 30.5s\tremaining: 7.43s\n",
            "804:\tlearn: 0.2774485\ttotal: 30.5s\tremaining: 7.39s\n",
            "805:\tlearn: 0.2774089\ttotal: 30.6s\tremaining: 7.36s\n",
            "806:\tlearn: 0.2773867\ttotal: 30.6s\tremaining: 7.32s\n",
            "807:\tlearn: 0.2773416\ttotal: 30.6s\tremaining: 7.28s\n",
            "808:\tlearn: 0.2773034\ttotal: 30.7s\tremaining: 7.24s\n",
            "809:\tlearn: 0.2772666\ttotal: 30.7s\tremaining: 7.2s\n",
            "810:\tlearn: 0.2772342\ttotal: 30.7s\tremaining: 7.16s\n",
            "811:\tlearn: 0.2772037\ttotal: 30.8s\tremaining: 7.12s\n",
            "812:\tlearn: 0.2771792\ttotal: 30.8s\tremaining: 7.08s\n",
            "813:\tlearn: 0.2771484\ttotal: 30.8s\tremaining: 7.04s\n",
            "814:\tlearn: 0.2771182\ttotal: 30.9s\tremaining: 7s\n",
            "815:\tlearn: 0.2770914\ttotal: 30.9s\tremaining: 6.97s\n",
            "816:\tlearn: 0.2770503\ttotal: 30.9s\tremaining: 6.93s\n",
            "817:\tlearn: 0.2770131\ttotal: 31s\tremaining: 6.89s\n",
            "818:\tlearn: 0.2769873\ttotal: 31s\tremaining: 6.85s\n",
            "819:\tlearn: 0.2769468\ttotal: 31s\tremaining: 6.81s\n",
            "820:\tlearn: 0.2769151\ttotal: 31.1s\tremaining: 6.77s\n",
            "821:\tlearn: 0.2768837\ttotal: 31.1s\tremaining: 6.74s\n",
            "822:\tlearn: 0.2768562\ttotal: 31.1s\tremaining: 6.7s\n",
            "823:\tlearn: 0.2768151\ttotal: 31.2s\tremaining: 6.66s\n",
            "824:\tlearn: 0.2767878\ttotal: 31.2s\tremaining: 6.62s\n",
            "825:\tlearn: 0.2767663\ttotal: 31.2s\tremaining: 6.58s\n",
            "826:\tlearn: 0.2767318\ttotal: 31.3s\tremaining: 6.54s\n",
            "827:\tlearn: 0.2766949\ttotal: 31.3s\tremaining: 6.5s\n",
            "828:\tlearn: 0.2766715\ttotal: 31.3s\tremaining: 6.46s\n",
            "829:\tlearn: 0.2766466\ttotal: 31.4s\tremaining: 6.42s\n",
            "830:\tlearn: 0.2766040\ttotal: 31.4s\tremaining: 6.38s\n",
            "831:\tlearn: 0.2765671\ttotal: 31.4s\tremaining: 6.35s\n",
            "832:\tlearn: 0.2765438\ttotal: 31.5s\tremaining: 6.31s\n",
            "833:\tlearn: 0.2765207\ttotal: 31.5s\tremaining: 6.27s\n",
            "834:\tlearn: 0.2764937\ttotal: 31.5s\tremaining: 6.23s\n",
            "835:\tlearn: 0.2764526\ttotal: 31.6s\tremaining: 6.19s\n",
            "836:\tlearn: 0.2764212\ttotal: 31.6s\tremaining: 6.15s\n",
            "837:\tlearn: 0.2763845\ttotal: 31.6s\tremaining: 6.11s\n",
            "838:\tlearn: 0.2763488\ttotal: 31.7s\tremaining: 6.07s\n",
            "839:\tlearn: 0.2763205\ttotal: 31.7s\tremaining: 6.04s\n",
            "840:\tlearn: 0.2762898\ttotal: 31.7s\tremaining: 6s\n",
            "841:\tlearn: 0.2762631\ttotal: 31.8s\tremaining: 5.96s\n",
            "842:\tlearn: 0.2762343\ttotal: 31.8s\tremaining: 5.92s\n",
            "843:\tlearn: 0.2761976\ttotal: 31.8s\tremaining: 5.88s\n",
            "844:\tlearn: 0.2761578\ttotal: 31.8s\tremaining: 5.84s\n",
            "845:\tlearn: 0.2761314\ttotal: 31.9s\tremaining: 5.8s\n",
            "846:\tlearn: 0.2760930\ttotal: 31.9s\tremaining: 5.76s\n",
            "847:\tlearn: 0.2760650\ttotal: 32s\tremaining: 5.73s\n",
            "848:\tlearn: 0.2760368\ttotal: 32s\tremaining: 5.69s\n",
            "849:\tlearn: 0.2760012\ttotal: 32s\tremaining: 5.65s\n",
            "850:\tlearn: 0.2759738\ttotal: 32.1s\tremaining: 5.61s\n",
            "851:\tlearn: 0.2759404\ttotal: 32.1s\tremaining: 5.58s\n",
            "852:\tlearn: 0.2758985\ttotal: 32.1s\tremaining: 5.54s\n",
            "853:\tlearn: 0.2758694\ttotal: 32.2s\tremaining: 5.5s\n",
            "854:\tlearn: 0.2758352\ttotal: 32.2s\tremaining: 5.46s\n",
            "855:\tlearn: 0.2757947\ttotal: 32.2s\tremaining: 5.42s\n",
            "856:\tlearn: 0.2757695\ttotal: 32.3s\tremaining: 5.38s\n",
            "857:\tlearn: 0.2757317\ttotal: 32.3s\tremaining: 5.35s\n",
            "858:\tlearn: 0.2757029\ttotal: 32.3s\tremaining: 5.31s\n",
            "859:\tlearn: 0.2756902\ttotal: 32.4s\tremaining: 5.27s\n",
            "860:\tlearn: 0.2756656\ttotal: 32.4s\tremaining: 5.23s\n",
            "861:\tlearn: 0.2756402\ttotal: 32.4s\tremaining: 5.19s\n",
            "862:\tlearn: 0.2756043\ttotal: 32.5s\tremaining: 5.15s\n",
            "863:\tlearn: 0.2755757\ttotal: 32.5s\tremaining: 5.12s\n",
            "864:\tlearn: 0.2755493\ttotal: 32.5s\tremaining: 5.08s\n",
            "865:\tlearn: 0.2755172\ttotal: 32.6s\tremaining: 5.04s\n",
            "866:\tlearn: 0.2754880\ttotal: 32.6s\tremaining: 5s\n",
            "867:\tlearn: 0.2754587\ttotal: 32.6s\tremaining: 4.96s\n",
            "868:\tlearn: 0.2754231\ttotal: 32.7s\tremaining: 4.92s\n",
            "869:\tlearn: 0.2753976\ttotal: 32.7s\tremaining: 4.89s\n",
            "870:\tlearn: 0.2753644\ttotal: 32.7s\tremaining: 4.85s\n",
            "871:\tlearn: 0.2753343\ttotal: 32.8s\tremaining: 4.81s\n",
            "872:\tlearn: 0.2752940\ttotal: 32.8s\tremaining: 4.77s\n",
            "873:\tlearn: 0.2752673\ttotal: 32.8s\tremaining: 4.73s\n",
            "874:\tlearn: 0.2752271\ttotal: 32.9s\tremaining: 4.7s\n",
            "875:\tlearn: 0.2751884\ttotal: 32.9s\tremaining: 4.66s\n",
            "876:\tlearn: 0.2751475\ttotal: 32.9s\tremaining: 4.62s\n",
            "877:\tlearn: 0.2751185\ttotal: 33s\tremaining: 4.58s\n",
            "878:\tlearn: 0.2750870\ttotal: 33s\tremaining: 4.54s\n",
            "879:\tlearn: 0.2750576\ttotal: 33.1s\tremaining: 4.51s\n",
            "880:\tlearn: 0.2750319\ttotal: 33.1s\tremaining: 4.47s\n",
            "881:\tlearn: 0.2749924\ttotal: 33.1s\tremaining: 4.43s\n",
            "882:\tlearn: 0.2749648\ttotal: 33.2s\tremaining: 4.39s\n",
            "883:\tlearn: 0.2749299\ttotal: 33.2s\tremaining: 4.36s\n",
            "884:\tlearn: 0.2749049\ttotal: 33.2s\tremaining: 4.32s\n",
            "885:\tlearn: 0.2748708\ttotal: 33.3s\tremaining: 4.28s\n",
            "886:\tlearn: 0.2748392\ttotal: 33.3s\tremaining: 4.24s\n",
            "887:\tlearn: 0.2748141\ttotal: 33.3s\tremaining: 4.2s\n",
            "888:\tlearn: 0.2747847\ttotal: 33.4s\tremaining: 4.17s\n",
            "889:\tlearn: 0.2747465\ttotal: 33.4s\tremaining: 4.13s\n",
            "890:\tlearn: 0.2747298\ttotal: 33.4s\tremaining: 4.09s\n",
            "891:\tlearn: 0.2746756\ttotal: 33.5s\tremaining: 4.05s\n",
            "892:\tlearn: 0.2746397\ttotal: 33.5s\tremaining: 4.01s\n",
            "893:\tlearn: 0.2746094\ttotal: 33.5s\tremaining: 3.97s\n",
            "894:\tlearn: 0.2745756\ttotal: 33.5s\tremaining: 3.94s\n",
            "895:\tlearn: 0.2745360\ttotal: 33.6s\tremaining: 3.9s\n",
            "896:\tlearn: 0.2745001\ttotal: 33.6s\tremaining: 3.86s\n",
            "897:\tlearn: 0.2744624\ttotal: 33.6s\tremaining: 3.82s\n",
            "898:\tlearn: 0.2744329\ttotal: 33.7s\tremaining: 3.78s\n",
            "899:\tlearn: 0.2744029\ttotal: 33.7s\tremaining: 3.75s\n",
            "900:\tlearn: 0.2743688\ttotal: 33.7s\tremaining: 3.71s\n",
            "901:\tlearn: 0.2743386\ttotal: 33.8s\tremaining: 3.67s\n",
            "902:\tlearn: 0.2743059\ttotal: 33.8s\tremaining: 3.63s\n",
            "903:\tlearn: 0.2742627\ttotal: 33.8s\tremaining: 3.59s\n",
            "904:\tlearn: 0.2742301\ttotal: 33.9s\tremaining: 3.56s\n",
            "905:\tlearn: 0.2741993\ttotal: 33.9s\tremaining: 3.52s\n",
            "906:\tlearn: 0.2741604\ttotal: 33.9s\tremaining: 3.48s\n",
            "907:\tlearn: 0.2741267\ttotal: 34s\tremaining: 3.44s\n",
            "908:\tlearn: 0.2741070\ttotal: 34s\tremaining: 3.4s\n",
            "909:\tlearn: 0.2740722\ttotal: 34.1s\tremaining: 3.37s\n",
            "910:\tlearn: 0.2740406\ttotal: 34.1s\tremaining: 3.33s\n",
            "911:\tlearn: 0.2740084\ttotal: 34.1s\tremaining: 3.29s\n",
            "912:\tlearn: 0.2739827\ttotal: 34.2s\tremaining: 3.25s\n",
            "913:\tlearn: 0.2739489\ttotal: 34.2s\tremaining: 3.22s\n",
            "914:\tlearn: 0.2739156\ttotal: 34.2s\tremaining: 3.18s\n",
            "915:\tlearn: 0.2738833\ttotal: 34.3s\tremaining: 3.14s\n",
            "916:\tlearn: 0.2738463\ttotal: 34.3s\tremaining: 3.1s\n",
            "917:\tlearn: 0.2738019\ttotal: 34.3s\tremaining: 3.07s\n",
            "918:\tlearn: 0.2737648\ttotal: 34.4s\tremaining: 3.03s\n",
            "919:\tlearn: 0.2737319\ttotal: 34.4s\tremaining: 2.99s\n",
            "920:\tlearn: 0.2736961\ttotal: 34.5s\tremaining: 2.96s\n",
            "921:\tlearn: 0.2736645\ttotal: 34.5s\tremaining: 2.92s\n",
            "922:\tlearn: 0.2736361\ttotal: 34.5s\tremaining: 2.88s\n",
            "923:\tlearn: 0.2735956\ttotal: 34.6s\tremaining: 2.84s\n",
            "924:\tlearn: 0.2735564\ttotal: 34.6s\tremaining: 2.8s\n",
            "925:\tlearn: 0.2735220\ttotal: 34.6s\tremaining: 2.77s\n",
            "926:\tlearn: 0.2734974\ttotal: 34.6s\tremaining: 2.73s\n",
            "927:\tlearn: 0.2734648\ttotal: 34.7s\tremaining: 2.69s\n",
            "928:\tlearn: 0.2734270\ttotal: 34.7s\tremaining: 2.65s\n",
            "929:\tlearn: 0.2733897\ttotal: 34.7s\tremaining: 2.62s\n",
            "930:\tlearn: 0.2733547\ttotal: 34.8s\tremaining: 2.58s\n",
            "931:\tlearn: 0.2733268\ttotal: 34.8s\tremaining: 2.54s\n",
            "932:\tlearn: 0.2732966\ttotal: 34.8s\tremaining: 2.5s\n",
            "933:\tlearn: 0.2732560\ttotal: 34.9s\tremaining: 2.46s\n",
            "934:\tlearn: 0.2732296\ttotal: 34.9s\tremaining: 2.43s\n",
            "935:\tlearn: 0.2732008\ttotal: 35s\tremaining: 2.39s\n",
            "936:\tlearn: 0.2731677\ttotal: 35s\tremaining: 2.35s\n",
            "937:\tlearn: 0.2731499\ttotal: 35s\tremaining: 2.31s\n",
            "938:\tlearn: 0.2731296\ttotal: 35.1s\tremaining: 2.28s\n",
            "939:\tlearn: 0.2730974\ttotal: 35.1s\tremaining: 2.24s\n",
            "940:\tlearn: 0.2730702\ttotal: 35.1s\tremaining: 2.2s\n",
            "941:\tlearn: 0.2730330\ttotal: 35.2s\tremaining: 2.16s\n",
            "942:\tlearn: 0.2730104\ttotal: 35.2s\tremaining: 2.13s\n",
            "943:\tlearn: 0.2729930\ttotal: 35.2s\tremaining: 2.09s\n",
            "944:\tlearn: 0.2729579\ttotal: 35.3s\tremaining: 2.05s\n",
            "945:\tlearn: 0.2729162\ttotal: 35.3s\tremaining: 2.01s\n",
            "946:\tlearn: 0.2728956\ttotal: 35.3s\tremaining: 1.98s\n",
            "947:\tlearn: 0.2728658\ttotal: 35.4s\tremaining: 1.94s\n",
            "948:\tlearn: 0.2728356\ttotal: 35.4s\tremaining: 1.9s\n",
            "949:\tlearn: 0.2728133\ttotal: 35.4s\tremaining: 1.86s\n",
            "950:\tlearn: 0.2727829\ttotal: 35.5s\tremaining: 1.83s\n",
            "951:\tlearn: 0.2727624\ttotal: 35.5s\tremaining: 1.79s\n",
            "952:\tlearn: 0.2727232\ttotal: 35.5s\tremaining: 1.75s\n",
            "953:\tlearn: 0.2726848\ttotal: 35.6s\tremaining: 1.71s\n",
            "954:\tlearn: 0.2726627\ttotal: 35.6s\tremaining: 1.68s\n",
            "955:\tlearn: 0.2726344\ttotal: 35.6s\tremaining: 1.64s\n",
            "956:\tlearn: 0.2725994\ttotal: 35.7s\tremaining: 1.6s\n",
            "957:\tlearn: 0.2725673\ttotal: 35.7s\tremaining: 1.56s\n",
            "958:\tlearn: 0.2725121\ttotal: 35.7s\tremaining: 1.53s\n",
            "959:\tlearn: 0.2724795\ttotal: 35.7s\tremaining: 1.49s\n",
            "960:\tlearn: 0.2724585\ttotal: 35.8s\tremaining: 1.45s\n",
            "961:\tlearn: 0.2724322\ttotal: 35.8s\tremaining: 1.41s\n",
            "962:\tlearn: 0.2724089\ttotal: 35.8s\tremaining: 1.38s\n",
            "963:\tlearn: 0.2723854\ttotal: 35.9s\tremaining: 1.34s\n",
            "964:\tlearn: 0.2723554\ttotal: 35.9s\tremaining: 1.3s\n",
            "965:\tlearn: 0.2723274\ttotal: 35.9s\tremaining: 1.26s\n",
            "966:\tlearn: 0.2723052\ttotal: 36s\tremaining: 1.23s\n",
            "967:\tlearn: 0.2722634\ttotal: 36s\tremaining: 1.19s\n",
            "968:\tlearn: 0.2722319\ttotal: 36.1s\tremaining: 1.15s\n",
            "969:\tlearn: 0.2721956\ttotal: 36.1s\tremaining: 1.12s\n",
            "970:\tlearn: 0.2721618\ttotal: 36.1s\tremaining: 1.08s\n",
            "971:\tlearn: 0.2721241\ttotal: 36.2s\tremaining: 1.04s\n",
            "972:\tlearn: 0.2720850\ttotal: 36.2s\tremaining: 1s\n",
            "973:\tlearn: 0.2720673\ttotal: 36.2s\tremaining: 967ms\n",
            "974:\tlearn: 0.2720337\ttotal: 36.3s\tremaining: 930ms\n",
            "975:\tlearn: 0.2720051\ttotal: 36.3s\tremaining: 893ms\n",
            "976:\tlearn: 0.2719697\ttotal: 36.3s\tremaining: 855ms\n",
            "977:\tlearn: 0.2719384\ttotal: 36.4s\tremaining: 818ms\n",
            "978:\tlearn: 0.2719145\ttotal: 36.4s\tremaining: 780ms\n",
            "979:\tlearn: 0.2718904\ttotal: 36.4s\tremaining: 743ms\n",
            "980:\tlearn: 0.2718549\ttotal: 36.5s\tremaining: 706ms\n",
            "981:\tlearn: 0.2718301\ttotal: 36.5s\tremaining: 669ms\n",
            "982:\tlearn: 0.2718027\ttotal: 36.5s\tremaining: 632ms\n",
            "983:\tlearn: 0.2717599\ttotal: 36.5s\tremaining: 594ms\n",
            "984:\tlearn: 0.2717246\ttotal: 36.6s\tremaining: 557ms\n",
            "985:\tlearn: 0.2717000\ttotal: 36.6s\tremaining: 520ms\n",
            "986:\tlearn: 0.2716623\ttotal: 36.7s\tremaining: 483ms\n",
            "987:\tlearn: 0.2716191\ttotal: 36.7s\tremaining: 446ms\n",
            "988:\tlearn: 0.2715787\ttotal: 36.7s\tremaining: 408ms\n",
            "989:\tlearn: 0.2715452\ttotal: 36.7s\tremaining: 371ms\n",
            "990:\tlearn: 0.2715073\ttotal: 36.8s\tremaining: 334ms\n",
            "991:\tlearn: 0.2714908\ttotal: 36.8s\tremaining: 297ms\n",
            "992:\tlearn: 0.2714555\ttotal: 36.8s\tremaining: 260ms\n",
            "993:\tlearn: 0.2714187\ttotal: 36.9s\tremaining: 223ms\n",
            "994:\tlearn: 0.2713886\ttotal: 36.9s\tremaining: 186ms\n",
            "995:\tlearn: 0.2713579\ttotal: 36.9s\tremaining: 148ms\n",
            "996:\tlearn: 0.2713189\ttotal: 37s\tremaining: 111ms\n",
            "997:\tlearn: 0.2712886\ttotal: 37s\tremaining: 74.2ms\n",
            "998:\tlearn: 0.2712479\ttotal: 37.1s\tremaining: 37.1ms\n",
            "999:\tlearn: 0.2712198\ttotal: 37.1s\tremaining: 0us\n",
            "16 : 0.8809326761080242\n",
            "Learning rate set to 0.079235\n",
            "0:\tlearn: 0.6226250\ttotal: 53ms\tremaining: 52.9s\n",
            "1:\tlearn: 0.5678100\ttotal: 124ms\tremaining: 1m 1s\n",
            "2:\tlearn: 0.5210081\ttotal: 184ms\tremaining: 1m\n",
            "3:\tlearn: 0.4864714\ttotal: 269ms\tremaining: 1m 6s\n",
            "4:\tlearn: 0.4568710\ttotal: 354ms\tremaining: 1m 10s\n",
            "5:\tlearn: 0.4314906\ttotal: 436ms\tremaining: 1m 12s\n",
            "6:\tlearn: 0.4138643\ttotal: 514ms\tremaining: 1m 12s\n",
            "7:\tlearn: 0.3986202\ttotal: 594ms\tremaining: 1m 13s\n",
            "8:\tlearn: 0.3861272\ttotal: 691ms\tremaining: 1m 16s\n",
            "9:\tlearn: 0.3763897\ttotal: 776ms\tremaining: 1m 16s\n",
            "10:\tlearn: 0.3684948\ttotal: 859ms\tremaining: 1m 17s\n",
            "11:\tlearn: 0.3617276\ttotal: 923ms\tremaining: 1m 16s\n",
            "12:\tlearn: 0.3555620\ttotal: 1000ms\tremaining: 1m 15s\n",
            "13:\tlearn: 0.3505840\ttotal: 1.08s\tremaining: 1m 15s\n",
            "14:\tlearn: 0.3466922\ttotal: 1.16s\tremaining: 1m 16s\n",
            "15:\tlearn: 0.3433275\ttotal: 1.24s\tremaining: 1m 16s\n",
            "16:\tlearn: 0.3400644\ttotal: 1.32s\tremaining: 1m 16s\n",
            "17:\tlearn: 0.3368738\ttotal: 1.41s\tremaining: 1m 16s\n",
            "18:\tlearn: 0.3342129\ttotal: 1.47s\tremaining: 1m 15s\n",
            "19:\tlearn: 0.3319985\ttotal: 1.54s\tremaining: 1m 15s\n",
            "20:\tlearn: 0.3303652\ttotal: 1.59s\tremaining: 1m 14s\n",
            "21:\tlearn: 0.3288002\ttotal: 1.65s\tremaining: 1m 13s\n",
            "22:\tlearn: 0.3271948\ttotal: 1.73s\tremaining: 1m 13s\n",
            "23:\tlearn: 0.3258157\ttotal: 1.79s\tremaining: 1m 13s\n",
            "24:\tlearn: 0.3248858\ttotal: 1.87s\tremaining: 1m 13s\n",
            "25:\tlearn: 0.3238939\ttotal: 1.93s\tremaining: 1m 12s\n",
            "26:\tlearn: 0.3230138\ttotal: 2s\tremaining: 1m 12s\n",
            "27:\tlearn: 0.3222126\ttotal: 2.07s\tremaining: 1m 12s\n",
            "28:\tlearn: 0.3215289\ttotal: 2.14s\tremaining: 1m 11s\n",
            "29:\tlearn: 0.3208089\ttotal: 2.23s\tremaining: 1m 12s\n",
            "30:\tlearn: 0.3201693\ttotal: 2.32s\tremaining: 1m 12s\n",
            "31:\tlearn: 0.3194777\ttotal: 2.4s\tremaining: 1m 12s\n",
            "32:\tlearn: 0.3189516\ttotal: 2.48s\tremaining: 1m 12s\n",
            "33:\tlearn: 0.3185244\ttotal: 2.56s\tremaining: 1m 12s\n",
            "34:\tlearn: 0.3180205\ttotal: 2.61s\tremaining: 1m 11s\n",
            "35:\tlearn: 0.3176668\ttotal: 2.64s\tremaining: 1m 10s\n",
            "36:\tlearn: 0.3172614\ttotal: 2.67s\tremaining: 1m 9s\n",
            "37:\tlearn: 0.3168639\ttotal: 2.7s\tremaining: 1m 8s\n",
            "38:\tlearn: 0.3164954\ttotal: 2.73s\tremaining: 1m 7s\n",
            "39:\tlearn: 0.3161588\ttotal: 2.78s\tremaining: 1m 6s\n",
            "40:\tlearn: 0.3158505\ttotal: 2.82s\tremaining: 1m 5s\n",
            "41:\tlearn: 0.3154729\ttotal: 2.85s\tremaining: 1m 5s\n",
            "42:\tlearn: 0.3152054\ttotal: 2.88s\tremaining: 1m 4s\n",
            "43:\tlearn: 0.3149351\ttotal: 2.92s\tremaining: 1m 3s\n",
            "44:\tlearn: 0.3145926\ttotal: 2.95s\tremaining: 1m 2s\n",
            "45:\tlearn: 0.3143362\ttotal: 2.98s\tremaining: 1m 1s\n",
            "46:\tlearn: 0.3141062\ttotal: 3.02s\tremaining: 1m 1s\n",
            "47:\tlearn: 0.3139361\ttotal: 3.06s\tremaining: 1m\n",
            "48:\tlearn: 0.3136966\ttotal: 3.09s\tremaining: 59.9s\n",
            "49:\tlearn: 0.3135021\ttotal: 3.12s\tremaining: 59.2s\n",
            "50:\tlearn: 0.3133366\ttotal: 3.15s\tremaining: 58.7s\n",
            "51:\tlearn: 0.3131901\ttotal: 3.2s\tremaining: 58.3s\n",
            "52:\tlearn: 0.3129591\ttotal: 3.23s\tremaining: 57.7s\n",
            "53:\tlearn: 0.3126214\ttotal: 3.26s\tremaining: 57.1s\n",
            "54:\tlearn: 0.3124178\ttotal: 3.29s\tremaining: 56.6s\n",
            "55:\tlearn: 0.3122967\ttotal: 3.32s\tremaining: 56s\n",
            "56:\tlearn: 0.3121254\ttotal: 3.36s\tremaining: 55.5s\n",
            "57:\tlearn: 0.3119730\ttotal: 3.42s\tremaining: 55.5s\n",
            "58:\tlearn: 0.3118451\ttotal: 3.46s\tremaining: 55.1s\n",
            "59:\tlearn: 0.3117193\ttotal: 3.49s\tremaining: 54.6s\n",
            "60:\tlearn: 0.3115593\ttotal: 3.52s\tremaining: 54.2s\n",
            "61:\tlearn: 0.3114043\ttotal: 3.55s\tremaining: 53.7s\n",
            "62:\tlearn: 0.3112864\ttotal: 3.58s\tremaining: 53.3s\n",
            "63:\tlearn: 0.3111587\ttotal: 3.62s\tremaining: 52.9s\n",
            "64:\tlearn: 0.3109925\ttotal: 3.65s\tremaining: 52.6s\n",
            "65:\tlearn: 0.3108756\ttotal: 3.69s\tremaining: 52.2s\n",
            "66:\tlearn: 0.3107745\ttotal: 3.72s\tremaining: 51.8s\n",
            "67:\tlearn: 0.3106562\ttotal: 3.75s\tremaining: 51.5s\n",
            "68:\tlearn: 0.3104952\ttotal: 3.79s\tremaining: 51.1s\n",
            "69:\tlearn: 0.3103363\ttotal: 3.82s\tremaining: 50.7s\n",
            "70:\tlearn: 0.3102366\ttotal: 3.85s\tremaining: 50.4s\n",
            "71:\tlearn: 0.3101150\ttotal: 3.89s\tremaining: 50.1s\n",
            "72:\tlearn: 0.3099946\ttotal: 3.92s\tremaining: 49.8s\n",
            "73:\tlearn: 0.3098819\ttotal: 3.95s\tremaining: 49.5s\n",
            "74:\tlearn: 0.3097730\ttotal: 3.98s\tremaining: 49.2s\n",
            "75:\tlearn: 0.3096476\ttotal: 4.02s\tremaining: 48.8s\n",
            "76:\tlearn: 0.3095587\ttotal: 4.05s\tremaining: 48.6s\n",
            "77:\tlearn: 0.3094765\ttotal: 4.08s\tremaining: 48.3s\n",
            "78:\tlearn: 0.3093519\ttotal: 4.13s\tremaining: 48.1s\n",
            "79:\tlearn: 0.3092452\ttotal: 4.16s\tremaining: 47.8s\n",
            "80:\tlearn: 0.3091569\ttotal: 4.19s\tremaining: 47.6s\n",
            "81:\tlearn: 0.3090760\ttotal: 4.22s\tremaining: 47.3s\n",
            "82:\tlearn: 0.3089781\ttotal: 4.25s\tremaining: 47s\n",
            "83:\tlearn: 0.3088595\ttotal: 4.29s\tremaining: 46.7s\n",
            "84:\tlearn: 0.3087991\ttotal: 4.32s\tremaining: 46.5s\n",
            "85:\tlearn: 0.3087141\ttotal: 4.37s\tremaining: 46.4s\n",
            "86:\tlearn: 0.3086003\ttotal: 4.43s\tremaining: 46.5s\n",
            "87:\tlearn: 0.3085106\ttotal: 4.46s\tremaining: 46.2s\n",
            "88:\tlearn: 0.3084402\ttotal: 4.49s\tremaining: 46s\n",
            "89:\tlearn: 0.3083636\ttotal: 4.53s\tremaining: 45.8s\n",
            "90:\tlearn: 0.3082677\ttotal: 4.56s\tremaining: 45.5s\n",
            "91:\tlearn: 0.3082007\ttotal: 4.6s\tremaining: 45.4s\n",
            "92:\tlearn: 0.3081266\ttotal: 4.64s\tremaining: 45.2s\n",
            "93:\tlearn: 0.3080592\ttotal: 4.67s\tremaining: 45s\n",
            "94:\tlearn: 0.3079828\ttotal: 4.7s\tremaining: 44.8s\n",
            "95:\tlearn: 0.3078929\ttotal: 4.74s\tremaining: 44.6s\n",
            "96:\tlearn: 0.3078314\ttotal: 4.77s\tremaining: 44.4s\n",
            "97:\tlearn: 0.3077445\ttotal: 4.8s\tremaining: 44.2s\n",
            "98:\tlearn: 0.3076728\ttotal: 4.84s\tremaining: 44.1s\n",
            "99:\tlearn: 0.3075936\ttotal: 4.88s\tremaining: 43.9s\n",
            "100:\tlearn: 0.3075412\ttotal: 4.91s\tremaining: 43.7s\n",
            "101:\tlearn: 0.3074938\ttotal: 4.94s\tremaining: 43.5s\n",
            "102:\tlearn: 0.3074193\ttotal: 4.98s\tremaining: 43.3s\n",
            "103:\tlearn: 0.3073426\ttotal: 5.01s\tremaining: 43.2s\n",
            "104:\tlearn: 0.3072924\ttotal: 5.05s\tremaining: 43.1s\n",
            "105:\tlearn: 0.3072018\ttotal: 5.08s\tremaining: 42.9s\n",
            "106:\tlearn: 0.3071469\ttotal: 5.12s\tremaining: 42.7s\n",
            "107:\tlearn: 0.3070716\ttotal: 5.15s\tremaining: 42.5s\n",
            "108:\tlearn: 0.3070166\ttotal: 5.18s\tremaining: 42.3s\n",
            "109:\tlearn: 0.3069508\ttotal: 5.22s\tremaining: 42.2s\n",
            "110:\tlearn: 0.3068963\ttotal: 5.26s\tremaining: 42.1s\n",
            "111:\tlearn: 0.3068027\ttotal: 5.29s\tremaining: 42s\n",
            "112:\tlearn: 0.3067618\ttotal: 5.32s\tremaining: 41.8s\n",
            "113:\tlearn: 0.3067195\ttotal: 5.36s\tremaining: 41.7s\n",
            "114:\tlearn: 0.3066654\ttotal: 5.39s\tremaining: 41.5s\n",
            "115:\tlearn: 0.3065878\ttotal: 5.45s\tremaining: 41.6s\n",
            "116:\tlearn: 0.3065185\ttotal: 5.49s\tremaining: 41.4s\n",
            "117:\tlearn: 0.3064553\ttotal: 5.52s\tremaining: 41.3s\n",
            "118:\tlearn: 0.3063914\ttotal: 5.55s\tremaining: 41.1s\n",
            "119:\tlearn: 0.3063179\ttotal: 5.58s\tremaining: 40.9s\n",
            "120:\tlearn: 0.3062684\ttotal: 5.61s\tremaining: 40.8s\n",
            "121:\tlearn: 0.3062040\ttotal: 5.65s\tremaining: 40.6s\n",
            "122:\tlearn: 0.3061631\ttotal: 5.69s\tremaining: 40.6s\n",
            "123:\tlearn: 0.3060844\ttotal: 5.73s\tremaining: 40.5s\n",
            "124:\tlearn: 0.3060341\ttotal: 5.76s\tremaining: 40.3s\n",
            "125:\tlearn: 0.3059644\ttotal: 5.79s\tremaining: 40.2s\n",
            "126:\tlearn: 0.3059048\ttotal: 5.82s\tremaining: 40s\n",
            "127:\tlearn: 0.3058631\ttotal: 5.85s\tremaining: 39.8s\n",
            "128:\tlearn: 0.3058133\ttotal: 5.88s\tremaining: 39.7s\n",
            "129:\tlearn: 0.3057387\ttotal: 5.92s\tremaining: 39.6s\n",
            "130:\tlearn: 0.3056758\ttotal: 5.95s\tremaining: 39.5s\n",
            "131:\tlearn: 0.3056213\ttotal: 5.98s\tremaining: 39.3s\n",
            "132:\tlearn: 0.3055605\ttotal: 6.01s\tremaining: 39.2s\n",
            "133:\tlearn: 0.3055184\ttotal: 6.04s\tremaining: 39.1s\n",
            "134:\tlearn: 0.3054662\ttotal: 6.08s\tremaining: 38.9s\n",
            "135:\tlearn: 0.3054263\ttotal: 6.11s\tremaining: 38.8s\n",
            "136:\tlearn: 0.3053589\ttotal: 6.15s\tremaining: 38.7s\n",
            "137:\tlearn: 0.3053005\ttotal: 6.18s\tremaining: 38.6s\n",
            "138:\tlearn: 0.3052524\ttotal: 6.21s\tremaining: 38.5s\n",
            "139:\tlearn: 0.3051881\ttotal: 6.24s\tremaining: 38.3s\n",
            "140:\tlearn: 0.3051457\ttotal: 6.27s\tremaining: 38.2s\n",
            "141:\tlearn: 0.3050722\ttotal: 6.3s\tremaining: 38.1s\n",
            "142:\tlearn: 0.3050262\ttotal: 6.34s\tremaining: 38s\n",
            "143:\tlearn: 0.3049998\ttotal: 6.38s\tremaining: 37.9s\n",
            "144:\tlearn: 0.3049476\ttotal: 6.42s\tremaining: 37.8s\n",
            "145:\tlearn: 0.3048813\ttotal: 6.46s\tremaining: 37.8s\n",
            "146:\tlearn: 0.3048351\ttotal: 6.5s\tremaining: 37.7s\n",
            "147:\tlearn: 0.3047961\ttotal: 6.53s\tremaining: 37.6s\n",
            "148:\tlearn: 0.3047480\ttotal: 6.56s\tremaining: 37.4s\n",
            "149:\tlearn: 0.3046785\ttotal: 6.6s\tremaining: 37.4s\n",
            "150:\tlearn: 0.3046140\ttotal: 6.63s\tremaining: 37.3s\n",
            "151:\tlearn: 0.3045504\ttotal: 6.66s\tremaining: 37.2s\n",
            "152:\tlearn: 0.3044905\ttotal: 6.69s\tremaining: 37.1s\n",
            "153:\tlearn: 0.3044342\ttotal: 6.72s\tremaining: 36.9s\n",
            "154:\tlearn: 0.3043859\ttotal: 6.75s\tremaining: 36.8s\n",
            "155:\tlearn: 0.3043346\ttotal: 6.79s\tremaining: 36.7s\n",
            "156:\tlearn: 0.3042795\ttotal: 6.83s\tremaining: 36.6s\n",
            "157:\tlearn: 0.3042253\ttotal: 6.86s\tremaining: 36.5s\n",
            "158:\tlearn: 0.3041662\ttotal: 6.89s\tremaining: 36.4s\n",
            "159:\tlearn: 0.3041062\ttotal: 6.92s\tremaining: 36.3s\n",
            "160:\tlearn: 0.3040229\ttotal: 6.95s\tremaining: 36.2s\n",
            "161:\tlearn: 0.3039777\ttotal: 6.98s\tremaining: 36.1s\n",
            "162:\tlearn: 0.3039146\ttotal: 7.01s\tremaining: 36s\n",
            "163:\tlearn: 0.3038599\ttotal: 7.05s\tremaining: 36s\n",
            "164:\tlearn: 0.3037959\ttotal: 7.08s\tremaining: 35.9s\n",
            "165:\tlearn: 0.3037455\ttotal: 7.12s\tremaining: 35.7s\n",
            "166:\tlearn: 0.3036826\ttotal: 7.15s\tremaining: 35.6s\n",
            "167:\tlearn: 0.3035895\ttotal: 7.18s\tremaining: 35.6s\n",
            "168:\tlearn: 0.3035165\ttotal: 7.21s\tremaining: 35.5s\n",
            "169:\tlearn: 0.3034760\ttotal: 7.24s\tremaining: 35.4s\n",
            "170:\tlearn: 0.3034165\ttotal: 7.28s\tremaining: 35.3s\n",
            "171:\tlearn: 0.3033579\ttotal: 7.32s\tremaining: 35.2s\n",
            "172:\tlearn: 0.3033014\ttotal: 7.35s\tremaining: 35.1s\n",
            "173:\tlearn: 0.3032529\ttotal: 7.38s\tremaining: 35s\n",
            "174:\tlearn: 0.3031942\ttotal: 7.41s\tremaining: 34.9s\n",
            "175:\tlearn: 0.3031538\ttotal: 7.45s\tremaining: 34.9s\n",
            "176:\tlearn: 0.3030992\ttotal: 7.49s\tremaining: 34.8s\n",
            "177:\tlearn: 0.3030152\ttotal: 7.53s\tremaining: 34.8s\n",
            "178:\tlearn: 0.3029549\ttotal: 7.56s\tremaining: 34.7s\n",
            "179:\tlearn: 0.3029137\ttotal: 7.59s\tremaining: 34.6s\n",
            "180:\tlearn: 0.3028548\ttotal: 7.62s\tremaining: 34.5s\n",
            "181:\tlearn: 0.3027941\ttotal: 7.65s\tremaining: 34.4s\n",
            "182:\tlearn: 0.3027162\ttotal: 7.68s\tremaining: 34.3s\n",
            "183:\tlearn: 0.3026431\ttotal: 7.72s\tremaining: 34.3s\n",
            "184:\tlearn: 0.3025920\ttotal: 7.75s\tremaining: 34.2s\n",
            "185:\tlearn: 0.3025381\ttotal: 7.79s\tremaining: 34.1s\n",
            "186:\tlearn: 0.3024813\ttotal: 7.82s\tremaining: 34s\n",
            "187:\tlearn: 0.3024236\ttotal: 7.85s\tremaining: 33.9s\n",
            "188:\tlearn: 0.3023819\ttotal: 7.88s\tremaining: 33.8s\n",
            "189:\tlearn: 0.3023195\ttotal: 7.91s\tremaining: 33.7s\n",
            "190:\tlearn: 0.3022673\ttotal: 7.95s\tremaining: 33.7s\n",
            "191:\tlearn: 0.3022065\ttotal: 7.98s\tremaining: 33.6s\n",
            "192:\tlearn: 0.3021540\ttotal: 8.01s\tremaining: 33.5s\n",
            "193:\tlearn: 0.3020657\ttotal: 8.04s\tremaining: 33.4s\n",
            "194:\tlearn: 0.3020065\ttotal: 8.08s\tremaining: 33.3s\n",
            "195:\tlearn: 0.3019409\ttotal: 8.11s\tremaining: 33.3s\n",
            "196:\tlearn: 0.3018810\ttotal: 8.15s\tremaining: 33.2s\n",
            "197:\tlearn: 0.3018119\ttotal: 8.19s\tremaining: 33.2s\n",
            "198:\tlearn: 0.3017632\ttotal: 8.22s\tremaining: 33.1s\n",
            "199:\tlearn: 0.3016941\ttotal: 8.25s\tremaining: 33s\n",
            "200:\tlearn: 0.3016450\ttotal: 8.29s\tremaining: 32.9s\n",
            "201:\tlearn: 0.3015823\ttotal: 8.32s\tremaining: 32.9s\n",
            "202:\tlearn: 0.3015214\ttotal: 8.35s\tremaining: 32.8s\n",
            "203:\tlearn: 0.3014607\ttotal: 8.39s\tremaining: 32.7s\n",
            "204:\tlearn: 0.3014218\ttotal: 8.43s\tremaining: 32.7s\n",
            "205:\tlearn: 0.3013580\ttotal: 8.47s\tremaining: 32.7s\n",
            "206:\tlearn: 0.3013198\ttotal: 8.51s\tremaining: 32.6s\n",
            "207:\tlearn: 0.3012511\ttotal: 8.54s\tremaining: 32.5s\n",
            "208:\tlearn: 0.3012029\ttotal: 8.57s\tremaining: 32.4s\n",
            "209:\tlearn: 0.3011407\ttotal: 8.6s\tremaining: 32.4s\n",
            "210:\tlearn: 0.3010794\ttotal: 8.63s\tremaining: 32.3s\n",
            "211:\tlearn: 0.3010302\ttotal: 8.67s\tremaining: 32.2s\n",
            "212:\tlearn: 0.3009796\ttotal: 8.7s\tremaining: 32.2s\n",
            "213:\tlearn: 0.3009406\ttotal: 8.73s\tremaining: 32.1s\n",
            "214:\tlearn: 0.3008814\ttotal: 8.77s\tremaining: 32s\n",
            "215:\tlearn: 0.3008433\ttotal: 8.8s\tremaining: 31.9s\n",
            "216:\tlearn: 0.3007782\ttotal: 8.83s\tremaining: 31.9s\n",
            "217:\tlearn: 0.3007227\ttotal: 8.88s\tremaining: 31.9s\n",
            "218:\tlearn: 0.3006735\ttotal: 8.91s\tremaining: 31.8s\n",
            "219:\tlearn: 0.3006375\ttotal: 8.94s\tremaining: 31.7s\n",
            "220:\tlearn: 0.3005798\ttotal: 8.97s\tremaining: 31.6s\n",
            "221:\tlearn: 0.3005254\ttotal: 9.01s\tremaining: 31.6s\n",
            "222:\tlearn: 0.3004670\ttotal: 9.04s\tremaining: 31.5s\n",
            "223:\tlearn: 0.3004146\ttotal: 9.07s\tremaining: 31.4s\n",
            "224:\tlearn: 0.3003670\ttotal: 9.11s\tremaining: 31.4s\n",
            "225:\tlearn: 0.3003160\ttotal: 9.14s\tremaining: 31.3s\n",
            "226:\tlearn: 0.3002719\ttotal: 9.17s\tremaining: 31.2s\n",
            "227:\tlearn: 0.3002297\ttotal: 9.21s\tremaining: 31.2s\n",
            "228:\tlearn: 0.3001717\ttotal: 9.24s\tremaining: 31.1s\n",
            "229:\tlearn: 0.3001192\ttotal: 9.27s\tremaining: 31s\n",
            "230:\tlearn: 0.3000872\ttotal: 9.3s\tremaining: 31s\n",
            "231:\tlearn: 0.3000442\ttotal: 9.35s\tremaining: 31s\n",
            "232:\tlearn: 0.2999944\ttotal: 9.38s\tremaining: 30.9s\n",
            "233:\tlearn: 0.2999431\ttotal: 9.41s\tremaining: 30.8s\n",
            "234:\tlearn: 0.2998881\ttotal: 9.45s\tremaining: 30.8s\n",
            "235:\tlearn: 0.2998213\ttotal: 9.49s\tremaining: 30.7s\n",
            "236:\tlearn: 0.2997776\ttotal: 9.53s\tremaining: 30.7s\n",
            "237:\tlearn: 0.2997237\ttotal: 9.57s\tremaining: 30.6s\n",
            "238:\tlearn: 0.2996603\ttotal: 9.6s\tremaining: 30.6s\n",
            "239:\tlearn: 0.2996078\ttotal: 9.63s\tremaining: 30.5s\n",
            "240:\tlearn: 0.2995452\ttotal: 9.66s\tremaining: 30.4s\n",
            "241:\tlearn: 0.2994967\ttotal: 9.69s\tremaining: 30.4s\n",
            "242:\tlearn: 0.2994484\ttotal: 9.72s\tremaining: 30.3s\n",
            "243:\tlearn: 0.2993946\ttotal: 9.76s\tremaining: 30.2s\n",
            "244:\tlearn: 0.2993509\ttotal: 9.8s\tremaining: 30.2s\n",
            "245:\tlearn: 0.2992917\ttotal: 9.83s\tremaining: 30.1s\n",
            "246:\tlearn: 0.2992459\ttotal: 9.86s\tremaining: 30.1s\n",
            "247:\tlearn: 0.2991978\ttotal: 9.9s\tremaining: 30s\n",
            "248:\tlearn: 0.2991535\ttotal: 9.93s\tremaining: 29.9s\n",
            "249:\tlearn: 0.2991136\ttotal: 9.96s\tremaining: 29.9s\n",
            "250:\tlearn: 0.2990611\ttotal: 9.99s\tremaining: 29.8s\n",
            "251:\tlearn: 0.2990038\ttotal: 10s\tremaining: 29.8s\n",
            "252:\tlearn: 0.2989495\ttotal: 10.1s\tremaining: 29.7s\n",
            "253:\tlearn: 0.2988957\ttotal: 10.1s\tremaining: 29.6s\n",
            "254:\tlearn: 0.2988486\ttotal: 10.1s\tremaining: 29.6s\n",
            "255:\tlearn: 0.2988055\ttotal: 10.2s\tremaining: 29.5s\n",
            "256:\tlearn: 0.2987696\ttotal: 10.2s\tremaining: 29.5s\n",
            "257:\tlearn: 0.2987308\ttotal: 10.2s\tremaining: 29.4s\n",
            "258:\tlearn: 0.2986786\ttotal: 10.3s\tremaining: 29.4s\n",
            "259:\tlearn: 0.2986389\ttotal: 10.3s\tremaining: 29.3s\n",
            "260:\tlearn: 0.2985875\ttotal: 10.3s\tremaining: 29.3s\n",
            "261:\tlearn: 0.2985200\ttotal: 10.4s\tremaining: 29.2s\n",
            "262:\tlearn: 0.2984726\ttotal: 10.4s\tremaining: 29.1s\n",
            "263:\tlearn: 0.2984332\ttotal: 10.4s\tremaining: 29.1s\n",
            "264:\tlearn: 0.2983922\ttotal: 10.5s\tremaining: 29s\n",
            "265:\tlearn: 0.2983326\ttotal: 10.5s\tremaining: 29s\n",
            "266:\tlearn: 0.2982772\ttotal: 10.6s\tremaining: 29s\n",
            "267:\tlearn: 0.2982330\ttotal: 10.6s\tremaining: 28.9s\n",
            "268:\tlearn: 0.2981911\ttotal: 10.6s\tremaining: 28.8s\n",
            "269:\tlearn: 0.2981414\ttotal: 10.7s\tremaining: 28.8s\n",
            "270:\tlearn: 0.2980911\ttotal: 10.7s\tremaining: 28.8s\n",
            "271:\tlearn: 0.2980437\ttotal: 10.7s\tremaining: 28.7s\n",
            "272:\tlearn: 0.2979773\ttotal: 10.8s\tremaining: 28.6s\n",
            "273:\tlearn: 0.2979302\ttotal: 10.8s\tremaining: 28.6s\n",
            "274:\tlearn: 0.2978710\ttotal: 10.8s\tremaining: 28.5s\n",
            "275:\tlearn: 0.2978211\ttotal: 10.8s\tremaining: 28.5s\n",
            "276:\tlearn: 0.2977750\ttotal: 10.9s\tremaining: 28.4s\n",
            "277:\tlearn: 0.2977226\ttotal: 10.9s\tremaining: 28.4s\n",
            "278:\tlearn: 0.2976796\ttotal: 11s\tremaining: 28.3s\n",
            "279:\tlearn: 0.2976256\ttotal: 11s\tremaining: 28.2s\n",
            "280:\tlearn: 0.2975729\ttotal: 11s\tremaining: 28.2s\n",
            "281:\tlearn: 0.2975122\ttotal: 11.1s\tremaining: 28.1s\n",
            "282:\tlearn: 0.2974535\ttotal: 11.1s\tremaining: 28.1s\n",
            "283:\tlearn: 0.2974016\ttotal: 11.1s\tremaining: 28.1s\n",
            "284:\tlearn: 0.2973693\ttotal: 11.2s\tremaining: 28s\n",
            "285:\tlearn: 0.2973250\ttotal: 11.2s\tremaining: 27.9s\n",
            "286:\tlearn: 0.2972583\ttotal: 11.2s\tremaining: 27.9s\n",
            "287:\tlearn: 0.2972186\ttotal: 11.3s\tremaining: 27.8s\n",
            "288:\tlearn: 0.2971623\ttotal: 11.3s\tremaining: 27.8s\n",
            "289:\tlearn: 0.2970995\ttotal: 11.3s\tremaining: 27.7s\n",
            "290:\tlearn: 0.2970570\ttotal: 11.4s\tremaining: 27.7s\n",
            "291:\tlearn: 0.2970150\ttotal: 11.4s\tremaining: 27.6s\n",
            "292:\tlearn: 0.2969720\ttotal: 11.4s\tremaining: 27.6s\n",
            "293:\tlearn: 0.2969302\ttotal: 11.5s\tremaining: 27.5s\n",
            "294:\tlearn: 0.2968809\ttotal: 11.5s\tremaining: 27.4s\n",
            "295:\tlearn: 0.2968296\ttotal: 11.5s\tremaining: 27.4s\n",
            "296:\tlearn: 0.2967680\ttotal: 11.6s\tremaining: 27.4s\n",
            "297:\tlearn: 0.2967128\ttotal: 11.6s\tremaining: 27.3s\n",
            "298:\tlearn: 0.2966779\ttotal: 11.6s\tremaining: 27.3s\n",
            "299:\tlearn: 0.2966288\ttotal: 11.7s\tremaining: 27.2s\n",
            "300:\tlearn: 0.2965741\ttotal: 11.7s\tremaining: 27.2s\n",
            "301:\tlearn: 0.2965255\ttotal: 11.7s\tremaining: 27.1s\n",
            "302:\tlearn: 0.2964946\ttotal: 11.8s\tremaining: 27.1s\n",
            "303:\tlearn: 0.2964430\ttotal: 11.8s\tremaining: 27s\n",
            "304:\tlearn: 0.2963996\ttotal: 11.8s\tremaining: 27s\n",
            "305:\tlearn: 0.2963533\ttotal: 11.9s\tremaining: 26.9s\n",
            "306:\tlearn: 0.2962902\ttotal: 11.9s\tremaining: 26.9s\n",
            "307:\tlearn: 0.2962335\ttotal: 11.9s\tremaining: 26.8s\n",
            "308:\tlearn: 0.2961802\ttotal: 12s\tremaining: 26.7s\n",
            "309:\tlearn: 0.2961170\ttotal: 12s\tremaining: 26.7s\n",
            "310:\tlearn: 0.2960825\ttotal: 12s\tremaining: 26.7s\n",
            "311:\tlearn: 0.2960253\ttotal: 12.1s\tremaining: 26.6s\n",
            "312:\tlearn: 0.2959651\ttotal: 12.1s\tremaining: 26.5s\n",
            "313:\tlearn: 0.2959224\ttotal: 12.1s\tremaining: 26.5s\n",
            "314:\tlearn: 0.2958673\ttotal: 12.2s\tremaining: 26.4s\n",
            "315:\tlearn: 0.2958261\ttotal: 12.2s\tremaining: 26.4s\n",
            "316:\tlearn: 0.2957809\ttotal: 12.2s\tremaining: 26.3s\n",
            "317:\tlearn: 0.2957369\ttotal: 12.3s\tremaining: 26.3s\n",
            "318:\tlearn: 0.2956928\ttotal: 12.3s\tremaining: 26.3s\n",
            "319:\tlearn: 0.2956452\ttotal: 12.3s\tremaining: 26.2s\n",
            "320:\tlearn: 0.2955953\ttotal: 12.4s\tremaining: 26.2s\n",
            "321:\tlearn: 0.2955470\ttotal: 12.4s\tremaining: 26.1s\n",
            "322:\tlearn: 0.2954975\ttotal: 12.4s\tremaining: 26s\n",
            "323:\tlearn: 0.2954417\ttotal: 12.5s\tremaining: 26s\n",
            "324:\tlearn: 0.2953976\ttotal: 12.5s\tremaining: 26s\n",
            "325:\tlearn: 0.2953300\ttotal: 12.6s\tremaining: 26.1s\n",
            "326:\tlearn: 0.2952917\ttotal: 12.7s\tremaining: 26.1s\n",
            "327:\tlearn: 0.2952515\ttotal: 12.8s\tremaining: 26.1s\n",
            "328:\tlearn: 0.2952149\ttotal: 12.8s\tremaining: 26.2s\n",
            "329:\tlearn: 0.2951522\ttotal: 12.9s\tremaining: 26.2s\n",
            "330:\tlearn: 0.2951164\ttotal: 13s\tremaining: 26.3s\n",
            "331:\tlearn: 0.2950650\ttotal: 13.1s\tremaining: 26.3s\n",
            "332:\tlearn: 0.2950209\ttotal: 13.1s\tremaining: 26.3s\n",
            "333:\tlearn: 0.2949673\ttotal: 13.2s\tremaining: 26.4s\n",
            "334:\tlearn: 0.2949231\ttotal: 13.3s\tremaining: 26.4s\n",
            "335:\tlearn: 0.2948689\ttotal: 13.4s\tremaining: 26.4s\n",
            "336:\tlearn: 0.2948401\ttotal: 13.4s\tremaining: 26.4s\n",
            "337:\tlearn: 0.2947884\ttotal: 13.5s\tremaining: 26.4s\n",
            "338:\tlearn: 0.2947413\ttotal: 13.6s\tremaining: 26.5s\n",
            "339:\tlearn: 0.2946964\ttotal: 13.7s\tremaining: 26.5s\n",
            "340:\tlearn: 0.2946586\ttotal: 13.7s\tremaining: 26.6s\n",
            "341:\tlearn: 0.2945860\ttotal: 13.8s\tremaining: 26.6s\n",
            "342:\tlearn: 0.2945374\ttotal: 13.9s\tremaining: 26.6s\n",
            "343:\tlearn: 0.2944869\ttotal: 14s\tremaining: 26.6s\n",
            "344:\tlearn: 0.2944380\ttotal: 14s\tremaining: 26.7s\n",
            "345:\tlearn: 0.2943985\ttotal: 14.1s\tremaining: 26.7s\n",
            "346:\tlearn: 0.2943417\ttotal: 14.2s\tremaining: 26.7s\n",
            "347:\tlearn: 0.2942930\ttotal: 14.3s\tremaining: 26.8s\n",
            "348:\tlearn: 0.2942461\ttotal: 14.4s\tremaining: 26.8s\n",
            "349:\tlearn: 0.2941935\ttotal: 14.4s\tremaining: 26.8s\n",
            "350:\tlearn: 0.2941255\ttotal: 14.5s\tremaining: 26.9s\n",
            "351:\tlearn: 0.2940711\ttotal: 14.6s\tremaining: 26.9s\n",
            "352:\tlearn: 0.2940141\ttotal: 14.7s\tremaining: 26.9s\n",
            "353:\tlearn: 0.2939741\ttotal: 14.8s\tremaining: 26.9s\n",
            "354:\tlearn: 0.2939392\ttotal: 14.8s\tremaining: 27s\n",
            "355:\tlearn: 0.2938996\ttotal: 14.9s\tremaining: 27s\n",
            "356:\tlearn: 0.2938520\ttotal: 15s\tremaining: 26.9s\n",
            "357:\tlearn: 0.2937973\ttotal: 15s\tremaining: 26.9s\n",
            "358:\tlearn: 0.2937645\ttotal: 15s\tremaining: 26.8s\n",
            "359:\tlearn: 0.2937351\ttotal: 15.1s\tremaining: 26.8s\n",
            "360:\tlearn: 0.2936983\ttotal: 15.1s\tremaining: 26.7s\n",
            "361:\tlearn: 0.2936637\ttotal: 15.1s\tremaining: 26.7s\n",
            "362:\tlearn: 0.2936343\ttotal: 15.2s\tremaining: 26.6s\n",
            "363:\tlearn: 0.2935891\ttotal: 15.2s\tremaining: 26.5s\n",
            "364:\tlearn: 0.2935436\ttotal: 15.2s\tremaining: 26.5s\n",
            "365:\tlearn: 0.2935099\ttotal: 15.3s\tremaining: 26.4s\n",
            "366:\tlearn: 0.2934716\ttotal: 15.3s\tremaining: 26.4s\n",
            "367:\tlearn: 0.2934350\ttotal: 15.3s\tremaining: 26.3s\n",
            "368:\tlearn: 0.2934015\ttotal: 15.4s\tremaining: 26.3s\n",
            "369:\tlearn: 0.2933704\ttotal: 15.4s\tremaining: 26.2s\n",
            "370:\tlearn: 0.2933311\ttotal: 15.4s\tremaining: 26.2s\n",
            "371:\tlearn: 0.2932878\ttotal: 15.5s\tremaining: 26.1s\n",
            "372:\tlearn: 0.2932456\ttotal: 15.5s\tremaining: 26.1s\n",
            "373:\tlearn: 0.2931889\ttotal: 15.5s\tremaining: 26s\n",
            "374:\tlearn: 0.2931396\ttotal: 15.6s\tremaining: 25.9s\n",
            "375:\tlearn: 0.2931078\ttotal: 15.6s\tremaining: 25.9s\n",
            "376:\tlearn: 0.2930688\ttotal: 15.6s\tremaining: 25.8s\n",
            "377:\tlearn: 0.2930204\ttotal: 15.7s\tremaining: 25.8s\n",
            "378:\tlearn: 0.2929526\ttotal: 15.7s\tremaining: 25.7s\n",
            "379:\tlearn: 0.2929106\ttotal: 15.7s\tremaining: 25.7s\n",
            "380:\tlearn: 0.2928573\ttotal: 15.8s\tremaining: 25.6s\n",
            "381:\tlearn: 0.2928059\ttotal: 15.8s\tremaining: 25.6s\n",
            "382:\tlearn: 0.2927560\ttotal: 15.8s\tremaining: 25.5s\n",
            "383:\tlearn: 0.2927040\ttotal: 15.9s\tremaining: 25.5s\n",
            "384:\tlearn: 0.2926607\ttotal: 15.9s\tremaining: 25.4s\n",
            "385:\tlearn: 0.2926291\ttotal: 15.9s\tremaining: 25.4s\n",
            "386:\tlearn: 0.2925821\ttotal: 16s\tremaining: 25.3s\n",
            "387:\tlearn: 0.2925299\ttotal: 16s\tremaining: 25.2s\n",
            "388:\tlearn: 0.2924787\ttotal: 16s\tremaining: 25.2s\n",
            "389:\tlearn: 0.2924432\ttotal: 16.1s\tremaining: 25.1s\n",
            "390:\tlearn: 0.2923930\ttotal: 16.1s\tremaining: 25.1s\n",
            "391:\tlearn: 0.2923459\ttotal: 16.1s\tremaining: 25s\n",
            "392:\tlearn: 0.2923022\ttotal: 16.2s\tremaining: 25s\n",
            "393:\tlearn: 0.2922633\ttotal: 16.2s\tremaining: 24.9s\n",
            "394:\tlearn: 0.2922137\ttotal: 16.2s\tremaining: 24.9s\n",
            "395:\tlearn: 0.2921579\ttotal: 16.3s\tremaining: 24.8s\n",
            "396:\tlearn: 0.2921194\ttotal: 16.3s\tremaining: 24.8s\n",
            "397:\tlearn: 0.2920860\ttotal: 16.3s\tremaining: 24.7s\n",
            "398:\tlearn: 0.2920598\ttotal: 16.4s\tremaining: 24.7s\n",
            "399:\tlearn: 0.2920161\ttotal: 16.4s\tremaining: 24.6s\n",
            "400:\tlearn: 0.2919705\ttotal: 16.4s\tremaining: 24.6s\n",
            "401:\tlearn: 0.2919189\ttotal: 16.5s\tremaining: 24.5s\n",
            "402:\tlearn: 0.2918898\ttotal: 16.5s\tremaining: 24.4s\n",
            "403:\tlearn: 0.2918425\ttotal: 16.5s\tremaining: 24.4s\n",
            "404:\tlearn: 0.2918198\ttotal: 16.6s\tremaining: 24.3s\n",
            "405:\tlearn: 0.2917821\ttotal: 16.6s\tremaining: 24.3s\n",
            "406:\tlearn: 0.2917490\ttotal: 16.6s\tremaining: 24.2s\n",
            "407:\tlearn: 0.2917034\ttotal: 16.7s\tremaining: 24.2s\n",
            "408:\tlearn: 0.2916668\ttotal: 16.7s\tremaining: 24.1s\n",
            "409:\tlearn: 0.2916163\ttotal: 16.7s\tremaining: 24.1s\n",
            "410:\tlearn: 0.2915705\ttotal: 16.8s\tremaining: 24s\n",
            "411:\tlearn: 0.2915211\ttotal: 16.8s\tremaining: 24s\n",
            "412:\tlearn: 0.2914830\ttotal: 16.8s\tremaining: 23.9s\n",
            "413:\tlearn: 0.2914443\ttotal: 16.9s\tremaining: 23.9s\n",
            "414:\tlearn: 0.2913913\ttotal: 16.9s\tremaining: 23.8s\n",
            "415:\tlearn: 0.2913430\ttotal: 16.9s\tremaining: 23.8s\n",
            "416:\tlearn: 0.2912937\ttotal: 17s\tremaining: 23.7s\n",
            "417:\tlearn: 0.2912577\ttotal: 17s\tremaining: 23.7s\n",
            "418:\tlearn: 0.2912027\ttotal: 17s\tremaining: 23.6s\n",
            "419:\tlearn: 0.2911638\ttotal: 17.1s\tremaining: 23.6s\n",
            "420:\tlearn: 0.2911197\ttotal: 17.1s\tremaining: 23.5s\n",
            "421:\tlearn: 0.2910551\ttotal: 17.1s\tremaining: 23.5s\n",
            "422:\tlearn: 0.2910145\ttotal: 17.2s\tremaining: 23.4s\n",
            "423:\tlearn: 0.2909779\ttotal: 17.2s\tremaining: 23.4s\n",
            "424:\tlearn: 0.2909396\ttotal: 17.2s\tremaining: 23.3s\n",
            "425:\tlearn: 0.2908741\ttotal: 17.3s\tremaining: 23.3s\n",
            "426:\tlearn: 0.2908337\ttotal: 17.3s\tremaining: 23.2s\n",
            "427:\tlearn: 0.2907853\ttotal: 17.3s\tremaining: 23.2s\n",
            "428:\tlearn: 0.2907434\ttotal: 17.4s\tremaining: 23.1s\n",
            "429:\tlearn: 0.2907092\ttotal: 17.4s\tremaining: 23.1s\n",
            "430:\tlearn: 0.2906624\ttotal: 17.4s\tremaining: 23s\n",
            "431:\tlearn: 0.2906223\ttotal: 17.5s\tremaining: 23s\n",
            "432:\tlearn: 0.2905762\ttotal: 17.5s\tremaining: 22.9s\n",
            "433:\tlearn: 0.2905257\ttotal: 17.5s\tremaining: 22.9s\n",
            "434:\tlearn: 0.2904831\ttotal: 17.6s\tremaining: 22.8s\n",
            "435:\tlearn: 0.2904488\ttotal: 17.6s\tremaining: 22.8s\n",
            "436:\tlearn: 0.2903998\ttotal: 17.6s\tremaining: 22.7s\n",
            "437:\tlearn: 0.2903734\ttotal: 17.7s\tremaining: 22.7s\n",
            "438:\tlearn: 0.2903270\ttotal: 17.7s\tremaining: 22.6s\n",
            "439:\tlearn: 0.2902826\ttotal: 17.8s\tremaining: 22.6s\n",
            "440:\tlearn: 0.2902523\ttotal: 17.8s\tremaining: 22.5s\n",
            "441:\tlearn: 0.2902180\ttotal: 17.8s\tremaining: 22.5s\n",
            "442:\tlearn: 0.2901845\ttotal: 17.9s\tremaining: 22.4s\n",
            "443:\tlearn: 0.2901302\ttotal: 17.9s\tremaining: 22.4s\n",
            "444:\tlearn: 0.2900984\ttotal: 17.9s\tremaining: 22.3s\n",
            "445:\tlearn: 0.2900578\ttotal: 18s\tremaining: 22.3s\n",
            "446:\tlearn: 0.2899949\ttotal: 18s\tremaining: 22.3s\n",
            "447:\tlearn: 0.2899551\ttotal: 18s\tremaining: 22.2s\n",
            "448:\tlearn: 0.2899129\ttotal: 18.1s\tremaining: 22.2s\n",
            "449:\tlearn: 0.2898803\ttotal: 18.1s\tremaining: 22.1s\n",
            "450:\tlearn: 0.2898252\ttotal: 18.1s\tremaining: 22s\n",
            "451:\tlearn: 0.2897752\ttotal: 18.1s\tremaining: 22s\n",
            "452:\tlearn: 0.2897368\ttotal: 18.2s\tremaining: 22s\n",
            "453:\tlearn: 0.2897018\ttotal: 18.2s\tremaining: 21.9s\n",
            "454:\tlearn: 0.2896557\ttotal: 18.3s\tremaining: 21.9s\n",
            "455:\tlearn: 0.2896212\ttotal: 18.3s\tremaining: 21.8s\n",
            "456:\tlearn: 0.2895956\ttotal: 18.3s\tremaining: 21.8s\n",
            "457:\tlearn: 0.2895579\ttotal: 18.3s\tremaining: 21.7s\n",
            "458:\tlearn: 0.2895254\ttotal: 18.4s\tremaining: 21.7s\n",
            "459:\tlearn: 0.2895007\ttotal: 18.4s\tremaining: 21.6s\n",
            "460:\tlearn: 0.2894453\ttotal: 18.4s\tremaining: 21.6s\n",
            "461:\tlearn: 0.2894025\ttotal: 18.5s\tremaining: 21.5s\n",
            "462:\tlearn: 0.2893572\ttotal: 18.5s\tremaining: 21.5s\n",
            "463:\tlearn: 0.2893079\ttotal: 18.5s\tremaining: 21.4s\n",
            "464:\tlearn: 0.2892473\ttotal: 18.6s\tremaining: 21.4s\n",
            "465:\tlearn: 0.2892007\ttotal: 18.6s\tremaining: 21.3s\n",
            "466:\tlearn: 0.2891479\ttotal: 18.7s\tremaining: 21.3s\n",
            "467:\tlearn: 0.2891063\ttotal: 18.7s\tremaining: 21.2s\n",
            "468:\tlearn: 0.2890607\ttotal: 18.7s\tremaining: 21.2s\n",
            "469:\tlearn: 0.2890187\ttotal: 18.8s\tremaining: 21.2s\n",
            "470:\tlearn: 0.2889728\ttotal: 18.8s\tremaining: 21.1s\n",
            "471:\tlearn: 0.2889215\ttotal: 18.8s\tremaining: 21.1s\n",
            "472:\tlearn: 0.2888824\ttotal: 18.9s\tremaining: 21s\n",
            "473:\tlearn: 0.2888448\ttotal: 18.9s\tremaining: 21s\n",
            "474:\tlearn: 0.2887978\ttotal: 18.9s\tremaining: 20.9s\n",
            "475:\tlearn: 0.2887629\ttotal: 19s\tremaining: 20.9s\n",
            "476:\tlearn: 0.2887050\ttotal: 19s\tremaining: 20.8s\n",
            "477:\tlearn: 0.2886562\ttotal: 19s\tremaining: 20.8s\n",
            "478:\tlearn: 0.2885986\ttotal: 19.1s\tremaining: 20.7s\n",
            "479:\tlearn: 0.2885613\ttotal: 19.1s\tremaining: 20.7s\n",
            "480:\tlearn: 0.2885179\ttotal: 19.1s\tremaining: 20.6s\n",
            "481:\tlearn: 0.2884711\ttotal: 19.2s\tremaining: 20.6s\n",
            "482:\tlearn: 0.2884146\ttotal: 19.2s\tremaining: 20.5s\n",
            "483:\tlearn: 0.2883752\ttotal: 19.2s\tremaining: 20.5s\n",
            "484:\tlearn: 0.2883385\ttotal: 19.3s\tremaining: 20.4s\n",
            "485:\tlearn: 0.2882963\ttotal: 19.3s\tremaining: 20.4s\n",
            "486:\tlearn: 0.2882488\ttotal: 19.3s\tremaining: 20.4s\n",
            "487:\tlearn: 0.2882104\ttotal: 19.4s\tremaining: 20.3s\n",
            "488:\tlearn: 0.2881656\ttotal: 19.4s\tremaining: 20.3s\n",
            "489:\tlearn: 0.2881150\ttotal: 19.4s\tremaining: 20.2s\n",
            "490:\tlearn: 0.2880731\ttotal: 19.5s\tremaining: 20.2s\n",
            "491:\tlearn: 0.2880335\ttotal: 19.5s\tremaining: 20.1s\n",
            "492:\tlearn: 0.2879920\ttotal: 19.5s\tremaining: 20.1s\n",
            "493:\tlearn: 0.2879521\ttotal: 19.6s\tremaining: 20s\n",
            "494:\tlearn: 0.2879012\ttotal: 19.6s\tremaining: 20s\n",
            "495:\tlearn: 0.2878515\ttotal: 19.6s\tremaining: 19.9s\n",
            "496:\tlearn: 0.2878149\ttotal: 19.7s\tremaining: 19.9s\n",
            "497:\tlearn: 0.2877681\ttotal: 19.7s\tremaining: 19.9s\n",
            "498:\tlearn: 0.2877287\ttotal: 19.7s\tremaining: 19.8s\n",
            "499:\tlearn: 0.2876732\ttotal: 19.8s\tremaining: 19.8s\n",
            "500:\tlearn: 0.2876204\ttotal: 19.8s\tremaining: 19.7s\n",
            "501:\tlearn: 0.2875805\ttotal: 19.9s\tremaining: 19.7s\n",
            "502:\tlearn: 0.2875250\ttotal: 19.9s\tremaining: 19.7s\n",
            "503:\tlearn: 0.2874891\ttotal: 19.9s\tremaining: 19.6s\n",
            "504:\tlearn: 0.2874502\ttotal: 20s\tremaining: 19.6s\n",
            "505:\tlearn: 0.2873993\ttotal: 20s\tremaining: 19.5s\n",
            "506:\tlearn: 0.2873471\ttotal: 20s\tremaining: 19.5s\n",
            "507:\tlearn: 0.2873027\ttotal: 20.1s\tremaining: 19.4s\n",
            "508:\tlearn: 0.2872655\ttotal: 20.1s\tremaining: 19.4s\n",
            "509:\tlearn: 0.2872283\ttotal: 20.1s\tremaining: 19.3s\n",
            "510:\tlearn: 0.2871784\ttotal: 20.1s\tremaining: 19.3s\n",
            "511:\tlearn: 0.2871304\ttotal: 20.2s\tremaining: 19.2s\n",
            "512:\tlearn: 0.2870971\ttotal: 20.2s\tremaining: 19.2s\n",
            "513:\tlearn: 0.2870657\ttotal: 20.3s\tremaining: 19.2s\n",
            "514:\tlearn: 0.2870145\ttotal: 20.3s\tremaining: 19.1s\n",
            "515:\tlearn: 0.2869784\ttotal: 20.3s\tremaining: 19.1s\n",
            "516:\tlearn: 0.2869510\ttotal: 20.4s\tremaining: 19s\n",
            "517:\tlearn: 0.2869178\ttotal: 20.4s\tremaining: 19s\n",
            "518:\tlearn: 0.2868962\ttotal: 20.4s\tremaining: 18.9s\n",
            "519:\tlearn: 0.2868474\ttotal: 20.5s\tremaining: 18.9s\n",
            "520:\tlearn: 0.2868113\ttotal: 20.5s\tremaining: 18.8s\n",
            "521:\tlearn: 0.2867624\ttotal: 20.5s\tremaining: 18.8s\n",
            "522:\tlearn: 0.2867143\ttotal: 20.6s\tremaining: 18.8s\n",
            "523:\tlearn: 0.2866658\ttotal: 20.6s\tremaining: 18.7s\n",
            "524:\tlearn: 0.2866245\ttotal: 20.6s\tremaining: 18.7s\n",
            "525:\tlearn: 0.2865907\ttotal: 20.7s\tremaining: 18.6s\n",
            "526:\tlearn: 0.2865534\ttotal: 20.7s\tremaining: 18.6s\n",
            "527:\tlearn: 0.2865166\ttotal: 20.7s\tremaining: 18.5s\n",
            "528:\tlearn: 0.2864650\ttotal: 20.8s\tremaining: 18.5s\n",
            "529:\tlearn: 0.2864283\ttotal: 20.8s\tremaining: 18.4s\n",
            "530:\tlearn: 0.2863974\ttotal: 20.8s\tremaining: 18.4s\n",
            "531:\tlearn: 0.2863585\ttotal: 20.9s\tremaining: 18.4s\n",
            "532:\tlearn: 0.2863262\ttotal: 20.9s\tremaining: 18.3s\n",
            "533:\tlearn: 0.2862739\ttotal: 20.9s\tremaining: 18.3s\n",
            "534:\tlearn: 0.2862354\ttotal: 21s\tremaining: 18.2s\n",
            "535:\tlearn: 0.2862033\ttotal: 21s\tremaining: 18.2s\n",
            "536:\tlearn: 0.2861559\ttotal: 21s\tremaining: 18.1s\n",
            "537:\tlearn: 0.2861118\ttotal: 21.1s\tremaining: 18.1s\n",
            "538:\tlearn: 0.2860740\ttotal: 21.1s\tremaining: 18s\n",
            "539:\tlearn: 0.2860253\ttotal: 21.1s\tremaining: 18s\n",
            "540:\tlearn: 0.2859858\ttotal: 21.2s\tremaining: 18s\n",
            "541:\tlearn: 0.2859610\ttotal: 21.2s\tremaining: 17.9s\n",
            "542:\tlearn: 0.2859186\ttotal: 21.2s\tremaining: 17.9s\n",
            "543:\tlearn: 0.2858706\ttotal: 21.3s\tremaining: 17.8s\n",
            "544:\tlearn: 0.2858164\ttotal: 21.3s\tremaining: 17.8s\n",
            "545:\tlearn: 0.2857703\ttotal: 21.3s\tremaining: 17.7s\n",
            "546:\tlearn: 0.2857265\ttotal: 21.4s\tremaining: 17.7s\n",
            "547:\tlearn: 0.2856803\ttotal: 21.4s\tremaining: 17.6s\n",
            "548:\tlearn: 0.2856436\ttotal: 21.4s\tremaining: 17.6s\n",
            "549:\tlearn: 0.2856082\ttotal: 21.5s\tremaining: 17.6s\n",
            "550:\tlearn: 0.2855742\ttotal: 21.5s\tremaining: 17.5s\n",
            "551:\tlearn: 0.2855466\ttotal: 21.5s\tremaining: 17.5s\n",
            "552:\tlearn: 0.2855094\ttotal: 21.6s\tremaining: 17.4s\n",
            "553:\tlearn: 0.2854543\ttotal: 21.6s\tremaining: 17.4s\n",
            "554:\tlearn: 0.2854154\ttotal: 21.6s\tremaining: 17.3s\n",
            "555:\tlearn: 0.2853719\ttotal: 21.7s\tremaining: 17.3s\n",
            "556:\tlearn: 0.2853376\ttotal: 21.7s\tremaining: 17.3s\n",
            "557:\tlearn: 0.2852931\ttotal: 21.7s\tremaining: 17.2s\n",
            "558:\tlearn: 0.2852460\ttotal: 21.8s\tremaining: 17.2s\n",
            "559:\tlearn: 0.2852109\ttotal: 21.8s\tremaining: 17.1s\n",
            "560:\tlearn: 0.2851768\ttotal: 21.8s\tremaining: 17.1s\n",
            "561:\tlearn: 0.2851453\ttotal: 21.9s\tremaining: 17s\n",
            "562:\tlearn: 0.2851012\ttotal: 21.9s\tremaining: 17s\n",
            "563:\tlearn: 0.2850547\ttotal: 21.9s\tremaining: 17s\n",
            "564:\tlearn: 0.2850209\ttotal: 22s\tremaining: 16.9s\n",
            "565:\tlearn: 0.2849813\ttotal: 22s\tremaining: 16.9s\n",
            "566:\tlearn: 0.2849348\ttotal: 22s\tremaining: 16.8s\n",
            "567:\tlearn: 0.2848841\ttotal: 22.1s\tremaining: 16.8s\n",
            "568:\tlearn: 0.2848438\ttotal: 22.1s\tremaining: 16.7s\n",
            "569:\tlearn: 0.2848061\ttotal: 22.1s\tremaining: 16.7s\n",
            "570:\tlearn: 0.2847560\ttotal: 22.2s\tremaining: 16.7s\n",
            "571:\tlearn: 0.2847192\ttotal: 22.2s\tremaining: 16.6s\n",
            "572:\tlearn: 0.2846903\ttotal: 22.2s\tremaining: 16.6s\n",
            "573:\tlearn: 0.2846537\ttotal: 22.3s\tremaining: 16.5s\n",
            "574:\tlearn: 0.2846251\ttotal: 22.3s\tremaining: 16.5s\n",
            "575:\tlearn: 0.2845631\ttotal: 22.3s\tremaining: 16.4s\n",
            "576:\tlearn: 0.2845199\ttotal: 22.4s\tremaining: 16.4s\n",
            "577:\tlearn: 0.2844763\ttotal: 22.4s\tremaining: 16.4s\n",
            "578:\tlearn: 0.2844555\ttotal: 22.4s\tremaining: 16.3s\n",
            "579:\tlearn: 0.2844109\ttotal: 22.5s\tremaining: 16.3s\n",
            "580:\tlearn: 0.2843678\ttotal: 22.5s\tremaining: 16.2s\n",
            "581:\tlearn: 0.2843423\ttotal: 22.5s\tremaining: 16.2s\n",
            "582:\tlearn: 0.2843099\ttotal: 22.6s\tremaining: 16.1s\n",
            "583:\tlearn: 0.2842877\ttotal: 22.6s\tremaining: 16.1s\n",
            "584:\tlearn: 0.2842464\ttotal: 22.6s\tremaining: 16.1s\n",
            "585:\tlearn: 0.2842037\ttotal: 22.7s\tremaining: 16s\n",
            "586:\tlearn: 0.2841611\ttotal: 22.7s\tremaining: 16s\n",
            "587:\tlearn: 0.2841245\ttotal: 22.7s\tremaining: 15.9s\n",
            "588:\tlearn: 0.2840875\ttotal: 22.8s\tremaining: 15.9s\n",
            "589:\tlearn: 0.2840363\ttotal: 22.8s\tremaining: 15.9s\n",
            "590:\tlearn: 0.2839867\ttotal: 22.9s\tremaining: 15.8s\n",
            "591:\tlearn: 0.2839465\ttotal: 22.9s\tremaining: 15.8s\n",
            "592:\tlearn: 0.2839010\ttotal: 22.9s\tremaining: 15.7s\n",
            "593:\tlearn: 0.2838376\ttotal: 23s\tremaining: 15.7s\n",
            "594:\tlearn: 0.2838064\ttotal: 23s\tremaining: 15.7s\n",
            "595:\tlearn: 0.2837740\ttotal: 23s\tremaining: 15.6s\n",
            "596:\tlearn: 0.2837401\ttotal: 23.1s\tremaining: 15.6s\n",
            "597:\tlearn: 0.2836991\ttotal: 23.1s\tremaining: 15.5s\n",
            "598:\tlearn: 0.2836532\ttotal: 23.1s\tremaining: 15.5s\n",
            "599:\tlearn: 0.2836205\ttotal: 23.2s\tremaining: 15.4s\n",
            "600:\tlearn: 0.2835834\ttotal: 23.2s\tremaining: 15.4s\n",
            "601:\tlearn: 0.2835483\ttotal: 23.2s\tremaining: 15.4s\n",
            "602:\tlearn: 0.2834989\ttotal: 23.3s\tremaining: 15.3s\n",
            "603:\tlearn: 0.2834764\ttotal: 23.3s\tremaining: 15.3s\n",
            "604:\tlearn: 0.2834464\ttotal: 23.3s\tremaining: 15.2s\n",
            "605:\tlearn: 0.2834054\ttotal: 23.4s\tremaining: 15.2s\n",
            "606:\tlearn: 0.2833732\ttotal: 23.4s\tremaining: 15.1s\n",
            "607:\tlearn: 0.2833356\ttotal: 23.4s\tremaining: 15.1s\n",
            "608:\tlearn: 0.2832973\ttotal: 23.5s\tremaining: 15.1s\n",
            "609:\tlearn: 0.2832564\ttotal: 23.5s\tremaining: 15s\n",
            "610:\tlearn: 0.2832288\ttotal: 23.5s\tremaining: 15s\n",
            "611:\tlearn: 0.2831968\ttotal: 23.5s\tremaining: 14.9s\n",
            "612:\tlearn: 0.2831506\ttotal: 23.6s\tremaining: 14.9s\n",
            "613:\tlearn: 0.2831045\ttotal: 23.6s\tremaining: 14.8s\n",
            "614:\tlearn: 0.2830627\ttotal: 23.7s\tremaining: 14.8s\n",
            "615:\tlearn: 0.2830361\ttotal: 23.7s\tremaining: 14.8s\n",
            "616:\tlearn: 0.2830143\ttotal: 23.7s\tremaining: 14.7s\n",
            "617:\tlearn: 0.2829839\ttotal: 23.7s\tremaining: 14.7s\n",
            "618:\tlearn: 0.2829553\ttotal: 23.8s\tremaining: 14.6s\n",
            "619:\tlearn: 0.2829195\ttotal: 23.8s\tremaining: 14.6s\n",
            "620:\tlearn: 0.2828646\ttotal: 23.9s\tremaining: 14.6s\n",
            "621:\tlearn: 0.2828111\ttotal: 23.9s\tremaining: 14.5s\n",
            "622:\tlearn: 0.2827773\ttotal: 23.9s\tremaining: 14.5s\n",
            "623:\tlearn: 0.2827445\ttotal: 24s\tremaining: 14.4s\n",
            "624:\tlearn: 0.2827110\ttotal: 24s\tremaining: 14.4s\n",
            "625:\tlearn: 0.2826726\ttotal: 24s\tremaining: 14.4s\n",
            "626:\tlearn: 0.2826291\ttotal: 24.1s\tremaining: 14.3s\n",
            "627:\tlearn: 0.2825998\ttotal: 24.1s\tremaining: 14.3s\n",
            "628:\tlearn: 0.2825656\ttotal: 24.1s\tremaining: 14.2s\n",
            "629:\tlearn: 0.2825255\ttotal: 24.2s\tremaining: 14.2s\n",
            "630:\tlearn: 0.2824850\ttotal: 24.2s\tremaining: 14.1s\n",
            "631:\tlearn: 0.2824473\ttotal: 24.2s\tremaining: 14.1s\n",
            "632:\tlearn: 0.2824118\ttotal: 24.3s\tremaining: 14.1s\n",
            "633:\tlearn: 0.2823738\ttotal: 24.3s\tremaining: 14s\n",
            "634:\tlearn: 0.2823407\ttotal: 24.3s\tremaining: 14s\n",
            "635:\tlearn: 0.2823140\ttotal: 24.4s\tremaining: 13.9s\n",
            "636:\tlearn: 0.2822655\ttotal: 24.4s\tremaining: 13.9s\n",
            "637:\tlearn: 0.2822176\ttotal: 24.4s\tremaining: 13.9s\n",
            "638:\tlearn: 0.2821860\ttotal: 24.5s\tremaining: 13.8s\n",
            "639:\tlearn: 0.2821544\ttotal: 24.5s\tremaining: 13.8s\n",
            "640:\tlearn: 0.2821167\ttotal: 24.5s\tremaining: 13.7s\n",
            "641:\tlearn: 0.2820748\ttotal: 24.5s\tremaining: 13.7s\n",
            "642:\tlearn: 0.2820365\ttotal: 24.6s\tremaining: 13.7s\n",
            "643:\tlearn: 0.2820006\ttotal: 24.6s\tremaining: 13.6s\n",
            "644:\tlearn: 0.2819657\ttotal: 24.7s\tremaining: 13.6s\n",
            "645:\tlearn: 0.2819367\ttotal: 24.7s\tremaining: 13.5s\n",
            "646:\tlearn: 0.2818996\ttotal: 24.7s\tremaining: 13.5s\n",
            "647:\tlearn: 0.2818604\ttotal: 24.7s\tremaining: 13.4s\n",
            "648:\tlearn: 0.2818133\ttotal: 24.8s\tremaining: 13.4s\n",
            "649:\tlearn: 0.2817696\ttotal: 24.8s\tremaining: 13.4s\n",
            "650:\tlearn: 0.2817342\ttotal: 24.9s\tremaining: 13.3s\n",
            "651:\tlearn: 0.2817134\ttotal: 24.9s\tremaining: 13.3s\n",
            "652:\tlearn: 0.2816653\ttotal: 25s\tremaining: 13.3s\n",
            "653:\tlearn: 0.2816044\ttotal: 25.1s\tremaining: 13.3s\n",
            "654:\tlearn: 0.2815733\ttotal: 25.1s\tremaining: 13.2s\n",
            "655:\tlearn: 0.2815343\ttotal: 25.2s\tremaining: 13.2s\n",
            "656:\tlearn: 0.2815058\ttotal: 25.2s\tremaining: 13.2s\n",
            "657:\tlearn: 0.2814597\ttotal: 25.3s\tremaining: 13.1s\n",
            "658:\tlearn: 0.2814275\ttotal: 25.4s\tremaining: 13.1s\n",
            "659:\tlearn: 0.2813894\ttotal: 25.4s\tremaining: 13.1s\n",
            "660:\tlearn: 0.2813447\ttotal: 25.5s\tremaining: 13.1s\n",
            "661:\tlearn: 0.2813074\ttotal: 25.6s\tremaining: 13.1s\n",
            "662:\tlearn: 0.2812844\ttotal: 25.6s\tremaining: 13s\n",
            "663:\tlearn: 0.2812407\ttotal: 25.7s\tremaining: 13s\n",
            "664:\tlearn: 0.2812097\ttotal: 25.8s\tremaining: 13s\n",
            "665:\tlearn: 0.2811654\ttotal: 25.9s\tremaining: 13s\n",
            "666:\tlearn: 0.2811298\ttotal: 25.9s\tremaining: 12.9s\n",
            "667:\tlearn: 0.2810960\ttotal: 26s\tremaining: 12.9s\n",
            "668:\tlearn: 0.2810502\ttotal: 26s\tremaining: 12.9s\n",
            "669:\tlearn: 0.2810117\ttotal: 26.1s\tremaining: 12.9s\n",
            "670:\tlearn: 0.2809788\ttotal: 26.2s\tremaining: 12.8s\n",
            "671:\tlearn: 0.2809353\ttotal: 26.3s\tremaining: 12.8s\n",
            "672:\tlearn: 0.2808978\ttotal: 26.4s\tremaining: 12.8s\n",
            "673:\tlearn: 0.2808735\ttotal: 26.4s\tremaining: 12.8s\n",
            "674:\tlearn: 0.2808517\ttotal: 26.5s\tremaining: 12.8s\n",
            "675:\tlearn: 0.2808038\ttotal: 26.6s\tremaining: 12.7s\n",
            "676:\tlearn: 0.2807771\ttotal: 26.6s\tremaining: 12.7s\n",
            "677:\tlearn: 0.2807342\ttotal: 26.7s\tremaining: 12.7s\n",
            "678:\tlearn: 0.2806932\ttotal: 26.8s\tremaining: 12.6s\n",
            "679:\tlearn: 0.2806648\ttotal: 26.8s\tremaining: 12.6s\n",
            "680:\tlearn: 0.2806332\ttotal: 26.9s\tremaining: 12.6s\n",
            "681:\tlearn: 0.2805957\ttotal: 27s\tremaining: 12.6s\n",
            "682:\tlearn: 0.2805686\ttotal: 27s\tremaining: 12.5s\n",
            "683:\tlearn: 0.2805246\ttotal: 27.1s\tremaining: 12.5s\n",
            "684:\tlearn: 0.2804844\ttotal: 27.2s\tremaining: 12.5s\n",
            "685:\tlearn: 0.2804340\ttotal: 27.3s\tremaining: 12.5s\n",
            "686:\tlearn: 0.2803992\ttotal: 27.3s\tremaining: 12.4s\n",
            "687:\tlearn: 0.2803453\ttotal: 27.4s\tremaining: 12.4s\n",
            "688:\tlearn: 0.2803109\ttotal: 27.5s\tremaining: 12.4s\n",
            "689:\tlearn: 0.2802785\ttotal: 27.5s\tremaining: 12.4s\n",
            "690:\tlearn: 0.2802248\ttotal: 27.6s\tremaining: 12.3s\n",
            "691:\tlearn: 0.2801900\ttotal: 27.6s\tremaining: 12.3s\n",
            "692:\tlearn: 0.2801573\ttotal: 27.6s\tremaining: 12.2s\n",
            "693:\tlearn: 0.2801281\ttotal: 27.6s\tremaining: 12.2s\n",
            "694:\tlearn: 0.2800812\ttotal: 27.7s\tremaining: 12.2s\n",
            "695:\tlearn: 0.2800490\ttotal: 27.7s\tremaining: 12.1s\n",
            "696:\tlearn: 0.2800024\ttotal: 27.8s\tremaining: 12.1s\n",
            "697:\tlearn: 0.2799642\ttotal: 27.8s\tremaining: 12s\n",
            "698:\tlearn: 0.2799125\ttotal: 27.8s\tremaining: 12s\n",
            "699:\tlearn: 0.2798616\ttotal: 27.9s\tremaining: 11.9s\n",
            "700:\tlearn: 0.2798306\ttotal: 27.9s\tremaining: 11.9s\n",
            "701:\tlearn: 0.2797819\ttotal: 27.9s\tremaining: 11.9s\n",
            "702:\tlearn: 0.2797425\ttotal: 28s\tremaining: 11.8s\n",
            "703:\tlearn: 0.2797044\ttotal: 28s\tremaining: 11.8s\n",
            "704:\tlearn: 0.2796695\ttotal: 28s\tremaining: 11.7s\n",
            "705:\tlearn: 0.2796180\ttotal: 28.1s\tremaining: 11.7s\n",
            "706:\tlearn: 0.2795792\ttotal: 28.1s\tremaining: 11.6s\n",
            "707:\tlearn: 0.2795452\ttotal: 28.1s\tremaining: 11.6s\n",
            "708:\tlearn: 0.2795289\ttotal: 28.2s\tremaining: 11.6s\n",
            "709:\tlearn: 0.2794858\ttotal: 28.2s\tremaining: 11.5s\n",
            "710:\tlearn: 0.2794514\ttotal: 28.2s\tremaining: 11.5s\n",
            "711:\tlearn: 0.2794156\ttotal: 28.3s\tremaining: 11.4s\n",
            "712:\tlearn: 0.2793754\ttotal: 28.3s\tremaining: 11.4s\n",
            "713:\tlearn: 0.2793358\ttotal: 28.3s\tremaining: 11.4s\n",
            "714:\tlearn: 0.2792894\ttotal: 28.4s\tremaining: 11.3s\n",
            "715:\tlearn: 0.2792513\ttotal: 28.4s\tremaining: 11.3s\n",
            "716:\tlearn: 0.2792153\ttotal: 28.4s\tremaining: 11.2s\n",
            "717:\tlearn: 0.2791766\ttotal: 28.5s\tremaining: 11.2s\n",
            "718:\tlearn: 0.2791303\ttotal: 28.5s\tremaining: 11.1s\n",
            "719:\tlearn: 0.2790885\ttotal: 28.5s\tremaining: 11.1s\n",
            "720:\tlearn: 0.2790540\ttotal: 28.6s\tremaining: 11.1s\n",
            "721:\tlearn: 0.2790201\ttotal: 28.6s\tremaining: 11s\n",
            "722:\tlearn: 0.2789962\ttotal: 28.7s\tremaining: 11s\n",
            "723:\tlearn: 0.2789492\ttotal: 28.7s\tremaining: 10.9s\n",
            "724:\tlearn: 0.2789160\ttotal: 28.7s\tremaining: 10.9s\n",
            "725:\tlearn: 0.2788784\ttotal: 28.8s\tremaining: 10.9s\n",
            "726:\tlearn: 0.2788171\ttotal: 28.8s\tremaining: 10.8s\n",
            "727:\tlearn: 0.2787747\ttotal: 28.8s\tremaining: 10.8s\n",
            "728:\tlearn: 0.2787259\ttotal: 28.9s\tremaining: 10.7s\n",
            "729:\tlearn: 0.2786899\ttotal: 28.9s\tremaining: 10.7s\n",
            "730:\tlearn: 0.2786589\ttotal: 28.9s\tremaining: 10.6s\n",
            "731:\tlearn: 0.2786327\ttotal: 29s\tremaining: 10.6s\n",
            "732:\tlearn: 0.2786015\ttotal: 29s\tremaining: 10.6s\n",
            "733:\tlearn: 0.2785653\ttotal: 29s\tremaining: 10.5s\n",
            "734:\tlearn: 0.2785301\ttotal: 29.1s\tremaining: 10.5s\n",
            "735:\tlearn: 0.2784901\ttotal: 29.1s\tremaining: 10.4s\n",
            "736:\tlearn: 0.2784597\ttotal: 29.1s\tremaining: 10.4s\n",
            "737:\tlearn: 0.2784105\ttotal: 29.2s\tremaining: 10.4s\n",
            "738:\tlearn: 0.2783829\ttotal: 29.2s\tremaining: 10.3s\n",
            "739:\tlearn: 0.2783545\ttotal: 29.2s\tremaining: 10.3s\n",
            "740:\tlearn: 0.2783096\ttotal: 29.3s\tremaining: 10.2s\n",
            "741:\tlearn: 0.2782759\ttotal: 29.3s\tremaining: 10.2s\n",
            "742:\tlearn: 0.2782407\ttotal: 29.3s\tremaining: 10.2s\n",
            "743:\tlearn: 0.2782024\ttotal: 29.4s\tremaining: 10.1s\n",
            "744:\tlearn: 0.2781656\ttotal: 29.4s\tremaining: 10.1s\n",
            "745:\tlearn: 0.2781211\ttotal: 29.4s\tremaining: 10s\n",
            "746:\tlearn: 0.2780832\ttotal: 29.5s\tremaining: 9.98s\n",
            "747:\tlearn: 0.2780610\ttotal: 29.5s\tremaining: 9.95s\n",
            "748:\tlearn: 0.2780305\ttotal: 29.6s\tremaining: 9.9s\n",
            "749:\tlearn: 0.2779837\ttotal: 29.6s\tremaining: 9.86s\n",
            "750:\tlearn: 0.2779527\ttotal: 29.6s\tremaining: 9.82s\n",
            "751:\tlearn: 0.2779254\ttotal: 29.6s\tremaining: 9.78s\n",
            "752:\tlearn: 0.2778894\ttotal: 29.7s\tremaining: 9.73s\n",
            "753:\tlearn: 0.2778397\ttotal: 29.7s\tremaining: 9.69s\n",
            "754:\tlearn: 0.2778070\ttotal: 29.8s\tremaining: 9.65s\n",
            "755:\tlearn: 0.2777643\ttotal: 29.8s\tremaining: 9.61s\n",
            "756:\tlearn: 0.2777406\ttotal: 29.8s\tremaining: 9.57s\n",
            "757:\tlearn: 0.2777122\ttotal: 29.8s\tremaining: 9.53s\n",
            "758:\tlearn: 0.2776772\ttotal: 29.9s\tremaining: 9.49s\n",
            "759:\tlearn: 0.2776442\ttotal: 29.9s\tremaining: 9.45s\n",
            "760:\tlearn: 0.2775979\ttotal: 29.9s\tremaining: 9.4s\n",
            "761:\tlearn: 0.2775521\ttotal: 30s\tremaining: 9.37s\n",
            "762:\tlearn: 0.2775007\ttotal: 30s\tremaining: 9.33s\n",
            "763:\tlearn: 0.2774545\ttotal: 30.1s\tremaining: 9.29s\n",
            "764:\tlearn: 0.2774202\ttotal: 30.1s\tremaining: 9.25s\n",
            "765:\tlearn: 0.2774014\ttotal: 30.1s\tremaining: 9.21s\n",
            "766:\tlearn: 0.2773667\ttotal: 30.2s\tremaining: 9.17s\n",
            "767:\tlearn: 0.2773283\ttotal: 30.2s\tremaining: 9.13s\n",
            "768:\tlearn: 0.2772889\ttotal: 30.2s\tremaining: 9.09s\n",
            "769:\tlearn: 0.2772443\ttotal: 30.3s\tremaining: 9.04s\n",
            "770:\tlearn: 0.2772049\ttotal: 30.3s\tremaining: 9s\n",
            "771:\tlearn: 0.2771614\ttotal: 30.3s\tremaining: 8.96s\n",
            "772:\tlearn: 0.2771271\ttotal: 30.4s\tremaining: 8.92s\n",
            "773:\tlearn: 0.2770910\ttotal: 30.4s\tremaining: 8.88s\n",
            "774:\tlearn: 0.2770495\ttotal: 30.5s\tremaining: 8.84s\n",
            "775:\tlearn: 0.2770213\ttotal: 30.5s\tremaining: 8.8s\n",
            "776:\tlearn: 0.2769791\ttotal: 30.5s\tremaining: 8.76s\n",
            "777:\tlearn: 0.2769360\ttotal: 30.6s\tremaining: 8.72s\n",
            "778:\tlearn: 0.2768866\ttotal: 30.6s\tremaining: 8.68s\n",
            "779:\tlearn: 0.2768414\ttotal: 30.6s\tremaining: 8.63s\n",
            "780:\tlearn: 0.2768169\ttotal: 30.6s\tremaining: 8.59s\n",
            "781:\tlearn: 0.2767832\ttotal: 30.7s\tremaining: 8.55s\n",
            "782:\tlearn: 0.2767448\ttotal: 30.7s\tremaining: 8.51s\n",
            "783:\tlearn: 0.2767122\ttotal: 30.7s\tremaining: 8.47s\n",
            "784:\tlearn: 0.2766785\ttotal: 30.8s\tremaining: 8.43s\n",
            "785:\tlearn: 0.2766463\ttotal: 30.8s\tremaining: 8.39s\n",
            "786:\tlearn: 0.2766117\ttotal: 30.8s\tremaining: 8.35s\n",
            "787:\tlearn: 0.2765734\ttotal: 30.9s\tremaining: 8.3s\n",
            "788:\tlearn: 0.2765409\ttotal: 30.9s\tremaining: 8.27s\n",
            "789:\tlearn: 0.2765014\ttotal: 30.9s\tremaining: 8.23s\n",
            "790:\tlearn: 0.2764723\ttotal: 31s\tremaining: 8.19s\n",
            "791:\tlearn: 0.2764344\ttotal: 31s\tremaining: 8.15s\n",
            "792:\tlearn: 0.2764063\ttotal: 31.1s\tremaining: 8.11s\n",
            "793:\tlearn: 0.2763472\ttotal: 31.1s\tremaining: 8.07s\n",
            "794:\tlearn: 0.2762910\ttotal: 31.1s\tremaining: 8.03s\n",
            "795:\tlearn: 0.2762671\ttotal: 31.2s\tremaining: 7.99s\n",
            "796:\tlearn: 0.2762222\ttotal: 31.2s\tremaining: 7.95s\n",
            "797:\tlearn: 0.2761931\ttotal: 31.2s\tremaining: 7.91s\n",
            "798:\tlearn: 0.2761623\ttotal: 31.3s\tremaining: 7.87s\n",
            "799:\tlearn: 0.2761190\ttotal: 31.3s\tremaining: 7.82s\n",
            "800:\tlearn: 0.2760760\ttotal: 31.3s\tremaining: 7.78s\n",
            "801:\tlearn: 0.2760448\ttotal: 31.4s\tremaining: 7.74s\n",
            "802:\tlearn: 0.2760155\ttotal: 31.4s\tremaining: 7.7s\n",
            "803:\tlearn: 0.2759834\ttotal: 31.4s\tremaining: 7.66s\n",
            "804:\tlearn: 0.2759490\ttotal: 31.5s\tremaining: 7.62s\n",
            "805:\tlearn: 0.2759072\ttotal: 31.5s\tremaining: 7.58s\n",
            "806:\tlearn: 0.2758661\ttotal: 31.5s\tremaining: 7.54s\n",
            "807:\tlearn: 0.2758288\ttotal: 31.6s\tremaining: 7.5s\n",
            "808:\tlearn: 0.2757958\ttotal: 31.6s\tremaining: 7.46s\n",
            "809:\tlearn: 0.2757639\ttotal: 31.6s\tremaining: 7.42s\n",
            "810:\tlearn: 0.2757338\ttotal: 31.7s\tremaining: 7.38s\n",
            "811:\tlearn: 0.2756979\ttotal: 31.7s\tremaining: 7.34s\n",
            "812:\tlearn: 0.2756576\ttotal: 31.7s\tremaining: 7.3s\n",
            "813:\tlearn: 0.2756244\ttotal: 31.8s\tremaining: 7.26s\n",
            "814:\tlearn: 0.2755929\ttotal: 31.8s\tremaining: 7.22s\n",
            "815:\tlearn: 0.2755574\ttotal: 31.8s\tremaining: 7.18s\n",
            "816:\tlearn: 0.2755168\ttotal: 31.9s\tremaining: 7.14s\n",
            "817:\tlearn: 0.2754914\ttotal: 31.9s\tremaining: 7.1s\n",
            "818:\tlearn: 0.2754617\ttotal: 31.9s\tremaining: 7.06s\n",
            "819:\tlearn: 0.2754169\ttotal: 32s\tremaining: 7.01s\n",
            "820:\tlearn: 0.2753860\ttotal: 32s\tremaining: 6.97s\n",
            "821:\tlearn: 0.2753365\ttotal: 32s\tremaining: 6.94s\n",
            "822:\tlearn: 0.2752909\ttotal: 32.1s\tremaining: 6.9s\n",
            "823:\tlearn: 0.2752494\ttotal: 32.1s\tremaining: 6.86s\n",
            "824:\tlearn: 0.2751983\ttotal: 32.2s\tremaining: 6.82s\n",
            "825:\tlearn: 0.2751522\ttotal: 32.2s\tremaining: 6.78s\n",
            "826:\tlearn: 0.2751039\ttotal: 32.2s\tremaining: 6.74s\n",
            "827:\tlearn: 0.2750545\ttotal: 32.3s\tremaining: 6.7s\n",
            "828:\tlearn: 0.2750265\ttotal: 32.3s\tremaining: 6.66s\n",
            "829:\tlearn: 0.2749818\ttotal: 32.3s\tremaining: 6.62s\n",
            "830:\tlearn: 0.2749512\ttotal: 32.4s\tremaining: 6.58s\n",
            "831:\tlearn: 0.2749100\ttotal: 32.4s\tremaining: 6.54s\n",
            "832:\tlearn: 0.2748707\ttotal: 32.4s\tremaining: 6.5s\n",
            "833:\tlearn: 0.2748284\ttotal: 32.5s\tremaining: 6.46s\n",
            "834:\tlearn: 0.2747824\ttotal: 32.5s\tremaining: 6.42s\n",
            "835:\tlearn: 0.2747605\ttotal: 32.5s\tremaining: 6.38s\n",
            "836:\tlearn: 0.2747234\ttotal: 32.6s\tremaining: 6.34s\n",
            "837:\tlearn: 0.2746943\ttotal: 32.6s\tremaining: 6.3s\n",
            "838:\tlearn: 0.2746484\ttotal: 32.6s\tremaining: 6.26s\n",
            "839:\tlearn: 0.2745983\ttotal: 32.7s\tremaining: 6.22s\n",
            "840:\tlearn: 0.2745620\ttotal: 32.7s\tremaining: 6.18s\n",
            "841:\tlearn: 0.2745368\ttotal: 32.7s\tremaining: 6.14s\n",
            "842:\tlearn: 0.2745135\ttotal: 32.7s\tremaining: 6.1s\n",
            "843:\tlearn: 0.2744729\ttotal: 32.8s\tremaining: 6.06s\n",
            "844:\tlearn: 0.2744349\ttotal: 32.8s\tremaining: 6.02s\n",
            "845:\tlearn: 0.2744167\ttotal: 32.9s\tremaining: 5.98s\n",
            "846:\tlearn: 0.2743778\ttotal: 32.9s\tremaining: 5.94s\n",
            "847:\tlearn: 0.2743513\ttotal: 32.9s\tremaining: 5.9s\n",
            "848:\tlearn: 0.2743126\ttotal: 33s\tremaining: 5.86s\n",
            "849:\tlearn: 0.2742726\ttotal: 33s\tremaining: 5.82s\n",
            "850:\tlearn: 0.2742438\ttotal: 33s\tremaining: 5.78s\n",
            "851:\tlearn: 0.2741995\ttotal: 33.1s\tremaining: 5.75s\n",
            "852:\tlearn: 0.2741758\ttotal: 33.1s\tremaining: 5.71s\n",
            "853:\tlearn: 0.2741489\ttotal: 33.1s\tremaining: 5.67s\n",
            "854:\tlearn: 0.2741018\ttotal: 33.2s\tremaining: 5.63s\n",
            "855:\tlearn: 0.2740694\ttotal: 33.2s\tremaining: 5.58s\n",
            "856:\tlearn: 0.2740340\ttotal: 33.2s\tremaining: 5.55s\n",
            "857:\tlearn: 0.2740120\ttotal: 33.3s\tremaining: 5.51s\n",
            "858:\tlearn: 0.2739845\ttotal: 33.3s\tremaining: 5.47s\n",
            "859:\tlearn: 0.2739576\ttotal: 33.3s\tremaining: 5.43s\n",
            "860:\tlearn: 0.2739186\ttotal: 33.4s\tremaining: 5.39s\n",
            "861:\tlearn: 0.2738773\ttotal: 33.4s\tremaining: 5.35s\n",
            "862:\tlearn: 0.2738478\ttotal: 33.4s\tremaining: 5.31s\n",
            "863:\tlearn: 0.2738030\ttotal: 33.5s\tremaining: 5.27s\n",
            "864:\tlearn: 0.2737661\ttotal: 33.5s\tremaining: 5.23s\n",
            "865:\tlearn: 0.2737265\ttotal: 33.5s\tremaining: 5.19s\n",
            "866:\tlearn: 0.2736958\ttotal: 33.6s\tremaining: 5.15s\n",
            "867:\tlearn: 0.2736595\ttotal: 33.6s\tremaining: 5.11s\n",
            "868:\tlearn: 0.2736118\ttotal: 33.6s\tremaining: 5.07s\n",
            "869:\tlearn: 0.2735823\ttotal: 33.7s\tremaining: 5.03s\n",
            "870:\tlearn: 0.2735467\ttotal: 33.7s\tremaining: 4.99s\n",
            "871:\tlearn: 0.2735055\ttotal: 33.7s\tremaining: 4.95s\n",
            "872:\tlearn: 0.2734663\ttotal: 33.8s\tremaining: 4.91s\n",
            "873:\tlearn: 0.2734320\ttotal: 33.8s\tremaining: 4.87s\n",
            "874:\tlearn: 0.2733994\ttotal: 33.8s\tremaining: 4.83s\n",
            "875:\tlearn: 0.2733470\ttotal: 33.9s\tremaining: 4.79s\n",
            "876:\tlearn: 0.2733168\ttotal: 33.9s\tremaining: 4.75s\n",
            "877:\tlearn: 0.2732849\ttotal: 33.9s\tremaining: 4.72s\n",
            "878:\tlearn: 0.2732580\ttotal: 34s\tremaining: 4.68s\n",
            "879:\tlearn: 0.2732111\ttotal: 34s\tremaining: 4.64s\n",
            "880:\tlearn: 0.2731669\ttotal: 34s\tremaining: 4.6s\n",
            "881:\tlearn: 0.2731295\ttotal: 34.1s\tremaining: 4.56s\n",
            "882:\tlearn: 0.2730882\ttotal: 34.1s\tremaining: 4.52s\n",
            "883:\tlearn: 0.2730555\ttotal: 34.2s\tremaining: 4.48s\n",
            "884:\tlearn: 0.2730245\ttotal: 34.2s\tremaining: 4.44s\n",
            "885:\tlearn: 0.2729869\ttotal: 34.2s\tremaining: 4.4s\n",
            "886:\tlearn: 0.2729659\ttotal: 34.3s\tremaining: 4.37s\n",
            "887:\tlearn: 0.2729342\ttotal: 34.3s\tremaining: 4.33s\n",
            "888:\tlearn: 0.2729086\ttotal: 34.3s\tremaining: 4.29s\n",
            "889:\tlearn: 0.2728664\ttotal: 34.4s\tremaining: 4.25s\n",
            "890:\tlearn: 0.2728345\ttotal: 34.4s\tremaining: 4.21s\n",
            "891:\tlearn: 0.2727975\ttotal: 34.4s\tremaining: 4.17s\n",
            "892:\tlearn: 0.2727654\ttotal: 34.5s\tremaining: 4.13s\n",
            "893:\tlearn: 0.2727269\ttotal: 34.5s\tremaining: 4.09s\n",
            "894:\tlearn: 0.2726872\ttotal: 34.5s\tremaining: 4.05s\n",
            "895:\tlearn: 0.2726592\ttotal: 34.5s\tremaining: 4.01s\n",
            "896:\tlearn: 0.2726240\ttotal: 34.6s\tremaining: 3.97s\n",
            "897:\tlearn: 0.2726015\ttotal: 34.6s\tremaining: 3.93s\n",
            "898:\tlearn: 0.2725731\ttotal: 34.7s\tremaining: 3.89s\n",
            "899:\tlearn: 0.2725376\ttotal: 34.7s\tremaining: 3.85s\n",
            "900:\tlearn: 0.2725089\ttotal: 34.7s\tremaining: 3.81s\n",
            "901:\tlearn: 0.2724725\ttotal: 34.8s\tremaining: 3.78s\n",
            "902:\tlearn: 0.2724364\ttotal: 34.8s\tremaining: 3.74s\n",
            "903:\tlearn: 0.2724021\ttotal: 34.8s\tremaining: 3.7s\n",
            "904:\tlearn: 0.2723643\ttotal: 34.9s\tremaining: 3.66s\n",
            "905:\tlearn: 0.2723183\ttotal: 34.9s\tremaining: 3.62s\n",
            "906:\tlearn: 0.2722784\ttotal: 34.9s\tremaining: 3.58s\n",
            "907:\tlearn: 0.2722401\ttotal: 35s\tremaining: 3.54s\n",
            "908:\tlearn: 0.2722076\ttotal: 35s\tremaining: 3.5s\n",
            "909:\tlearn: 0.2721770\ttotal: 35s\tremaining: 3.46s\n",
            "910:\tlearn: 0.2721223\ttotal: 35.1s\tremaining: 3.42s\n",
            "911:\tlearn: 0.2720776\ttotal: 35.1s\tremaining: 3.39s\n",
            "912:\tlearn: 0.2720415\ttotal: 35.1s\tremaining: 3.35s\n",
            "913:\tlearn: 0.2720027\ttotal: 35.2s\tremaining: 3.31s\n",
            "914:\tlearn: 0.2719640\ttotal: 35.2s\tremaining: 3.27s\n",
            "915:\tlearn: 0.2719293\ttotal: 35.2s\tremaining: 3.23s\n",
            "916:\tlearn: 0.2718923\ttotal: 35.3s\tremaining: 3.19s\n",
            "917:\tlearn: 0.2718385\ttotal: 35.3s\tremaining: 3.15s\n",
            "918:\tlearn: 0.2718083\ttotal: 35.3s\tremaining: 3.12s\n",
            "919:\tlearn: 0.2717797\ttotal: 35.4s\tremaining: 3.08s\n",
            "920:\tlearn: 0.2717453\ttotal: 35.4s\tremaining: 3.04s\n",
            "921:\tlearn: 0.2716955\ttotal: 35.4s\tremaining: 3s\n",
            "922:\tlearn: 0.2716587\ttotal: 35.5s\tremaining: 2.96s\n",
            "923:\tlearn: 0.2716256\ttotal: 35.5s\tremaining: 2.92s\n",
            "924:\tlearn: 0.2715950\ttotal: 35.5s\tremaining: 2.88s\n",
            "925:\tlearn: 0.2715496\ttotal: 35.6s\tremaining: 2.84s\n",
            "926:\tlearn: 0.2715211\ttotal: 35.6s\tremaining: 2.8s\n",
            "927:\tlearn: 0.2714823\ttotal: 35.6s\tremaining: 2.77s\n",
            "928:\tlearn: 0.2714518\ttotal: 35.7s\tremaining: 2.73s\n",
            "929:\tlearn: 0.2714235\ttotal: 35.7s\tremaining: 2.69s\n",
            "930:\tlearn: 0.2713911\ttotal: 35.8s\tremaining: 2.65s\n",
            "931:\tlearn: 0.2713607\ttotal: 35.8s\tremaining: 2.61s\n",
            "932:\tlearn: 0.2713233\ttotal: 35.8s\tremaining: 2.57s\n",
            "933:\tlearn: 0.2712977\ttotal: 35.8s\tremaining: 2.53s\n",
            "934:\tlearn: 0.2712607\ttotal: 35.9s\tremaining: 2.49s\n",
            "935:\tlearn: 0.2712319\ttotal: 35.9s\tremaining: 2.46s\n",
            "936:\tlearn: 0.2711926\ttotal: 35.9s\tremaining: 2.42s\n",
            "937:\tlearn: 0.2711639\ttotal: 36s\tremaining: 2.38s\n",
            "938:\tlearn: 0.2711349\ttotal: 36s\tremaining: 2.34s\n",
            "939:\tlearn: 0.2710874\ttotal: 36s\tremaining: 2.3s\n",
            "940:\tlearn: 0.2710623\ttotal: 36.1s\tremaining: 2.26s\n",
            "941:\tlearn: 0.2710226\ttotal: 36.1s\tremaining: 2.22s\n",
            "942:\tlearn: 0.2709878\ttotal: 36.2s\tremaining: 2.19s\n",
            "943:\tlearn: 0.2709609\ttotal: 36.2s\tremaining: 2.15s\n",
            "944:\tlearn: 0.2709186\ttotal: 36.2s\tremaining: 2.11s\n",
            "945:\tlearn: 0.2708808\ttotal: 36.3s\tremaining: 2.07s\n",
            "946:\tlearn: 0.2708482\ttotal: 36.3s\tremaining: 2.03s\n",
            "947:\tlearn: 0.2708134\ttotal: 36.3s\tremaining: 1.99s\n",
            "948:\tlearn: 0.2707863\ttotal: 36.4s\tremaining: 1.95s\n",
            "949:\tlearn: 0.2707656\ttotal: 36.4s\tremaining: 1.92s\n",
            "950:\tlearn: 0.2707281\ttotal: 36.4s\tremaining: 1.88s\n",
            "951:\tlearn: 0.2706996\ttotal: 36.5s\tremaining: 1.84s\n",
            "952:\tlearn: 0.2706655\ttotal: 36.5s\tremaining: 1.8s\n",
            "953:\tlearn: 0.2706241\ttotal: 36.5s\tremaining: 1.76s\n",
            "954:\tlearn: 0.2705872\ttotal: 36.6s\tremaining: 1.72s\n",
            "955:\tlearn: 0.2705561\ttotal: 36.6s\tremaining: 1.68s\n",
            "956:\tlearn: 0.2705297\ttotal: 36.6s\tremaining: 1.65s\n",
            "957:\tlearn: 0.2704887\ttotal: 36.7s\tremaining: 1.61s\n",
            "958:\tlearn: 0.2704570\ttotal: 36.7s\tremaining: 1.57s\n",
            "959:\tlearn: 0.2704311\ttotal: 36.7s\tremaining: 1.53s\n",
            "960:\tlearn: 0.2703847\ttotal: 36.8s\tremaining: 1.49s\n",
            "961:\tlearn: 0.2703512\ttotal: 36.8s\tremaining: 1.45s\n",
            "962:\tlearn: 0.2703147\ttotal: 36.8s\tremaining: 1.42s\n",
            "963:\tlearn: 0.2702875\ttotal: 36.9s\tremaining: 1.38s\n",
            "964:\tlearn: 0.2702449\ttotal: 36.9s\tremaining: 1.34s\n",
            "965:\tlearn: 0.2702169\ttotal: 36.9s\tremaining: 1.3s\n",
            "966:\tlearn: 0.2701724\ttotal: 37s\tremaining: 1.26s\n",
            "967:\tlearn: 0.2701406\ttotal: 37s\tremaining: 1.22s\n",
            "968:\tlearn: 0.2701116\ttotal: 37s\tremaining: 1.18s\n",
            "969:\tlearn: 0.2700752\ttotal: 37.1s\tremaining: 1.15s\n",
            "970:\tlearn: 0.2700458\ttotal: 37.1s\tremaining: 1.11s\n",
            "971:\tlearn: 0.2700041\ttotal: 37.2s\tremaining: 1.07s\n",
            "972:\tlearn: 0.2699654\ttotal: 37.2s\tremaining: 1.03s\n",
            "973:\tlearn: 0.2699458\ttotal: 37.2s\tremaining: 993ms\n",
            "974:\tlearn: 0.2698990\ttotal: 37.2s\tremaining: 955ms\n",
            "975:\tlearn: 0.2698717\ttotal: 37.3s\tremaining: 917ms\n",
            "976:\tlearn: 0.2698426\ttotal: 37.3s\tremaining: 878ms\n",
            "977:\tlearn: 0.2698149\ttotal: 37.3s\tremaining: 840ms\n",
            "978:\tlearn: 0.2697701\ttotal: 37.4s\tremaining: 802ms\n",
            "979:\tlearn: 0.2697359\ttotal: 37.5s\tremaining: 764ms\n",
            "980:\tlearn: 0.2697039\ttotal: 37.5s\tremaining: 726ms\n",
            "981:\tlearn: 0.2696624\ttotal: 37.6s\tremaining: 689ms\n",
            "982:\tlearn: 0.2696238\ttotal: 37.6s\tremaining: 651ms\n",
            "983:\tlearn: 0.2696031\ttotal: 37.7s\tremaining: 613ms\n",
            "984:\tlearn: 0.2695742\ttotal: 37.8s\tremaining: 575ms\n",
            "985:\tlearn: 0.2695449\ttotal: 37.8s\tremaining: 537ms\n",
            "986:\tlearn: 0.2695194\ttotal: 37.9s\tremaining: 499ms\n",
            "987:\tlearn: 0.2694816\ttotal: 37.9s\tremaining: 461ms\n",
            "988:\tlearn: 0.2694528\ttotal: 38s\tremaining: 423ms\n",
            "989:\tlearn: 0.2694208\ttotal: 38s\tremaining: 384ms\n",
            "990:\tlearn: 0.2693966\ttotal: 38.1s\tremaining: 346ms\n",
            "991:\tlearn: 0.2693688\ttotal: 38.2s\tremaining: 308ms\n",
            "992:\tlearn: 0.2693238\ttotal: 38.2s\tremaining: 269ms\n",
            "993:\tlearn: 0.2692858\ttotal: 38.3s\tremaining: 231ms\n",
            "994:\tlearn: 0.2692507\ttotal: 38.3s\tremaining: 193ms\n",
            "995:\tlearn: 0.2692170\ttotal: 38.4s\tremaining: 154ms\n",
            "996:\tlearn: 0.2691807\ttotal: 38.5s\tremaining: 116ms\n",
            "997:\tlearn: 0.2691488\ttotal: 38.5s\tremaining: 77.3ms\n",
            "998:\tlearn: 0.2691044\ttotal: 38.6s\tremaining: 38.7ms\n",
            "999:\tlearn: 0.2690756\ttotal: 38.7s\tremaining: 0us\n",
            "17 : 0.878784565553291\n",
            "Learning rate set to 0.079235\n",
            "0:\tlearn: 0.6246796\ttotal: 80.2ms\tremaining: 1m 20s\n",
            "1:\tlearn: 0.5651277\ttotal: 153ms\tremaining: 1m 16s\n",
            "2:\tlearn: 0.5205433\ttotal: 236ms\tremaining: 1m 18s\n",
            "3:\tlearn: 0.4861699\ttotal: 271ms\tremaining: 1m 7s\n",
            "4:\tlearn: 0.4563874\ttotal: 303ms\tremaining: 1m\n",
            "5:\tlearn: 0.4338505\ttotal: 338ms\tremaining: 56s\n",
            "6:\tlearn: 0.4159187\ttotal: 370ms\tremaining: 52.5s\n",
            "7:\tlearn: 0.4003447\ttotal: 410ms\tremaining: 50.8s\n",
            "8:\tlearn: 0.3872149\ttotal: 467ms\tremaining: 51.4s\n",
            "9:\tlearn: 0.3767375\ttotal: 501ms\tremaining: 49.6s\n",
            "10:\tlearn: 0.3683816\ttotal: 534ms\tremaining: 48s\n",
            "11:\tlearn: 0.3617369\ttotal: 567ms\tremaining: 46.7s\n",
            "12:\tlearn: 0.3554854\ttotal: 602ms\tremaining: 45.7s\n",
            "13:\tlearn: 0.3498493\ttotal: 635ms\tremaining: 44.8s\n",
            "14:\tlearn: 0.3459363\ttotal: 670ms\tremaining: 44s\n",
            "15:\tlearn: 0.3422543\ttotal: 710ms\tremaining: 43.7s\n",
            "16:\tlearn: 0.3390226\ttotal: 745ms\tremaining: 43.1s\n",
            "17:\tlearn: 0.3365877\ttotal: 785ms\tremaining: 42.8s\n",
            "18:\tlearn: 0.3342260\ttotal: 819ms\tremaining: 42.3s\n",
            "19:\tlearn: 0.3319999\ttotal: 854ms\tremaining: 41.8s\n",
            "20:\tlearn: 0.3300604\ttotal: 896ms\tremaining: 41.8s\n",
            "21:\tlearn: 0.3284298\ttotal: 930ms\tremaining: 41.3s\n",
            "22:\tlearn: 0.3270290\ttotal: 964ms\tremaining: 40.9s\n",
            "23:\tlearn: 0.3258125\ttotal: 998ms\tremaining: 40.6s\n",
            "24:\tlearn: 0.3247844\ttotal: 1.03s\tremaining: 40.2s\n",
            "25:\tlearn: 0.3237505\ttotal: 1.06s\tremaining: 39.9s\n",
            "26:\tlearn: 0.3230336\ttotal: 1.1s\tremaining: 39.7s\n",
            "27:\tlearn: 0.3221785\ttotal: 1.15s\tremaining: 39.8s\n",
            "28:\tlearn: 0.3214599\ttotal: 1.18s\tremaining: 39.5s\n",
            "29:\tlearn: 0.3207473\ttotal: 1.21s\tremaining: 39.2s\n",
            "30:\tlearn: 0.3201795\ttotal: 1.25s\tremaining: 38.9s\n",
            "31:\tlearn: 0.3196587\ttotal: 1.28s\tremaining: 38.7s\n",
            "32:\tlearn: 0.3190842\ttotal: 1.32s\tremaining: 38.8s\n",
            "33:\tlearn: 0.3186007\ttotal: 1.36s\tremaining: 38.5s\n",
            "34:\tlearn: 0.3179578\ttotal: 1.39s\tremaining: 38.4s\n",
            "35:\tlearn: 0.3175166\ttotal: 1.44s\tremaining: 38.7s\n",
            "36:\tlearn: 0.3171400\ttotal: 1.48s\tremaining: 38.4s\n",
            "37:\tlearn: 0.3167372\ttotal: 1.51s\tremaining: 38.2s\n",
            "38:\tlearn: 0.3163999\ttotal: 1.55s\tremaining: 38.3s\n",
            "39:\tlearn: 0.3161951\ttotal: 1.58s\tremaining: 38s\n",
            "40:\tlearn: 0.3158404\ttotal: 1.62s\tremaining: 37.9s\n",
            "41:\tlearn: 0.3155017\ttotal: 1.65s\tremaining: 37.7s\n",
            "42:\tlearn: 0.3152549\ttotal: 1.68s\tremaining: 37.5s\n",
            "43:\tlearn: 0.3150374\ttotal: 1.72s\tremaining: 37.3s\n",
            "44:\tlearn: 0.3147559\ttotal: 1.75s\tremaining: 37.2s\n",
            "45:\tlearn: 0.3144770\ttotal: 1.79s\tremaining: 37.2s\n",
            "46:\tlearn: 0.3142340\ttotal: 1.83s\tremaining: 37s\n",
            "47:\tlearn: 0.3140040\ttotal: 1.86s\tremaining: 37s\n",
            "48:\tlearn: 0.3136845\ttotal: 1.9s\tremaining: 36.8s\n",
            "49:\tlearn: 0.3134770\ttotal: 1.93s\tremaining: 36.6s\n",
            "50:\tlearn: 0.3132923\ttotal: 1.96s\tremaining: 36.5s\n",
            "51:\tlearn: 0.3130908\ttotal: 1.99s\tremaining: 36.3s\n",
            "52:\tlearn: 0.3129193\ttotal: 2.03s\tremaining: 36.3s\n",
            "53:\tlearn: 0.3127125\ttotal: 2.06s\tremaining: 36.1s\n",
            "54:\tlearn: 0.3124541\ttotal: 2.1s\tremaining: 36s\n",
            "55:\tlearn: 0.3122717\ttotal: 2.13s\tremaining: 35.9s\n",
            "56:\tlearn: 0.3120974\ttotal: 2.16s\tremaining: 35.8s\n",
            "57:\tlearn: 0.3119279\ttotal: 2.2s\tremaining: 35.7s\n",
            "58:\tlearn: 0.3117965\ttotal: 2.24s\tremaining: 35.7s\n",
            "59:\tlearn: 0.3116745\ttotal: 2.27s\tremaining: 35.5s\n",
            "60:\tlearn: 0.3115612\ttotal: 2.3s\tremaining: 35.4s\n",
            "61:\tlearn: 0.3113509\ttotal: 2.33s\tremaining: 35.3s\n",
            "62:\tlearn: 0.3111961\ttotal: 2.37s\tremaining: 35.2s\n",
            "63:\tlearn: 0.3110519\ttotal: 2.4s\tremaining: 35.1s\n",
            "64:\tlearn: 0.3109660\ttotal: 2.43s\tremaining: 35s\n",
            "65:\tlearn: 0.3108457\ttotal: 2.49s\tremaining: 35.3s\n",
            "66:\tlearn: 0.3106987\ttotal: 2.53s\tremaining: 35.2s\n",
            "67:\tlearn: 0.3105737\ttotal: 2.56s\tremaining: 35.1s\n",
            "68:\tlearn: 0.3104425\ttotal: 2.59s\tremaining: 35s\n",
            "69:\tlearn: 0.3103200\ttotal: 2.62s\tremaining: 34.8s\n",
            "70:\tlearn: 0.3101835\ttotal: 2.65s\tremaining: 34.7s\n",
            "71:\tlearn: 0.3100589\ttotal: 2.68s\tremaining: 34.6s\n",
            "72:\tlearn: 0.3099352\ttotal: 2.73s\tremaining: 34.6s\n",
            "73:\tlearn: 0.3098444\ttotal: 2.76s\tremaining: 34.5s\n",
            "74:\tlearn: 0.3097193\ttotal: 2.8s\tremaining: 34.5s\n",
            "75:\tlearn: 0.3095874\ttotal: 2.83s\tremaining: 34.4s\n",
            "76:\tlearn: 0.3095071\ttotal: 2.86s\tremaining: 34.3s\n",
            "77:\tlearn: 0.3094152\ttotal: 2.9s\tremaining: 34.2s\n",
            "78:\tlearn: 0.3093371\ttotal: 2.94s\tremaining: 34.3s\n",
            "79:\tlearn: 0.3092453\ttotal: 2.97s\tremaining: 34.2s\n",
            "80:\tlearn: 0.3091272\ttotal: 3s\tremaining: 34.1s\n",
            "81:\tlearn: 0.3090168\ttotal: 3.04s\tremaining: 34s\n",
            "82:\tlearn: 0.3089268\ttotal: 3.07s\tremaining: 33.9s\n",
            "83:\tlearn: 0.3088418\ttotal: 3.1s\tremaining: 33.8s\n",
            "84:\tlearn: 0.3087559\ttotal: 3.14s\tremaining: 33.8s\n",
            "85:\tlearn: 0.3086941\ttotal: 3.18s\tremaining: 33.8s\n",
            "86:\tlearn: 0.3085957\ttotal: 3.21s\tremaining: 33.7s\n",
            "87:\tlearn: 0.3084887\ttotal: 3.24s\tremaining: 33.6s\n",
            "88:\tlearn: 0.3083897\ttotal: 3.27s\tremaining: 33.5s\n",
            "89:\tlearn: 0.3083268\ttotal: 3.3s\tremaining: 33.4s\n",
            "90:\tlearn: 0.3082650\ttotal: 3.33s\tremaining: 33.3s\n",
            "91:\tlearn: 0.3081941\ttotal: 3.38s\tremaining: 33.4s\n",
            "92:\tlearn: 0.3081059\ttotal: 3.41s\tremaining: 33.3s\n",
            "93:\tlearn: 0.3080357\ttotal: 3.45s\tremaining: 33.2s\n",
            "94:\tlearn: 0.3079238\ttotal: 3.5s\tremaining: 33.3s\n",
            "95:\tlearn: 0.3078464\ttotal: 3.53s\tremaining: 33.2s\n",
            "96:\tlearn: 0.3077947\ttotal: 3.56s\tremaining: 33.1s\n",
            "97:\tlearn: 0.3077298\ttotal: 3.6s\tremaining: 33.2s\n",
            "98:\tlearn: 0.3076483\ttotal: 3.63s\tremaining: 33.1s\n",
            "99:\tlearn: 0.3076027\ttotal: 3.67s\tremaining: 33s\n",
            "100:\tlearn: 0.3075340\ttotal: 3.7s\tremaining: 32.9s\n",
            "101:\tlearn: 0.3074589\ttotal: 3.73s\tremaining: 32.8s\n",
            "102:\tlearn: 0.3073823\ttotal: 3.76s\tremaining: 32.8s\n",
            "103:\tlearn: 0.3073464\ttotal: 3.8s\tremaining: 32.7s\n",
            "104:\tlearn: 0.3072765\ttotal: 3.84s\tremaining: 32.7s\n",
            "105:\tlearn: 0.3072248\ttotal: 3.87s\tremaining: 32.6s\n",
            "106:\tlearn: 0.3071445\ttotal: 3.9s\tremaining: 32.6s\n",
            "107:\tlearn: 0.3070937\ttotal: 3.93s\tremaining: 32.5s\n",
            "108:\tlearn: 0.3070207\ttotal: 3.96s\tremaining: 32.4s\n",
            "109:\tlearn: 0.3069563\ttotal: 4s\tremaining: 32.3s\n",
            "110:\tlearn: 0.3068799\ttotal: 4.03s\tremaining: 32.3s\n",
            "111:\tlearn: 0.3067901\ttotal: 4.08s\tremaining: 32.4s\n",
            "112:\tlearn: 0.3067296\ttotal: 4.11s\tremaining: 32.3s\n",
            "113:\tlearn: 0.3066836\ttotal: 4.14s\tremaining: 32.2s\n",
            "114:\tlearn: 0.3066140\ttotal: 4.17s\tremaining: 32.1s\n",
            "115:\tlearn: 0.3065679\ttotal: 4.21s\tremaining: 32.1s\n",
            "116:\tlearn: 0.3065002\ttotal: 4.24s\tremaining: 32s\n",
            "117:\tlearn: 0.3063938\ttotal: 4.27s\tremaining: 31.9s\n",
            "118:\tlearn: 0.3063406\ttotal: 4.31s\tremaining: 31.9s\n",
            "119:\tlearn: 0.3062769\ttotal: 4.34s\tremaining: 31.9s\n",
            "120:\tlearn: 0.3062012\ttotal: 4.38s\tremaining: 31.8s\n",
            "121:\tlearn: 0.3061318\ttotal: 4.41s\tremaining: 31.8s\n",
            "122:\tlearn: 0.3060795\ttotal: 4.45s\tremaining: 31.7s\n",
            "123:\tlearn: 0.3059808\ttotal: 4.49s\tremaining: 31.7s\n",
            "124:\tlearn: 0.3058969\ttotal: 4.54s\tremaining: 31.8s\n",
            "125:\tlearn: 0.3058452\ttotal: 4.57s\tremaining: 31.7s\n",
            "126:\tlearn: 0.3057826\ttotal: 4.6s\tremaining: 31.6s\n",
            "127:\tlearn: 0.3057193\ttotal: 4.63s\tremaining: 31.5s\n",
            "128:\tlearn: 0.3056606\ttotal: 4.66s\tremaining: 31.5s\n",
            "129:\tlearn: 0.3055909\ttotal: 4.69s\tremaining: 31.4s\n",
            "130:\tlearn: 0.3055309\ttotal: 4.73s\tremaining: 31.4s\n",
            "131:\tlearn: 0.3054517\ttotal: 4.77s\tremaining: 31.4s\n",
            "132:\tlearn: 0.3054000\ttotal: 4.81s\tremaining: 31.3s\n",
            "133:\tlearn: 0.3053403\ttotal: 4.84s\tremaining: 31.3s\n",
            "134:\tlearn: 0.3052671\ttotal: 4.87s\tremaining: 31.2s\n",
            "135:\tlearn: 0.3052136\ttotal: 4.9s\tremaining: 31.1s\n",
            "136:\tlearn: 0.3051595\ttotal: 4.93s\tremaining: 31.1s\n",
            "137:\tlearn: 0.3050939\ttotal: 4.96s\tremaining: 31s\n",
            "138:\tlearn: 0.3050205\ttotal: 5.01s\tremaining: 31s\n",
            "139:\tlearn: 0.3049745\ttotal: 5.04s\tremaining: 30.9s\n",
            "140:\tlearn: 0.3048960\ttotal: 5.07s\tremaining: 30.9s\n",
            "141:\tlearn: 0.3048310\ttotal: 5.1s\tremaining: 30.8s\n",
            "142:\tlearn: 0.3047801\ttotal: 5.13s\tremaining: 30.8s\n",
            "143:\tlearn: 0.3047133\ttotal: 5.17s\tremaining: 30.7s\n",
            "144:\tlearn: 0.3046683\ttotal: 5.2s\tremaining: 30.6s\n",
            "145:\tlearn: 0.3046054\ttotal: 5.24s\tremaining: 30.6s\n",
            "146:\tlearn: 0.3045274\ttotal: 5.27s\tremaining: 30.6s\n",
            "147:\tlearn: 0.3044738\ttotal: 5.3s\tremaining: 30.5s\n",
            "148:\tlearn: 0.3044138\ttotal: 5.33s\tremaining: 30.4s\n",
            "149:\tlearn: 0.3043687\ttotal: 5.37s\tremaining: 30.4s\n",
            "150:\tlearn: 0.3043111\ttotal: 5.4s\tremaining: 30.4s\n",
            "151:\tlearn: 0.3042585\ttotal: 5.43s\tremaining: 30.3s\n",
            "152:\tlearn: 0.3042170\ttotal: 5.48s\tremaining: 30.3s\n",
            "153:\tlearn: 0.3041528\ttotal: 5.52s\tremaining: 30.3s\n",
            "154:\tlearn: 0.3040866\ttotal: 5.55s\tremaining: 30.3s\n",
            "155:\tlearn: 0.3040397\ttotal: 5.58s\tremaining: 30.2s\n",
            "156:\tlearn: 0.3039838\ttotal: 5.61s\tremaining: 30.1s\n",
            "157:\tlearn: 0.3039244\ttotal: 5.64s\tremaining: 30.1s\n",
            "158:\tlearn: 0.3038705\ttotal: 5.67s\tremaining: 30s\n",
            "159:\tlearn: 0.3038062\ttotal: 5.72s\tremaining: 30s\n",
            "160:\tlearn: 0.3037536\ttotal: 5.75s\tremaining: 30s\n",
            "161:\tlearn: 0.3037017\ttotal: 5.78s\tremaining: 29.9s\n",
            "162:\tlearn: 0.3036482\ttotal: 5.81s\tremaining: 29.8s\n",
            "163:\tlearn: 0.3035941\ttotal: 5.84s\tremaining: 29.8s\n",
            "164:\tlearn: 0.3035337\ttotal: 5.87s\tremaining: 29.7s\n",
            "165:\tlearn: 0.3034860\ttotal: 5.9s\tremaining: 29.7s\n",
            "166:\tlearn: 0.3034233\ttotal: 5.95s\tremaining: 29.7s\n",
            "167:\tlearn: 0.3033699\ttotal: 5.98s\tremaining: 29.6s\n",
            "168:\tlearn: 0.3033119\ttotal: 6.01s\tremaining: 29.6s\n",
            "169:\tlearn: 0.3032466\ttotal: 6.04s\tremaining: 29.5s\n",
            "170:\tlearn: 0.3031975\ttotal: 6.08s\tremaining: 29.5s\n",
            "171:\tlearn: 0.3031277\ttotal: 6.11s\tremaining: 29.4s\n",
            "172:\tlearn: 0.3030587\ttotal: 6.14s\tremaining: 29.3s\n",
            "173:\tlearn: 0.3029905\ttotal: 6.18s\tremaining: 29.4s\n",
            "174:\tlearn: 0.3029085\ttotal: 6.21s\tremaining: 29.3s\n",
            "175:\tlearn: 0.3028677\ttotal: 6.25s\tremaining: 29.2s\n",
            "176:\tlearn: 0.3028001\ttotal: 6.28s\tremaining: 29.2s\n",
            "177:\tlearn: 0.3027516\ttotal: 6.31s\tremaining: 29.2s\n",
            "178:\tlearn: 0.3026946\ttotal: 6.35s\tremaining: 29.1s\n",
            "179:\tlearn: 0.3026325\ttotal: 6.38s\tremaining: 29.1s\n",
            "180:\tlearn: 0.3025705\ttotal: 6.42s\tremaining: 29s\n",
            "181:\tlearn: 0.3025121\ttotal: 6.45s\tremaining: 29s\n",
            "182:\tlearn: 0.3024425\ttotal: 6.48s\tremaining: 28.9s\n",
            "183:\tlearn: 0.3023678\ttotal: 6.52s\tremaining: 28.9s\n",
            "184:\tlearn: 0.3023089\ttotal: 6.56s\tremaining: 28.9s\n",
            "185:\tlearn: 0.3022382\ttotal: 6.59s\tremaining: 28.9s\n",
            "186:\tlearn: 0.3021749\ttotal: 6.64s\tremaining: 28.9s\n",
            "187:\tlearn: 0.3021236\ttotal: 6.67s\tremaining: 28.8s\n",
            "188:\tlearn: 0.3020667\ttotal: 6.71s\tremaining: 28.8s\n",
            "189:\tlearn: 0.3020242\ttotal: 6.74s\tremaining: 28.7s\n",
            "190:\tlearn: 0.3019719\ttotal: 6.77s\tremaining: 28.7s\n",
            "191:\tlearn: 0.3019010\ttotal: 6.8s\tremaining: 28.6s\n",
            "192:\tlearn: 0.3018639\ttotal: 6.83s\tremaining: 28.6s\n",
            "193:\tlearn: 0.3017995\ttotal: 6.87s\tremaining: 28.5s\n",
            "194:\tlearn: 0.3017296\ttotal: 6.9s\tremaining: 28.5s\n",
            "195:\tlearn: 0.3016691\ttotal: 6.93s\tremaining: 28.4s\n",
            "196:\tlearn: 0.3016244\ttotal: 6.97s\tremaining: 28.4s\n",
            "197:\tlearn: 0.3015769\ttotal: 7s\tremaining: 28.3s\n",
            "198:\tlearn: 0.3015221\ttotal: 7.03s\tremaining: 28.3s\n",
            "199:\tlearn: 0.3014464\ttotal: 7.06s\tremaining: 28.2s\n",
            "200:\tlearn: 0.3013968\ttotal: 7.11s\tremaining: 28.2s\n",
            "201:\tlearn: 0.3013419\ttotal: 7.14s\tremaining: 28.2s\n",
            "202:\tlearn: 0.3012790\ttotal: 7.17s\tremaining: 28.1s\n",
            "203:\tlearn: 0.3012084\ttotal: 7.2s\tremaining: 28.1s\n",
            "204:\tlearn: 0.3011541\ttotal: 7.23s\tremaining: 28s\n",
            "205:\tlearn: 0.3010999\ttotal: 7.26s\tremaining: 28s\n",
            "206:\tlearn: 0.3010405\ttotal: 7.29s\tremaining: 27.9s\n",
            "207:\tlearn: 0.3009727\ttotal: 7.33s\tremaining: 27.9s\n",
            "208:\tlearn: 0.3009203\ttotal: 7.37s\tremaining: 27.9s\n",
            "209:\tlearn: 0.3008575\ttotal: 7.4s\tremaining: 27.8s\n",
            "210:\tlearn: 0.3007921\ttotal: 7.43s\tremaining: 27.8s\n",
            "211:\tlearn: 0.3007358\ttotal: 7.47s\tremaining: 27.8s\n",
            "212:\tlearn: 0.3006810\ttotal: 7.5s\tremaining: 27.7s\n",
            "213:\tlearn: 0.3006164\ttotal: 7.55s\tremaining: 27.7s\n",
            "214:\tlearn: 0.3005685\ttotal: 7.59s\tremaining: 27.7s\n",
            "215:\tlearn: 0.3005170\ttotal: 7.62s\tremaining: 27.6s\n",
            "216:\tlearn: 0.3004516\ttotal: 7.65s\tremaining: 27.6s\n",
            "217:\tlearn: 0.3003947\ttotal: 7.68s\tremaining: 27.5s\n",
            "218:\tlearn: 0.3003477\ttotal: 7.71s\tremaining: 27.5s\n",
            "219:\tlearn: 0.3002819\ttotal: 7.74s\tremaining: 27.4s\n",
            "220:\tlearn: 0.3002399\ttotal: 7.79s\tremaining: 27.4s\n",
            "221:\tlearn: 0.3001834\ttotal: 7.82s\tremaining: 27.4s\n",
            "222:\tlearn: 0.3001275\ttotal: 7.85s\tremaining: 27.3s\n",
            "223:\tlearn: 0.3000685\ttotal: 7.88s\tremaining: 27.3s\n",
            "224:\tlearn: 0.3000138\ttotal: 7.91s\tremaining: 27.3s\n",
            "225:\tlearn: 0.2999565\ttotal: 7.94s\tremaining: 27.2s\n",
            "226:\tlearn: 0.2998997\ttotal: 7.97s\tremaining: 27.2s\n",
            "227:\tlearn: 0.2998536\ttotal: 8.02s\tremaining: 27.1s\n",
            "228:\tlearn: 0.2997926\ttotal: 8.05s\tremaining: 27.1s\n",
            "229:\tlearn: 0.2997371\ttotal: 8.08s\tremaining: 27.1s\n",
            "230:\tlearn: 0.2997032\ttotal: 8.11s\tremaining: 27s\n",
            "231:\tlearn: 0.2996449\ttotal: 8.14s\tremaining: 27s\n",
            "232:\tlearn: 0.2996078\ttotal: 8.18s\tremaining: 26.9s\n",
            "233:\tlearn: 0.2995644\ttotal: 8.21s\tremaining: 26.9s\n",
            "234:\tlearn: 0.2995059\ttotal: 8.25s\tremaining: 26.9s\n",
            "235:\tlearn: 0.2994499\ttotal: 8.28s\tremaining: 26.8s\n",
            "236:\tlearn: 0.2994101\ttotal: 8.31s\tremaining: 26.8s\n",
            "237:\tlearn: 0.2993600\ttotal: 8.34s\tremaining: 26.7s\n",
            "238:\tlearn: 0.2992906\ttotal: 8.38s\tremaining: 26.7s\n",
            "239:\tlearn: 0.2992286\ttotal: 8.41s\tremaining: 26.6s\n",
            "240:\tlearn: 0.2991685\ttotal: 8.44s\tremaining: 26.6s\n",
            "241:\tlearn: 0.2991060\ttotal: 8.49s\tremaining: 26.6s\n",
            "242:\tlearn: 0.2990566\ttotal: 8.52s\tremaining: 26.5s\n",
            "243:\tlearn: 0.2990001\ttotal: 8.56s\tremaining: 26.5s\n",
            "244:\tlearn: 0.2989422\ttotal: 8.6s\tremaining: 26.5s\n",
            "245:\tlearn: 0.2988922\ttotal: 8.63s\tremaining: 26.4s\n",
            "246:\tlearn: 0.2988419\ttotal: 8.66s\tremaining: 26.4s\n",
            "247:\tlearn: 0.2987806\ttotal: 8.7s\tremaining: 26.4s\n",
            "248:\tlearn: 0.2987223\ttotal: 8.73s\tremaining: 26.3s\n",
            "249:\tlearn: 0.2986708\ttotal: 8.76s\tremaining: 26.3s\n",
            "250:\tlearn: 0.2985997\ttotal: 8.8s\tremaining: 26.3s\n",
            "251:\tlearn: 0.2985304\ttotal: 8.83s\tremaining: 26.2s\n",
            "252:\tlearn: 0.2984726\ttotal: 8.86s\tremaining: 26.2s\n",
            "253:\tlearn: 0.2984139\ttotal: 8.89s\tremaining: 26.1s\n",
            "254:\tlearn: 0.2983690\ttotal: 8.94s\tremaining: 26.1s\n",
            "255:\tlearn: 0.2983334\ttotal: 8.97s\tremaining: 26.1s\n",
            "256:\tlearn: 0.2982905\ttotal: 9s\tremaining: 26s\n",
            "257:\tlearn: 0.2982552\ttotal: 9.03s\tremaining: 26s\n",
            "258:\tlearn: 0.2982040\ttotal: 9.06s\tremaining: 25.9s\n",
            "259:\tlearn: 0.2981506\ttotal: 9.1s\tremaining: 25.9s\n",
            "260:\tlearn: 0.2980955\ttotal: 9.13s\tremaining: 25.9s\n",
            "261:\tlearn: 0.2980413\ttotal: 9.17s\tremaining: 25.8s\n",
            "262:\tlearn: 0.2979834\ttotal: 9.2s\tremaining: 25.8s\n",
            "263:\tlearn: 0.2979250\ttotal: 9.23s\tremaining: 25.7s\n",
            "264:\tlearn: 0.2978763\ttotal: 9.27s\tremaining: 25.7s\n",
            "265:\tlearn: 0.2978239\ttotal: 9.3s\tremaining: 25.7s\n",
            "266:\tlearn: 0.2977582\ttotal: 9.33s\tremaining: 25.6s\n",
            "267:\tlearn: 0.2977134\ttotal: 9.36s\tremaining: 25.6s\n",
            "268:\tlearn: 0.2976682\ttotal: 9.4s\tremaining: 25.5s\n",
            "269:\tlearn: 0.2976133\ttotal: 9.44s\tremaining: 25.5s\n",
            "270:\tlearn: 0.2975697\ttotal: 9.47s\tremaining: 25.5s\n",
            "271:\tlearn: 0.2975003\ttotal: 9.5s\tremaining: 25.4s\n",
            "272:\tlearn: 0.2974475\ttotal: 9.53s\tremaining: 25.4s\n",
            "273:\tlearn: 0.2974010\ttotal: 9.57s\tremaining: 25.4s\n",
            "274:\tlearn: 0.2973614\ttotal: 9.62s\tremaining: 25.4s\n",
            "275:\tlearn: 0.2973005\ttotal: 9.65s\tremaining: 25.3s\n",
            "276:\tlearn: 0.2972486\ttotal: 9.68s\tremaining: 25.3s\n",
            "277:\tlearn: 0.2971983\ttotal: 9.71s\tremaining: 25.2s\n",
            "278:\tlearn: 0.2971547\ttotal: 9.75s\tremaining: 25.2s\n",
            "279:\tlearn: 0.2971208\ttotal: 9.78s\tremaining: 25.1s\n",
            "280:\tlearn: 0.2970703\ttotal: 9.8s\tremaining: 25.1s\n",
            "281:\tlearn: 0.2970186\ttotal: 9.85s\tremaining: 25.1s\n",
            "282:\tlearn: 0.2969836\ttotal: 9.88s\tremaining: 25s\n",
            "283:\tlearn: 0.2969399\ttotal: 9.91s\tremaining: 25s\n",
            "284:\tlearn: 0.2968860\ttotal: 9.94s\tremaining: 24.9s\n",
            "285:\tlearn: 0.2968350\ttotal: 9.97s\tremaining: 24.9s\n",
            "286:\tlearn: 0.2967821\ttotal: 10s\tremaining: 24.9s\n",
            "287:\tlearn: 0.2967184\ttotal: 10s\tremaining: 24.8s\n",
            "288:\tlearn: 0.2966731\ttotal: 10.1s\tremaining: 24.8s\n",
            "289:\tlearn: 0.2966160\ttotal: 10.1s\tremaining: 24.8s\n",
            "290:\tlearn: 0.2965596\ttotal: 10.2s\tremaining: 24.8s\n",
            "291:\tlearn: 0.2965122\ttotal: 10.2s\tremaining: 24.8s\n",
            "292:\tlearn: 0.2964642\ttotal: 10.3s\tremaining: 24.9s\n",
            "293:\tlearn: 0.2964086\ttotal: 10.4s\tremaining: 24.9s\n",
            "294:\tlearn: 0.2963572\ttotal: 10.5s\tremaining: 25s\n",
            "295:\tlearn: 0.2962981\ttotal: 10.5s\tremaining: 25s\n",
            "296:\tlearn: 0.2962506\ttotal: 10.6s\tremaining: 25.1s\n",
            "297:\tlearn: 0.2961937\ttotal: 10.7s\tremaining: 25.2s\n",
            "298:\tlearn: 0.2961516\ttotal: 10.8s\tremaining: 25.2s\n",
            "299:\tlearn: 0.2961080\ttotal: 10.8s\tremaining: 25.3s\n",
            "300:\tlearn: 0.2960579\ttotal: 10.9s\tremaining: 25.4s\n",
            "301:\tlearn: 0.2960166\ttotal: 11s\tremaining: 25.4s\n",
            "302:\tlearn: 0.2959802\ttotal: 11.1s\tremaining: 25.5s\n",
            "303:\tlearn: 0.2959289\ttotal: 11.2s\tremaining: 25.5s\n",
            "304:\tlearn: 0.2958822\ttotal: 11.2s\tremaining: 25.6s\n",
            "305:\tlearn: 0.2958274\ttotal: 11.3s\tremaining: 25.7s\n",
            "306:\tlearn: 0.2957757\ttotal: 11.4s\tremaining: 25.7s\n",
            "307:\tlearn: 0.2957236\ttotal: 11.5s\tremaining: 25.8s\n",
            "308:\tlearn: 0.2956921\ttotal: 11.5s\tremaining: 25.8s\n",
            "309:\tlearn: 0.2956417\ttotal: 11.6s\tremaining: 25.9s\n",
            "310:\tlearn: 0.2955923\ttotal: 11.7s\tremaining: 25.9s\n",
            "311:\tlearn: 0.2955338\ttotal: 11.8s\tremaining: 26s\n",
            "312:\tlearn: 0.2954840\ttotal: 11.8s\tremaining: 26s\n",
            "313:\tlearn: 0.2954336\ttotal: 11.9s\tremaining: 26s\n",
            "314:\tlearn: 0.2953766\ttotal: 12s\tremaining: 26.1s\n",
            "315:\tlearn: 0.2953138\ttotal: 12.1s\tremaining: 26.1s\n",
            "316:\tlearn: 0.2952670\ttotal: 12.1s\tremaining: 26.2s\n",
            "317:\tlearn: 0.2952187\ttotal: 12.2s\tremaining: 26.2s\n",
            "318:\tlearn: 0.2951670\ttotal: 12.3s\tremaining: 26.3s\n",
            "319:\tlearn: 0.2951191\ttotal: 12.4s\tremaining: 26.3s\n",
            "320:\tlearn: 0.2950772\ttotal: 12.5s\tremaining: 26.3s\n",
            "321:\tlearn: 0.2950241\ttotal: 12.5s\tremaining: 26.4s\n",
            "322:\tlearn: 0.2949869\ttotal: 12.6s\tremaining: 26.5s\n",
            "323:\tlearn: 0.2949344\ttotal: 12.7s\tremaining: 26.5s\n",
            "324:\tlearn: 0.2948885\ttotal: 12.7s\tremaining: 26.5s\n",
            "325:\tlearn: 0.2948704\ttotal: 12.8s\tremaining: 26.4s\n",
            "326:\tlearn: 0.2948229\ttotal: 12.8s\tremaining: 26.3s\n",
            "327:\tlearn: 0.2947916\ttotal: 12.8s\tremaining: 26.3s\n",
            "328:\tlearn: 0.2947472\ttotal: 12.9s\tremaining: 26.2s\n",
            "329:\tlearn: 0.2947141\ttotal: 12.9s\tremaining: 26.2s\n",
            "330:\tlearn: 0.2946558\ttotal: 12.9s\tremaining: 26.1s\n",
            "331:\tlearn: 0.2946128\ttotal: 13s\tremaining: 26.1s\n",
            "332:\tlearn: 0.2945552\ttotal: 13s\tremaining: 26s\n",
            "333:\tlearn: 0.2945079\ttotal: 13s\tremaining: 26s\n",
            "334:\tlearn: 0.2944680\ttotal: 13.1s\tremaining: 26s\n",
            "335:\tlearn: 0.2944274\ttotal: 13.1s\tremaining: 25.9s\n",
            "336:\tlearn: 0.2943913\ttotal: 13.1s\tremaining: 25.9s\n",
            "337:\tlearn: 0.2943535\ttotal: 13.2s\tremaining: 25.8s\n",
            "338:\tlearn: 0.2943118\ttotal: 13.2s\tremaining: 25.7s\n",
            "339:\tlearn: 0.2942711\ttotal: 13.2s\tremaining: 25.7s\n",
            "340:\tlearn: 0.2942136\ttotal: 13.3s\tremaining: 25.6s\n",
            "341:\tlearn: 0.2941749\ttotal: 13.3s\tremaining: 25.6s\n",
            "342:\tlearn: 0.2941341\ttotal: 13.3s\tremaining: 25.6s\n",
            "343:\tlearn: 0.2940819\ttotal: 13.4s\tremaining: 25.5s\n",
            "344:\tlearn: 0.2940297\ttotal: 13.4s\tremaining: 25.4s\n",
            "345:\tlearn: 0.2939777\ttotal: 13.4s\tremaining: 25.4s\n",
            "346:\tlearn: 0.2939213\ttotal: 13.5s\tremaining: 25.3s\n",
            "347:\tlearn: 0.2938803\ttotal: 13.5s\tremaining: 25.3s\n",
            "348:\tlearn: 0.2938248\ttotal: 13.5s\tremaining: 25.3s\n",
            "349:\tlearn: 0.2937809\ttotal: 13.6s\tremaining: 25.2s\n",
            "350:\tlearn: 0.2937349\ttotal: 13.6s\tremaining: 25.2s\n",
            "351:\tlearn: 0.2936891\ttotal: 13.6s\tremaining: 25.1s\n",
            "352:\tlearn: 0.2936392\ttotal: 13.7s\tremaining: 25.1s\n",
            "353:\tlearn: 0.2935903\ttotal: 13.7s\tremaining: 25.1s\n",
            "354:\tlearn: 0.2935432\ttotal: 13.8s\tremaining: 25s\n",
            "355:\tlearn: 0.2934922\ttotal: 13.8s\tremaining: 25s\n",
            "356:\tlearn: 0.2934501\ttotal: 13.8s\tremaining: 24.9s\n",
            "357:\tlearn: 0.2933988\ttotal: 13.9s\tremaining: 24.8s\n",
            "358:\tlearn: 0.2933688\ttotal: 13.9s\tremaining: 24.8s\n",
            "359:\tlearn: 0.2933252\ttotal: 13.9s\tremaining: 24.7s\n",
            "360:\tlearn: 0.2932762\ttotal: 14s\tremaining: 24.7s\n",
            "361:\tlearn: 0.2932250\ttotal: 14s\tremaining: 24.7s\n",
            "362:\tlearn: 0.2931703\ttotal: 14s\tremaining: 24.6s\n",
            "363:\tlearn: 0.2931224\ttotal: 14.1s\tremaining: 24.6s\n",
            "364:\tlearn: 0.2930729\ttotal: 14.1s\tremaining: 24.5s\n",
            "365:\tlearn: 0.2930145\ttotal: 14.1s\tremaining: 24.5s\n",
            "366:\tlearn: 0.2929550\ttotal: 14.2s\tremaining: 24.4s\n",
            "367:\tlearn: 0.2928954\ttotal: 14.2s\tremaining: 24.4s\n",
            "368:\tlearn: 0.2928615\ttotal: 14.2s\tremaining: 24.3s\n",
            "369:\tlearn: 0.2928141\ttotal: 14.3s\tremaining: 24.3s\n",
            "370:\tlearn: 0.2927656\ttotal: 14.3s\tremaining: 24.2s\n",
            "371:\tlearn: 0.2927169\ttotal: 14.3s\tremaining: 24.2s\n",
            "372:\tlearn: 0.2926585\ttotal: 14.4s\tremaining: 24.1s\n",
            "373:\tlearn: 0.2926136\ttotal: 14.4s\tremaining: 24.1s\n",
            "374:\tlearn: 0.2925645\ttotal: 14.4s\tremaining: 24s\n",
            "375:\tlearn: 0.2925226\ttotal: 14.5s\tremaining: 24s\n",
            "376:\tlearn: 0.2924950\ttotal: 14.5s\tremaining: 23.9s\n",
            "377:\tlearn: 0.2924532\ttotal: 14.5s\tremaining: 23.9s\n",
            "378:\tlearn: 0.2924068\ttotal: 14.5s\tremaining: 23.8s\n",
            "379:\tlearn: 0.2923648\ttotal: 14.6s\tremaining: 23.8s\n",
            "380:\tlearn: 0.2923166\ttotal: 14.6s\tremaining: 23.7s\n",
            "381:\tlearn: 0.2922847\ttotal: 14.7s\tremaining: 23.7s\n",
            "382:\tlearn: 0.2922486\ttotal: 14.7s\tremaining: 23.7s\n",
            "383:\tlearn: 0.2922138\ttotal: 14.7s\tremaining: 23.6s\n",
            "384:\tlearn: 0.2921643\ttotal: 14.8s\tremaining: 23.6s\n",
            "385:\tlearn: 0.2921240\ttotal: 14.8s\tremaining: 23.5s\n",
            "386:\tlearn: 0.2920804\ttotal: 14.8s\tremaining: 23.5s\n",
            "387:\tlearn: 0.2920287\ttotal: 14.8s\tremaining: 23.4s\n",
            "388:\tlearn: 0.2919821\ttotal: 14.9s\tremaining: 23.4s\n",
            "389:\tlearn: 0.2919411\ttotal: 14.9s\tremaining: 23.3s\n",
            "390:\tlearn: 0.2918989\ttotal: 15s\tremaining: 23.3s\n",
            "391:\tlearn: 0.2918448\ttotal: 15s\tremaining: 23.3s\n",
            "392:\tlearn: 0.2917937\ttotal: 15s\tremaining: 23.2s\n",
            "393:\tlearn: 0.2917464\ttotal: 15.1s\tremaining: 23.2s\n",
            "394:\tlearn: 0.2917050\ttotal: 15.1s\tremaining: 23.1s\n",
            "395:\tlearn: 0.2916659\ttotal: 15.1s\tremaining: 23.1s\n",
            "396:\tlearn: 0.2916293\ttotal: 15.2s\tremaining: 23s\n",
            "397:\tlearn: 0.2915786\ttotal: 15.2s\tremaining: 23s\n",
            "398:\tlearn: 0.2915493\ttotal: 15.2s\tremaining: 22.9s\n",
            "399:\tlearn: 0.2915103\ttotal: 15.3s\tremaining: 22.9s\n",
            "400:\tlearn: 0.2914649\ttotal: 15.3s\tremaining: 22.8s\n",
            "401:\tlearn: 0.2914362\ttotal: 15.3s\tremaining: 22.8s\n",
            "402:\tlearn: 0.2913680\ttotal: 15.4s\tremaining: 22.8s\n",
            "403:\tlearn: 0.2913300\ttotal: 15.4s\tremaining: 22.7s\n",
            "404:\tlearn: 0.2912745\ttotal: 15.4s\tremaining: 22.7s\n",
            "405:\tlearn: 0.2912076\ttotal: 15.5s\tremaining: 22.6s\n",
            "406:\tlearn: 0.2911638\ttotal: 15.5s\tremaining: 22.6s\n",
            "407:\tlearn: 0.2911050\ttotal: 15.5s\tremaining: 22.5s\n",
            "408:\tlearn: 0.2910481\ttotal: 15.6s\tremaining: 22.5s\n",
            "409:\tlearn: 0.2909949\ttotal: 15.6s\tremaining: 22.5s\n",
            "410:\tlearn: 0.2909689\ttotal: 15.6s\tremaining: 22.4s\n",
            "411:\tlearn: 0.2909141\ttotal: 15.7s\tremaining: 22.4s\n",
            "412:\tlearn: 0.2908629\ttotal: 15.7s\tremaining: 22.3s\n",
            "413:\tlearn: 0.2908094\ttotal: 15.7s\tremaining: 22.3s\n",
            "414:\tlearn: 0.2907674\ttotal: 15.8s\tremaining: 22.2s\n",
            "415:\tlearn: 0.2907212\ttotal: 15.8s\tremaining: 22.2s\n",
            "416:\tlearn: 0.2906766\ttotal: 15.8s\tremaining: 22.2s\n",
            "417:\tlearn: 0.2906312\ttotal: 15.9s\tremaining: 22.1s\n",
            "418:\tlearn: 0.2905936\ttotal: 15.9s\tremaining: 22.1s\n",
            "419:\tlearn: 0.2905510\ttotal: 15.9s\tremaining: 22s\n",
            "420:\tlearn: 0.2905162\ttotal: 16s\tremaining: 22s\n",
            "421:\tlearn: 0.2904825\ttotal: 16s\tremaining: 21.9s\n",
            "422:\tlearn: 0.2904624\ttotal: 16.1s\tremaining: 21.9s\n",
            "423:\tlearn: 0.2904203\ttotal: 16.1s\tremaining: 21.9s\n",
            "424:\tlearn: 0.2903743\ttotal: 16.1s\tremaining: 21.8s\n",
            "425:\tlearn: 0.2903353\ttotal: 16.2s\tremaining: 21.8s\n",
            "426:\tlearn: 0.2902837\ttotal: 16.2s\tremaining: 21.7s\n",
            "427:\tlearn: 0.2902407\ttotal: 16.2s\tremaining: 21.7s\n",
            "428:\tlearn: 0.2902043\ttotal: 16.3s\tremaining: 21.7s\n",
            "429:\tlearn: 0.2901550\ttotal: 16.3s\tremaining: 21.6s\n",
            "430:\tlearn: 0.2901000\ttotal: 16.3s\tremaining: 21.6s\n",
            "431:\tlearn: 0.2900510\ttotal: 16.4s\tremaining: 21.5s\n",
            "432:\tlearn: 0.2900190\ttotal: 16.4s\tremaining: 21.5s\n",
            "433:\tlearn: 0.2899739\ttotal: 16.4s\tremaining: 21.4s\n",
            "434:\tlearn: 0.2899436\ttotal: 16.5s\tremaining: 21.4s\n",
            "435:\tlearn: 0.2898866\ttotal: 16.5s\tremaining: 21.3s\n",
            "436:\tlearn: 0.2898409\ttotal: 16.5s\tremaining: 21.3s\n",
            "437:\tlearn: 0.2898073\ttotal: 16.6s\tremaining: 21.3s\n",
            "438:\tlearn: 0.2897588\ttotal: 16.6s\tremaining: 21.2s\n",
            "439:\tlearn: 0.2897100\ttotal: 16.6s\tremaining: 21.2s\n",
            "440:\tlearn: 0.2896726\ttotal: 16.7s\tremaining: 21.1s\n",
            "441:\tlearn: 0.2896256\ttotal: 16.7s\tremaining: 21.1s\n",
            "442:\tlearn: 0.2895922\ttotal: 16.7s\tremaining: 21s\n",
            "443:\tlearn: 0.2895420\ttotal: 16.8s\tremaining: 21s\n",
            "444:\tlearn: 0.2894928\ttotal: 16.8s\tremaining: 21s\n",
            "445:\tlearn: 0.2894472\ttotal: 16.8s\tremaining: 20.9s\n",
            "446:\tlearn: 0.2893985\ttotal: 16.9s\tremaining: 20.9s\n",
            "447:\tlearn: 0.2893382\ttotal: 16.9s\tremaining: 20.8s\n",
            "448:\tlearn: 0.2892923\ttotal: 16.9s\tremaining: 20.8s\n",
            "449:\tlearn: 0.2892429\ttotal: 17s\tremaining: 20.8s\n",
            "450:\tlearn: 0.2892035\ttotal: 17s\tremaining: 20.7s\n",
            "451:\tlearn: 0.2891597\ttotal: 17s\tremaining: 20.7s\n",
            "452:\tlearn: 0.2891150\ttotal: 17.1s\tremaining: 20.6s\n",
            "453:\tlearn: 0.2890728\ttotal: 17.1s\tremaining: 20.6s\n",
            "454:\tlearn: 0.2890352\ttotal: 17.1s\tremaining: 20.5s\n",
            "455:\tlearn: 0.2889922\ttotal: 17.2s\tremaining: 20.5s\n",
            "456:\tlearn: 0.2889371\ttotal: 17.2s\tremaining: 20.5s\n",
            "457:\tlearn: 0.2888893\ttotal: 17.2s\tremaining: 20.4s\n",
            "458:\tlearn: 0.2888412\ttotal: 17.3s\tremaining: 20.4s\n",
            "459:\tlearn: 0.2888013\ttotal: 17.3s\tremaining: 20.3s\n",
            "460:\tlearn: 0.2887539\ttotal: 17.3s\tremaining: 20.3s\n",
            "461:\tlearn: 0.2887025\ttotal: 17.4s\tremaining: 20.2s\n",
            "462:\tlearn: 0.2886539\ttotal: 17.4s\tremaining: 20.2s\n",
            "463:\tlearn: 0.2886066\ttotal: 17.4s\tremaining: 20.2s\n",
            "464:\tlearn: 0.2885736\ttotal: 17.5s\tremaining: 20.1s\n",
            "465:\tlearn: 0.2885378\ttotal: 17.5s\tremaining: 20.1s\n",
            "466:\tlearn: 0.2885013\ttotal: 17.5s\tremaining: 20s\n",
            "467:\tlearn: 0.2884626\ttotal: 17.6s\tremaining: 20s\n",
            "468:\tlearn: 0.2884195\ttotal: 17.6s\tremaining: 19.9s\n",
            "469:\tlearn: 0.2883803\ttotal: 17.6s\tremaining: 19.9s\n",
            "470:\tlearn: 0.2883430\ttotal: 17.7s\tremaining: 19.8s\n",
            "471:\tlearn: 0.2882990\ttotal: 17.7s\tremaining: 19.8s\n",
            "472:\tlearn: 0.2882695\ttotal: 17.7s\tremaining: 19.8s\n",
            "473:\tlearn: 0.2882375\ttotal: 17.8s\tremaining: 19.7s\n",
            "474:\tlearn: 0.2881837\ttotal: 17.8s\tremaining: 19.7s\n",
            "475:\tlearn: 0.2881436\ttotal: 17.9s\tremaining: 19.7s\n",
            "476:\tlearn: 0.2880902\ttotal: 17.9s\tremaining: 19.6s\n",
            "477:\tlearn: 0.2880480\ttotal: 17.9s\tremaining: 19.6s\n",
            "478:\tlearn: 0.2880110\ttotal: 17.9s\tremaining: 19.5s\n",
            "479:\tlearn: 0.2879449\ttotal: 18s\tremaining: 19.5s\n",
            "480:\tlearn: 0.2879063\ttotal: 18s\tremaining: 19.4s\n",
            "481:\tlearn: 0.2878599\ttotal: 18s\tremaining: 19.4s\n",
            "482:\tlearn: 0.2878075\ttotal: 18.1s\tremaining: 19.4s\n",
            "483:\tlearn: 0.2877779\ttotal: 18.1s\tremaining: 19.3s\n",
            "484:\tlearn: 0.2877375\ttotal: 18.1s\tremaining: 19.3s\n",
            "485:\tlearn: 0.2876957\ttotal: 18.2s\tremaining: 19.2s\n",
            "486:\tlearn: 0.2876537\ttotal: 18.2s\tremaining: 19.2s\n",
            "487:\tlearn: 0.2875992\ttotal: 18.2s\tremaining: 19.1s\n",
            "488:\tlearn: 0.2875625\ttotal: 18.3s\tremaining: 19.1s\n",
            "489:\tlearn: 0.2875153\ttotal: 18.3s\tremaining: 19.1s\n",
            "490:\tlearn: 0.2874669\ttotal: 18.4s\tremaining: 19s\n",
            "491:\tlearn: 0.2874125\ttotal: 18.4s\tremaining: 19s\n",
            "492:\tlearn: 0.2873685\ttotal: 18.4s\tremaining: 18.9s\n",
            "493:\tlearn: 0.2873141\ttotal: 18.4s\tremaining: 18.9s\n",
            "494:\tlearn: 0.2872677\ttotal: 18.5s\tremaining: 18.9s\n",
            "495:\tlearn: 0.2872110\ttotal: 18.5s\tremaining: 18.8s\n",
            "496:\tlearn: 0.2871542\ttotal: 18.6s\tremaining: 18.8s\n",
            "497:\tlearn: 0.2871149\ttotal: 18.6s\tremaining: 18.7s\n",
            "498:\tlearn: 0.2870702\ttotal: 18.6s\tremaining: 18.7s\n",
            "499:\tlearn: 0.2870260\ttotal: 18.7s\tremaining: 18.7s\n",
            "500:\tlearn: 0.2869879\ttotal: 18.7s\tremaining: 18.6s\n",
            "501:\tlearn: 0.2869334\ttotal: 18.7s\tremaining: 18.6s\n",
            "502:\tlearn: 0.2868944\ttotal: 18.7s\tremaining: 18.5s\n",
            "503:\tlearn: 0.2868547\ttotal: 18.8s\tremaining: 18.5s\n",
            "504:\tlearn: 0.2868148\ttotal: 18.8s\tremaining: 18.5s\n",
            "505:\tlearn: 0.2867708\ttotal: 18.9s\tremaining: 18.4s\n",
            "506:\tlearn: 0.2867335\ttotal: 18.9s\tremaining: 18.4s\n",
            "507:\tlearn: 0.2867079\ttotal: 18.9s\tremaining: 18.3s\n",
            "508:\tlearn: 0.2866624\ttotal: 19s\tremaining: 18.3s\n",
            "509:\tlearn: 0.2866216\ttotal: 19s\tremaining: 18.2s\n",
            "510:\tlearn: 0.2865791\ttotal: 19s\tremaining: 18.2s\n",
            "511:\tlearn: 0.2865315\ttotal: 19.1s\tremaining: 18.2s\n",
            "512:\tlearn: 0.2864821\ttotal: 19.1s\tremaining: 18.1s\n",
            "513:\tlearn: 0.2864249\ttotal: 19.1s\tremaining: 18.1s\n",
            "514:\tlearn: 0.2863793\ttotal: 19.2s\tremaining: 18s\n",
            "515:\tlearn: 0.2863436\ttotal: 19.2s\tremaining: 18s\n",
            "516:\tlearn: 0.2862954\ttotal: 19.2s\tremaining: 18s\n",
            "517:\tlearn: 0.2862550\ttotal: 19.3s\tremaining: 17.9s\n",
            "518:\tlearn: 0.2862146\ttotal: 19.3s\tremaining: 17.9s\n",
            "519:\tlearn: 0.2861768\ttotal: 19.3s\tremaining: 17.9s\n",
            "520:\tlearn: 0.2861277\ttotal: 19.4s\tremaining: 17.8s\n",
            "521:\tlearn: 0.2860897\ttotal: 19.4s\tremaining: 17.8s\n",
            "522:\tlearn: 0.2860320\ttotal: 19.4s\tremaining: 17.7s\n",
            "523:\tlearn: 0.2859949\ttotal: 19.5s\tremaining: 17.7s\n",
            "524:\tlearn: 0.2859523\ttotal: 19.5s\tremaining: 17.7s\n",
            "525:\tlearn: 0.2858993\ttotal: 19.5s\tremaining: 17.6s\n",
            "526:\tlearn: 0.2858541\ttotal: 19.6s\tremaining: 17.6s\n",
            "527:\tlearn: 0.2858013\ttotal: 19.6s\tremaining: 17.5s\n",
            "528:\tlearn: 0.2857519\ttotal: 19.6s\tremaining: 17.5s\n",
            "529:\tlearn: 0.2857251\ttotal: 19.7s\tremaining: 17.4s\n",
            "530:\tlearn: 0.2856882\ttotal: 19.7s\tremaining: 17.4s\n",
            "531:\tlearn: 0.2856545\ttotal: 19.7s\tremaining: 17.4s\n",
            "532:\tlearn: 0.2856132\ttotal: 19.8s\tremaining: 17.3s\n",
            "533:\tlearn: 0.2855668\ttotal: 19.8s\tremaining: 17.3s\n",
            "534:\tlearn: 0.2855152\ttotal: 19.8s\tremaining: 17.2s\n",
            "535:\tlearn: 0.2854689\ttotal: 19.9s\tremaining: 17.2s\n",
            "536:\tlearn: 0.2854177\ttotal: 19.9s\tremaining: 17.2s\n",
            "537:\tlearn: 0.2853740\ttotal: 20s\tremaining: 17.1s\n",
            "538:\tlearn: 0.2853293\ttotal: 20s\tremaining: 17.1s\n",
            "539:\tlearn: 0.2852790\ttotal: 20s\tremaining: 17.1s\n",
            "540:\tlearn: 0.2852405\ttotal: 20.1s\tremaining: 17s\n",
            "541:\tlearn: 0.2852003\ttotal: 20.1s\tremaining: 17s\n",
            "542:\tlearn: 0.2851603\ttotal: 20.1s\tremaining: 16.9s\n",
            "543:\tlearn: 0.2850968\ttotal: 20.2s\tremaining: 16.9s\n",
            "544:\tlearn: 0.2850465\ttotal: 20.2s\tremaining: 16.9s\n",
            "545:\tlearn: 0.2850060\ttotal: 20.2s\tremaining: 16.8s\n",
            "546:\tlearn: 0.2849703\ttotal: 20.3s\tremaining: 16.8s\n",
            "547:\tlearn: 0.2849337\ttotal: 20.3s\tremaining: 16.7s\n",
            "548:\tlearn: 0.2848919\ttotal: 20.3s\tremaining: 16.7s\n",
            "549:\tlearn: 0.2848379\ttotal: 20.4s\tremaining: 16.7s\n",
            "550:\tlearn: 0.2847972\ttotal: 20.4s\tremaining: 16.6s\n",
            "551:\tlearn: 0.2847415\ttotal: 20.4s\tremaining: 16.6s\n",
            "552:\tlearn: 0.2846843\ttotal: 20.5s\tremaining: 16.5s\n",
            "553:\tlearn: 0.2846365\ttotal: 20.5s\tremaining: 16.5s\n",
            "554:\tlearn: 0.2845996\ttotal: 20.5s\tremaining: 16.5s\n",
            "555:\tlearn: 0.2845688\ttotal: 20.6s\tremaining: 16.4s\n",
            "556:\tlearn: 0.2845297\ttotal: 20.6s\tremaining: 16.4s\n",
            "557:\tlearn: 0.2844927\ttotal: 20.6s\tremaining: 16.3s\n",
            "558:\tlearn: 0.2844488\ttotal: 20.6s\tremaining: 16.3s\n",
            "559:\tlearn: 0.2844184\ttotal: 20.7s\tremaining: 16.3s\n",
            "560:\tlearn: 0.2843786\ttotal: 20.7s\tremaining: 16.2s\n",
            "561:\tlearn: 0.2843263\ttotal: 20.8s\tremaining: 16.2s\n",
            "562:\tlearn: 0.2842806\ttotal: 20.8s\tremaining: 16.1s\n",
            "563:\tlearn: 0.2842350\ttotal: 20.8s\tremaining: 16.1s\n",
            "564:\tlearn: 0.2841852\ttotal: 20.9s\tremaining: 16.1s\n",
            "565:\tlearn: 0.2841442\ttotal: 20.9s\tremaining: 16s\n",
            "566:\tlearn: 0.2841114\ttotal: 20.9s\tremaining: 16s\n",
            "567:\tlearn: 0.2840589\ttotal: 21s\tremaining: 16s\n",
            "568:\tlearn: 0.2840242\ttotal: 21s\tremaining: 15.9s\n",
            "569:\tlearn: 0.2839911\ttotal: 21s\tremaining: 15.9s\n",
            "570:\tlearn: 0.2839330\ttotal: 21.1s\tremaining: 15.8s\n",
            "571:\tlearn: 0.2838908\ttotal: 21.1s\tremaining: 15.8s\n",
            "572:\tlearn: 0.2838521\ttotal: 21.1s\tremaining: 15.8s\n",
            "573:\tlearn: 0.2838109\ttotal: 21.2s\tremaining: 15.7s\n",
            "574:\tlearn: 0.2837696\ttotal: 21.2s\tremaining: 15.7s\n",
            "575:\tlearn: 0.2837321\ttotal: 21.2s\tremaining: 15.6s\n",
            "576:\tlearn: 0.2836796\ttotal: 21.3s\tremaining: 15.6s\n",
            "577:\tlearn: 0.2836451\ttotal: 21.3s\tremaining: 15.6s\n",
            "578:\tlearn: 0.2835996\ttotal: 21.3s\tremaining: 15.5s\n",
            "579:\tlearn: 0.2835543\ttotal: 21.4s\tremaining: 15.5s\n",
            "580:\tlearn: 0.2835057\ttotal: 21.4s\tremaining: 15.4s\n",
            "581:\tlearn: 0.2834654\ttotal: 21.5s\tremaining: 15.4s\n",
            "582:\tlearn: 0.2834304\ttotal: 21.5s\tremaining: 15.4s\n",
            "583:\tlearn: 0.2833916\ttotal: 21.5s\tremaining: 15.3s\n",
            "584:\tlearn: 0.2833544\ttotal: 21.5s\tremaining: 15.3s\n",
            "585:\tlearn: 0.2833146\ttotal: 21.6s\tremaining: 15.2s\n",
            "586:\tlearn: 0.2832700\ttotal: 21.6s\tremaining: 15.2s\n",
            "587:\tlearn: 0.2832268\ttotal: 21.6s\tremaining: 15.2s\n",
            "588:\tlearn: 0.2831849\ttotal: 21.7s\tremaining: 15.1s\n",
            "589:\tlearn: 0.2831411\ttotal: 21.7s\tremaining: 15.1s\n",
            "590:\tlearn: 0.2831005\ttotal: 21.7s\tremaining: 15s\n",
            "591:\tlearn: 0.2830606\ttotal: 21.8s\tremaining: 15s\n",
            "592:\tlearn: 0.2830098\ttotal: 21.8s\tremaining: 15s\n",
            "593:\tlearn: 0.2829714\ttotal: 21.9s\tremaining: 14.9s\n",
            "594:\tlearn: 0.2829354\ttotal: 21.9s\tremaining: 14.9s\n",
            "595:\tlearn: 0.2828829\ttotal: 21.9s\tremaining: 14.9s\n",
            "596:\tlearn: 0.2828345\ttotal: 22s\tremaining: 14.8s\n",
            "597:\tlearn: 0.2827981\ttotal: 22s\tremaining: 14.8s\n",
            "598:\tlearn: 0.2827690\ttotal: 22s\tremaining: 14.7s\n",
            "599:\tlearn: 0.2827300\ttotal: 22.1s\tremaining: 14.7s\n",
            "600:\tlearn: 0.2826945\ttotal: 22.1s\tremaining: 14.7s\n",
            "601:\tlearn: 0.2826542\ttotal: 22.1s\tremaining: 14.6s\n",
            "602:\tlearn: 0.2826120\ttotal: 22.2s\tremaining: 14.6s\n",
            "603:\tlearn: 0.2825660\ttotal: 22.2s\tremaining: 14.5s\n",
            "604:\tlearn: 0.2825263\ttotal: 22.2s\tremaining: 14.5s\n",
            "605:\tlearn: 0.2824942\ttotal: 22.3s\tremaining: 14.5s\n",
            "606:\tlearn: 0.2824443\ttotal: 22.3s\tremaining: 14.4s\n",
            "607:\tlearn: 0.2823923\ttotal: 22.3s\tremaining: 14.4s\n",
            "608:\tlearn: 0.2823580\ttotal: 22.4s\tremaining: 14.4s\n",
            "609:\tlearn: 0.2823320\ttotal: 22.4s\tremaining: 14.3s\n",
            "610:\tlearn: 0.2822831\ttotal: 22.4s\tremaining: 14.3s\n",
            "611:\tlearn: 0.2822403\ttotal: 22.5s\tremaining: 14.2s\n",
            "612:\tlearn: 0.2821842\ttotal: 22.5s\tremaining: 14.2s\n",
            "613:\tlearn: 0.2821536\ttotal: 22.5s\tremaining: 14.2s\n",
            "614:\tlearn: 0.2821160\ttotal: 22.6s\tremaining: 14.1s\n",
            "615:\tlearn: 0.2820790\ttotal: 22.6s\tremaining: 14.1s\n",
            "616:\tlearn: 0.2820481\ttotal: 22.7s\tremaining: 14.1s\n",
            "617:\tlearn: 0.2819956\ttotal: 22.7s\tremaining: 14s\n",
            "618:\tlearn: 0.2819512\ttotal: 22.8s\tremaining: 14s\n",
            "619:\tlearn: 0.2819125\ttotal: 22.9s\tremaining: 14s\n",
            "620:\tlearn: 0.2818741\ttotal: 23s\tremaining: 14s\n",
            "621:\tlearn: 0.2818294\ttotal: 23s\tremaining: 14s\n",
            "622:\tlearn: 0.2817953\ttotal: 23.1s\tremaining: 14s\n",
            "623:\tlearn: 0.2817538\ttotal: 23.2s\tremaining: 14s\n",
            "624:\tlearn: 0.2817287\ttotal: 23.2s\tremaining: 13.9s\n",
            "625:\tlearn: 0.2816934\ttotal: 23.3s\tremaining: 13.9s\n",
            "626:\tlearn: 0.2816466\ttotal: 23.4s\tremaining: 13.9s\n",
            "627:\tlearn: 0.2816066\ttotal: 23.5s\tremaining: 13.9s\n",
            "628:\tlearn: 0.2815602\ttotal: 23.5s\tremaining: 13.9s\n",
            "629:\tlearn: 0.2815135\ttotal: 23.6s\tremaining: 13.9s\n",
            "630:\tlearn: 0.2814786\ttotal: 23.6s\tremaining: 13.8s\n",
            "631:\tlearn: 0.2814413\ttotal: 23.7s\tremaining: 13.8s\n",
            "632:\tlearn: 0.2814030\ttotal: 23.8s\tremaining: 13.8s\n",
            "633:\tlearn: 0.2813618\ttotal: 23.9s\tremaining: 13.8s\n",
            "634:\tlearn: 0.2813166\ttotal: 24s\tremaining: 13.8s\n",
            "635:\tlearn: 0.2812871\ttotal: 24s\tremaining: 13.8s\n",
            "636:\tlearn: 0.2812402\ttotal: 24.1s\tremaining: 13.7s\n",
            "637:\tlearn: 0.2812037\ttotal: 24.2s\tremaining: 13.7s\n",
            "638:\tlearn: 0.2811725\ttotal: 24.2s\tremaining: 13.7s\n",
            "639:\tlearn: 0.2811370\ttotal: 24.3s\tremaining: 13.7s\n",
            "640:\tlearn: 0.2811076\ttotal: 24.4s\tremaining: 13.7s\n",
            "641:\tlearn: 0.2810811\ttotal: 24.4s\tremaining: 13.6s\n",
            "642:\tlearn: 0.2810445\ttotal: 24.5s\tremaining: 13.6s\n",
            "643:\tlearn: 0.2810075\ttotal: 24.6s\tremaining: 13.6s\n",
            "644:\tlearn: 0.2809543\ttotal: 24.7s\tremaining: 13.6s\n",
            "645:\tlearn: 0.2809169\ttotal: 24.8s\tremaining: 13.6s\n",
            "646:\tlearn: 0.2808952\ttotal: 24.8s\tremaining: 13.6s\n",
            "647:\tlearn: 0.2808560\ttotal: 24.9s\tremaining: 13.5s\n",
            "648:\tlearn: 0.2808086\ttotal: 25s\tremaining: 13.5s\n",
            "649:\tlearn: 0.2807598\ttotal: 25.1s\tremaining: 13.5s\n",
            "650:\tlearn: 0.2807220\ttotal: 25.1s\tremaining: 13.5s\n",
            "651:\tlearn: 0.2806948\ttotal: 25.2s\tremaining: 13.4s\n",
            "652:\tlearn: 0.2806632\ttotal: 25.2s\tremaining: 13.4s\n",
            "653:\tlearn: 0.2806311\ttotal: 25.2s\tremaining: 13.4s\n",
            "654:\tlearn: 0.2805768\ttotal: 25.3s\tremaining: 13.3s\n",
            "655:\tlearn: 0.2805423\ttotal: 25.3s\tremaining: 13.3s\n",
            "656:\tlearn: 0.2804977\ttotal: 25.3s\tremaining: 13.2s\n",
            "657:\tlearn: 0.2804642\ttotal: 25.4s\tremaining: 13.2s\n",
            "658:\tlearn: 0.2804099\ttotal: 25.4s\tremaining: 13.1s\n",
            "659:\tlearn: 0.2803620\ttotal: 25.4s\tremaining: 13.1s\n",
            "660:\tlearn: 0.2803128\ttotal: 25.5s\tremaining: 13.1s\n",
            "661:\tlearn: 0.2802713\ttotal: 25.5s\tremaining: 13s\n",
            "662:\tlearn: 0.2802150\ttotal: 25.5s\tremaining: 13s\n",
            "663:\tlearn: 0.2801652\ttotal: 25.6s\tremaining: 12.9s\n",
            "664:\tlearn: 0.2801296\ttotal: 25.6s\tremaining: 12.9s\n",
            "665:\tlearn: 0.2800890\ttotal: 25.7s\tremaining: 12.9s\n",
            "666:\tlearn: 0.2800422\ttotal: 25.7s\tremaining: 12.8s\n",
            "667:\tlearn: 0.2799906\ttotal: 25.7s\tremaining: 12.8s\n",
            "668:\tlearn: 0.2799517\ttotal: 25.7s\tremaining: 12.7s\n",
            "669:\tlearn: 0.2799106\ttotal: 25.8s\tremaining: 12.7s\n",
            "670:\tlearn: 0.2798729\ttotal: 25.8s\tremaining: 12.7s\n",
            "671:\tlearn: 0.2798217\ttotal: 25.8s\tremaining: 12.6s\n",
            "672:\tlearn: 0.2797810\ttotal: 25.9s\tremaining: 12.6s\n",
            "673:\tlearn: 0.2797422\ttotal: 25.9s\tremaining: 12.5s\n",
            "674:\tlearn: 0.2796974\ttotal: 25.9s\tremaining: 12.5s\n",
            "675:\tlearn: 0.2796625\ttotal: 26s\tremaining: 12.5s\n",
            "676:\tlearn: 0.2796307\ttotal: 26s\tremaining: 12.4s\n",
            "677:\tlearn: 0.2795819\ttotal: 26.1s\tremaining: 12.4s\n",
            "678:\tlearn: 0.2795484\ttotal: 26.1s\tremaining: 12.3s\n",
            "679:\tlearn: 0.2795004\ttotal: 26.1s\tremaining: 12.3s\n",
            "680:\tlearn: 0.2794732\ttotal: 26.2s\tremaining: 12.3s\n",
            "681:\tlearn: 0.2794223\ttotal: 26.2s\tremaining: 12.2s\n",
            "682:\tlearn: 0.2793869\ttotal: 26.2s\tremaining: 12.2s\n",
            "683:\tlearn: 0.2793304\ttotal: 26.3s\tremaining: 12.1s\n",
            "684:\tlearn: 0.2792820\ttotal: 26.3s\tremaining: 12.1s\n",
            "685:\tlearn: 0.2792373\ttotal: 26.3s\tremaining: 12.1s\n",
            "686:\tlearn: 0.2792047\ttotal: 26.4s\tremaining: 12s\n",
            "687:\tlearn: 0.2791740\ttotal: 26.4s\tremaining: 12s\n",
            "688:\tlearn: 0.2791392\ttotal: 26.4s\tremaining: 11.9s\n",
            "689:\tlearn: 0.2790988\ttotal: 26.5s\tremaining: 11.9s\n",
            "690:\tlearn: 0.2790621\ttotal: 26.5s\tremaining: 11.9s\n",
            "691:\tlearn: 0.2790352\ttotal: 26.5s\tremaining: 11.8s\n",
            "692:\tlearn: 0.2789989\ttotal: 26.6s\tremaining: 11.8s\n",
            "693:\tlearn: 0.2789443\ttotal: 26.6s\tremaining: 11.7s\n",
            "694:\tlearn: 0.2789014\ttotal: 26.6s\tremaining: 11.7s\n",
            "695:\tlearn: 0.2788668\ttotal: 26.7s\tremaining: 11.6s\n",
            "696:\tlearn: 0.2788393\ttotal: 26.7s\tremaining: 11.6s\n",
            "697:\tlearn: 0.2787932\ttotal: 26.7s\tremaining: 11.6s\n",
            "698:\tlearn: 0.2787296\ttotal: 26.8s\tremaining: 11.5s\n",
            "699:\tlearn: 0.2786978\ttotal: 26.8s\tremaining: 11.5s\n",
            "700:\tlearn: 0.2786720\ttotal: 26.8s\tremaining: 11.4s\n",
            "701:\tlearn: 0.2786400\ttotal: 26.9s\tremaining: 11.4s\n",
            "702:\tlearn: 0.2785999\ttotal: 26.9s\tremaining: 11.4s\n",
            "703:\tlearn: 0.2785444\ttotal: 26.9s\tremaining: 11.3s\n",
            "704:\tlearn: 0.2784993\ttotal: 27s\tremaining: 11.3s\n",
            "705:\tlearn: 0.2784661\ttotal: 27s\tremaining: 11.3s\n",
            "706:\tlearn: 0.2784275\ttotal: 27.1s\tremaining: 11.2s\n",
            "707:\tlearn: 0.2783908\ttotal: 27.1s\tremaining: 11.2s\n",
            "708:\tlearn: 0.2783507\ttotal: 27.1s\tremaining: 11.1s\n",
            "709:\tlearn: 0.2783182\ttotal: 27.1s\tremaining: 11.1s\n",
            "710:\tlearn: 0.2782822\ttotal: 27.2s\tremaining: 11s\n",
            "711:\tlearn: 0.2782301\ttotal: 27.2s\tremaining: 11s\n",
            "712:\tlearn: 0.2781949\ttotal: 27.3s\tremaining: 11s\n",
            "713:\tlearn: 0.2781524\ttotal: 27.3s\tremaining: 10.9s\n",
            "714:\tlearn: 0.2781071\ttotal: 27.3s\tremaining: 10.9s\n",
            "715:\tlearn: 0.2780652\ttotal: 27.4s\tremaining: 10.8s\n",
            "716:\tlearn: 0.2780344\ttotal: 27.4s\tremaining: 10.8s\n",
            "717:\tlearn: 0.2779996\ttotal: 27.4s\tremaining: 10.8s\n",
            "718:\tlearn: 0.2779762\ttotal: 27.4s\tremaining: 10.7s\n",
            "719:\tlearn: 0.2779324\ttotal: 27.5s\tremaining: 10.7s\n",
            "720:\tlearn: 0.2778868\ttotal: 27.5s\tremaining: 10.6s\n",
            "721:\tlearn: 0.2778551\ttotal: 27.6s\tremaining: 10.6s\n",
            "722:\tlearn: 0.2778122\ttotal: 27.6s\tremaining: 10.6s\n",
            "723:\tlearn: 0.2777739\ttotal: 27.6s\tremaining: 10.5s\n",
            "724:\tlearn: 0.2777384\ttotal: 27.7s\tremaining: 10.5s\n",
            "725:\tlearn: 0.2776981\ttotal: 27.7s\tremaining: 10.4s\n",
            "726:\tlearn: 0.2776713\ttotal: 27.7s\tremaining: 10.4s\n",
            "727:\tlearn: 0.2776419\ttotal: 27.8s\tremaining: 10.4s\n",
            "728:\tlearn: 0.2776083\ttotal: 27.8s\tremaining: 10.3s\n",
            "729:\tlearn: 0.2775640\ttotal: 27.8s\tremaining: 10.3s\n",
            "730:\tlearn: 0.2775390\ttotal: 27.8s\tremaining: 10.2s\n",
            "731:\tlearn: 0.2774908\ttotal: 27.9s\tremaining: 10.2s\n",
            "732:\tlearn: 0.2774534\ttotal: 27.9s\tremaining: 10.2s\n",
            "733:\tlearn: 0.2774060\ttotal: 28s\tremaining: 10.1s\n",
            "734:\tlearn: 0.2773632\ttotal: 28s\tremaining: 10.1s\n",
            "735:\tlearn: 0.2773245\ttotal: 28s\tremaining: 10.1s\n",
            "736:\tlearn: 0.2772826\ttotal: 28.1s\tremaining: 10s\n",
            "737:\tlearn: 0.2772373\ttotal: 28.1s\tremaining: 9.98s\n",
            "738:\tlearn: 0.2771913\ttotal: 28.1s\tremaining: 9.94s\n",
            "739:\tlearn: 0.2771479\ttotal: 28.2s\tremaining: 9.9s\n",
            "740:\tlearn: 0.2771029\ttotal: 28.2s\tremaining: 9.86s\n",
            "741:\tlearn: 0.2770737\ttotal: 28.2s\tremaining: 9.82s\n",
            "742:\tlearn: 0.2770383\ttotal: 28.3s\tremaining: 9.78s\n",
            "743:\tlearn: 0.2770085\ttotal: 28.3s\tremaining: 9.74s\n",
            "744:\tlearn: 0.2769728\ttotal: 28.3s\tremaining: 9.7s\n",
            "745:\tlearn: 0.2769439\ttotal: 28.4s\tremaining: 9.66s\n",
            "746:\tlearn: 0.2769010\ttotal: 28.4s\tremaining: 9.62s\n",
            "747:\tlearn: 0.2768620\ttotal: 28.4s\tremaining: 9.58s\n",
            "748:\tlearn: 0.2768131\ttotal: 28.5s\tremaining: 9.54s\n",
            "749:\tlearn: 0.2767821\ttotal: 28.5s\tremaining: 9.5s\n",
            "750:\tlearn: 0.2767506\ttotal: 28.5s\tremaining: 9.46s\n",
            "751:\tlearn: 0.2767144\ttotal: 28.6s\tremaining: 9.42s\n",
            "752:\tlearn: 0.2766755\ttotal: 28.6s\tremaining: 9.38s\n",
            "753:\tlearn: 0.2766334\ttotal: 28.6s\tremaining: 9.35s\n",
            "754:\tlearn: 0.2765974\ttotal: 28.7s\tremaining: 9.31s\n",
            "755:\tlearn: 0.2765577\ttotal: 28.7s\tremaining: 9.27s\n",
            "756:\tlearn: 0.2765226\ttotal: 28.7s\tremaining: 9.23s\n",
            "757:\tlearn: 0.2764936\ttotal: 28.8s\tremaining: 9.19s\n",
            "758:\tlearn: 0.2764652\ttotal: 28.8s\tremaining: 9.15s\n",
            "759:\tlearn: 0.2764214\ttotal: 28.8s\tremaining: 9.11s\n",
            "760:\tlearn: 0.2763751\ttotal: 28.9s\tremaining: 9.07s\n",
            "761:\tlearn: 0.2763309\ttotal: 28.9s\tremaining: 9.03s\n",
            "762:\tlearn: 0.2762957\ttotal: 29s\tremaining: 8.99s\n",
            "763:\tlearn: 0.2762589\ttotal: 29s\tremaining: 8.95s\n",
            "764:\tlearn: 0.2762211\ttotal: 29s\tremaining: 8.92s\n",
            "765:\tlearn: 0.2761875\ttotal: 29.1s\tremaining: 8.88s\n",
            "766:\tlearn: 0.2761536\ttotal: 29.1s\tremaining: 8.84s\n",
            "767:\tlearn: 0.2761189\ttotal: 29.1s\tremaining: 8.8s\n",
            "768:\tlearn: 0.2760807\ttotal: 29.2s\tremaining: 8.76s\n",
            "769:\tlearn: 0.2760465\ttotal: 29.2s\tremaining: 8.72s\n",
            "770:\tlearn: 0.2760140\ttotal: 29.2s\tremaining: 8.68s\n",
            "771:\tlearn: 0.2759739\ttotal: 29.3s\tremaining: 8.64s\n",
            "772:\tlearn: 0.2759160\ttotal: 29.3s\tremaining: 8.6s\n",
            "773:\tlearn: 0.2758856\ttotal: 29.3s\tremaining: 8.56s\n",
            "774:\tlearn: 0.2758591\ttotal: 29.4s\tremaining: 8.52s\n",
            "775:\tlearn: 0.2758225\ttotal: 29.4s\tremaining: 8.48s\n",
            "776:\tlearn: 0.2757798\ttotal: 29.4s\tremaining: 8.44s\n",
            "777:\tlearn: 0.2757505\ttotal: 29.5s\tremaining: 8.4s\n",
            "778:\tlearn: 0.2757134\ttotal: 29.5s\tremaining: 8.36s\n",
            "779:\tlearn: 0.2756806\ttotal: 29.5s\tremaining: 8.32s\n",
            "780:\tlearn: 0.2756370\ttotal: 29.6s\tremaining: 8.29s\n",
            "781:\tlearn: 0.2755988\ttotal: 29.6s\tremaining: 8.25s\n",
            "782:\tlearn: 0.2755580\ttotal: 29.6s\tremaining: 8.21s\n",
            "783:\tlearn: 0.2755267\ttotal: 29.7s\tremaining: 8.17s\n",
            "784:\tlearn: 0.2754898\ttotal: 29.7s\tremaining: 8.13s\n",
            "785:\tlearn: 0.2754473\ttotal: 29.7s\tremaining: 8.09s\n",
            "786:\tlearn: 0.2754083\ttotal: 29.7s\tremaining: 8.05s\n",
            "787:\tlearn: 0.2753802\ttotal: 29.8s\tremaining: 8.01s\n",
            "788:\tlearn: 0.2753433\ttotal: 29.8s\tremaining: 7.97s\n",
            "789:\tlearn: 0.2753144\ttotal: 29.8s\tremaining: 7.93s\n",
            "790:\tlearn: 0.2752816\ttotal: 29.9s\tremaining: 7.89s\n",
            "791:\tlearn: 0.2752374\ttotal: 29.9s\tremaining: 7.86s\n",
            "792:\tlearn: 0.2752063\ttotal: 29.9s\tremaining: 7.82s\n",
            "793:\tlearn: 0.2751690\ttotal: 30s\tremaining: 7.78s\n",
            "794:\tlearn: 0.2751340\ttotal: 30s\tremaining: 7.74s\n",
            "795:\tlearn: 0.2750924\ttotal: 30.1s\tremaining: 7.71s\n",
            "796:\tlearn: 0.2750611\ttotal: 30.1s\tremaining: 7.67s\n",
            "797:\tlearn: 0.2750157\ttotal: 30.1s\tremaining: 7.63s\n",
            "798:\tlearn: 0.2749875\ttotal: 30.2s\tremaining: 7.59s\n",
            "799:\tlearn: 0.2749483\ttotal: 30.2s\tremaining: 7.55s\n",
            "800:\tlearn: 0.2749018\ttotal: 30.2s\tremaining: 7.51s\n",
            "801:\tlearn: 0.2748536\ttotal: 30.3s\tremaining: 7.47s\n",
            "802:\tlearn: 0.2748114\ttotal: 30.3s\tremaining: 7.43s\n",
            "803:\tlearn: 0.2747747\ttotal: 30.3s\tremaining: 7.39s\n",
            "804:\tlearn: 0.2747403\ttotal: 30.4s\tremaining: 7.36s\n",
            "805:\tlearn: 0.2746934\ttotal: 30.4s\tremaining: 7.32s\n",
            "806:\tlearn: 0.2746568\ttotal: 30.4s\tremaining: 7.28s\n",
            "807:\tlearn: 0.2746129\ttotal: 30.5s\tremaining: 7.24s\n",
            "808:\tlearn: 0.2745781\ttotal: 30.5s\tremaining: 7.2s\n",
            "809:\tlearn: 0.2745415\ttotal: 30.5s\tremaining: 7.16s\n",
            "810:\tlearn: 0.2745029\ttotal: 30.6s\tremaining: 7.12s\n",
            "811:\tlearn: 0.2744533\ttotal: 30.6s\tremaining: 7.08s\n",
            "812:\tlearn: 0.2744299\ttotal: 30.6s\tremaining: 7.04s\n",
            "813:\tlearn: 0.2743861\ttotal: 30.7s\tremaining: 7.01s\n",
            "814:\tlearn: 0.2743379\ttotal: 30.7s\tremaining: 6.97s\n",
            "815:\tlearn: 0.2742804\ttotal: 30.7s\tremaining: 6.93s\n",
            "816:\tlearn: 0.2742371\ttotal: 30.8s\tremaining: 6.89s\n",
            "817:\tlearn: 0.2741975\ttotal: 30.8s\tremaining: 6.85s\n",
            "818:\tlearn: 0.2741578\ttotal: 30.8s\tremaining: 6.81s\n",
            "819:\tlearn: 0.2741178\ttotal: 30.9s\tremaining: 6.77s\n",
            "820:\tlearn: 0.2740971\ttotal: 30.9s\tremaining: 6.74s\n",
            "821:\tlearn: 0.2740429\ttotal: 30.9s\tremaining: 6.7s\n",
            "822:\tlearn: 0.2739994\ttotal: 31s\tremaining: 6.66s\n",
            "823:\tlearn: 0.2739687\ttotal: 31s\tremaining: 6.62s\n",
            "824:\tlearn: 0.2739285\ttotal: 31s\tremaining: 6.58s\n",
            "825:\tlearn: 0.2738953\ttotal: 31.1s\tremaining: 6.55s\n",
            "826:\tlearn: 0.2738483\ttotal: 31.1s\tremaining: 6.51s\n",
            "827:\tlearn: 0.2738199\ttotal: 31.1s\tremaining: 6.47s\n",
            "828:\tlearn: 0.2737878\ttotal: 31.2s\tremaining: 6.43s\n",
            "829:\tlearn: 0.2737512\ttotal: 31.2s\tremaining: 6.39s\n",
            "830:\tlearn: 0.2737069\ttotal: 31.3s\tremaining: 6.36s\n",
            "831:\tlearn: 0.2736582\ttotal: 31.3s\tremaining: 6.32s\n",
            "832:\tlearn: 0.2736320\ttotal: 31.3s\tremaining: 6.28s\n",
            "833:\tlearn: 0.2735990\ttotal: 31.4s\tremaining: 6.24s\n",
            "834:\tlearn: 0.2735786\ttotal: 31.4s\tremaining: 6.2s\n",
            "835:\tlearn: 0.2735448\ttotal: 31.4s\tremaining: 6.16s\n",
            "836:\tlearn: 0.2735073\ttotal: 31.5s\tremaining: 6.13s\n",
            "837:\tlearn: 0.2734759\ttotal: 31.5s\tremaining: 6.09s\n",
            "838:\tlearn: 0.2734289\ttotal: 31.5s\tremaining: 6.05s\n",
            "839:\tlearn: 0.2733984\ttotal: 31.5s\tremaining: 6.01s\n",
            "840:\tlearn: 0.2733673\ttotal: 31.6s\tremaining: 5.97s\n",
            "841:\tlearn: 0.2733203\ttotal: 31.6s\tremaining: 5.93s\n",
            "842:\tlearn: 0.2732719\ttotal: 31.7s\tremaining: 5.89s\n",
            "843:\tlearn: 0.2732059\ttotal: 31.7s\tremaining: 5.86s\n",
            "844:\tlearn: 0.2731823\ttotal: 31.7s\tremaining: 5.82s\n",
            "845:\tlearn: 0.2731533\ttotal: 31.7s\tremaining: 5.78s\n",
            "846:\tlearn: 0.2731116\ttotal: 31.8s\tremaining: 5.74s\n",
            "847:\tlearn: 0.2730759\ttotal: 31.8s\tremaining: 5.7s\n",
            "848:\tlearn: 0.2730272\ttotal: 31.9s\tremaining: 5.67s\n",
            "849:\tlearn: 0.2729800\ttotal: 31.9s\tremaining: 5.63s\n",
            "850:\tlearn: 0.2729425\ttotal: 31.9s\tremaining: 5.59s\n",
            "851:\tlearn: 0.2728955\ttotal: 31.9s\tremaining: 5.55s\n",
            "852:\tlearn: 0.2728515\ttotal: 32s\tremaining: 5.51s\n",
            "853:\tlearn: 0.2728157\ttotal: 32s\tremaining: 5.47s\n",
            "854:\tlearn: 0.2727900\ttotal: 32.1s\tremaining: 5.44s\n",
            "855:\tlearn: 0.2727619\ttotal: 32.1s\tremaining: 5.4s\n",
            "856:\tlearn: 0.2727299\ttotal: 32.1s\tremaining: 5.36s\n",
            "857:\tlearn: 0.2727012\ttotal: 32.2s\tremaining: 5.32s\n",
            "858:\tlearn: 0.2726584\ttotal: 32.2s\tremaining: 5.29s\n",
            "859:\tlearn: 0.2726172\ttotal: 32.2s\tremaining: 5.25s\n",
            "860:\tlearn: 0.2725734\ttotal: 32.3s\tremaining: 5.21s\n",
            "861:\tlearn: 0.2725336\ttotal: 32.3s\tremaining: 5.17s\n",
            "862:\tlearn: 0.2724985\ttotal: 32.3s\tremaining: 5.13s\n",
            "863:\tlearn: 0.2724660\ttotal: 32.4s\tremaining: 5.09s\n",
            "864:\tlearn: 0.2724334\ttotal: 32.4s\tremaining: 5.06s\n",
            "865:\tlearn: 0.2723889\ttotal: 32.4s\tremaining: 5.02s\n",
            "866:\tlearn: 0.2723695\ttotal: 32.5s\tremaining: 4.98s\n",
            "867:\tlearn: 0.2723331\ttotal: 32.5s\tremaining: 4.94s\n",
            "868:\tlearn: 0.2722968\ttotal: 32.5s\tremaining: 4.9s\n",
            "869:\tlearn: 0.2722499\ttotal: 32.6s\tremaining: 4.87s\n",
            "870:\tlearn: 0.2722229\ttotal: 32.6s\tremaining: 4.83s\n",
            "871:\tlearn: 0.2721858\ttotal: 32.6s\tremaining: 4.79s\n",
            "872:\tlearn: 0.2721525\ttotal: 32.7s\tremaining: 4.75s\n",
            "873:\tlearn: 0.2721206\ttotal: 32.7s\tremaining: 4.71s\n",
            "874:\tlearn: 0.2720719\ttotal: 32.7s\tremaining: 4.67s\n",
            "875:\tlearn: 0.2720462\ttotal: 32.8s\tremaining: 4.64s\n",
            "876:\tlearn: 0.2720179\ttotal: 32.8s\tremaining: 4.6s\n",
            "877:\tlearn: 0.2719799\ttotal: 32.8s\tremaining: 4.56s\n",
            "878:\tlearn: 0.2719435\ttotal: 32.9s\tremaining: 4.52s\n",
            "879:\tlearn: 0.2719202\ttotal: 32.9s\tremaining: 4.49s\n",
            "880:\tlearn: 0.2718898\ttotal: 32.9s\tremaining: 4.45s\n",
            "881:\tlearn: 0.2718526\ttotal: 33s\tremaining: 4.41s\n",
            "882:\tlearn: 0.2718240\ttotal: 33s\tremaining: 4.37s\n",
            "883:\tlearn: 0.2717862\ttotal: 33s\tremaining: 4.33s\n",
            "884:\tlearn: 0.2717427\ttotal: 33.1s\tremaining: 4.3s\n",
            "885:\tlearn: 0.2717040\ttotal: 33.1s\tremaining: 4.26s\n",
            "886:\tlearn: 0.2716743\ttotal: 33.1s\tremaining: 4.22s\n",
            "887:\tlearn: 0.2716405\ttotal: 33.2s\tremaining: 4.18s\n",
            "888:\tlearn: 0.2716194\ttotal: 33.2s\tremaining: 4.15s\n",
            "889:\tlearn: 0.2715954\ttotal: 33.2s\tremaining: 4.11s\n",
            "890:\tlearn: 0.2715616\ttotal: 33.3s\tremaining: 4.07s\n",
            "891:\tlearn: 0.2715405\ttotal: 33.3s\tremaining: 4.03s\n",
            "892:\tlearn: 0.2714888\ttotal: 33.3s\tremaining: 3.99s\n",
            "893:\tlearn: 0.2714596\ttotal: 33.4s\tremaining: 3.96s\n",
            "894:\tlearn: 0.2714298\ttotal: 33.4s\tremaining: 3.92s\n",
            "895:\tlearn: 0.2713919\ttotal: 33.4s\tremaining: 3.88s\n",
            "896:\tlearn: 0.2713575\ttotal: 33.5s\tremaining: 3.84s\n",
            "897:\tlearn: 0.2713284\ttotal: 33.5s\tremaining: 3.81s\n",
            "898:\tlearn: 0.2712881\ttotal: 33.5s\tremaining: 3.77s\n",
            "899:\tlearn: 0.2712530\ttotal: 33.6s\tremaining: 3.73s\n",
            "900:\tlearn: 0.2712185\ttotal: 33.6s\tremaining: 3.69s\n",
            "901:\tlearn: 0.2711706\ttotal: 33.6s\tremaining: 3.65s\n",
            "902:\tlearn: 0.2711378\ttotal: 33.7s\tremaining: 3.62s\n",
            "903:\tlearn: 0.2710739\ttotal: 33.7s\tremaining: 3.58s\n",
            "904:\tlearn: 0.2710435\ttotal: 33.8s\tremaining: 3.54s\n",
            "905:\tlearn: 0.2709942\ttotal: 33.8s\tremaining: 3.5s\n",
            "906:\tlearn: 0.2709699\ttotal: 33.8s\tremaining: 3.47s\n",
            "907:\tlearn: 0.2709249\ttotal: 33.9s\tremaining: 3.43s\n",
            "908:\tlearn: 0.2708968\ttotal: 33.9s\tremaining: 3.39s\n",
            "909:\tlearn: 0.2708670\ttotal: 33.9s\tremaining: 3.35s\n",
            "910:\tlearn: 0.2708274\ttotal: 34s\tremaining: 3.32s\n",
            "911:\tlearn: 0.2707850\ttotal: 34s\tremaining: 3.28s\n",
            "912:\tlearn: 0.2707416\ttotal: 34s\tremaining: 3.24s\n",
            "913:\tlearn: 0.2707002\ttotal: 34.1s\tremaining: 3.2s\n",
            "914:\tlearn: 0.2706621\ttotal: 34.1s\tremaining: 3.17s\n",
            "915:\tlearn: 0.2706365\ttotal: 34.1s\tremaining: 3.13s\n",
            "916:\tlearn: 0.2706116\ttotal: 34.2s\tremaining: 3.09s\n",
            "917:\tlearn: 0.2705659\ttotal: 34.2s\tremaining: 3.06s\n",
            "918:\tlearn: 0.2705214\ttotal: 34.2s\tremaining: 3.02s\n",
            "919:\tlearn: 0.2704974\ttotal: 34.3s\tremaining: 2.98s\n",
            "920:\tlearn: 0.2704652\ttotal: 34.3s\tremaining: 2.94s\n",
            "921:\tlearn: 0.2704261\ttotal: 34.3s\tremaining: 2.9s\n",
            "922:\tlearn: 0.2704032\ttotal: 34.4s\tremaining: 2.87s\n",
            "923:\tlearn: 0.2703646\ttotal: 34.4s\tremaining: 2.83s\n",
            "924:\tlearn: 0.2703222\ttotal: 34.4s\tremaining: 2.79s\n",
            "925:\tlearn: 0.2702870\ttotal: 34.5s\tremaining: 2.75s\n",
            "926:\tlearn: 0.2702668\ttotal: 34.5s\tremaining: 2.72s\n",
            "927:\tlearn: 0.2702148\ttotal: 34.5s\tremaining: 2.68s\n",
            "928:\tlearn: 0.2701827\ttotal: 34.6s\tremaining: 2.64s\n",
            "929:\tlearn: 0.2701384\ttotal: 34.6s\tremaining: 2.6s\n",
            "930:\tlearn: 0.2700946\ttotal: 34.6s\tremaining: 2.57s\n",
            "931:\tlearn: 0.2700604\ttotal: 34.7s\tremaining: 2.53s\n",
            "932:\tlearn: 0.2700305\ttotal: 34.7s\tremaining: 2.49s\n",
            "933:\tlearn: 0.2700067\ttotal: 34.7s\tremaining: 2.45s\n",
            "934:\tlearn: 0.2699755\ttotal: 34.8s\tremaining: 2.42s\n",
            "935:\tlearn: 0.2699379\ttotal: 34.8s\tremaining: 2.38s\n",
            "936:\tlearn: 0.2698902\ttotal: 34.8s\tremaining: 2.34s\n",
            "937:\tlearn: 0.2698581\ttotal: 34.9s\tremaining: 2.3s\n",
            "938:\tlearn: 0.2698225\ttotal: 34.9s\tremaining: 2.27s\n",
            "939:\tlearn: 0.2697955\ttotal: 34.9s\tremaining: 2.23s\n",
            "940:\tlearn: 0.2697631\ttotal: 35s\tremaining: 2.19s\n",
            "941:\tlearn: 0.2697207\ttotal: 35s\tremaining: 2.16s\n",
            "942:\tlearn: 0.2696929\ttotal: 35.1s\tremaining: 2.12s\n",
            "943:\tlearn: 0.2696570\ttotal: 35.1s\tremaining: 2.08s\n",
            "944:\tlearn: 0.2696174\ttotal: 35.2s\tremaining: 2.05s\n",
            "945:\tlearn: 0.2695758\ttotal: 35.3s\tremaining: 2.01s\n",
            "946:\tlearn: 0.2695490\ttotal: 35.4s\tremaining: 1.98s\n",
            "947:\tlearn: 0.2695208\ttotal: 35.4s\tremaining: 1.94s\n",
            "948:\tlearn: 0.2694767\ttotal: 35.5s\tremaining: 1.91s\n",
            "949:\tlearn: 0.2694638\ttotal: 35.6s\tremaining: 1.87s\n",
            "950:\tlearn: 0.2694384\ttotal: 35.7s\tremaining: 1.84s\n",
            "951:\tlearn: 0.2694054\ttotal: 35.7s\tremaining: 1.8s\n",
            "952:\tlearn: 0.2693681\ttotal: 35.8s\tremaining: 1.77s\n",
            "953:\tlearn: 0.2693213\ttotal: 35.9s\tremaining: 1.73s\n",
            "954:\tlearn: 0.2692893\ttotal: 35.9s\tremaining: 1.69s\n",
            "955:\tlearn: 0.2692602\ttotal: 36s\tremaining: 1.66s\n",
            "956:\tlearn: 0.2692222\ttotal: 36s\tremaining: 1.62s\n",
            "957:\tlearn: 0.2691889\ttotal: 36.1s\tremaining: 1.58s\n",
            "958:\tlearn: 0.2691554\ttotal: 36.2s\tremaining: 1.55s\n",
            "959:\tlearn: 0.2691317\ttotal: 36.2s\tremaining: 1.51s\n",
            "960:\tlearn: 0.2690879\ttotal: 36.3s\tremaining: 1.47s\n",
            "961:\tlearn: 0.2690522\ttotal: 36.4s\tremaining: 1.44s\n",
            "962:\tlearn: 0.2689952\ttotal: 36.5s\tremaining: 1.4s\n",
            "963:\tlearn: 0.2689607\ttotal: 36.5s\tremaining: 1.36s\n",
            "964:\tlearn: 0.2689224\ttotal: 36.6s\tremaining: 1.33s\n",
            "965:\tlearn: 0.2688866\ttotal: 36.7s\tremaining: 1.29s\n",
            "966:\tlearn: 0.2688608\ttotal: 36.8s\tremaining: 1.25s\n",
            "967:\tlearn: 0.2688342\ttotal: 36.8s\tremaining: 1.22s\n",
            "968:\tlearn: 0.2688016\ttotal: 36.9s\tremaining: 1.18s\n",
            "969:\tlearn: 0.2687682\ttotal: 36.9s\tremaining: 1.14s\n",
            "970:\tlearn: 0.2687344\ttotal: 37s\tremaining: 1.1s\n",
            "971:\tlearn: 0.2687022\ttotal: 37.1s\tremaining: 1.07s\n",
            "972:\tlearn: 0.2686476\ttotal: 37.2s\tremaining: 1.03s\n",
            "973:\tlearn: 0.2685928\ttotal: 37.3s\tremaining: 995ms\n",
            "974:\tlearn: 0.2685445\ttotal: 37.3s\tremaining: 958ms\n",
            "975:\tlearn: 0.2685079\ttotal: 37.4s\tremaining: 921ms\n",
            "976:\tlearn: 0.2684827\ttotal: 37.5s\tremaining: 883ms\n",
            "977:\tlearn: 0.2684541\ttotal: 37.6s\tremaining: 846ms\n",
            "978:\tlearn: 0.2684227\ttotal: 37.6s\tremaining: 807ms\n",
            "979:\tlearn: 0.2683813\ttotal: 37.7s\tremaining: 769ms\n",
            "980:\tlearn: 0.2683464\ttotal: 37.7s\tremaining: 730ms\n",
            "981:\tlearn: 0.2683202\ttotal: 37.7s\tremaining: 692ms\n",
            "982:\tlearn: 0.2682717\ttotal: 37.8s\tremaining: 653ms\n",
            "983:\tlearn: 0.2682236\ttotal: 37.8s\tremaining: 615ms\n",
            "984:\tlearn: 0.2682134\ttotal: 37.8s\tremaining: 576ms\n",
            "985:\tlearn: 0.2681782\ttotal: 37.9s\tremaining: 538ms\n",
            "986:\tlearn: 0.2681286\ttotal: 37.9s\tremaining: 499ms\n",
            "987:\tlearn: 0.2681019\ttotal: 37.9s\tremaining: 461ms\n",
            "988:\tlearn: 0.2680605\ttotal: 38s\tremaining: 422ms\n",
            "989:\tlearn: 0.2680273\ttotal: 38s\tremaining: 384ms\n",
            "990:\tlearn: 0.2680041\ttotal: 38s\tremaining: 345ms\n",
            "991:\tlearn: 0.2679674\ttotal: 38.1s\tremaining: 307ms\n",
            "992:\tlearn: 0.2679423\ttotal: 38.1s\tremaining: 269ms\n",
            "993:\tlearn: 0.2679145\ttotal: 38.1s\tremaining: 230ms\n",
            "994:\tlearn: 0.2678701\ttotal: 38.2s\tremaining: 192ms\n",
            "995:\tlearn: 0.2678499\ttotal: 38.2s\tremaining: 154ms\n",
            "996:\tlearn: 0.2678098\ttotal: 38.3s\tremaining: 115ms\n",
            "997:\tlearn: 0.2677505\ttotal: 38.3s\tremaining: 76.8ms\n",
            "998:\tlearn: 0.2677181\ttotal: 38.3s\tremaining: 38.4ms\n",
            "999:\tlearn: 0.2676750\ttotal: 38.4s\tremaining: 0us\n",
            "18 : 0.874915134254296\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "n_components=19 must be between 0 and min(n_samples, n_features)=18 with svd_solver='full'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-e39a47a7f8ce>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"arpack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"randomized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    524\u001b[0m                 )\n\u001b[1;32m    525\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    527\u001b[0m                 \u001b[0;34m\"n_components=%r must be between 0 and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: n_components=19 must be between 0 and min(n_samples, n_features)=18 with svd_solver='full'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna\n",
        "\n",
        "# Fit CatBoostClassifier with PCA-transformed training data\n",
        "CBC = CatBoostClassifier()\n",
        "pca = PCA(n_components=16)\n",
        "x_train_pca = pca.fit_transform(x_train)\n",
        "CBC.fit(x_train_pca, y_train)\n",
        "\n",
        "# Predict probabilities on original test data\n",
        "x_test_pca = pca.transform(x_test)\n",
        "predicted_probabilities = CBC.predict_proba(x_test_pca)[:, 1]\n",
        "auc_roc = roc_auc_score(y_test, predicted_probabilities)\n",
        "print(\"AUC-ROC Score:\", auc_roc)\n",
        "\n",
        "# Define objective function for Optuna\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
        "        'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
        "    }\n",
        "\n",
        "    clf = CatBoostClassifier(**params, verbose=0, random_state=0)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Apply PCA\n",
        "    pca = PCA(n_components=16)\n",
        "    X_train_pca = pca.fit_transform(X_train)\n",
        "    X_val_pca = pca.transform(X_val)\n",
        "\n",
        "    # Train classifier\n",
        "    clf.fit(X_train_pca, y_train)\n",
        "\n",
        "    # Evaluate classifier on validation set\n",
        "    y_pred = clf.predict_proba(X_val_pca)[:, 1]\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "    return auc\n",
        "\n",
        "# Optimize hyperparameters with Optuna\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_auc = study.best_value\n",
        "\n",
        "print(\"Best AUC:\", best_auc)\n",
        "print(\"Best Hyperparameters:\", best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31YVzew6yWQI",
        "outputId": "818b867c-2e28-46f4-db95-f95b4afe5055"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.079235\n",
            "0:\tlearn: 0.6239698\ttotal: 90.5ms\tremaining: 1m 30s\n",
            "1:\tlearn: 0.5644664\ttotal: 172ms\tremaining: 1m 25s\n",
            "2:\tlearn: 0.5202763\ttotal: 252ms\tremaining: 1m 23s\n",
            "3:\tlearn: 0.4818244\ttotal: 328ms\tremaining: 1m 21s\n",
            "4:\tlearn: 0.4535864\ttotal: 399ms\tremaining: 1m 19s\n",
            "5:\tlearn: 0.4318711\ttotal: 501ms\tremaining: 1m 23s\n",
            "6:\tlearn: 0.4133792\ttotal: 585ms\tremaining: 1m 22s\n",
            "7:\tlearn: 0.3969100\ttotal: 663ms\tremaining: 1m 22s\n",
            "8:\tlearn: 0.3855463\ttotal: 744ms\tremaining: 1m 21s\n",
            "9:\tlearn: 0.3755443\ttotal: 838ms\tremaining: 1m 22s\n",
            "10:\tlearn: 0.3664253\ttotal: 901ms\tremaining: 1m 21s\n",
            "11:\tlearn: 0.3600528\ttotal: 981ms\tremaining: 1m 20s\n",
            "12:\tlearn: 0.3541721\ttotal: 1.06s\tremaining: 1m 20s\n",
            "13:\tlearn: 0.3492045\ttotal: 1.21s\tremaining: 1m 25s\n",
            "14:\tlearn: 0.3448693\ttotal: 1.3s\tremaining: 1m 25s\n",
            "15:\tlearn: 0.3414687\ttotal: 1.43s\tremaining: 1m 28s\n",
            "16:\tlearn: 0.3387432\ttotal: 1.56s\tremaining: 1m 30s\n",
            "17:\tlearn: 0.3360328\ttotal: 1.65s\tremaining: 1m 30s\n",
            "18:\tlearn: 0.3336519\ttotal: 1.75s\tremaining: 1m 30s\n",
            "19:\tlearn: 0.3315082\ttotal: 1.84s\tremaining: 1m 30s\n",
            "20:\tlearn: 0.3298629\ttotal: 1.92s\tremaining: 1m 29s\n",
            "21:\tlearn: 0.3284601\ttotal: 2.01s\tremaining: 1m 29s\n",
            "22:\tlearn: 0.3271478\ttotal: 2.08s\tremaining: 1m 28s\n",
            "23:\tlearn: 0.3255959\ttotal: 2.16s\tremaining: 1m 27s\n",
            "24:\tlearn: 0.3244694\ttotal: 2.23s\tremaining: 1m 26s\n",
            "25:\tlearn: 0.3233861\ttotal: 2.31s\tremaining: 1m 26s\n",
            "26:\tlearn: 0.3224574\ttotal: 2.39s\tremaining: 1m 26s\n",
            "27:\tlearn: 0.3215874\ttotal: 2.47s\tremaining: 1m 25s\n",
            "28:\tlearn: 0.3207870\ttotal: 2.55s\tremaining: 1m 25s\n",
            "29:\tlearn: 0.3201373\ttotal: 2.63s\tremaining: 1m 25s\n",
            "30:\tlearn: 0.3195138\ttotal: 2.71s\tremaining: 1m 24s\n",
            "31:\tlearn: 0.3189863\ttotal: 2.77s\tremaining: 1m 23s\n",
            "32:\tlearn: 0.3183729\ttotal: 2.81s\tremaining: 1m 22s\n",
            "33:\tlearn: 0.3178960\ttotal: 2.87s\tremaining: 1m 21s\n",
            "34:\tlearn: 0.3174444\ttotal: 2.92s\tremaining: 1m 20s\n",
            "35:\tlearn: 0.3169997\ttotal: 2.96s\tremaining: 1m 19s\n",
            "36:\tlearn: 0.3166537\ttotal: 3.03s\tremaining: 1m 18s\n",
            "37:\tlearn: 0.3163149\ttotal: 3.08s\tremaining: 1m 18s\n",
            "38:\tlearn: 0.3159243\ttotal: 3.12s\tremaining: 1m 16s\n",
            "39:\tlearn: 0.3155584\ttotal: 3.17s\tremaining: 1m 15s\n",
            "40:\tlearn: 0.3152449\ttotal: 3.21s\tremaining: 1m 15s\n",
            "41:\tlearn: 0.3149020\ttotal: 3.32s\tremaining: 1m 15s\n",
            "42:\tlearn: 0.3146695\ttotal: 3.4s\tremaining: 1m 15s\n",
            "43:\tlearn: 0.3143849\ttotal: 3.51s\tremaining: 1m 16s\n",
            "44:\tlearn: 0.3141892\ttotal: 3.58s\tremaining: 1m 16s\n",
            "45:\tlearn: 0.3139502\ttotal: 3.64s\tremaining: 1m 15s\n",
            "46:\tlearn: 0.3136788\ttotal: 3.7s\tremaining: 1m 15s\n",
            "47:\tlearn: 0.3134643\ttotal: 3.81s\tremaining: 1m 15s\n",
            "48:\tlearn: 0.3132219\ttotal: 3.88s\tremaining: 1m 15s\n",
            "49:\tlearn: 0.3130080\ttotal: 3.96s\tremaining: 1m 15s\n",
            "50:\tlearn: 0.3126908\ttotal: 4.04s\tremaining: 1m 15s\n",
            "51:\tlearn: 0.3124885\ttotal: 4.11s\tremaining: 1m 14s\n",
            "52:\tlearn: 0.3123169\ttotal: 4.2s\tremaining: 1m 14s\n",
            "53:\tlearn: 0.3121621\ttotal: 4.29s\tremaining: 1m 15s\n",
            "54:\tlearn: 0.3120169\ttotal: 4.34s\tremaining: 1m 14s\n",
            "55:\tlearn: 0.3118278\ttotal: 4.42s\tremaining: 1m 14s\n",
            "56:\tlearn: 0.3116658\ttotal: 4.54s\tremaining: 1m 15s\n",
            "57:\tlearn: 0.3115011\ttotal: 4.62s\tremaining: 1m 15s\n",
            "58:\tlearn: 0.3113690\ttotal: 4.7s\tremaining: 1m 15s\n",
            "59:\tlearn: 0.3112229\ttotal: 4.81s\tremaining: 1m 15s\n",
            "60:\tlearn: 0.3110640\ttotal: 4.93s\tremaining: 1m 15s\n",
            "61:\tlearn: 0.3109646\ttotal: 5.06s\tremaining: 1m 16s\n",
            "62:\tlearn: 0.3108474\ttotal: 5.17s\tremaining: 1m 16s\n",
            "63:\tlearn: 0.3107127\ttotal: 5.27s\tremaining: 1m 17s\n",
            "64:\tlearn: 0.3105907\ttotal: 5.35s\tremaining: 1m 17s\n",
            "65:\tlearn: 0.3104796\ttotal: 5.46s\tremaining: 1m 17s\n",
            "66:\tlearn: 0.3103183\ttotal: 5.56s\tremaining: 1m 17s\n",
            "67:\tlearn: 0.3102129\ttotal: 5.65s\tremaining: 1m 17s\n",
            "68:\tlearn: 0.3100766\ttotal: 5.74s\tremaining: 1m 17s\n",
            "69:\tlearn: 0.3100005\ttotal: 5.83s\tremaining: 1m 17s\n",
            "70:\tlearn: 0.3098965\ttotal: 5.92s\tremaining: 1m 17s\n",
            "71:\tlearn: 0.3097712\ttotal: 5.99s\tremaining: 1m 17s\n",
            "72:\tlearn: 0.3096525\ttotal: 6.09s\tremaining: 1m 17s\n",
            "73:\tlearn: 0.3095347\ttotal: 6.18s\tremaining: 1m 17s\n",
            "74:\tlearn: 0.3094625\ttotal: 6.26s\tremaining: 1m 17s\n",
            "75:\tlearn: 0.3093403\ttotal: 6.31s\tremaining: 1m 16s\n",
            "76:\tlearn: 0.3092290\ttotal: 6.41s\tremaining: 1m 16s\n",
            "77:\tlearn: 0.3091179\ttotal: 6.49s\tremaining: 1m 16s\n",
            "78:\tlearn: 0.3089965\ttotal: 6.6s\tremaining: 1m 16s\n",
            "79:\tlearn: 0.3088963\ttotal: 6.66s\tremaining: 1m 16s\n",
            "80:\tlearn: 0.3088024\ttotal: 6.72s\tremaining: 1m 16s\n",
            "81:\tlearn: 0.3087177\ttotal: 6.77s\tremaining: 1m 15s\n",
            "82:\tlearn: 0.3086400\ttotal: 6.82s\tremaining: 1m 15s\n",
            "83:\tlearn: 0.3085577\ttotal: 6.92s\tremaining: 1m 15s\n",
            "84:\tlearn: 0.3084841\ttotal: 6.99s\tremaining: 1m 15s\n",
            "85:\tlearn: 0.3084060\ttotal: 7.08s\tremaining: 1m 15s\n",
            "86:\tlearn: 0.3083270\ttotal: 7.18s\tremaining: 1m 15s\n",
            "87:\tlearn: 0.3082159\ttotal: 7.24s\tremaining: 1m 15s\n",
            "88:\tlearn: 0.3081423\ttotal: 7.29s\tremaining: 1m 14s\n",
            "89:\tlearn: 0.3080911\ttotal: 7.34s\tremaining: 1m 14s\n",
            "90:\tlearn: 0.3080321\ttotal: 7.41s\tremaining: 1m 14s\n",
            "91:\tlearn: 0.3079359\ttotal: 7.51s\tremaining: 1m 14s\n",
            "92:\tlearn: 0.3078519\ttotal: 7.61s\tremaining: 1m 14s\n",
            "93:\tlearn: 0.3077834\ttotal: 7.74s\tremaining: 1m 14s\n",
            "94:\tlearn: 0.3077019\ttotal: 7.81s\tremaining: 1m 14s\n",
            "95:\tlearn: 0.3076123\ttotal: 7.95s\tremaining: 1m 14s\n",
            "96:\tlearn: 0.3075502\ttotal: 8.02s\tremaining: 1m 14s\n",
            "97:\tlearn: 0.3074786\ttotal: 8.06s\tremaining: 1m 14s\n",
            "98:\tlearn: 0.3074140\ttotal: 8.1s\tremaining: 1m 13s\n",
            "99:\tlearn: 0.3073479\ttotal: 8.19s\tremaining: 1m 13s\n",
            "100:\tlearn: 0.3072722\ttotal: 8.27s\tremaining: 1m 13s\n",
            "101:\tlearn: 0.3072205\ttotal: 8.36s\tremaining: 1m 13s\n",
            "102:\tlearn: 0.3071155\ttotal: 8.49s\tremaining: 1m 13s\n",
            "103:\tlearn: 0.3070487\ttotal: 8.61s\tremaining: 1m 14s\n",
            "104:\tlearn: 0.3069813\ttotal: 8.71s\tremaining: 1m 14s\n",
            "105:\tlearn: 0.3069238\ttotal: 8.85s\tremaining: 1m 14s\n",
            "106:\tlearn: 0.3068608\ttotal: 8.96s\tremaining: 1m 14s\n",
            "107:\tlearn: 0.3067943\ttotal: 9.04s\tremaining: 1m 14s\n",
            "108:\tlearn: 0.3067498\ttotal: 9.13s\tremaining: 1m 14s\n",
            "109:\tlearn: 0.3066993\ttotal: 9.24s\tremaining: 1m 14s\n",
            "110:\tlearn: 0.3066324\ttotal: 9.38s\tremaining: 1m 15s\n",
            "111:\tlearn: 0.3065767\ttotal: 9.48s\tremaining: 1m 15s\n",
            "112:\tlearn: 0.3065137\ttotal: 9.56s\tremaining: 1m 15s\n",
            "113:\tlearn: 0.3064480\ttotal: 9.7s\tremaining: 1m 15s\n",
            "114:\tlearn: 0.3063862\ttotal: 9.8s\tremaining: 1m 15s\n",
            "115:\tlearn: 0.3063349\ttotal: 9.93s\tremaining: 1m 15s\n",
            "116:\tlearn: 0.3062679\ttotal: 10s\tremaining: 1m 15s\n",
            "117:\tlearn: 0.3062020\ttotal: 10.2s\tremaining: 1m 16s\n",
            "118:\tlearn: 0.3061624\ttotal: 10.3s\tremaining: 1m 16s\n",
            "119:\tlearn: 0.3060827\ttotal: 10.4s\tremaining: 1m 16s\n",
            "120:\tlearn: 0.3060173\ttotal: 10.5s\tremaining: 1m 16s\n",
            "121:\tlearn: 0.3059638\ttotal: 10.6s\tremaining: 1m 16s\n",
            "122:\tlearn: 0.3059118\ttotal: 10.7s\tremaining: 1m 16s\n",
            "123:\tlearn: 0.3058677\ttotal: 10.8s\tremaining: 1m 15s\n",
            "124:\tlearn: 0.3058220\ttotal: 10.9s\tremaining: 1m 16s\n",
            "125:\tlearn: 0.3057765\ttotal: 11.1s\tremaining: 1m 16s\n",
            "126:\tlearn: 0.3057139\ttotal: 11.2s\tremaining: 1m 16s\n",
            "127:\tlearn: 0.3056387\ttotal: 11.2s\tremaining: 1m 16s\n",
            "128:\tlearn: 0.3055821\ttotal: 11.4s\tremaining: 1m 16s\n",
            "129:\tlearn: 0.3055260\ttotal: 11.5s\tremaining: 1m 16s\n",
            "130:\tlearn: 0.3054680\ttotal: 11.6s\tremaining: 1m 17s\n",
            "131:\tlearn: 0.3054118\ttotal: 11.7s\tremaining: 1m 16s\n",
            "132:\tlearn: 0.3053608\ttotal: 11.7s\tremaining: 1m 16s\n",
            "133:\tlearn: 0.3053066\ttotal: 11.8s\tremaining: 1m 16s\n",
            "134:\tlearn: 0.3052662\ttotal: 11.9s\tremaining: 1m 16s\n",
            "135:\tlearn: 0.3052418\ttotal: 12s\tremaining: 1m 16s\n",
            "136:\tlearn: 0.3051757\ttotal: 12.1s\tremaining: 1m 16s\n",
            "137:\tlearn: 0.3051319\ttotal: 12.1s\tremaining: 1m 15s\n",
            "138:\tlearn: 0.3050541\ttotal: 12.2s\tremaining: 1m 15s\n",
            "139:\tlearn: 0.3049935\ttotal: 12.2s\tremaining: 1m 14s\n",
            "140:\tlearn: 0.3049580\ttotal: 12.2s\tremaining: 1m 14s\n",
            "141:\tlearn: 0.3048923\ttotal: 12.3s\tremaining: 1m 14s\n",
            "142:\tlearn: 0.3048472\ttotal: 12.3s\tremaining: 1m 13s\n",
            "143:\tlearn: 0.3048069\ttotal: 12.4s\tremaining: 1m 13s\n",
            "144:\tlearn: 0.3047349\ttotal: 12.4s\tremaining: 1m 13s\n",
            "145:\tlearn: 0.3046931\ttotal: 12.5s\tremaining: 1m 13s\n",
            "146:\tlearn: 0.3046278\ttotal: 12.5s\tremaining: 1m 12s\n",
            "147:\tlearn: 0.3045618\ttotal: 12.6s\tremaining: 1m 12s\n",
            "148:\tlearn: 0.3045125\ttotal: 12.7s\tremaining: 1m 12s\n",
            "149:\tlearn: 0.3044428\ttotal: 12.8s\tremaining: 1m 12s\n",
            "150:\tlearn: 0.3043837\ttotal: 12.9s\tremaining: 1m 12s\n",
            "151:\tlearn: 0.3043190\ttotal: 12.9s\tremaining: 1m 12s\n",
            "152:\tlearn: 0.3042814\ttotal: 13s\tremaining: 1m 12s\n",
            "153:\tlearn: 0.3042124\ttotal: 13.1s\tremaining: 1m 11s\n",
            "154:\tlearn: 0.3041637\ttotal: 13.1s\tremaining: 1m 11s\n",
            "155:\tlearn: 0.3041051\ttotal: 13.2s\tremaining: 1m 11s\n",
            "156:\tlearn: 0.3040414\ttotal: 13.2s\tremaining: 1m 11s\n",
            "157:\tlearn: 0.3039832\ttotal: 13.3s\tremaining: 1m 10s\n",
            "158:\tlearn: 0.3039239\ttotal: 13.4s\tremaining: 1m 10s\n",
            "159:\tlearn: 0.3038681\ttotal: 13.5s\tremaining: 1m 10s\n",
            "160:\tlearn: 0.3038130\ttotal: 13.5s\tremaining: 1m 10s\n",
            "161:\tlearn: 0.3037608\ttotal: 13.6s\tremaining: 1m 10s\n",
            "162:\tlearn: 0.3037087\ttotal: 13.7s\tremaining: 1m 10s\n",
            "163:\tlearn: 0.3036613\ttotal: 13.8s\tremaining: 1m 10s\n",
            "164:\tlearn: 0.3036132\ttotal: 13.9s\tremaining: 1m 10s\n",
            "165:\tlearn: 0.3035671\ttotal: 13.9s\tremaining: 1m 10s\n",
            "166:\tlearn: 0.3035133\ttotal: 14s\tremaining: 1m 9s\n",
            "167:\tlearn: 0.3034548\ttotal: 14.1s\tremaining: 1m 9s\n",
            "168:\tlearn: 0.3033971\ttotal: 14.2s\tremaining: 1m 9s\n",
            "169:\tlearn: 0.3033284\ttotal: 14.3s\tremaining: 1m 9s\n",
            "170:\tlearn: 0.3032698\ttotal: 14.4s\tremaining: 1m 9s\n",
            "171:\tlearn: 0.3032148\ttotal: 14.4s\tremaining: 1m 9s\n",
            "172:\tlearn: 0.3031581\ttotal: 14.5s\tremaining: 1m 9s\n",
            "173:\tlearn: 0.3030987\ttotal: 14.5s\tremaining: 1m 8s\n",
            "174:\tlearn: 0.3030664\ttotal: 14.6s\tremaining: 1m 8s\n",
            "175:\tlearn: 0.3030119\ttotal: 14.7s\tremaining: 1m 8s\n",
            "176:\tlearn: 0.3029664\ttotal: 14.8s\tremaining: 1m 8s\n",
            "177:\tlearn: 0.3029137\ttotal: 14.8s\tremaining: 1m 8s\n",
            "178:\tlearn: 0.3028439\ttotal: 14.9s\tremaining: 1m 8s\n",
            "179:\tlearn: 0.3027913\ttotal: 15s\tremaining: 1m 8s\n",
            "180:\tlearn: 0.3027389\ttotal: 15.1s\tremaining: 1m 8s\n",
            "181:\tlearn: 0.3026949\ttotal: 15.1s\tremaining: 1m 8s\n",
            "182:\tlearn: 0.3026427\ttotal: 15.2s\tremaining: 1m 7s\n",
            "183:\tlearn: 0.3025904\ttotal: 15.2s\tremaining: 1m 7s\n",
            "184:\tlearn: 0.3025367\ttotal: 15.3s\tremaining: 1m 7s\n",
            "185:\tlearn: 0.3024726\ttotal: 15.4s\tremaining: 1m 7s\n",
            "186:\tlearn: 0.3024079\ttotal: 15.5s\tremaining: 1m 7s\n",
            "187:\tlearn: 0.3023591\ttotal: 15.5s\tremaining: 1m 7s\n",
            "188:\tlearn: 0.3023067\ttotal: 15.6s\tremaining: 1m 7s\n",
            "189:\tlearn: 0.3022460\ttotal: 15.7s\tremaining: 1m 7s\n",
            "190:\tlearn: 0.3021758\ttotal: 15.8s\tremaining: 1m 6s\n",
            "191:\tlearn: 0.3020972\ttotal: 15.9s\tremaining: 1m 6s\n",
            "192:\tlearn: 0.3020508\ttotal: 15.9s\tremaining: 1m 6s\n",
            "193:\tlearn: 0.3020104\ttotal: 16s\tremaining: 1m 6s\n",
            "194:\tlearn: 0.3019570\ttotal: 16.1s\tremaining: 1m 6s\n",
            "195:\tlearn: 0.3018851\ttotal: 16.2s\tremaining: 1m 6s\n",
            "196:\tlearn: 0.3018484\ttotal: 16.2s\tremaining: 1m 6s\n",
            "197:\tlearn: 0.3017973\ttotal: 16.3s\tremaining: 1m 6s\n",
            "198:\tlearn: 0.3017531\ttotal: 16.4s\tremaining: 1m 5s\n",
            "199:\tlearn: 0.3016818\ttotal: 16.4s\tremaining: 1m 5s\n",
            "200:\tlearn: 0.3016269\ttotal: 16.4s\tremaining: 1m 5s\n",
            "201:\tlearn: 0.3015703\ttotal: 16.5s\tremaining: 1m 5s\n",
            "202:\tlearn: 0.3015231\ttotal: 16.5s\tremaining: 1m 4s\n",
            "203:\tlearn: 0.3014729\ttotal: 16.6s\tremaining: 1m 4s\n",
            "204:\tlearn: 0.3014132\ttotal: 16.7s\tremaining: 1m 4s\n",
            "205:\tlearn: 0.3013660\ttotal: 16.8s\tremaining: 1m 4s\n",
            "206:\tlearn: 0.3013056\ttotal: 16.8s\tremaining: 1m 4s\n",
            "207:\tlearn: 0.3012563\ttotal: 17s\tremaining: 1m 4s\n",
            "208:\tlearn: 0.3012030\ttotal: 17.1s\tremaining: 1m 4s\n",
            "209:\tlearn: 0.3011597\ttotal: 17.2s\tremaining: 1m 4s\n",
            "210:\tlearn: 0.3011192\ttotal: 17.3s\tremaining: 1m 4s\n",
            "211:\tlearn: 0.3010534\ttotal: 17.4s\tremaining: 1m 4s\n",
            "212:\tlearn: 0.3009974\ttotal: 17.6s\tremaining: 1m 4s\n",
            "213:\tlearn: 0.3009487\ttotal: 17.6s\tremaining: 1m 4s\n",
            "214:\tlearn: 0.3009059\ttotal: 17.7s\tremaining: 1m 4s\n",
            "215:\tlearn: 0.3008554\ttotal: 17.7s\tremaining: 1m 4s\n",
            "216:\tlearn: 0.3007985\ttotal: 17.8s\tremaining: 1m 4s\n",
            "217:\tlearn: 0.3007551\ttotal: 17.8s\tremaining: 1m 4s\n",
            "218:\tlearn: 0.3006989\ttotal: 17.9s\tremaining: 1m 3s\n",
            "219:\tlearn: 0.3006619\ttotal: 18s\tremaining: 1m 3s\n",
            "220:\tlearn: 0.3006251\ttotal: 18s\tremaining: 1m 3s\n",
            "221:\tlearn: 0.3005650\ttotal: 18s\tremaining: 1m 3s\n",
            "222:\tlearn: 0.3005049\ttotal: 18.1s\tremaining: 1m 3s\n",
            "223:\tlearn: 0.3004560\ttotal: 18.2s\tremaining: 1m 3s\n",
            "224:\tlearn: 0.3004029\ttotal: 18.3s\tremaining: 1m 2s\n",
            "225:\tlearn: 0.3003729\ttotal: 18.3s\tremaining: 1m 2s\n",
            "226:\tlearn: 0.3003184\ttotal: 18.4s\tremaining: 1m 2s\n",
            "227:\tlearn: 0.3002721\ttotal: 18.5s\tremaining: 1m 2s\n",
            "228:\tlearn: 0.3002222\ttotal: 18.6s\tremaining: 1m 2s\n",
            "229:\tlearn: 0.3001763\ttotal: 18.7s\tremaining: 1m 2s\n",
            "230:\tlearn: 0.3001184\ttotal: 18.8s\tremaining: 1m 2s\n",
            "231:\tlearn: 0.3000656\ttotal: 19s\tremaining: 1m 2s\n",
            "232:\tlearn: 0.3000084\ttotal: 19.1s\tremaining: 1m 2s\n",
            "233:\tlearn: 0.2999480\ttotal: 19.2s\tremaining: 1m 2s\n",
            "234:\tlearn: 0.2998960\ttotal: 19.3s\tremaining: 1m 2s\n",
            "235:\tlearn: 0.2998488\ttotal: 19.4s\tremaining: 1m 2s\n",
            "236:\tlearn: 0.2998020\ttotal: 19.6s\tremaining: 1m 2s\n",
            "237:\tlearn: 0.2997453\ttotal: 19.7s\tremaining: 1m 2s\n",
            "238:\tlearn: 0.2996871\ttotal: 19.8s\tremaining: 1m 2s\n",
            "239:\tlearn: 0.2996429\ttotal: 19.8s\tremaining: 1m 2s\n",
            "240:\tlearn: 0.2996061\ttotal: 19.9s\tremaining: 1m 2s\n",
            "241:\tlearn: 0.2995472\ttotal: 20s\tremaining: 1m 2s\n",
            "242:\tlearn: 0.2995032\ttotal: 20.1s\tremaining: 1m 2s\n",
            "243:\tlearn: 0.2994526\ttotal: 20.1s\tremaining: 1m 2s\n",
            "244:\tlearn: 0.2994144\ttotal: 20.2s\tremaining: 1m 2s\n",
            "245:\tlearn: 0.2993727\ttotal: 20.3s\tremaining: 1m 2s\n",
            "246:\tlearn: 0.2993236\ttotal: 20.4s\tremaining: 1m 2s\n",
            "247:\tlearn: 0.2992641\ttotal: 20.4s\tremaining: 1m 1s\n",
            "248:\tlearn: 0.2992274\ttotal: 20.5s\tremaining: 1m 1s\n",
            "249:\tlearn: 0.2991846\ttotal: 20.6s\tremaining: 1m 1s\n",
            "250:\tlearn: 0.2991420\ttotal: 20.7s\tremaining: 1m 1s\n",
            "251:\tlearn: 0.2990896\ttotal: 20.7s\tremaining: 1m 1s\n",
            "252:\tlearn: 0.2990477\ttotal: 20.8s\tremaining: 1m 1s\n",
            "253:\tlearn: 0.2990024\ttotal: 20.9s\tremaining: 1m 1s\n",
            "254:\tlearn: 0.2989606\ttotal: 20.9s\tremaining: 1m 1s\n",
            "255:\tlearn: 0.2989222\ttotal: 21s\tremaining: 1m 1s\n",
            "256:\tlearn: 0.2988767\ttotal: 21.1s\tremaining: 1m 1s\n",
            "257:\tlearn: 0.2988244\ttotal: 21.2s\tremaining: 1m\n",
            "258:\tlearn: 0.2987770\ttotal: 21.3s\tremaining: 1m\n",
            "259:\tlearn: 0.2987305\ttotal: 21.4s\tremaining: 1m\n",
            "260:\tlearn: 0.2986823\ttotal: 21.5s\tremaining: 1m\n",
            "261:\tlearn: 0.2986406\ttotal: 21.7s\tremaining: 1m 1s\n",
            "262:\tlearn: 0.2985894\ttotal: 21.9s\tremaining: 1m 1s\n",
            "263:\tlearn: 0.2985375\ttotal: 22s\tremaining: 1m 1s\n",
            "264:\tlearn: 0.2984886\ttotal: 22.3s\tremaining: 1m 1s\n",
            "265:\tlearn: 0.2984518\ttotal: 22.5s\tremaining: 1m 2s\n",
            "266:\tlearn: 0.2983978\ttotal: 22.6s\tremaining: 1m 2s\n",
            "267:\tlearn: 0.2983417\ttotal: 22.8s\tremaining: 1m 2s\n",
            "268:\tlearn: 0.2982809\ttotal: 22.9s\tremaining: 1m 2s\n",
            "269:\tlearn: 0.2982269\ttotal: 23.1s\tremaining: 1m 2s\n",
            "270:\tlearn: 0.2981714\ttotal: 23.2s\tremaining: 1m 2s\n",
            "271:\tlearn: 0.2981255\ttotal: 23.3s\tremaining: 1m 2s\n",
            "272:\tlearn: 0.2980637\ttotal: 23.5s\tremaining: 1m 2s\n",
            "273:\tlearn: 0.2980177\ttotal: 23.6s\tremaining: 1m 2s\n",
            "274:\tlearn: 0.2979619\ttotal: 23.7s\tremaining: 1m 2s\n",
            "275:\tlearn: 0.2979100\ttotal: 23.9s\tremaining: 1m 2s\n",
            "276:\tlearn: 0.2978790\ttotal: 24s\tremaining: 1m 2s\n",
            "277:\tlearn: 0.2978454\ttotal: 24.1s\tremaining: 1m 2s\n",
            "278:\tlearn: 0.2978066\ttotal: 24.1s\tremaining: 1m 2s\n",
            "279:\tlearn: 0.2977650\ttotal: 24.3s\tremaining: 1m 2s\n",
            "280:\tlearn: 0.2977097\ttotal: 24.3s\tremaining: 1m 2s\n",
            "281:\tlearn: 0.2976656\ttotal: 24.5s\tremaining: 1m 2s\n",
            "282:\tlearn: 0.2976192\ttotal: 24.6s\tremaining: 1m 2s\n",
            "283:\tlearn: 0.2975809\ttotal: 24.7s\tremaining: 1m 2s\n",
            "284:\tlearn: 0.2975400\ttotal: 24.8s\tremaining: 1m 2s\n",
            "285:\tlearn: 0.2974962\ttotal: 24.9s\tremaining: 1m 2s\n",
            "286:\tlearn: 0.2974534\ttotal: 25s\tremaining: 1m 2s\n",
            "287:\tlearn: 0.2974019\ttotal: 25.1s\tremaining: 1m 2s\n",
            "288:\tlearn: 0.2973610\ttotal: 25.2s\tremaining: 1m 1s\n",
            "289:\tlearn: 0.2973053\ttotal: 25.2s\tremaining: 1m 1s\n",
            "290:\tlearn: 0.2972657\ttotal: 25.3s\tremaining: 1m 1s\n",
            "291:\tlearn: 0.2972183\ttotal: 25.3s\tremaining: 1m 1s\n",
            "292:\tlearn: 0.2971648\ttotal: 25.5s\tremaining: 1m 1s\n",
            "293:\tlearn: 0.2971040\ttotal: 25.7s\tremaining: 1m 1s\n",
            "294:\tlearn: 0.2970599\ttotal: 25.8s\tremaining: 1m 1s\n",
            "295:\tlearn: 0.2970052\ttotal: 25.9s\tremaining: 1m 1s\n",
            "296:\tlearn: 0.2969519\ttotal: 25.9s\tremaining: 1m 1s\n",
            "297:\tlearn: 0.2968965\ttotal: 26s\tremaining: 1m 1s\n",
            "298:\tlearn: 0.2968599\ttotal: 26.1s\tremaining: 1m 1s\n",
            "299:\tlearn: 0.2968122\ttotal: 26.1s\tremaining: 1m\n",
            "300:\tlearn: 0.2967875\ttotal: 26.2s\tremaining: 1m\n",
            "301:\tlearn: 0.2967469\ttotal: 26.3s\tremaining: 1m\n",
            "302:\tlearn: 0.2967142\ttotal: 26.3s\tremaining: 1m\n",
            "303:\tlearn: 0.2966637\ttotal: 26.4s\tremaining: 1m\n",
            "304:\tlearn: 0.2966144\ttotal: 26.5s\tremaining: 1m\n",
            "305:\tlearn: 0.2965741\ttotal: 26.6s\tremaining: 1m\n",
            "306:\tlearn: 0.2965252\ttotal: 26.6s\tremaining: 1m\n",
            "307:\tlearn: 0.2964726\ttotal: 26.8s\tremaining: 1m\n",
            "308:\tlearn: 0.2964340\ttotal: 26.8s\tremaining: 1m\n",
            "309:\tlearn: 0.2963880\ttotal: 26.9s\tremaining: 59.9s\n",
            "310:\tlearn: 0.2963421\ttotal: 27.1s\tremaining: 59.9s\n",
            "311:\tlearn: 0.2963022\ttotal: 27.2s\tremaining: 59.9s\n",
            "312:\tlearn: 0.2962638\ttotal: 27.2s\tremaining: 59.8s\n",
            "313:\tlearn: 0.2962321\ttotal: 27.3s\tremaining: 59.6s\n",
            "314:\tlearn: 0.2961879\ttotal: 27.3s\tremaining: 59.4s\n",
            "315:\tlearn: 0.2961340\ttotal: 27.4s\tremaining: 59.3s\n",
            "316:\tlearn: 0.2960958\ttotal: 27.4s\tremaining: 59.1s\n",
            "317:\tlearn: 0.2960573\ttotal: 27.6s\tremaining: 59.1s\n",
            "318:\tlearn: 0.2960136\ttotal: 27.6s\tremaining: 59s\n",
            "319:\tlearn: 0.2959735\ttotal: 27.7s\tremaining: 58.8s\n",
            "320:\tlearn: 0.2959231\ttotal: 27.8s\tremaining: 58.7s\n",
            "321:\tlearn: 0.2958808\ttotal: 27.8s\tremaining: 58.6s\n",
            "322:\tlearn: 0.2958367\ttotal: 27.9s\tremaining: 58.4s\n",
            "323:\tlearn: 0.2957979\ttotal: 27.9s\tremaining: 58.3s\n",
            "324:\tlearn: 0.2957530\ttotal: 28s\tremaining: 58.2s\n",
            "325:\tlearn: 0.2957104\ttotal: 28.1s\tremaining: 58s\n",
            "326:\tlearn: 0.2956537\ttotal: 28.2s\tremaining: 58s\n",
            "327:\tlearn: 0.2956038\ttotal: 28.3s\tremaining: 58s\n",
            "328:\tlearn: 0.2955672\ttotal: 28.3s\tremaining: 57.8s\n",
            "329:\tlearn: 0.2955216\ttotal: 28.4s\tremaining: 57.7s\n",
            "330:\tlearn: 0.2954788\ttotal: 28.5s\tremaining: 57.6s\n",
            "331:\tlearn: 0.2954399\ttotal: 28.6s\tremaining: 57.5s\n",
            "332:\tlearn: 0.2953999\ttotal: 28.7s\tremaining: 57.4s\n",
            "333:\tlearn: 0.2953637\ttotal: 28.7s\tremaining: 57.2s\n",
            "334:\tlearn: 0.2953243\ttotal: 28.8s\tremaining: 57.1s\n",
            "335:\tlearn: 0.2952882\ttotal: 28.9s\tremaining: 57s\n",
            "336:\tlearn: 0.2952539\ttotal: 28.9s\tremaining: 56.9s\n",
            "337:\tlearn: 0.2952070\ttotal: 29.1s\tremaining: 56.9s\n",
            "338:\tlearn: 0.2951721\ttotal: 29.2s\tremaining: 56.9s\n",
            "339:\tlearn: 0.2951337\ttotal: 29.2s\tremaining: 56.7s\n",
            "340:\tlearn: 0.2950910\ttotal: 29.3s\tremaining: 56.7s\n",
            "341:\tlearn: 0.2950447\ttotal: 29.4s\tremaining: 56.6s\n",
            "342:\tlearn: 0.2950126\ttotal: 29.5s\tremaining: 56.5s\n",
            "343:\tlearn: 0.2949640\ttotal: 29.6s\tremaining: 56.4s\n",
            "344:\tlearn: 0.2949162\ttotal: 29.6s\tremaining: 56.2s\n",
            "345:\tlearn: 0.2948658\ttotal: 29.7s\tremaining: 56s\n",
            "346:\tlearn: 0.2948219\ttotal: 29.7s\tremaining: 55.9s\n",
            "347:\tlearn: 0.2947711\ttotal: 29.8s\tremaining: 55.8s\n",
            "348:\tlearn: 0.2947270\ttotal: 29.9s\tremaining: 55.7s\n",
            "349:\tlearn: 0.2946910\ttotal: 29.9s\tremaining: 55.6s\n",
            "350:\tlearn: 0.2946427\ttotal: 30s\tremaining: 55.4s\n",
            "351:\tlearn: 0.2945965\ttotal: 30.1s\tremaining: 55.3s\n",
            "352:\tlearn: 0.2945283\ttotal: 30.1s\tremaining: 55.2s\n",
            "353:\tlearn: 0.2944956\ttotal: 30.2s\tremaining: 55.1s\n",
            "354:\tlearn: 0.2944471\ttotal: 30.3s\tremaining: 55s\n",
            "355:\tlearn: 0.2943930\ttotal: 30.3s\tremaining: 54.8s\n",
            "356:\tlearn: 0.2943476\ttotal: 30.4s\tremaining: 54.7s\n",
            "357:\tlearn: 0.2943097\ttotal: 30.5s\tremaining: 54.7s\n",
            "358:\tlearn: 0.2942718\ttotal: 30.6s\tremaining: 54.6s\n",
            "359:\tlearn: 0.2942181\ttotal: 30.6s\tremaining: 54.4s\n",
            "360:\tlearn: 0.2941831\ttotal: 30.7s\tremaining: 54.4s\n",
            "361:\tlearn: 0.2941419\ttotal: 30.9s\tremaining: 54.4s\n",
            "362:\tlearn: 0.2940990\ttotal: 31s\tremaining: 54.4s\n",
            "363:\tlearn: 0.2940374\ttotal: 31.1s\tremaining: 54.4s\n",
            "364:\tlearn: 0.2940045\ttotal: 31.2s\tremaining: 54.3s\n",
            "365:\tlearn: 0.2939524\ttotal: 31.3s\tremaining: 54.2s\n",
            "366:\tlearn: 0.2938988\ttotal: 31.4s\tremaining: 54.1s\n",
            "367:\tlearn: 0.2938630\ttotal: 31.5s\tremaining: 54s\n",
            "368:\tlearn: 0.2938284\ttotal: 31.6s\tremaining: 54s\n",
            "369:\tlearn: 0.2937969\ttotal: 31.6s\tremaining: 53.9s\n",
            "370:\tlearn: 0.2937477\ttotal: 31.7s\tremaining: 53.7s\n",
            "371:\tlearn: 0.2937002\ttotal: 31.8s\tremaining: 53.6s\n",
            "372:\tlearn: 0.2936640\ttotal: 31.8s\tremaining: 53.5s\n",
            "373:\tlearn: 0.2936192\ttotal: 31.9s\tremaining: 53.4s\n",
            "374:\tlearn: 0.2935634\ttotal: 32s\tremaining: 53.3s\n",
            "375:\tlearn: 0.2935248\ttotal: 32.1s\tremaining: 53.3s\n",
            "376:\tlearn: 0.2934735\ttotal: 32.2s\tremaining: 53.2s\n",
            "377:\tlearn: 0.2934409\ttotal: 32.2s\tremaining: 53.1s\n",
            "378:\tlearn: 0.2934102\ttotal: 32.3s\tremaining: 52.9s\n",
            "379:\tlearn: 0.2933623\ttotal: 32.3s\tremaining: 52.8s\n",
            "380:\tlearn: 0.2933087\ttotal: 32.4s\tremaining: 52.7s\n",
            "381:\tlearn: 0.2932672\ttotal: 32.5s\tremaining: 52.5s\n",
            "382:\tlearn: 0.2932211\ttotal: 32.6s\tremaining: 52.5s\n",
            "383:\tlearn: 0.2931839\ttotal: 32.6s\tremaining: 52.3s\n",
            "384:\tlearn: 0.2931382\ttotal: 32.7s\tremaining: 52.3s\n",
            "385:\tlearn: 0.2930748\ttotal: 32.8s\tremaining: 52.2s\n",
            "386:\tlearn: 0.2930276\ttotal: 32.9s\tremaining: 52.1s\n",
            "387:\tlearn: 0.2929833\ttotal: 33s\tremaining: 52s\n",
            "388:\tlearn: 0.2929556\ttotal: 33s\tremaining: 51.9s\n",
            "389:\tlearn: 0.2929071\ttotal: 33.1s\tremaining: 51.8s\n",
            "390:\tlearn: 0.2928601\ttotal: 33.2s\tremaining: 51.8s\n",
            "391:\tlearn: 0.2928213\ttotal: 33.3s\tremaining: 51.7s\n",
            "392:\tlearn: 0.2927627\ttotal: 33.4s\tremaining: 51.6s\n",
            "393:\tlearn: 0.2927268\ttotal: 33.5s\tremaining: 51.5s\n",
            "394:\tlearn: 0.2926884\ttotal: 33.6s\tremaining: 51.4s\n",
            "395:\tlearn: 0.2926483\ttotal: 33.7s\tremaining: 51.4s\n",
            "396:\tlearn: 0.2926019\ttotal: 33.7s\tremaining: 51.2s\n",
            "397:\tlearn: 0.2925632\ttotal: 33.8s\tremaining: 51.2s\n",
            "398:\tlearn: 0.2925284\ttotal: 33.9s\tremaining: 51.1s\n",
            "399:\tlearn: 0.2924857\ttotal: 34s\tremaining: 50.9s\n",
            "400:\tlearn: 0.2924469\ttotal: 34s\tremaining: 50.8s\n",
            "401:\tlearn: 0.2924159\ttotal: 34.1s\tremaining: 50.7s\n",
            "402:\tlearn: 0.2923660\ttotal: 34.1s\tremaining: 50.5s\n",
            "403:\tlearn: 0.2923259\ttotal: 34.2s\tremaining: 50.4s\n",
            "404:\tlearn: 0.2922867\ttotal: 34.2s\tremaining: 50.2s\n",
            "405:\tlearn: 0.2922481\ttotal: 34.2s\tremaining: 50.1s\n",
            "406:\tlearn: 0.2922058\ttotal: 34.3s\tremaining: 50s\n",
            "407:\tlearn: 0.2921625\ttotal: 34.4s\tremaining: 49.9s\n",
            "408:\tlearn: 0.2921368\ttotal: 34.5s\tremaining: 49.8s\n",
            "409:\tlearn: 0.2921097\ttotal: 34.6s\tremaining: 49.7s\n",
            "410:\tlearn: 0.2920829\ttotal: 34.6s\tremaining: 49.6s\n",
            "411:\tlearn: 0.2920438\ttotal: 34.7s\tremaining: 49.5s\n",
            "412:\tlearn: 0.2919886\ttotal: 34.8s\tremaining: 49.5s\n",
            "413:\tlearn: 0.2919594\ttotal: 35s\tremaining: 49.5s\n",
            "414:\tlearn: 0.2919155\ttotal: 35s\tremaining: 49.4s\n",
            "415:\tlearn: 0.2918873\ttotal: 35.1s\tremaining: 49.3s\n",
            "416:\tlearn: 0.2918344\ttotal: 35.3s\tremaining: 49.3s\n",
            "417:\tlearn: 0.2917938\ttotal: 35.5s\tremaining: 49.5s\n",
            "418:\tlearn: 0.2917453\ttotal: 35.8s\tremaining: 49.6s\n",
            "419:\tlearn: 0.2917138\ttotal: 36s\tremaining: 49.8s\n",
            "420:\tlearn: 0.2916751\ttotal: 36.3s\tremaining: 49.9s\n",
            "421:\tlearn: 0.2916381\ttotal: 36.5s\tremaining: 50s\n",
            "422:\tlearn: 0.2916041\ttotal: 36.7s\tremaining: 50.1s\n",
            "423:\tlearn: 0.2915510\ttotal: 36.9s\tremaining: 50.2s\n",
            "424:\tlearn: 0.2915102\ttotal: 37.1s\tremaining: 50.2s\n",
            "425:\tlearn: 0.2914647\ttotal: 37.3s\tremaining: 50.3s\n",
            "426:\tlearn: 0.2914263\ttotal: 37.5s\tremaining: 50.3s\n",
            "427:\tlearn: 0.2913932\ttotal: 37.6s\tremaining: 50.3s\n",
            "428:\tlearn: 0.2913504\ttotal: 37.7s\tremaining: 50.2s\n",
            "429:\tlearn: 0.2912960\ttotal: 37.8s\tremaining: 50.1s\n",
            "430:\tlearn: 0.2912551\ttotal: 37.8s\tremaining: 49.9s\n",
            "431:\tlearn: 0.2912230\ttotal: 37.9s\tremaining: 49.9s\n",
            "432:\tlearn: 0.2911807\ttotal: 38s\tremaining: 49.8s\n",
            "433:\tlearn: 0.2911427\ttotal: 38.2s\tremaining: 49.8s\n",
            "434:\tlearn: 0.2911052\ttotal: 38.3s\tremaining: 49.7s\n",
            "435:\tlearn: 0.2910611\ttotal: 38.4s\tremaining: 49.6s\n",
            "436:\tlearn: 0.2910153\ttotal: 38.4s\tremaining: 49.5s\n",
            "437:\tlearn: 0.2909656\ttotal: 38.5s\tremaining: 49.4s\n",
            "438:\tlearn: 0.2909199\ttotal: 38.6s\tremaining: 49.3s\n",
            "439:\tlearn: 0.2908781\ttotal: 38.6s\tremaining: 49.2s\n",
            "440:\tlearn: 0.2908325\ttotal: 38.7s\tremaining: 49.1s\n",
            "441:\tlearn: 0.2907883\ttotal: 38.9s\tremaining: 49.1s\n",
            "442:\tlearn: 0.2907264\ttotal: 38.9s\tremaining: 49s\n",
            "443:\tlearn: 0.2906850\ttotal: 39s\tremaining: 48.9s\n",
            "444:\tlearn: 0.2906424\ttotal: 39.1s\tremaining: 48.8s\n",
            "445:\tlearn: 0.2906033\ttotal: 39.2s\tremaining: 48.7s\n",
            "446:\tlearn: 0.2905629\ttotal: 39.3s\tremaining: 48.6s\n",
            "447:\tlearn: 0.2905319\ttotal: 39.3s\tremaining: 48.5s\n",
            "448:\tlearn: 0.2904943\ttotal: 39.4s\tremaining: 48.4s\n",
            "449:\tlearn: 0.2904498\ttotal: 39.5s\tremaining: 48.3s\n",
            "450:\tlearn: 0.2904178\ttotal: 39.6s\tremaining: 48.2s\n",
            "451:\tlearn: 0.2903658\ttotal: 39.7s\tremaining: 48.1s\n",
            "452:\tlearn: 0.2903175\ttotal: 39.7s\tremaining: 48s\n",
            "453:\tlearn: 0.2902784\ttotal: 39.8s\tremaining: 47.9s\n",
            "454:\tlearn: 0.2902292\ttotal: 39.9s\tremaining: 47.8s\n",
            "455:\tlearn: 0.2901992\ttotal: 40s\tremaining: 47.7s\n",
            "456:\tlearn: 0.2901511\ttotal: 40.1s\tremaining: 47.6s\n",
            "457:\tlearn: 0.2901233\ttotal: 40.2s\tremaining: 47.6s\n",
            "458:\tlearn: 0.2900956\ttotal: 40.3s\tremaining: 47.5s\n",
            "459:\tlearn: 0.2900422\ttotal: 40.3s\tremaining: 47.3s\n",
            "460:\tlearn: 0.2899948\ttotal: 40.4s\tremaining: 47.2s\n",
            "461:\tlearn: 0.2899549\ttotal: 40.4s\tremaining: 47.1s\n",
            "462:\tlearn: 0.2899137\ttotal: 40.5s\tremaining: 46.9s\n",
            "463:\tlearn: 0.2898725\ttotal: 40.5s\tremaining: 46.8s\n",
            "464:\tlearn: 0.2898200\ttotal: 40.6s\tremaining: 46.7s\n",
            "465:\tlearn: 0.2897695\ttotal: 40.7s\tremaining: 46.6s\n",
            "466:\tlearn: 0.2897375\ttotal: 40.8s\tremaining: 46.5s\n",
            "467:\tlearn: 0.2896990\ttotal: 40.9s\tremaining: 46.5s\n",
            "468:\tlearn: 0.2896631\ttotal: 40.9s\tremaining: 46.3s\n",
            "469:\tlearn: 0.2896223\ttotal: 41s\tremaining: 46.2s\n",
            "470:\tlearn: 0.2895829\ttotal: 41s\tremaining: 46.1s\n",
            "471:\tlearn: 0.2895445\ttotal: 41s\tremaining: 45.9s\n",
            "472:\tlearn: 0.2894999\ttotal: 41.1s\tremaining: 45.8s\n",
            "473:\tlearn: 0.2894556\ttotal: 41.1s\tremaining: 45.6s\n",
            "474:\tlearn: 0.2894182\ttotal: 41.2s\tremaining: 45.6s\n",
            "475:\tlearn: 0.2893752\ttotal: 41.4s\tremaining: 45.6s\n",
            "476:\tlearn: 0.2893329\ttotal: 41.5s\tremaining: 45.5s\n",
            "477:\tlearn: 0.2892840\ttotal: 41.5s\tremaining: 45.4s\n",
            "478:\tlearn: 0.2892468\ttotal: 41.6s\tremaining: 45.3s\n",
            "479:\tlearn: 0.2892077\ttotal: 41.7s\tremaining: 45.2s\n",
            "480:\tlearn: 0.2891910\ttotal: 41.8s\tremaining: 45.1s\n",
            "481:\tlearn: 0.2891417\ttotal: 41.9s\tremaining: 45s\n",
            "482:\tlearn: 0.2891043\ttotal: 42s\tremaining: 44.9s\n",
            "483:\tlearn: 0.2890677\ttotal: 42s\tremaining: 44.8s\n",
            "484:\tlearn: 0.2890271\ttotal: 42.1s\tremaining: 44.7s\n",
            "485:\tlearn: 0.2889850\ttotal: 42.2s\tremaining: 44.6s\n",
            "486:\tlearn: 0.2889543\ttotal: 42.3s\tremaining: 44.5s\n",
            "487:\tlearn: 0.2889123\ttotal: 42.4s\tremaining: 44.5s\n",
            "488:\tlearn: 0.2888682\ttotal: 42.5s\tremaining: 44.4s\n",
            "489:\tlearn: 0.2888357\ttotal: 42.5s\tremaining: 44.2s\n",
            "490:\tlearn: 0.2887979\ttotal: 42.5s\tremaining: 44.1s\n",
            "491:\tlearn: 0.2887673\ttotal: 42.6s\tremaining: 44s\n",
            "492:\tlearn: 0.2887209\ttotal: 42.6s\tremaining: 43.8s\n",
            "493:\tlearn: 0.2886775\ttotal: 42.6s\tremaining: 43.7s\n",
            "494:\tlearn: 0.2886356\ttotal: 42.7s\tremaining: 43.5s\n",
            "495:\tlearn: 0.2886043\ttotal: 42.7s\tremaining: 43.4s\n",
            "496:\tlearn: 0.2885520\ttotal: 42.7s\tremaining: 43.2s\n",
            "497:\tlearn: 0.2885227\ttotal: 42.8s\tremaining: 43.1s\n",
            "498:\tlearn: 0.2884841\ttotal: 42.8s\tremaining: 43s\n",
            "499:\tlearn: 0.2884530\ttotal: 42.8s\tremaining: 42.8s\n",
            "500:\tlearn: 0.2884045\ttotal: 42.9s\tremaining: 42.7s\n",
            "501:\tlearn: 0.2883507\ttotal: 42.9s\tremaining: 42.6s\n",
            "502:\tlearn: 0.2883073\ttotal: 42.9s\tremaining: 42.4s\n",
            "503:\tlearn: 0.2882642\ttotal: 43s\tremaining: 42.3s\n",
            "504:\tlearn: 0.2882239\ttotal: 43s\tremaining: 42.1s\n",
            "505:\tlearn: 0.2881839\ttotal: 43s\tremaining: 42s\n",
            "506:\tlearn: 0.2881531\ttotal: 43.1s\tremaining: 41.9s\n",
            "507:\tlearn: 0.2881080\ttotal: 43.1s\tremaining: 41.7s\n",
            "508:\tlearn: 0.2880699\ttotal: 43.1s\tremaining: 41.6s\n",
            "509:\tlearn: 0.2880236\ttotal: 43.2s\tremaining: 41.5s\n",
            "510:\tlearn: 0.2879861\ttotal: 43.2s\tremaining: 41.3s\n",
            "511:\tlearn: 0.2879540\ttotal: 43.2s\tremaining: 41.2s\n",
            "512:\tlearn: 0.2879156\ttotal: 43.3s\tremaining: 41.1s\n",
            "513:\tlearn: 0.2878839\ttotal: 43.3s\tremaining: 40.9s\n",
            "514:\tlearn: 0.2878540\ttotal: 43.3s\tremaining: 40.8s\n",
            "515:\tlearn: 0.2878084\ttotal: 43.4s\tremaining: 40.7s\n",
            "516:\tlearn: 0.2877797\ttotal: 43.4s\tremaining: 40.5s\n",
            "517:\tlearn: 0.2877533\ttotal: 43.4s\tremaining: 40.4s\n",
            "518:\tlearn: 0.2877230\ttotal: 43.4s\tremaining: 40.3s\n",
            "519:\tlearn: 0.2876911\ttotal: 43.5s\tremaining: 40.1s\n",
            "520:\tlearn: 0.2876451\ttotal: 43.5s\tremaining: 40s\n",
            "521:\tlearn: 0.2876090\ttotal: 43.5s\tremaining: 39.9s\n",
            "522:\tlearn: 0.2875642\ttotal: 43.6s\tremaining: 39.7s\n",
            "523:\tlearn: 0.2875419\ttotal: 43.6s\tremaining: 39.6s\n",
            "524:\tlearn: 0.2875091\ttotal: 43.6s\tremaining: 39.5s\n",
            "525:\tlearn: 0.2874610\ttotal: 43.7s\tremaining: 39.3s\n",
            "526:\tlearn: 0.2874303\ttotal: 43.7s\tremaining: 39.2s\n",
            "527:\tlearn: 0.2873999\ttotal: 43.7s\tremaining: 39.1s\n",
            "528:\tlearn: 0.2873608\ttotal: 43.7s\tremaining: 39s\n",
            "529:\tlearn: 0.2873347\ttotal: 43.8s\tremaining: 38.8s\n",
            "530:\tlearn: 0.2872991\ttotal: 43.8s\tremaining: 38.7s\n",
            "531:\tlearn: 0.2872689\ttotal: 43.8s\tremaining: 38.6s\n",
            "532:\tlearn: 0.2872370\ttotal: 43.9s\tremaining: 38.5s\n",
            "533:\tlearn: 0.2872139\ttotal: 43.9s\tremaining: 38.3s\n",
            "534:\tlearn: 0.2871824\ttotal: 43.9s\tremaining: 38.2s\n",
            "535:\tlearn: 0.2871373\ttotal: 44s\tremaining: 38.1s\n",
            "536:\tlearn: 0.2870901\ttotal: 44s\tremaining: 38s\n",
            "537:\tlearn: 0.2870588\ttotal: 44.1s\tremaining: 37.8s\n",
            "538:\tlearn: 0.2870202\ttotal: 44.1s\tremaining: 37.7s\n",
            "539:\tlearn: 0.2869855\ttotal: 44.1s\tremaining: 37.6s\n",
            "540:\tlearn: 0.2869380\ttotal: 44.1s\tremaining: 37.5s\n",
            "541:\tlearn: 0.2868968\ttotal: 44.2s\tremaining: 37.3s\n",
            "542:\tlearn: 0.2868629\ttotal: 44.2s\tremaining: 37.2s\n",
            "543:\tlearn: 0.2868140\ttotal: 44.2s\tremaining: 37.1s\n",
            "544:\tlearn: 0.2867857\ttotal: 44.3s\tremaining: 37s\n",
            "545:\tlearn: 0.2867431\ttotal: 44.3s\tremaining: 36.8s\n",
            "546:\tlearn: 0.2867065\ttotal: 44.3s\tremaining: 36.7s\n",
            "547:\tlearn: 0.2866735\ttotal: 44.4s\tremaining: 36.6s\n",
            "548:\tlearn: 0.2866450\ttotal: 44.4s\tremaining: 36.5s\n",
            "549:\tlearn: 0.2866074\ttotal: 44.4s\tremaining: 36.4s\n",
            "550:\tlearn: 0.2865747\ttotal: 44.5s\tremaining: 36.2s\n",
            "551:\tlearn: 0.2865406\ttotal: 44.5s\tremaining: 36.1s\n",
            "552:\tlearn: 0.2865024\ttotal: 44.5s\tremaining: 36s\n",
            "553:\tlearn: 0.2864520\ttotal: 44.6s\tremaining: 35.9s\n",
            "554:\tlearn: 0.2864090\ttotal: 44.6s\tremaining: 35.7s\n",
            "555:\tlearn: 0.2863646\ttotal: 44.6s\tremaining: 35.6s\n",
            "556:\tlearn: 0.2863388\ttotal: 44.7s\tremaining: 35.5s\n",
            "557:\tlearn: 0.2863045\ttotal: 44.7s\tremaining: 35.4s\n",
            "558:\tlearn: 0.2862602\ttotal: 44.7s\tremaining: 35.3s\n",
            "559:\tlearn: 0.2862249\ttotal: 44.7s\tremaining: 35.2s\n",
            "560:\tlearn: 0.2861915\ttotal: 44.8s\tremaining: 35s\n",
            "561:\tlearn: 0.2861542\ttotal: 44.8s\tremaining: 34.9s\n",
            "562:\tlearn: 0.2861071\ttotal: 44.8s\tremaining: 34.8s\n",
            "563:\tlearn: 0.2860693\ttotal: 44.9s\tremaining: 34.7s\n",
            "564:\tlearn: 0.2860264\ttotal: 44.9s\tremaining: 34.6s\n",
            "565:\tlearn: 0.2859962\ttotal: 45s\tremaining: 34.5s\n",
            "566:\tlearn: 0.2859737\ttotal: 45s\tremaining: 34.4s\n",
            "567:\tlearn: 0.2859260\ttotal: 45s\tremaining: 34.2s\n",
            "568:\tlearn: 0.2858842\ttotal: 45s\tremaining: 34.1s\n",
            "569:\tlearn: 0.2858426\ttotal: 45.1s\tremaining: 34s\n",
            "570:\tlearn: 0.2858154\ttotal: 45.1s\tremaining: 33.9s\n",
            "571:\tlearn: 0.2857782\ttotal: 45.2s\tremaining: 33.8s\n",
            "572:\tlearn: 0.2857466\ttotal: 45.2s\tremaining: 33.7s\n",
            "573:\tlearn: 0.2857167\ttotal: 45.2s\tremaining: 33.6s\n",
            "574:\tlearn: 0.2856681\ttotal: 45.2s\tremaining: 33.4s\n",
            "575:\tlearn: 0.2856363\ttotal: 45.3s\tremaining: 33.3s\n",
            "576:\tlearn: 0.2856073\ttotal: 45.3s\tremaining: 33.2s\n",
            "577:\tlearn: 0.2855745\ttotal: 45.3s\tremaining: 33.1s\n",
            "578:\tlearn: 0.2855346\ttotal: 45.4s\tremaining: 33s\n",
            "579:\tlearn: 0.2855039\ttotal: 45.4s\tremaining: 32.9s\n",
            "580:\tlearn: 0.2854493\ttotal: 45.4s\tremaining: 32.8s\n",
            "581:\tlearn: 0.2854015\ttotal: 45.5s\tremaining: 32.7s\n",
            "582:\tlearn: 0.2853557\ttotal: 45.5s\tremaining: 32.5s\n",
            "583:\tlearn: 0.2853167\ttotal: 45.5s\tremaining: 32.4s\n",
            "584:\tlearn: 0.2852830\ttotal: 45.6s\tremaining: 32.3s\n",
            "585:\tlearn: 0.2852444\ttotal: 45.6s\tremaining: 32.2s\n",
            "586:\tlearn: 0.2852157\ttotal: 45.6s\tremaining: 32.1s\n",
            "587:\tlearn: 0.2851679\ttotal: 45.7s\tremaining: 32s\n",
            "588:\tlearn: 0.2851221\ttotal: 45.7s\tremaining: 31.9s\n",
            "589:\tlearn: 0.2850787\ttotal: 45.7s\tremaining: 31.8s\n",
            "590:\tlearn: 0.2850343\ttotal: 45.8s\tremaining: 31.7s\n",
            "591:\tlearn: 0.2850072\ttotal: 45.8s\tremaining: 31.6s\n",
            "592:\tlearn: 0.2849711\ttotal: 45.8s\tremaining: 31.4s\n",
            "593:\tlearn: 0.2849315\ttotal: 45.8s\tremaining: 31.3s\n",
            "594:\tlearn: 0.2849005\ttotal: 45.9s\tremaining: 31.2s\n",
            "595:\tlearn: 0.2848588\ttotal: 45.9s\tremaining: 31.1s\n",
            "596:\tlearn: 0.2848327\ttotal: 46s\tremaining: 31s\n",
            "597:\tlearn: 0.2847888\ttotal: 46s\tremaining: 30.9s\n",
            "598:\tlearn: 0.2847494\ttotal: 46s\tremaining: 30.8s\n",
            "599:\tlearn: 0.2847140\ttotal: 46.1s\tremaining: 30.7s\n",
            "600:\tlearn: 0.2846819\ttotal: 46.1s\tremaining: 30.6s\n",
            "601:\tlearn: 0.2846403\ttotal: 46.1s\tremaining: 30.5s\n",
            "602:\tlearn: 0.2845830\ttotal: 46.1s\tremaining: 30.4s\n",
            "603:\tlearn: 0.2845508\ttotal: 46.2s\tremaining: 30.3s\n",
            "604:\tlearn: 0.2845111\ttotal: 46.2s\tremaining: 30.2s\n",
            "605:\tlearn: 0.2844640\ttotal: 46.2s\tremaining: 30.1s\n",
            "606:\tlearn: 0.2844186\ttotal: 46.3s\tremaining: 30s\n",
            "607:\tlearn: 0.2843695\ttotal: 46.3s\tremaining: 29.9s\n",
            "608:\tlearn: 0.2843174\ttotal: 46.3s\tremaining: 29.8s\n",
            "609:\tlearn: 0.2842791\ttotal: 46.4s\tremaining: 29.6s\n",
            "610:\tlearn: 0.2842431\ttotal: 46.4s\tremaining: 29.5s\n",
            "611:\tlearn: 0.2842211\ttotal: 46.4s\tremaining: 29.4s\n",
            "612:\tlearn: 0.2841790\ttotal: 46.5s\tremaining: 29.3s\n",
            "613:\tlearn: 0.2841337\ttotal: 46.5s\tremaining: 29.2s\n",
            "614:\tlearn: 0.2840804\ttotal: 46.5s\tremaining: 29.1s\n",
            "615:\tlearn: 0.2840522\ttotal: 46.6s\tremaining: 29s\n",
            "616:\tlearn: 0.2840138\ttotal: 46.6s\tremaining: 28.9s\n",
            "617:\tlearn: 0.2839826\ttotal: 46.6s\tremaining: 28.8s\n",
            "618:\tlearn: 0.2839324\ttotal: 46.7s\tremaining: 28.7s\n",
            "619:\tlearn: 0.2839018\ttotal: 46.7s\tremaining: 28.6s\n",
            "620:\tlearn: 0.2838745\ttotal: 46.7s\tremaining: 28.5s\n",
            "621:\tlearn: 0.2838317\ttotal: 46.8s\tremaining: 28.4s\n",
            "622:\tlearn: 0.2838081\ttotal: 46.8s\tremaining: 28.3s\n",
            "623:\tlearn: 0.2837753\ttotal: 46.8s\tremaining: 28.2s\n",
            "624:\tlearn: 0.2837492\ttotal: 46.8s\tremaining: 28.1s\n",
            "625:\tlearn: 0.2837158\ttotal: 46.9s\tremaining: 28s\n",
            "626:\tlearn: 0.2836731\ttotal: 46.9s\tremaining: 27.9s\n",
            "627:\tlearn: 0.2836392\ttotal: 47s\tremaining: 27.8s\n",
            "628:\tlearn: 0.2836087\ttotal: 47s\tremaining: 27.7s\n",
            "629:\tlearn: 0.2835816\ttotal: 47s\tremaining: 27.6s\n",
            "630:\tlearn: 0.2835452\ttotal: 47.1s\tremaining: 27.5s\n",
            "631:\tlearn: 0.2835126\ttotal: 47.1s\tremaining: 27.4s\n",
            "632:\tlearn: 0.2834783\ttotal: 47.1s\tremaining: 27.3s\n",
            "633:\tlearn: 0.2834442\ttotal: 47.2s\tremaining: 27.2s\n",
            "634:\tlearn: 0.2834108\ttotal: 47.2s\tremaining: 27.1s\n",
            "635:\tlearn: 0.2833765\ttotal: 47.2s\tremaining: 27s\n",
            "636:\tlearn: 0.2833501\ttotal: 47.3s\tremaining: 26.9s\n",
            "637:\tlearn: 0.2833211\ttotal: 47.3s\tremaining: 26.8s\n",
            "638:\tlearn: 0.2832908\ttotal: 47.3s\tremaining: 26.7s\n",
            "639:\tlearn: 0.2832499\ttotal: 47.3s\tremaining: 26.6s\n",
            "640:\tlearn: 0.2832037\ttotal: 47.4s\tremaining: 26.5s\n",
            "641:\tlearn: 0.2831698\ttotal: 47.4s\tremaining: 26.4s\n",
            "642:\tlearn: 0.2831295\ttotal: 47.4s\tremaining: 26.3s\n",
            "643:\tlearn: 0.2831028\ttotal: 47.5s\tremaining: 26.2s\n",
            "644:\tlearn: 0.2830477\ttotal: 47.5s\tremaining: 26.2s\n",
            "645:\tlearn: 0.2830134\ttotal: 47.6s\tremaining: 26.1s\n",
            "646:\tlearn: 0.2829730\ttotal: 47.7s\tremaining: 26s\n",
            "647:\tlearn: 0.2829259\ttotal: 47.7s\tremaining: 25.9s\n",
            "648:\tlearn: 0.2828826\ttotal: 47.8s\tremaining: 25.9s\n",
            "649:\tlearn: 0.2828414\ttotal: 47.9s\tremaining: 25.8s\n",
            "650:\tlearn: 0.2828139\ttotal: 47.9s\tremaining: 25.7s\n",
            "651:\tlearn: 0.2827618\ttotal: 48s\tremaining: 25.6s\n",
            "652:\tlearn: 0.2827154\ttotal: 48s\tremaining: 25.5s\n",
            "653:\tlearn: 0.2826864\ttotal: 48.1s\tremaining: 25.4s\n",
            "654:\tlearn: 0.2826522\ttotal: 48.1s\tremaining: 25.4s\n",
            "655:\tlearn: 0.2826160\ttotal: 48.2s\tremaining: 25.3s\n",
            "656:\tlearn: 0.2825727\ttotal: 48.3s\tremaining: 25.2s\n",
            "657:\tlearn: 0.2825374\ttotal: 48.4s\tremaining: 25.1s\n",
            "658:\tlearn: 0.2824970\ttotal: 48.4s\tremaining: 25.1s\n",
            "659:\tlearn: 0.2824751\ttotal: 48.5s\tremaining: 25s\n",
            "660:\tlearn: 0.2824317\ttotal: 48.6s\tremaining: 24.9s\n",
            "661:\tlearn: 0.2824043\ttotal: 48.7s\tremaining: 24.8s\n",
            "662:\tlearn: 0.2823653\ttotal: 48.7s\tremaining: 24.8s\n",
            "663:\tlearn: 0.2823249\ttotal: 48.8s\tremaining: 24.7s\n",
            "664:\tlearn: 0.2823022\ttotal: 48.9s\tremaining: 24.6s\n",
            "665:\tlearn: 0.2822592\ttotal: 49s\tremaining: 24.6s\n",
            "666:\tlearn: 0.2822321\ttotal: 49s\tremaining: 24.5s\n",
            "667:\tlearn: 0.2821865\ttotal: 49.1s\tremaining: 24.4s\n",
            "668:\tlearn: 0.2821597\ttotal: 49.2s\tremaining: 24.3s\n",
            "669:\tlearn: 0.2821202\ttotal: 49.3s\tremaining: 24.3s\n",
            "670:\tlearn: 0.2820866\ttotal: 49.3s\tremaining: 24.2s\n",
            "671:\tlearn: 0.2820490\ttotal: 49.4s\tremaining: 24.1s\n",
            "672:\tlearn: 0.2820133\ttotal: 49.5s\tremaining: 24s\n",
            "673:\tlearn: 0.2819763\ttotal: 49.5s\tremaining: 24s\n",
            "674:\tlearn: 0.2819458\ttotal: 49.6s\tremaining: 23.9s\n",
            "675:\tlearn: 0.2819170\ttotal: 49.7s\tremaining: 23.8s\n",
            "676:\tlearn: 0.2818860\ttotal: 49.8s\tremaining: 23.7s\n",
            "677:\tlearn: 0.2818551\ttotal: 49.8s\tremaining: 23.7s\n",
            "678:\tlearn: 0.2818103\ttotal: 49.9s\tremaining: 23.6s\n",
            "679:\tlearn: 0.2817672\ttotal: 50s\tremaining: 23.5s\n",
            "680:\tlearn: 0.2817423\ttotal: 50.1s\tremaining: 23.5s\n",
            "681:\tlearn: 0.2817056\ttotal: 50.2s\tremaining: 23.4s\n",
            "682:\tlearn: 0.2816720\ttotal: 50.2s\tremaining: 23.3s\n",
            "683:\tlearn: 0.2816390\ttotal: 50.3s\tremaining: 23.2s\n",
            "684:\tlearn: 0.2815967\ttotal: 50.3s\tremaining: 23.1s\n",
            "685:\tlearn: 0.2815621\ttotal: 50.3s\tremaining: 23s\n",
            "686:\tlearn: 0.2815316\ttotal: 50.4s\tremaining: 22.9s\n",
            "687:\tlearn: 0.2815018\ttotal: 50.4s\tremaining: 22.8s\n",
            "688:\tlearn: 0.2814650\ttotal: 50.4s\tremaining: 22.8s\n",
            "689:\tlearn: 0.2814198\ttotal: 50.4s\tremaining: 22.7s\n",
            "690:\tlearn: 0.2813815\ttotal: 50.5s\tremaining: 22.6s\n",
            "691:\tlearn: 0.2813312\ttotal: 50.5s\tremaining: 22.5s\n",
            "692:\tlearn: 0.2813001\ttotal: 50.5s\tremaining: 22.4s\n",
            "693:\tlearn: 0.2812707\ttotal: 50.6s\tremaining: 22.3s\n",
            "694:\tlearn: 0.2812415\ttotal: 50.6s\tremaining: 22.2s\n",
            "695:\tlearn: 0.2811986\ttotal: 50.6s\tremaining: 22.1s\n",
            "696:\tlearn: 0.2811753\ttotal: 50.7s\tremaining: 22s\n",
            "697:\tlearn: 0.2811411\ttotal: 50.7s\tremaining: 21.9s\n",
            "698:\tlearn: 0.2811054\ttotal: 50.7s\tremaining: 21.8s\n",
            "699:\tlearn: 0.2810741\ttotal: 50.8s\tremaining: 21.8s\n",
            "700:\tlearn: 0.2810503\ttotal: 50.8s\tremaining: 21.7s\n",
            "701:\tlearn: 0.2810160\ttotal: 50.8s\tremaining: 21.6s\n",
            "702:\tlearn: 0.2809808\ttotal: 50.8s\tremaining: 21.5s\n",
            "703:\tlearn: 0.2809539\ttotal: 50.9s\tremaining: 21.4s\n",
            "704:\tlearn: 0.2809171\ttotal: 50.9s\tremaining: 21.3s\n",
            "705:\tlearn: 0.2808943\ttotal: 50.9s\tremaining: 21.2s\n",
            "706:\tlearn: 0.2808657\ttotal: 51s\tremaining: 21.1s\n",
            "707:\tlearn: 0.2808308\ttotal: 51s\tremaining: 21s\n",
            "708:\tlearn: 0.2808015\ttotal: 51s\tremaining: 20.9s\n",
            "709:\tlearn: 0.2807634\ttotal: 51.1s\tremaining: 20.9s\n",
            "710:\tlearn: 0.2807345\ttotal: 51.1s\tremaining: 20.8s\n",
            "711:\tlearn: 0.2806983\ttotal: 51.1s\tremaining: 20.7s\n",
            "712:\tlearn: 0.2806685\ttotal: 51.2s\tremaining: 20.6s\n",
            "713:\tlearn: 0.2806266\ttotal: 51.2s\tremaining: 20.5s\n",
            "714:\tlearn: 0.2806006\ttotal: 51.2s\tremaining: 20.4s\n",
            "715:\tlearn: 0.2805744\ttotal: 51.3s\tremaining: 20.3s\n",
            "716:\tlearn: 0.2805441\ttotal: 51.3s\tremaining: 20.2s\n",
            "717:\tlearn: 0.2805210\ttotal: 51.3s\tremaining: 20.2s\n",
            "718:\tlearn: 0.2804772\ttotal: 51.4s\tremaining: 20.1s\n",
            "719:\tlearn: 0.2804221\ttotal: 51.4s\tremaining: 20s\n",
            "720:\tlearn: 0.2803996\ttotal: 51.4s\tremaining: 19.9s\n",
            "721:\tlearn: 0.2803672\ttotal: 51.4s\tremaining: 19.8s\n",
            "722:\tlearn: 0.2803355\ttotal: 51.5s\tremaining: 19.7s\n",
            "723:\tlearn: 0.2802932\ttotal: 51.5s\tremaining: 19.6s\n",
            "724:\tlearn: 0.2802640\ttotal: 51.5s\tremaining: 19.5s\n",
            "725:\tlearn: 0.2802346\ttotal: 51.6s\tremaining: 19.5s\n",
            "726:\tlearn: 0.2801995\ttotal: 51.6s\tremaining: 19.4s\n",
            "727:\tlearn: 0.2801664\ttotal: 51.6s\tremaining: 19.3s\n",
            "728:\tlearn: 0.2801381\ttotal: 51.7s\tremaining: 19.2s\n",
            "729:\tlearn: 0.2800975\ttotal: 51.7s\tremaining: 19.1s\n",
            "730:\tlearn: 0.2800545\ttotal: 51.7s\tremaining: 19s\n",
            "731:\tlearn: 0.2800282\ttotal: 51.8s\tremaining: 19s\n",
            "732:\tlearn: 0.2799878\ttotal: 51.8s\tremaining: 18.9s\n",
            "733:\tlearn: 0.2799544\ttotal: 51.8s\tremaining: 18.8s\n",
            "734:\tlearn: 0.2799268\ttotal: 51.9s\tremaining: 18.7s\n",
            "735:\tlearn: 0.2798908\ttotal: 51.9s\tremaining: 18.6s\n",
            "736:\tlearn: 0.2798394\ttotal: 51.9s\tremaining: 18.5s\n",
            "737:\tlearn: 0.2798005\ttotal: 52s\tremaining: 18.4s\n",
            "738:\tlearn: 0.2797770\ttotal: 52s\tremaining: 18.4s\n",
            "739:\tlearn: 0.2797302\ttotal: 52s\tremaining: 18.3s\n",
            "740:\tlearn: 0.2796821\ttotal: 52s\tremaining: 18.2s\n",
            "741:\tlearn: 0.2796457\ttotal: 52.1s\tremaining: 18.1s\n",
            "742:\tlearn: 0.2796178\ttotal: 52.1s\tremaining: 18s\n",
            "743:\tlearn: 0.2795879\ttotal: 52.2s\tremaining: 17.9s\n",
            "744:\tlearn: 0.2795612\ttotal: 52.2s\tremaining: 17.9s\n",
            "745:\tlearn: 0.2795118\ttotal: 52.2s\tremaining: 17.8s\n",
            "746:\tlearn: 0.2794572\ttotal: 52.2s\tremaining: 17.7s\n",
            "747:\tlearn: 0.2794319\ttotal: 52.3s\tremaining: 17.6s\n",
            "748:\tlearn: 0.2793874\ttotal: 52.3s\tremaining: 17.5s\n",
            "749:\tlearn: 0.2793461\ttotal: 52.3s\tremaining: 17.4s\n",
            "750:\tlearn: 0.2793064\ttotal: 52.4s\tremaining: 17.4s\n",
            "751:\tlearn: 0.2792798\ttotal: 52.4s\tremaining: 17.3s\n",
            "752:\tlearn: 0.2792572\ttotal: 52.4s\tremaining: 17.2s\n",
            "753:\tlearn: 0.2792174\ttotal: 52.5s\tremaining: 17.1s\n",
            "754:\tlearn: 0.2791992\ttotal: 52.5s\tremaining: 17s\n",
            "755:\tlearn: 0.2791657\ttotal: 52.5s\tremaining: 17s\n",
            "756:\tlearn: 0.2791191\ttotal: 52.6s\tremaining: 16.9s\n",
            "757:\tlearn: 0.2790827\ttotal: 52.6s\tremaining: 16.8s\n",
            "758:\tlearn: 0.2790508\ttotal: 52.6s\tremaining: 16.7s\n",
            "759:\tlearn: 0.2790052\ttotal: 52.6s\tremaining: 16.6s\n",
            "760:\tlearn: 0.2789735\ttotal: 52.7s\tremaining: 16.5s\n",
            "761:\tlearn: 0.2789384\ttotal: 52.7s\tremaining: 16.5s\n",
            "762:\tlearn: 0.2788973\ttotal: 52.7s\tremaining: 16.4s\n",
            "763:\tlearn: 0.2788663\ttotal: 52.8s\tremaining: 16.3s\n",
            "764:\tlearn: 0.2788401\ttotal: 52.8s\tremaining: 16.2s\n",
            "765:\tlearn: 0.2788063\ttotal: 52.8s\tremaining: 16.1s\n",
            "766:\tlearn: 0.2787722\ttotal: 52.9s\tremaining: 16.1s\n",
            "767:\tlearn: 0.2787328\ttotal: 52.9s\tremaining: 16s\n",
            "768:\tlearn: 0.2787137\ttotal: 52.9s\tremaining: 15.9s\n",
            "769:\tlearn: 0.2786705\ttotal: 53s\tremaining: 15.8s\n",
            "770:\tlearn: 0.2786374\ttotal: 53s\tremaining: 15.7s\n",
            "771:\tlearn: 0.2785985\ttotal: 53s\tremaining: 15.7s\n",
            "772:\tlearn: 0.2785632\ttotal: 53.1s\tremaining: 15.6s\n",
            "773:\tlearn: 0.2785296\ttotal: 53.1s\tremaining: 15.5s\n",
            "774:\tlearn: 0.2785010\ttotal: 53.1s\tremaining: 15.4s\n",
            "775:\tlearn: 0.2784722\ttotal: 53.2s\tremaining: 15.3s\n",
            "776:\tlearn: 0.2784383\ttotal: 53.2s\tremaining: 15.3s\n",
            "777:\tlearn: 0.2784061\ttotal: 53.2s\tremaining: 15.2s\n",
            "778:\tlearn: 0.2783753\ttotal: 53.3s\tremaining: 15.1s\n",
            "779:\tlearn: 0.2783220\ttotal: 53.3s\tremaining: 15s\n",
            "780:\tlearn: 0.2782815\ttotal: 53.3s\tremaining: 15s\n",
            "781:\tlearn: 0.2782514\ttotal: 53.4s\tremaining: 14.9s\n",
            "782:\tlearn: 0.2782196\ttotal: 53.4s\tremaining: 14.8s\n",
            "783:\tlearn: 0.2781768\ttotal: 53.4s\tremaining: 14.7s\n",
            "784:\tlearn: 0.2781459\ttotal: 53.5s\tremaining: 14.6s\n",
            "785:\tlearn: 0.2781203\ttotal: 53.5s\tremaining: 14.6s\n",
            "786:\tlearn: 0.2780847\ttotal: 53.5s\tremaining: 14.5s\n",
            "787:\tlearn: 0.2780477\ttotal: 53.6s\tremaining: 14.4s\n",
            "788:\tlearn: 0.2780220\ttotal: 53.6s\tremaining: 14.3s\n",
            "789:\tlearn: 0.2779944\ttotal: 53.6s\tremaining: 14.3s\n",
            "790:\tlearn: 0.2779482\ttotal: 53.7s\tremaining: 14.2s\n",
            "791:\tlearn: 0.2779083\ttotal: 53.7s\tremaining: 14.1s\n",
            "792:\tlearn: 0.2778809\ttotal: 53.7s\tremaining: 14s\n",
            "793:\tlearn: 0.2778511\ttotal: 53.8s\tremaining: 13.9s\n",
            "794:\tlearn: 0.2778137\ttotal: 53.8s\tremaining: 13.9s\n",
            "795:\tlearn: 0.2777589\ttotal: 53.8s\tremaining: 13.8s\n",
            "796:\tlearn: 0.2777263\ttotal: 53.9s\tremaining: 13.7s\n",
            "797:\tlearn: 0.2776839\ttotal: 53.9s\tremaining: 13.6s\n",
            "798:\tlearn: 0.2776474\ttotal: 53.9s\tremaining: 13.6s\n",
            "799:\tlearn: 0.2776157\ttotal: 54s\tremaining: 13.5s\n",
            "800:\tlearn: 0.2775944\ttotal: 54s\tremaining: 13.4s\n",
            "801:\tlearn: 0.2775595\ttotal: 54s\tremaining: 13.3s\n",
            "802:\tlearn: 0.2775266\ttotal: 54s\tremaining: 13.3s\n",
            "803:\tlearn: 0.2774834\ttotal: 54.1s\tremaining: 13.2s\n",
            "804:\tlearn: 0.2774485\ttotal: 54.1s\tremaining: 13.1s\n",
            "805:\tlearn: 0.2774089\ttotal: 54.2s\tremaining: 13s\n",
            "806:\tlearn: 0.2773867\ttotal: 54.2s\tremaining: 13s\n",
            "807:\tlearn: 0.2773416\ttotal: 54.2s\tremaining: 12.9s\n",
            "808:\tlearn: 0.2773034\ttotal: 54.2s\tremaining: 12.8s\n",
            "809:\tlearn: 0.2772666\ttotal: 54.3s\tremaining: 12.7s\n",
            "810:\tlearn: 0.2772342\ttotal: 54.3s\tremaining: 12.7s\n",
            "811:\tlearn: 0.2772037\ttotal: 54.3s\tremaining: 12.6s\n",
            "812:\tlearn: 0.2771792\ttotal: 54.4s\tremaining: 12.5s\n",
            "813:\tlearn: 0.2771484\ttotal: 54.4s\tremaining: 12.4s\n",
            "814:\tlearn: 0.2771182\ttotal: 54.4s\tremaining: 12.4s\n",
            "815:\tlearn: 0.2770914\ttotal: 54.5s\tremaining: 12.3s\n",
            "816:\tlearn: 0.2770503\ttotal: 54.5s\tremaining: 12.2s\n",
            "817:\tlearn: 0.2770131\ttotal: 54.5s\tremaining: 12.1s\n",
            "818:\tlearn: 0.2769873\ttotal: 54.6s\tremaining: 12.1s\n",
            "819:\tlearn: 0.2769468\ttotal: 54.6s\tremaining: 12s\n",
            "820:\tlearn: 0.2769151\ttotal: 54.6s\tremaining: 11.9s\n",
            "821:\tlearn: 0.2768837\ttotal: 54.7s\tremaining: 11.8s\n",
            "822:\tlearn: 0.2768562\ttotal: 54.7s\tremaining: 11.8s\n",
            "823:\tlearn: 0.2768151\ttotal: 54.7s\tremaining: 11.7s\n",
            "824:\tlearn: 0.2767878\ttotal: 54.7s\tremaining: 11.6s\n",
            "825:\tlearn: 0.2767663\ttotal: 54.8s\tremaining: 11.5s\n",
            "826:\tlearn: 0.2767318\ttotal: 54.8s\tremaining: 11.5s\n",
            "827:\tlearn: 0.2766949\ttotal: 54.8s\tremaining: 11.4s\n",
            "828:\tlearn: 0.2766715\ttotal: 54.9s\tremaining: 11.3s\n",
            "829:\tlearn: 0.2766466\ttotal: 54.9s\tremaining: 11.2s\n",
            "830:\tlearn: 0.2766040\ttotal: 54.9s\tremaining: 11.2s\n",
            "831:\tlearn: 0.2765671\ttotal: 55s\tremaining: 11.1s\n",
            "832:\tlearn: 0.2765438\ttotal: 55s\tremaining: 11s\n",
            "833:\tlearn: 0.2765207\ttotal: 55s\tremaining: 11s\n",
            "834:\tlearn: 0.2764937\ttotal: 55.1s\tremaining: 10.9s\n",
            "835:\tlearn: 0.2764526\ttotal: 55.1s\tremaining: 10.8s\n",
            "836:\tlearn: 0.2764212\ttotal: 55.1s\tremaining: 10.7s\n",
            "837:\tlearn: 0.2763845\ttotal: 55.2s\tremaining: 10.7s\n",
            "838:\tlearn: 0.2763488\ttotal: 55.2s\tremaining: 10.6s\n",
            "839:\tlearn: 0.2763205\ttotal: 55.2s\tremaining: 10.5s\n",
            "840:\tlearn: 0.2762898\ttotal: 55.3s\tremaining: 10.4s\n",
            "841:\tlearn: 0.2762631\ttotal: 55.3s\tremaining: 10.4s\n",
            "842:\tlearn: 0.2762343\ttotal: 55.3s\tremaining: 10.3s\n",
            "843:\tlearn: 0.2761976\ttotal: 55.4s\tremaining: 10.2s\n",
            "844:\tlearn: 0.2761578\ttotal: 55.4s\tremaining: 10.2s\n",
            "845:\tlearn: 0.2761314\ttotal: 55.4s\tremaining: 10.1s\n",
            "846:\tlearn: 0.2760930\ttotal: 55.5s\tremaining: 10s\n",
            "847:\tlearn: 0.2760650\ttotal: 55.5s\tremaining: 9.94s\n",
            "848:\tlearn: 0.2760368\ttotal: 55.5s\tremaining: 9.87s\n",
            "849:\tlearn: 0.2760012\ttotal: 55.5s\tremaining: 9.8s\n",
            "850:\tlearn: 0.2759738\ttotal: 55.6s\tremaining: 9.73s\n",
            "851:\tlearn: 0.2759404\ttotal: 55.6s\tremaining: 9.66s\n",
            "852:\tlearn: 0.2758985\ttotal: 55.6s\tremaining: 9.59s\n",
            "853:\tlearn: 0.2758694\ttotal: 55.7s\tremaining: 9.52s\n",
            "854:\tlearn: 0.2758352\ttotal: 55.7s\tremaining: 9.45s\n",
            "855:\tlearn: 0.2757947\ttotal: 55.7s\tremaining: 9.38s\n",
            "856:\tlearn: 0.2757695\ttotal: 55.8s\tremaining: 9.3s\n",
            "857:\tlearn: 0.2757317\ttotal: 55.8s\tremaining: 9.23s\n",
            "858:\tlearn: 0.2757029\ttotal: 55.8s\tremaining: 9.16s\n",
            "859:\tlearn: 0.2756902\ttotal: 55.9s\tremaining: 9.09s\n",
            "860:\tlearn: 0.2756656\ttotal: 55.9s\tremaining: 9.02s\n",
            "861:\tlearn: 0.2756402\ttotal: 55.9s\tremaining: 8.95s\n",
            "862:\tlearn: 0.2756043\ttotal: 55.9s\tremaining: 8.88s\n",
            "863:\tlearn: 0.2755757\ttotal: 56s\tremaining: 8.81s\n",
            "864:\tlearn: 0.2755493\ttotal: 56s\tremaining: 8.74s\n",
            "865:\tlearn: 0.2755172\ttotal: 56s\tremaining: 8.67s\n",
            "866:\tlearn: 0.2754880\ttotal: 56.1s\tremaining: 8.6s\n",
            "867:\tlearn: 0.2754587\ttotal: 56.1s\tremaining: 8.53s\n",
            "868:\tlearn: 0.2754231\ttotal: 56.2s\tremaining: 8.46s\n",
            "869:\tlearn: 0.2753976\ttotal: 56.2s\tremaining: 8.39s\n",
            "870:\tlearn: 0.2753644\ttotal: 56.2s\tremaining: 8.33s\n",
            "871:\tlearn: 0.2753343\ttotal: 56.2s\tremaining: 8.26s\n",
            "872:\tlearn: 0.2752940\ttotal: 56.3s\tremaining: 8.19s\n",
            "873:\tlearn: 0.2752673\ttotal: 56.3s\tremaining: 8.12s\n",
            "874:\tlearn: 0.2752271\ttotal: 56.3s\tremaining: 8.05s\n",
            "875:\tlearn: 0.2751884\ttotal: 56.4s\tremaining: 7.98s\n",
            "876:\tlearn: 0.2751475\ttotal: 56.4s\tremaining: 7.91s\n",
            "877:\tlearn: 0.2751185\ttotal: 56.4s\tremaining: 7.84s\n",
            "878:\tlearn: 0.2750870\ttotal: 56.5s\tremaining: 7.77s\n",
            "879:\tlearn: 0.2750576\ttotal: 56.5s\tremaining: 7.71s\n",
            "880:\tlearn: 0.2750319\ttotal: 56.5s\tremaining: 7.64s\n",
            "881:\tlearn: 0.2749924\ttotal: 56.6s\tremaining: 7.57s\n",
            "882:\tlearn: 0.2749648\ttotal: 56.6s\tremaining: 7.5s\n",
            "883:\tlearn: 0.2749299\ttotal: 56.6s\tremaining: 7.43s\n",
            "884:\tlearn: 0.2749049\ttotal: 56.7s\tremaining: 7.36s\n",
            "885:\tlearn: 0.2748708\ttotal: 56.7s\tremaining: 7.29s\n",
            "886:\tlearn: 0.2748392\ttotal: 56.7s\tremaining: 7.22s\n",
            "887:\tlearn: 0.2748141\ttotal: 56.8s\tremaining: 7.16s\n",
            "888:\tlearn: 0.2747847\ttotal: 56.8s\tremaining: 7.09s\n",
            "889:\tlearn: 0.2747465\ttotal: 56.8s\tremaining: 7.02s\n",
            "890:\tlearn: 0.2747298\ttotal: 56.8s\tremaining: 6.95s\n",
            "891:\tlearn: 0.2746756\ttotal: 56.9s\tremaining: 6.89s\n",
            "892:\tlearn: 0.2746397\ttotal: 56.9s\tremaining: 6.82s\n",
            "893:\tlearn: 0.2746094\ttotal: 56.9s\tremaining: 6.75s\n",
            "894:\tlearn: 0.2745756\ttotal: 57s\tremaining: 6.68s\n",
            "895:\tlearn: 0.2745360\ttotal: 57s\tremaining: 6.62s\n",
            "896:\tlearn: 0.2745001\ttotal: 57s\tremaining: 6.55s\n",
            "897:\tlearn: 0.2744624\ttotal: 57.1s\tremaining: 6.48s\n",
            "898:\tlearn: 0.2744329\ttotal: 57.1s\tremaining: 6.41s\n",
            "899:\tlearn: 0.2744029\ttotal: 57.1s\tremaining: 6.35s\n",
            "900:\tlearn: 0.2743688\ttotal: 57.2s\tremaining: 6.28s\n",
            "901:\tlearn: 0.2743386\ttotal: 57.2s\tremaining: 6.21s\n",
            "902:\tlearn: 0.2743059\ttotal: 57.2s\tremaining: 6.15s\n",
            "903:\tlearn: 0.2742627\ttotal: 57.3s\tremaining: 6.08s\n",
            "904:\tlearn: 0.2742301\ttotal: 57.3s\tremaining: 6.01s\n",
            "905:\tlearn: 0.2741993\ttotal: 57.3s\tremaining: 5.95s\n",
            "906:\tlearn: 0.2741604\ttotal: 57.4s\tremaining: 5.88s\n",
            "907:\tlearn: 0.2741267\ttotal: 57.4s\tremaining: 5.82s\n",
            "908:\tlearn: 0.2741070\ttotal: 57.4s\tremaining: 5.75s\n",
            "909:\tlearn: 0.2740722\ttotal: 57.5s\tremaining: 5.68s\n",
            "910:\tlearn: 0.2740406\ttotal: 57.5s\tremaining: 5.62s\n",
            "911:\tlearn: 0.2740084\ttotal: 57.5s\tremaining: 5.55s\n",
            "912:\tlearn: 0.2739827\ttotal: 57.6s\tremaining: 5.48s\n",
            "913:\tlearn: 0.2739489\ttotal: 57.6s\tremaining: 5.42s\n",
            "914:\tlearn: 0.2739156\ttotal: 57.6s\tremaining: 5.35s\n",
            "915:\tlearn: 0.2738833\ttotal: 57.7s\tremaining: 5.29s\n",
            "916:\tlearn: 0.2738463\ttotal: 57.7s\tremaining: 5.22s\n",
            "917:\tlearn: 0.2738019\ttotal: 57.7s\tremaining: 5.16s\n",
            "918:\tlearn: 0.2737648\ttotal: 57.8s\tremaining: 5.09s\n",
            "919:\tlearn: 0.2737319\ttotal: 57.8s\tremaining: 5.02s\n",
            "920:\tlearn: 0.2736961\ttotal: 57.8s\tremaining: 4.96s\n",
            "921:\tlearn: 0.2736645\ttotal: 57.9s\tremaining: 4.89s\n",
            "922:\tlearn: 0.2736361\ttotal: 57.9s\tremaining: 4.83s\n",
            "923:\tlearn: 0.2735956\ttotal: 57.9s\tremaining: 4.76s\n",
            "924:\tlearn: 0.2735564\ttotal: 57.9s\tremaining: 4.7s\n",
            "925:\tlearn: 0.2735220\ttotal: 58s\tremaining: 4.63s\n",
            "926:\tlearn: 0.2734974\ttotal: 58s\tremaining: 4.57s\n",
            "927:\tlearn: 0.2734648\ttotal: 58s\tremaining: 4.5s\n",
            "928:\tlearn: 0.2734270\ttotal: 58.1s\tremaining: 4.44s\n",
            "929:\tlearn: 0.2733897\ttotal: 58.1s\tremaining: 4.37s\n",
            "930:\tlearn: 0.2733547\ttotal: 58.1s\tremaining: 4.31s\n",
            "931:\tlearn: 0.2733268\ttotal: 58.2s\tremaining: 4.24s\n",
            "932:\tlearn: 0.2732966\ttotal: 58.2s\tremaining: 4.18s\n",
            "933:\tlearn: 0.2732560\ttotal: 58.2s\tremaining: 4.12s\n",
            "934:\tlearn: 0.2732296\ttotal: 58.3s\tremaining: 4.05s\n",
            "935:\tlearn: 0.2732008\ttotal: 58.3s\tremaining: 3.99s\n",
            "936:\tlearn: 0.2731677\ttotal: 58.3s\tremaining: 3.92s\n",
            "937:\tlearn: 0.2731499\ttotal: 58.4s\tremaining: 3.86s\n",
            "938:\tlearn: 0.2731296\ttotal: 58.4s\tremaining: 3.79s\n",
            "939:\tlearn: 0.2730974\ttotal: 58.4s\tremaining: 3.73s\n",
            "940:\tlearn: 0.2730702\ttotal: 58.5s\tremaining: 3.67s\n",
            "941:\tlearn: 0.2730330\ttotal: 58.5s\tremaining: 3.6s\n",
            "942:\tlearn: 0.2730104\ttotal: 58.5s\tremaining: 3.54s\n",
            "943:\tlearn: 0.2729930\ttotal: 58.6s\tremaining: 3.47s\n",
            "944:\tlearn: 0.2729579\ttotal: 58.6s\tremaining: 3.41s\n",
            "945:\tlearn: 0.2729162\ttotal: 58.6s\tremaining: 3.35s\n",
            "946:\tlearn: 0.2728956\ttotal: 58.6s\tremaining: 3.28s\n",
            "947:\tlearn: 0.2728658\ttotal: 58.7s\tremaining: 3.22s\n",
            "948:\tlearn: 0.2728356\ttotal: 58.7s\tremaining: 3.15s\n",
            "949:\tlearn: 0.2728133\ttotal: 58.7s\tremaining: 3.09s\n",
            "950:\tlearn: 0.2727829\ttotal: 58.8s\tremaining: 3.03s\n",
            "951:\tlearn: 0.2727624\ttotal: 58.8s\tremaining: 2.96s\n",
            "952:\tlearn: 0.2727232\ttotal: 58.8s\tremaining: 2.9s\n",
            "953:\tlearn: 0.2726848\ttotal: 58.9s\tremaining: 2.84s\n",
            "954:\tlearn: 0.2726627\ttotal: 58.9s\tremaining: 2.77s\n",
            "955:\tlearn: 0.2726344\ttotal: 58.9s\tremaining: 2.71s\n",
            "956:\tlearn: 0.2725994\ttotal: 59s\tremaining: 2.65s\n",
            "957:\tlearn: 0.2725673\ttotal: 59s\tremaining: 2.59s\n",
            "958:\tlearn: 0.2725121\ttotal: 59s\tremaining: 2.52s\n",
            "959:\tlearn: 0.2724795\ttotal: 59.1s\tremaining: 2.46s\n",
            "960:\tlearn: 0.2724585\ttotal: 59.1s\tremaining: 2.4s\n",
            "961:\tlearn: 0.2724322\ttotal: 59.1s\tremaining: 2.33s\n",
            "962:\tlearn: 0.2724089\ttotal: 59.1s\tremaining: 2.27s\n",
            "963:\tlearn: 0.2723854\ttotal: 59.2s\tremaining: 2.21s\n",
            "964:\tlearn: 0.2723554\ttotal: 59.2s\tremaining: 2.15s\n",
            "965:\tlearn: 0.2723274\ttotal: 59.3s\tremaining: 2.08s\n",
            "966:\tlearn: 0.2723052\ttotal: 59.3s\tremaining: 2.02s\n",
            "967:\tlearn: 0.2722634\ttotal: 59.3s\tremaining: 1.96s\n",
            "968:\tlearn: 0.2722319\ttotal: 59.3s\tremaining: 1.9s\n",
            "969:\tlearn: 0.2721956\ttotal: 59.4s\tremaining: 1.84s\n",
            "970:\tlearn: 0.2721618\ttotal: 59.4s\tremaining: 1.77s\n",
            "971:\tlearn: 0.2721241\ttotal: 59.4s\tremaining: 1.71s\n",
            "972:\tlearn: 0.2720850\ttotal: 59.5s\tremaining: 1.65s\n",
            "973:\tlearn: 0.2720673\ttotal: 59.5s\tremaining: 1.59s\n",
            "974:\tlearn: 0.2720337\ttotal: 59.5s\tremaining: 1.53s\n",
            "975:\tlearn: 0.2720051\ttotal: 59.6s\tremaining: 1.46s\n",
            "976:\tlearn: 0.2719697\ttotal: 59.6s\tremaining: 1.4s\n",
            "977:\tlearn: 0.2719384\ttotal: 59.6s\tremaining: 1.34s\n",
            "978:\tlearn: 0.2719145\ttotal: 59.7s\tremaining: 1.28s\n",
            "979:\tlearn: 0.2718904\ttotal: 59.7s\tremaining: 1.22s\n",
            "980:\tlearn: 0.2718549\ttotal: 59.7s\tremaining: 1.16s\n",
            "981:\tlearn: 0.2718301\ttotal: 59.8s\tremaining: 1.09s\n",
            "982:\tlearn: 0.2718027\ttotal: 59.8s\tremaining: 1.03s\n",
            "983:\tlearn: 0.2717599\ttotal: 59.8s\tremaining: 973ms\n",
            "984:\tlearn: 0.2717246\ttotal: 59.9s\tremaining: 911ms\n",
            "985:\tlearn: 0.2717000\ttotal: 59.9s\tremaining: 850ms\n",
            "986:\tlearn: 0.2716623\ttotal: 59.9s\tremaining: 789ms\n",
            "987:\tlearn: 0.2716191\ttotal: 60s\tremaining: 728ms\n",
            "988:\tlearn: 0.2715787\ttotal: 60s\tremaining: 667ms\n",
            "989:\tlearn: 0.2715452\ttotal: 1m\tremaining: 606ms\n",
            "990:\tlearn: 0.2715073\ttotal: 1m\tremaining: 545ms\n",
            "991:\tlearn: 0.2714908\ttotal: 1m\tremaining: 485ms\n",
            "992:\tlearn: 0.2714555\ttotal: 1m\tremaining: 424ms\n",
            "993:\tlearn: 0.2714187\ttotal: 1m\tremaining: 363ms\n",
            "994:\tlearn: 0.2713886\ttotal: 1m\tremaining: 303ms\n",
            "995:\tlearn: 0.2713579\ttotal: 1m\tremaining: 242ms\n",
            "996:\tlearn: 0.2713189\ttotal: 1m\tremaining: 182ms\n",
            "997:\tlearn: 0.2712886\ttotal: 1m\tremaining: 121ms\n",
            "998:\tlearn: 0.2712479\ttotal: 1m\tremaining: 60.6ms\n",
            "999:\tlearn: 0.2712198\ttotal: 1m\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-19 14:40:08,772] A new study created in memory with name: no-name-aa1d4b3a-74ab-49e9-ab6c-ad6ab80e61c0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC Score: 0.8809326761080242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:40:45,569] Trial 0 finished with value: 0.8859901776407939 and parameters: {'iterations': 488, 'depth': 9, 'learning_rate': 0.02714390416524977, 'l2_leaf_reg': 0.090873736441082, 'scale_pos_weight': 5.7987014182014045}. Best is trial 0 with value: 0.8859901776407939.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:40:55,536] Trial 1 finished with value: 0.8857781447025125 and parameters: {'iterations': 309, 'depth': 4, 'learning_rate': 0.15276415660465986, 'l2_leaf_reg': 0.12368756605765797, 'scale_pos_weight': 9.097721528915736}. Best is trial 0 with value: 0.8859901776407939.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:41:18,383] Trial 2 finished with value: 0.8873346929301732 and parameters: {'iterations': 739, 'depth': 4, 'learning_rate': 0.024398492765395765, 'l2_leaf_reg': 2.6541471923440794, 'scale_pos_weight': 2.1659139705474413}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:41:26,030] Trial 3 finished with value: 0.88692806087298 and parameters: {'iterations': 166, 'depth': 8, 'learning_rate': 0.04509169653057858, 'l2_leaf_reg': 0.1499370768309006, 'scale_pos_weight': 5.236268359905678}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:41:41,744] Trial 4 finished with value: 0.8851821842159847 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.01608512134102425, 'l2_leaf_reg': 0.01050521803426844, 'scale_pos_weight': 2.6492438404353367}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:41:45,830] Trial 5 finished with value: 0.8845923783461838 and parameters: {'iterations': 125, 'depth': 7, 'learning_rate': 0.03201725578266625, 'l2_leaf_reg': 2.4511091352112904, 'scale_pos_weight': 0.7571359129142139}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:42:59,806] Trial 6 finished with value: 0.8609981528917688 and parameters: {'iterations': 608, 'depth': 10, 'learning_rate': 0.2051650442001501, 'l2_leaf_reg': 5.6809330726918335, 'scale_pos_weight': 4.313534236632846}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:43:36,378] Trial 7 finished with value: 0.8773838538170338 and parameters: {'iterations': 948, 'depth': 6, 'learning_rate': 0.186419755730956, 'l2_leaf_reg': 7.1144574654212285, 'scale_pos_weight': 7.929480054585406}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:44:27,840] Trial 8 finished with value: 0.8796157187347899 and parameters: {'iterations': 931, 'depth': 8, 'learning_rate': 0.06730025765146003, 'l2_leaf_reg': 0.7015137295088808, 'scale_pos_weight': 4.968162549724611}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:44:45,626] Trial 9 finished with value: 0.880664622486512 and parameters: {'iterations': 232, 'depth': 9, 'learning_rate': 0.08765284596210658, 'l2_leaf_reg': 0.11734479869267701, 'scale_pos_weight': 9.148001218161944}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:45:06,289] Trial 10 finished with value: 0.8841238531255251 and parameters: {'iterations': 669, 'depth': 4, 'learning_rate': 0.011353403271783453, 'l2_leaf_reg': 1.1790678148834006, 'scale_pos_weight': 0.5647132469177416}. Best is trial 2 with value: 0.8873346929301732.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:45:34,454] Trial 11 finished with value: 0.8875872404136987 and parameters: {'iterations': 758, 'depth': 6, 'learning_rate': 0.034916000558290874, 'l2_leaf_reg': 0.34367236309499066, 'scale_pos_weight': 2.9743274298357782}. Best is trial 11 with value: 0.8875872404136987.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:45:59,847] Trial 12 finished with value: 0.8878508990806566 and parameters: {'iterations': 780, 'depth': 5, 'learning_rate': 0.02341510649094464, 'l2_leaf_reg': 0.5137507185110416, 'scale_pos_weight': 2.731924010078604}. Best is trial 12 with value: 0.8878508990806566.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:46:30,780] Trial 13 finished with value: 0.8879547386052459 and parameters: {'iterations': 797, 'depth': 6, 'learning_rate': 0.01825669604811579, 'l2_leaf_reg': 0.42717954854004325, 'scale_pos_weight': 3.15150606072069}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:46:57,526] Trial 14 finished with value: 0.8873837764551451 and parameters: {'iterations': 827, 'depth': 5, 'learning_rate': 0.015002661690802893, 'l2_leaf_reg': 0.025153560960913975, 'scale_pos_weight': 3.776774126705571}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:47:15,287] Trial 15 finished with value: 0.8869679179517489 and parameters: {'iterations': 474, 'depth': 6, 'learning_rate': 0.020295753093854008, 'l2_leaf_reg': 0.4154733192376877, 'scale_pos_weight': 6.971475070355729}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:47:42,743] Trial 16 finished with value: 0.886603374706749 and parameters: {'iterations': 845, 'depth': 5, 'learning_rate': 0.010349199904698628, 'l2_leaf_reg': 1.1671128093293834, 'scale_pos_weight': 2.1319036564199907}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:48:02,053] Trial 17 finished with value: 0.887773668685359 and parameters: {'iterations': 564, 'depth': 5, 'learning_rate': 0.05398218200044108, 'l2_leaf_reg': 0.04360488133046937, 'scale_pos_weight': 1.5074598808029263}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:48:44,985] Trial 18 finished with value: 0.8499786787274655 and parameters: {'iterations': 993, 'depth': 7, 'learning_rate': 0.2973455130175915, 'l2_leaf_reg': 0.23173021586767376, 'scale_pos_weight': 3.696509793668288}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:49:01,365] Trial 19 finished with value: 0.8864106749354325 and parameters: {'iterations': 392, 'depth': 6, 'learning_rate': 0.016988884417137046, 'l2_leaf_reg': 0.6528482009262792, 'scale_pos_weight': 6.27360679123177}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:49:22,859] Trial 20 finished with value: 0.886538581385609 and parameters: {'iterations': 681, 'depth': 5, 'learning_rate': 0.09053634395299667, 'l2_leaf_reg': 0.05061101413029954, 'scale_pos_weight': 1.2086406818961386}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:49:51,194] Trial 21 finished with value: 0.8876068694405777 and parameters: {'iterations': 845, 'depth': 5, 'learning_rate': 0.0461348391046313, 'l2_leaf_reg': 0.048315882197038015, 'scale_pos_weight': 1.5715000146054094}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:50:10,009] Trial 22 finished with value: 0.8871590324983414 and parameters: {'iterations': 574, 'depth': 5, 'learning_rate': 0.05995470001769214, 'l2_leaf_reg': 0.2725719257530866, 'scale_pos_weight': 2.805106443585364}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:50:43,677] Trial 23 finished with value: 0.8870202121046752 and parameters: {'iterations': 769, 'depth': 7, 'learning_rate': 0.039033799373378024, 'l2_leaf_reg': 0.011062140303447316, 'scale_pos_weight': 0.2359118558115787}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:51:08,442] Trial 24 finished with value: 0.8878946096434889 and parameters: {'iterations': 651, 'depth': 6, 'learning_rate': 0.023001829931127826, 'l2_leaf_reg': 0.6041025117024408, 'scale_pos_weight': 3.535195507975982}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:51:34,175] Trial 25 finished with value: 0.887775089543464 and parameters: {'iterations': 676, 'depth': 6, 'learning_rate': 0.02231692134577335, 'l2_leaf_reg': 0.6364254950759597, 'scale_pos_weight': 3.8372927963869428}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:52:14,115] Trial 26 finished with value: 0.8876663811143659 and parameters: {'iterations': 904, 'depth': 7, 'learning_rate': 0.012020779996958924, 'l2_leaf_reg': 1.4339701031998222, 'scale_pos_weight': 4.60796300558078}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:52:38,294] Trial 27 finished with value: 0.887907181863533 and parameters: {'iterations': 636, 'depth': 6, 'learning_rate': 0.029320862040544713, 'l2_leaf_reg': 2.3524368580750967, 'scale_pos_weight': 3.118549888429223}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:53:05,292] Trial 28 finished with value: 0.8879508522478585 and parameters: {'iterations': 489, 'depth': 8, 'learning_rate': 0.029023663299592, 'l2_leaf_reg': 4.070054436981641, 'scale_pos_weight': 3.3763207107962514}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:53:33,348] Trial 29 finished with value: 0.8876492796808254 and parameters: {'iterations': 512, 'depth': 8, 'learning_rate': 0.030504571998962393, 'l2_leaf_reg': 3.082804793250434, 'scale_pos_weight': 5.791158026635767}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:54:09,009] Trial 30 finished with value: 0.8875239957913672 and parameters: {'iterations': 463, 'depth': 9, 'learning_rate': 0.01813732221259394, 'l2_leaf_reg': 4.626985342875101, 'scale_pos_weight': 4.338860195899699}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:54:36,447] Trial 31 finished with value: 0.887920469991517 and parameters: {'iterations': 626, 'depth': 7, 'learning_rate': 0.02812038544298119, 'l2_leaf_reg': 9.289295880931087, 'scale_pos_weight': 3.5670811480128255}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:54:58,612] Trial 32 finished with value: 0.8877935789617857 and parameters: {'iterations': 389, 'depth': 8, 'learning_rate': 0.02818948491402716, 'l2_leaf_reg': 8.259153828039336, 'scale_pos_weight': 3.0995488156540594}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:55:15,712] Trial 33 finished with value: 0.8865760277539685 and parameters: {'iterations': 381, 'depth': 7, 'learning_rate': 0.013091634570223352, 'l2_leaf_reg': 4.228228611621693, 'scale_pos_weight': 2.2906810772605914}. Best is trial 13 with value: 0.8879547386052459.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:55:57,090] Trial 34 finished with value: 0.887987575403095 and parameters: {'iterations': 607, 'depth': 8, 'learning_rate': 0.0388479919010372, 'l2_leaf_reg': 9.133553221075331, 'scale_pos_weight': 1.9795837925298871}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:56:27,899] Trial 35 finished with value: 0.8877048136824384 and parameters: {'iterations': 525, 'depth': 8, 'learning_rate': 0.041257600983421176, 'l2_leaf_reg': 9.351869648202513, 'scale_pos_weight': 2.148197786171586}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:57:00,098] Trial 36 finished with value: 0.8870897209214796 and parameters: {'iterations': 435, 'depth': 9, 'learning_rate': 0.03592066070464618, 'l2_leaf_reg': 9.642572385089613, 'scale_pos_weight': 5.407234404135575}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:57:39,582] Trial 37 finished with value: 0.8877782380773623 and parameters: {'iterations': 713, 'depth': 8, 'learning_rate': 0.026478996213717593, 'l2_leaf_reg': 1.7895594286405143, 'scale_pos_weight': 1.749634319626811}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:57:53,578] Trial 38 finished with value: 0.8875388508811172 and parameters: {'iterations': 299, 'depth': 7, 'learning_rate': 0.051442740511399306, 'l2_leaf_reg': 3.6056419171609764, 'scale_pos_weight': 0.8483131581916945}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:59:05,445] Trial 39 finished with value: 0.8775707496204099 and parameters: {'iterations': 604, 'depth': 10, 'learning_rate': 0.07874918299835283, 'l2_leaf_reg': 6.308106522211159, 'scale_pos_weight': 4.669720719122909}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 14:59:48,503] Trial 40 finished with value: 0.8873477071137924 and parameters: {'iterations': 547, 'depth': 9, 'learning_rate': 0.014420269187877602, 'l2_leaf_reg': 4.546429228016615, 'scale_pos_weight': 4.0706125231231685}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:00:15,588] Trial 41 finished with value: 0.8878175253518525 and parameters: {'iterations': 617, 'depth': 7, 'learning_rate': 0.029974234653632525, 'l2_leaf_reg': 2.025787008502013, 'scale_pos_weight': 3.317193785914755}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:00:51,334] Trial 42 finished with value: 0.8872957599570613 and parameters: {'iterations': 635, 'depth': 8, 'learning_rate': 0.01914300018337304, 'l2_leaf_reg': 2.630326573666722, 'scale_pos_weight': 9.703987967970686}. Best is trial 34 with value: 0.887987575403095.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:01:18,816] Trial 43 finished with value: 0.8882062743209176 and parameters: {'iterations': 727, 'depth': 6, 'learning_rate': 0.026023494985055833, 'l2_leaf_reg': 6.041821060019927, 'scale_pos_weight': 2.469363299768256}. Best is trial 43 with value: 0.8882062743209176.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:01:49,976] Trial 44 finished with value: 0.8879795177861811 and parameters: {'iterations': 722, 'depth': 7, 'learning_rate': 0.03507082582744476, 'l2_leaf_reg': 5.973018095945027, 'scale_pos_weight': 2.36893146374722}. Best is trial 43 with value: 0.8882062743209176.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:02:22,745] Trial 45 finished with value: 0.8874640421540038 and parameters: {'iterations': 740, 'depth': 7, 'learning_rate': 0.04263607871331479, 'l2_leaf_reg': 4.67773223285136, 'scale_pos_weight': 1.0674983137870673}. Best is trial 43 with value: 0.8882062743209176.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:03:06,309] Trial 46 finished with value: 0.8876828287340228 and parameters: {'iterations': 809, 'depth': 8, 'learning_rate': 0.02068189480274683, 'l2_leaf_reg': 6.125563160962102, 'scale_pos_weight': 2.3993820231785445}. Best is trial 43 with value: 0.8882062743209176.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:03:32,579] Trial 47 finished with value: 0.8878932801001722 and parameters: {'iterations': 694, 'depth': 6, 'learning_rate': 0.03619014930728654, 'l2_leaf_reg': 0.8685222336990067, 'scale_pos_weight': 1.777559853659408}. Best is trial 43 with value: 0.8882062743209176.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:03:59,153] Trial 48 finished with value: 0.8866614216913341 and parameters: {'iterations': 877, 'depth': 4, 'learning_rate': 0.11321462058064395, 'l2_leaf_reg': 5.885911242758013, 'scale_pos_weight': 2.6279283373165203}. Best is trial 43 with value: 0.8882062743209176.\n",
            "<ipython-input-83-835be0908da1>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-83-835be0908da1>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.01, 10.0),\n",
            "<ipython-input-83-835be0908da1>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 0.1, 10.0)\n",
            "[I 2024-02-19 15:04:42,085] Trial 49 finished with value: 0.8872313793787642 and parameters: {'iterations': 798, 'depth': 8, 'learning_rate': 0.03366148639388757, 'l2_leaf_reg': 7.138115925146208, 'scale_pos_weight': 1.8319533314633365}. Best is trial 43 with value: 0.8882062743209176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best AUC: 0.8882062743209176\n",
            "Best Hyperparameters: {'iterations': 727, 'depth': 6, 'learning_rate': 0.026023494985055833, 'l2_leaf_reg': 6.041821060019927, 'scale_pos_weight': 2.469363299768256}\n"
          ]
        }
      ]
    }
  ]
}